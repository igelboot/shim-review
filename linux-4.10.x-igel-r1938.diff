diff -Naurp -x debian.hwe linux-4.10.x.ori/arch/x86/kernel/pci-dma.c linux-4.10.x/arch/x86/kernel/pci-dma.c
--- linux-4.10.x.ori/arch/x86/kernel/pci-dma.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/arch/x86/kernel/pci-dma.c	2017-05-08 07:34:11.211503000 +0200
@@ -43,7 +43,8 @@ int iommu_detected __read_mostly = 0;
  * useful if a user wants to use an IOMMU only for KVM device assignment to
  * guests and not for driver dma translation.
  */
-int iommu_pass_through __read_mostly;
+/* gottwald@igel.com set this to 1 to fix serious problems with r8168 driver on AMD devices */
+int iommu_pass_through __read_mostly = 1;
 
 extern struct iommu_table_entry __iommu_table[], __iommu_table_end[];
 
diff -Naurp -x debian.hwe linux-4.10.x.ori/arch/x86/kernel/reboot.c linux-4.10.x/arch/x86/kernel/reboot.c
--- linux-4.10.x.ori/arch/x86/kernel/reboot.c	2017-05-03 11:18:05.164927000 +0200
+++ linux-4.10.x/arch/x86/kernel/reboot.c	2017-05-03 11:18:05.164927000 +0200
@@ -349,7 +349,17 @@ static struct dmi_system_id __initdata r
 		.matches = {
 			DMI_MATCH(DMI_SYS_VENDOR, "Dell Inc."),
 			DMI_MATCH(DMI_PRODUCT_NAME, "OptiPlex 760"),
-			DMI_MATCH(DMI_BOARD_NAME, "0G919G"),
+			/* lang@igel: fix reboot on other OptiPlex 760 devices */
+			/*DMI_MATCH(DMI_BOARD_NAME, "0G919G"),*/
+		},
+	},
+	/* lang@igel: fix reboot on  OptiPlex 755 devices */
+	{	/* Handle problems with rebooting on Dell OptiPlex 755 */
+		.callback = set_bios_reboot,
+		.ident = "Dell OptiPlex 755",
+		.matches = {
+			DMI_MATCH(DMI_SYS_VENDOR, "Dell Inc."),
+			DMI_MATCH(DMI_PRODUCT_NAME, "OptiPlex 755"),
 		},
 	},
 	{	/* Handle problems with rebooting on the OptiPlex 990. */
diff -Naurp -x debian.hwe linux-4.10.x.ori/Documentation/gpu/i915.rst linux-4.10.x/Documentation/gpu/i915.rst
--- linux-4.10.x.ori/Documentation/gpu/i915.rst	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/Documentation/gpu/i915.rst	2017-04-21 17:01:32.706015000 +0200
@@ -213,6 +213,15 @@ Video BIOS Table (VBT)
 .. kernel-doc:: drivers/gpu/drm/i915/intel_vbt_defs.h
    :internal:
 
+intel hdmi lpe audio support
+----------------------------
+
+.. kernel-doc:: drivers/gpu/drm/i915/intel_lpe_audio.c
+   :doc:  LPE Audio integration for HDMI or DP playback
+
+.. kernel-doc:: drivers/gpu/drm/i915/intel_lpe_audio.c
+   :internal:
+
 Memory Management and Command Submission
 ========================================
 
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/acpi/pci_root.c linux-4.10.x/drivers/acpi/pci_root.c
--- linux-4.10.x.ori/drivers/acpi/pci_root.c	2017-05-24 07:18:02.975911000 +0200
+++ linux-4.10.x/drivers/acpi/pci_root.c	2017-05-24 07:18:02.975911000 +0200
@@ -419,7 +419,10 @@ out:
 }
 EXPORT_SYMBOL(acpi_pci_osc_control_set);
 
-static void negotiate_os_control(struct acpi_pci_root *root, int *no_aspm)
+/* gottwald@igel.com leave clear_aspm as it is, remove cause problems with 
+ * Tuxedo laptop (network with r8168 not working) */
+static void negotiate_os_control(struct acpi_pci_root *root, int *no_aspm,
+				 int *clear_aspm)
 {
 	u32 support, control, requested;
 	acpi_status status;
@@ -490,12 +493,10 @@ static void negotiate_os_control(struct
 		decode_osc_control(root, "OS now controls", control);
 		if (acpi_gbl_FADT.boot_flags & ACPI_FADT_NO_ASPM) {
 			/*
-			 * We have ASPM control, but the FADT indicates that
-			 * it's unsupported. Leave existing configuration
-			 * intact and prevent the OS from touching it.
+			 * We have ASPM control, but the FADT indicates
+			 * that it's unsupported. Clear it.
 			 */
-			dev_info(&device->dev, "FADT indicates ASPM is unsupported, using BIOS configuration\n");
-			*no_aspm = 1;
+			*clear_aspm = 1;
 		}
 	} else {
 		decode_osc_control(root, "OS requested", requested);
@@ -522,7 +523,7 @@ static int acpi_pci_root_add(struct acpi
 	int result;
 	struct acpi_pci_root *root;
 	acpi_handle handle = device->handle;
-	int no_aspm = 0;
+	int no_aspm = 0, clear_aspm = 0;
 	bool hotadd = system_state != SYSTEM_BOOTING;
 
 	root = kzalloc(sizeof(struct acpi_pci_root), GFP_KERNEL);
@@ -581,7 +582,7 @@ static int acpi_pci_root_add(struct acpi
 
 	root->mcfg_addr = acpi_pci_root_get_mcfg_addr(handle);
 
-	negotiate_os_control(root, &no_aspm);
+	negotiate_os_control(root, &no_aspm, &clear_aspm);
 
 	/*
 	 * TBD: Need PCI interface for enumeration/configuration of roots.
@@ -604,6 +605,10 @@ static int acpi_pci_root_add(struct acpi
 		goto remove_dmar;
 	}
 
+	if (clear_aspm) {
+		dev_info(&device->dev, "Disabling ASPM (FADT indicates it is unsupported)\n");
+		pcie_clear_aspm(root->bus);
+	}
 	if (no_aspm)
 		pcie_no_aspm();
 
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/bcma/host_pci.c linux-4.10.x/drivers/bcma/host_pci.c
--- linux-4.10.x.ori/drivers/bcma/host_pci.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/bcma/host_pci.c	2017-04-10 11:27:25.836919000 +0200
@@ -286,6 +286,8 @@ static SIMPLE_DEV_PM_OPS(bcma_pm_ops, bc
 
 static const struct pci_device_id bcma_pci_bridge_tbl[] = {
 	{ PCI_DEVICE(PCI_VENDOR_ID_BROADCOM, 0x0576) },
+/*	The following devices are handled by WL (broadcom_sta kernel driver): */
+#if 0
 	{ PCI_DEVICE(PCI_VENDOR_ID_BROADCOM, 0x4313) },
 	{ PCI_DEVICE(PCI_VENDOR_ID_BROADCOM, 43224) },	/* 0xa8d8 */
 	{ PCI_DEVICE(PCI_VENDOR_ID_BROADCOM, 0x4331) },
@@ -304,6 +306,7 @@ static const struct pci_device_id bcma_p
 	{ PCI_DEVICE(PCI_VENDOR_ID_BROADCOM, 0x4727) },
 	{ PCI_DEVICE(PCI_VENDOR_ID_BROADCOM, 43227) },	/* 0xa8db, BCM43217 (sic!) */
 	{ PCI_DEVICE(PCI_VENDOR_ID_BROADCOM, 43228) },	/* 0xa8dc */
+#endif
 	{ 0, },
 };
 MODULE_DEVICE_TABLE(pci, bcma_pci_bridge_tbl);
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/firmware/efi/efi.c linux-4.10.x/drivers/firmware/efi/efi.c
--- linux-4.10.x.ori/drivers/firmware/efi/efi.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/firmware/efi/efi.c	2017-04-10 11:27:25.836919000 +0200
@@ -304,7 +304,7 @@ static int __init efisubsys_init(void)
 {
 	int error;
 
-	if (!efi_enabled(EFI_BOOT))
+	if (!efi_enabled(EFI_BOOT) || efi_runtime_disabled())
 		return 0;
 
 	/* We register the efi directory at /sys/firmware/efi */
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c linux-4.10.x/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
--- linux-4.10.x.ori/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c	2017-07-12 14:38:17.467676000 +0200
@@ -1027,6 +1027,7 @@ static int amdgpu_cs_submit(struct amdgp
 	cs->out.handle = amdgpu_ctx_add_fence(p->ctx, ring, p->fence);
 	job->uf_sequence = cs->out.handle;
 	amdgpu_job_free_resources(job);
+	amdgpu_cs_parser_fini(p, 0, true);
 
 	trace_amdgpu_cs_ioctl(job);
 	amd_sched_entity_push_job(&job->base);
@@ -1082,7 +1083,10 @@ int amdgpu_cs_ioctl(struct drm_device *d
 		goto out;
 
 	r = amdgpu_cs_submit(&parser, cs);
+	if (r)
+		goto out;
 
+	return 0;
 out:
 	amdgpu_cs_parser_fini(&parser, r, reserved_buffers);
 	return r;
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/gpu/drm/amd/amdgpu/amdgpu_device.c linux-4.10.x/drivers/gpu/drm/amd/amdgpu/amdgpu_device.c
--- linux-4.10.x.ori/drivers/gpu/drm/amd/amdgpu/amdgpu_device.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/gpu/drm/amd/amdgpu/amdgpu_device.c	2017-07-12 14:35:55.819839000 +0200
@@ -2226,12 +2226,24 @@ static int amdgpu_recover_vram_from_shad
        domain = amdgpu_mem_type_to_domain(bo->tbo.mem.mem_type);
        /* if bo has been evicted, then no need to recover */
        if (domain == AMDGPU_GEM_DOMAIN_VRAM) {
-               r = amdgpu_bo_restore_from_shadow(adev, ring, bo,
+		r = amdgpu_bo_validate(bo->shadow);
+		if (r) {
+			DRM_ERROR("bo validate failed!\n");
+			goto err;
+		}
+
+		r = amdgpu_ttm_bind(&bo->shadow->tbo, &bo->shadow->tbo.mem);
+		if (r) {
+			DRM_ERROR("%p bind failed\n", bo->shadow);
+			goto err;
+		}
+
+		r = amdgpu_bo_restore_from_shadow(adev, ring, bo,
 						 NULL, fence, true);
-               if (r) {
-                       DRM_ERROR("recover page table failed!\n");
-                       goto err;
-               }
+		if (r) {
+		       DRM_ERROR("recover page table failed!\n");
+		       goto err;
+		}
        }
 err:
        amdgpu_bo_unreserve(bo);
@@ -2333,6 +2345,7 @@ retry:
 			DRM_INFO("recover vram bo from shadow\n");
 			mutex_lock(&adev->shadow_list_lock);
 			list_for_each_entry_safe(bo, tmp, &adev->shadow_list, shadow_list) {
+				next = NULL;
 				amdgpu_recover_vram_from_shadow(adev, ring, bo, &next);
 				if (fence) {
 					r = dma_fence_wait(fence, false);
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/gpu/drm/amd/amdgpu/amdgpu_fb.c linux-4.10.x/drivers/gpu/drm/amd/amdgpu/amdgpu_fb.c
--- linux-4.10.x.ori/drivers/gpu/drm/amd/amdgpu/amdgpu_fb.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/gpu/drm/amd/amdgpu/amdgpu_fb.c	2017-04-10 11:27:25.836919000 +0200
@@ -360,7 +360,7 @@ int amdgpu_fbdev_init(struct amdgpu_devi
 		return 0;
 
 	/* select 8 bpp console on low vram cards */
-	if (adev->mc.real_vram_size <= (32*1024*1024))
+	if (adev->mc.real_vram_size <= (8*1024*1024))
 		bpp_sel = 8;
 
 	rfbdev = kzalloc(sizeof(struct amdgpu_fbdev), GFP_KERNEL);
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/gpu/drm/amd/amdgpu/amdgpu_gem.c linux-4.10.x/drivers/gpu/drm/amd/amdgpu/amdgpu_gem.c
--- linux-4.10.x.ori/drivers/gpu/drm/amd/amdgpu/amdgpu_gem.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/gpu/drm/amd/amdgpu/amdgpu_gem.c	2017-07-12 14:05:34.463130000 +0200
@@ -471,12 +471,15 @@ out:
 
 static int amdgpu_gem_va_check(void *param, struct amdgpu_bo *bo)
 {
-	unsigned domain = amdgpu_mem_type_to_domain(bo->tbo.mem.mem_type);
-
 	/* if anything is swapped out don't swap it in here,
 	   just abort and wait for the next CS */
+	if (!amdgpu_bo_gpu_accessible(bo))
+		return -ERESTARTSYS;
+
+	if (bo->shadow && !amdgpu_bo_gpu_accessible(bo->shadow))
+		return -ERESTARTSYS;
 
-	return domain == AMDGPU_GEM_DOMAIN_CPU ? -ERESTARTSYS : 0;
+	return 0;
 }
 
 /**
@@ -496,7 +499,6 @@ static void amdgpu_gem_va_update_vm(stru
 	struct amdgpu_bo_list_entry vm_pd;
 	struct ww_acquire_ctx ticket;
 	struct list_head list, duplicates;
-	unsigned domain;
 	int r;
 
 	INIT_LIST_HEAD(&list);
@@ -514,10 +516,14 @@ static void amdgpu_gem_va_update_vm(stru
 		goto error_print;
 
 	list_for_each_entry(entry, &list, head) {
-		domain = amdgpu_mem_type_to_domain(entry->bo->mem.mem_type);
+		struct amdgpu_bo *bo =
+			container_of(entry->bo, struct amdgpu_bo, tbo);
 		/* if anything is swapped out don't swap it in here,
 		   just abort and wait for the next CS */
-		if (domain == AMDGPU_GEM_DOMAIN_CPU)
+		if (!amdgpu_bo_gpu_accessible(bo))
+			goto error_unreserve;
+
+		if (bo->shadow && !amdgpu_bo_gpu_accessible(bo->shadow))
 			goto error_unreserve;
 	}
 	r = amdgpu_vm_validate_pt_bos(adev, bo_va->vm, amdgpu_gem_va_check,
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/gpu/drm/amd/amdgpu/amdgpu_object.c linux-4.10.x/drivers/gpu/drm/amd/amdgpu/amdgpu_object.c
--- linux-4.10.x.ori/drivers/gpu/drm/amd/amdgpu/amdgpu_object.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/gpu/drm/amd/amdgpu/amdgpu_object.c	2017-07-12 14:58:46.400789000 +0200
@@ -472,7 +472,15 @@ int amdgpu_bo_create(struct amdgpu_devic
 		return r;
 
 	if (amdgpu_need_backup(adev) && (flags & AMDGPU_GEM_CREATE_SHADOW)) {
+		if (!resv) {
+			r = ww_mutex_lock(&(*bo_ptr)->tbo.resv->lock, NULL);
+			WARN_ON(r != 0);
+		}
 		r = amdgpu_bo_create_shadow(adev, size, byte_align, (*bo_ptr));
+
+		if (!resv)
+			ww_mutex_unlock(&(*bo_ptr)->tbo.resv->lock);
+
 		if (r)
 			amdgpu_bo_unref(bo_ptr);
 	}
@@ -512,6 +520,27 @@ err:
 	return r;
 }
 
+int amdgpu_bo_validate(struct amdgpu_bo *bo)
+{
+	uint32_t domain;
+	int r;
+
+	if (bo->pin_count)
+		return 0;
+
+	domain = bo->prefered_domains;
+
+retry:
+	amdgpu_ttm_placement_from_domain(bo, domain);
+	r = ttm_bo_validate(&bo->tbo, &bo->placement, false, false);
+	if (unlikely(r == -ENOMEM) && domain != bo->allowed_domains) {
+		domain = bo->allowed_domains;
+		goto retry;
+	}
+
+	return r;
+}
+
 int amdgpu_bo_restore_from_shadow(struct amdgpu_device *adev,
 				  struct amdgpu_ring *ring,
 				  struct amdgpu_bo *bo,
@@ -849,6 +878,7 @@ int amdgpu_bo_get_metadata(struct amdgpu
 }
 
 void amdgpu_bo_move_notify(struct ttm_buffer_object *bo,
+			   bool evict,
 			   struct ttm_mem_reg *new_mem)
 {
 	struct amdgpu_device *adev = amdgpu_ttm_adev(bo->bdev);
@@ -861,6 +891,10 @@ void amdgpu_bo_move_notify(struct ttm_bu
 	abo = container_of(bo, struct amdgpu_bo, tbo);
 	amdgpu_vm_bo_invalidate(adev, abo);
 
+	/* remember the eviction */
+	if (evict)
+		atomic64_inc(&adev->num_evictions);
+
 	/* update statistics */
 	if (!new_mem)
 		return;
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/gpu/drm/amd/amdgpu/amdgpu_object.h linux-4.10.x/drivers/gpu/drm/amd/amdgpu/amdgpu_object.h
--- linux-4.10.x.ori/drivers/gpu/drm/amd/amdgpu/amdgpu_object.h	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/gpu/drm/amd/amdgpu/amdgpu_object.h	2017-07-12 14:58:46.400789000 +0200
@@ -114,6 +114,15 @@ static inline u64 amdgpu_bo_mmap_offset(
 	return drm_vma_node_offset_addr(&bo->tbo.vma_node);
 }
 
+/**
+ * amdgpu_bo_gpu_accessible - return whether the bo is currently in memory that
+ * is accessible to the GPU.
+ */
+static inline bool amdgpu_bo_gpu_accessible(struct amdgpu_bo *bo)
+{
+	return bo->tbo.mem.mem_type != TTM_PL_SYSTEM;
+}
+
 int amdgpu_bo_create(struct amdgpu_device *adev,
 			    unsigned long size, int byte_align,
 			    bool kernel, u32 domain, u64 flags,
@@ -155,7 +164,8 @@ int amdgpu_bo_get_metadata(struct amdgpu
 			   size_t buffer_size, uint32_t *metadata_size,
 			   uint64_t *flags);
 void amdgpu_bo_move_notify(struct ttm_buffer_object *bo,
-				  struct ttm_mem_reg *new_mem);
+			   bool evict,
+			   struct ttm_mem_reg *new_mem);
 int amdgpu_bo_fault_reserve_notify(struct ttm_buffer_object *bo);
 void amdgpu_bo_fence(struct amdgpu_bo *bo, struct dma_fence *fence,
 		     bool shared);
@@ -165,6 +175,7 @@ int amdgpu_bo_backup_to_shadow(struct am
 			       struct amdgpu_bo *bo,
 			       struct reservation_object *resv,
 			       struct dma_fence **fence, bool direct);
+int amdgpu_bo_validate(struct amdgpu_bo *bo);
 int amdgpu_bo_restore_from_shadow(struct amdgpu_device *adev,
 				  struct amdgpu_ring *ring,
 				  struct amdgpu_bo *bo,
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/gpu/drm/amd/amdgpu/amdgpu_ttm.c linux-4.10.x/drivers/gpu/drm/amd/amdgpu/amdgpu_ttm.c
--- linux-4.10.x.ori/drivers/gpu/drm/amd/amdgpu/amdgpu_ttm.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/gpu/drm/amd/amdgpu/amdgpu_ttm.c	2017-07-12 14:01:40.722720000 +0200
@@ -466,10 +466,6 @@ static int amdgpu_bo_move(struct ttm_buf
 
 	adev = amdgpu_ttm_adev(bo->bdev);
 
-	/* remember the eviction */
-	if (evict)
-		atomic64_inc(&adev->num_evictions);
-
 	if (old_mem->mem_type == TTM_PL_SYSTEM && bo->ttm == NULL) {
 		amdgpu_move_null(bo, new_mem);
 		return 0;
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/gpu/drm/drm_edid.c linux-4.10.x/drivers/gpu/drm/drm_edid.c
--- linux-4.10.x.ori/drivers/gpu/drm/drm_edid.c	2017-05-03 11:18:05.164927000 +0200
+++ linux-4.10.x/drivers/gpu/drm/drm_edid.c	2017-05-03 11:18:05.164927000 +0200
@@ -1254,9 +1254,15 @@ drm_do_probe_ddc_edid(void *data, u8 *bu
 		ret = i2c_transfer(adapter, &msgs[3 - xfers], xfers);
 
 		if (ret == -ENXIO) {
-			DRM_DEBUG_KMS("drm: skipping non-existent adapter %s\n",
-					adapter->name);
-			break;
+			/* gottwald@igel.com try a second time if getting a ENXIO 
+			 * this fix wrong detection on Lenovo ThinkCentre M32 */
+			if (retries <= 2) {
+				DRM_DEBUG_KMS("drm: skipping non-existent adapter %s\n",
+						adapter->name);
+				break;
+			} else {
+				retries = 2;
+			}
 		}
 	} while (ret != xfers && --retries);
 
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/gpu/drm/drm_fb_helper.c linux-4.10.x/drivers/gpu/drm/drm_fb_helper.c
--- linux-4.10.x.ori/drivers/gpu/drm/drm_fb_helper.c	2017-05-24 07:18:02.975911000 +0200
+++ linux-4.10.x/drivers/gpu/drm/drm_fb_helper.c	2017-05-24 07:18:02.975911000 +0200
@@ -1578,6 +1578,9 @@ static int drm_fb_helper_single_fb_probe
 
 	/* push down into drivers */
 	ret = (*fb_helper->funcs->fb_probe)(fb_helper, &sizes);
+
+	/* schneider@igel.com: call fb_probe() another time to allow the VGA to use the DVI modes if there is no VGA EDID found */
+ 	ret = (*fb_helper->funcs->fb_probe)(fb_helper, &sizes);
 	if (ret < 0)
 		return ret;
 
@@ -1945,6 +1948,78 @@ static int drm_get_tile_offsets(struct d
 	return 0;
 }
 
+/* schneider@igel.com: find a mode common to all connected displays with highest horizontal size */
+static bool drm_target_common_modes(struct drm_fb_helper *fb_helper,
+			      struct drm_display_mode **modes,
+			      bool *enabled, int width, int height)
+{
+	struct drm_fb_helper_connector *fb_helper_conn_a;
+	struct drm_fb_helper_connector *fb_helper_conn_b;
+    struct drm_display_mode *common_mode, *tmp1, *tmp2;
+	int i, j;
+    bool matches_found = false;
+ 
+	if (fb_helper->connector_count <= 1) {
+        return false;
+    }
+ 
+	for (i = 0; i < fb_helper->connector_count; i++) {
+		fb_helper_conn_a = fb_helper->connector_info[i];
+ 
+        if (enabled[i] == false)
+            continue;
+ 
+		modes[i] = drm_pick_cmdline_mode(fb_helper_conn_a, width, height);
+        if(modes[i]) {
+            continue;
+        }
+ 
+        common_mode = NULL;
+ 
+        for (j = 0; j < fb_helper->connector_count; j++) {
+            fb_helper_conn_b = fb_helper->connector_info[j];
+ 
+            if(i != j) {
+ 
+                if (enabled[j] == false)
+                    continue;
+ 
+                if (!list_empty(&fb_helper_conn_a->connector->modes) && !list_empty(&fb_helper_conn_b->connector->modes)) {
+                    list_for_each_entry(tmp1, &fb_helper_conn_a->connector->modes, head)
+                    {
+                        list_for_each_entry(tmp2, &fb_helper_conn_b->connector->modes, head)
+                        {
+                            if (drm_mode_equal(tmp1, tmp2))
+                            {
+                                DRM_DEBUG_KMS("connector #%d vs. connector #%d: %dx%d vs. %dx%d MATCH\n", i, j, tmp1->hdisplay, tmp1->vdisplay, tmp2->hdisplay, tmp2->vdisplay);
+                                if(common_mode) {
+                                    if(common_mode->hdisplay < tmp1->hdisplay) {
+                                        DRM_DEBUG_KMS("connector #%d vs. connector #%d: %dx%d vs. %dx%d SELECTED (OVERWRITTEN)\n", i, j, tmp1->hdisplay, tmp1->vdisplay, tmp2->hdisplay, tmp2->vdisplay);
+                                        common_mode = tmp1;
+                                    }
+                                } else {
+                                    DRM_DEBUG_KMS("connector #%d vs. connector #%d: %dx%d vs. %dx%d SELECTED\n", i, j, tmp1->hdisplay, tmp1->vdisplay, tmp2->hdisplay, tmp2->vdisplay);
+                                    common_mode = tmp1;
+                                }
+                            }
+                        }
+                    }
+                }
+            }
+        }
+ 
+        if(common_mode) {
+            modes[i] = common_mode;
+            matches_found = true;
+ 
+            DRM_DEBUG_KMS("found common mode for connector #%d: %s\n", i, modes[i] ? modes[i]->name :
+                    "none");
+        }
+    }
+ 
+	return matches_found;
+}
+
 static bool drm_target_preferred(struct drm_fb_helper *fb_helper,
 				 struct drm_display_mode **modes,
 				 struct drm_fb_offset *offsets,
@@ -2146,11 +2221,15 @@ static void drm_setup_crtcs(struct drm_f
 		memset(offsets, 0, fb_helper->connector_count*sizeof(offsets[0]));
 
 		if (!drm_target_cloned(fb_helper, modes, offsets,
-				       enabled, width, height) &&
-		    !drm_target_preferred(fb_helper, modes, offsets,
-					  enabled, width, height))
-			DRM_ERROR("Unable to find initial modes\n");
-
+				       enabled, width, height)) {
+			/* schneider@igel.com: check for common modes here */
+			if (!drm_target_common_modes(fb_helper, modes,
+						     enabled, width, height)) {
+			    if (!drm_target_preferred(fb_helper, modes, offsets,
+						  enabled, width, height))
+					DRM_ERROR("Unable to find initial modes\n");
+			}
+		}
 		DRM_DEBUG_KMS("picking CRTCs for %dx%d config\n",
 			      width, height);
 
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/gpu/drm/drm_ioctl.c linux-4.10.x/drivers/gpu/drm/drm_ioctl.c
--- linux-4.10.x.ori/drivers/gpu/drm/drm_ioctl.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/gpu/drm/drm_ioctl.c	2017-04-10 11:27:25.836919000 +0200
@@ -687,10 +687,18 @@ long drm_ioctl(struct file *filp,
 
 	drv_size = _IOC_SIZE(ioctl->cmd);
 	out_size = in_size = _IOC_SIZE(cmd);
-	if ((cmd & ioctl->cmd & IOC_IN) == 0)
-		in_size = 0;
-	if ((cmd & ioctl->cmd & IOC_OUT) == 0)
-		out_size = 0;
+	/* lang@igel: via uses wrong ioctl definitions */
+	if (strncmp(dev->driver->name, "via_chrome9", 11) == 0) {
+		if ((cmd & IOC_IN) == 0)
+			in_size = 0;
+		if ((cmd & IOC_OUT) == 0)
+			out_size = 0;
+	} else {
+		if ((cmd & ioctl->cmd & IOC_IN) == 0)
+			in_size = 0;
+		if ((cmd & ioctl->cmd & IOC_OUT) == 0)
+			out_size = 0;
+	}
 	ksize = max(max(in_size, out_size), drv_size);
 
 	DRM_DEBUG("pid=%d, dev=0x%lx, auth=%d, %s\n",
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/gpu/drm/i915/i915_drv.c linux-4.10.x/drivers/gpu/drm/i915/i915_drv.c
--- linux-4.10.x.ori/drivers/gpu/drm/i915/i915_drv.c	2017-05-03 11:18:05.164927000 +0200
+++ linux-4.10.x/drivers/gpu/drm/i915/i915_drv.c	2017-05-03 11:18:05.164927000 +0200
@@ -1137,7 +1137,8 @@ static void i915_driver_register(struct
 	if (IS_GEN5(dev_priv))
 		intel_gpu_ips_init(dev_priv);
 
-	i915_audio_component_init(dev_priv);
+	if (intel_lpe_audio_init(dev_priv) < 0)
+		i915_audio_component_init(dev_priv);
 
 	/*
 	 * Some ports require correctly set-up hpd registers for detection to
@@ -1155,7 +1156,10 @@ static void i915_driver_register(struct
  */
 static void i915_driver_unregister(struct drm_i915_private *dev_priv)
 {
-	i915_audio_component_cleanup(dev_priv);
+	if (HAS_LPE_AUDIO(dev_priv))
+		intel_lpe_audio_teardown(dev_priv);
+	else
+		i915_audio_component_cleanup(dev_priv);
 
 	intel_gpu_ips_teardown();
 	acpi_video_unregister();
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/gpu/drm/i915/i915_drv.h linux-4.10.x/drivers/gpu/drm/i915/i915_drv.h
--- linux-4.10.x.ori/drivers/gpu/drm/i915/i915_drv.h	2017-05-03 11:18:05.164927000 +0200
+++ linux-4.10.x/drivers/gpu/drm/i915/i915_drv.h	2017-11-16 16:11:18.239316000 +0100
@@ -79,6 +79,17 @@
 #define DRIVER_DATE		"20161121"
 #define DRIVER_TIMESTAMP	1479717903
 
+/* nagel@igel.com: define enum for IGEL platforms,
+ * that require special treatment. */
+enum igel_platforms {
+	NO_IGEL_PLATFORM = -1,
+	IGEL_H830C,
+	IGEL_TC215B
+};
+extern enum igel_platforms igel_platform;
+#define IS_IGEL_H830C (igel_platform==IGEL_H830C)
+#define IS_IGEL_TC215B (igel_platform==IGEL_TC215B)
+
 #undef WARN_ON
 /* Many gcc seem to no see through this and fall over :( */
 #if 0
@@ -1119,6 +1130,7 @@ enum intel_sbi_destination {
 #define QUIRK_BACKLIGHT_PRESENT (1<<3)
 #define QUIRK_PIPEB_FORCE (1<<4)
 #define QUIRK_PIN_SWIZZLED_PAGES (1<<5)
+#define QUIRK_SKIP_DP_DPMS_D3 (1<<15)
 
 struct intel_fbdev;
 struct intel_fbc_work;
@@ -2138,6 +2150,12 @@ struct drm_i915_private {
 	/* Used to save the pipe-to-encoder mapping for audio */
 	struct intel_encoder *av_enc_map[I915_MAX_PIPES];
 
+	/* necessary resource sharing with HDMI LPE audio driver. */
+	struct {
+		struct platform_device *platdev;
+		int	irq;
+	} lpe_audio;
+
 	/*
 	 * NOTE: This is the dri1/ums dungeon, don't add stuff here. Your patch
 	 * will be rejected. Instead look for a better place.
@@ -2627,6 +2645,8 @@ intel_info(const struct drm_i915_private
 
 #define HAS_POOLED_EU(dev_priv)	((dev_priv)->info.has_pooled_eu)
 
+#define HAS_LPE_AUDIO(dev_priv) ((dev_priv)->lpe_audio.platdev != NULL)
+
 #define INTEL_PCH_DEVICE_ID_MASK		0xff00
 #define INTEL_PCH_IBX_DEVICE_ID_TYPE		0x3b00
 #define INTEL_PCH_CPT_DEVICE_ID_TYPE		0x1c00
@@ -3385,6 +3405,15 @@ extern int i915_restore_state(struct drm
 void i915_setup_sysfs(struct drm_i915_private *dev_priv);
 void i915_teardown_sysfs(struct drm_i915_private *dev_priv);
 
+/* i915_lpe_audio.c */
+int  intel_lpe_audio_init(struct drm_i915_private *dev_priv);
+int  intel_lpe_audio_setup(struct drm_i915_private *dev_priv);
+void intel_lpe_audio_teardown(struct drm_i915_private *dev_priv);
+void intel_lpe_audio_irq_handler(struct drm_i915_private *dev_priv);
+bool intel_lpe_audio_detect(struct drm_i915_private *dev_priv);
+void intel_lpe_audio_notify(struct drm_i915_private *dev_priv,
+			void *eld, int port, int tmds_clk_speed);
+
 /* intel_i2c.c */
 extern int intel_setup_gmbus(struct drm_device *dev);
 extern void intel_teardown_gmbus(struct drm_device *dev);
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/gpu/drm/i915/i915_irq.c linux-4.10.x/drivers/gpu/drm/i915/i915_irq.c
--- linux-4.10.x.ori/drivers/gpu/drm/i915/i915_irq.c	2017-05-03 11:18:05.164927000 +0200
+++ linux-4.10.x/drivers/gpu/drm/i915/i915_irq.c	2017-05-03 11:18:05.164927000 +0200
@@ -1876,6 +1876,10 @@ static irqreturn_t valleyview_irq_handle
 		 * signalled in iir */
 		valleyview_pipestat_irq_ack(dev_priv, iir, pipe_stats);
 
+		if (iir & (I915_LPE_PIPE_A_INTERRUPT |
+			   I915_LPE_PIPE_B_INTERRUPT))
+			intel_lpe_audio_irq_handler(dev_priv);
+
 		/*
 		 * VLV_IIR is single buffered, and reflects the level
 		 * from PIPESTAT/PORT_HOTPLUG_STAT, hence clear it last.
@@ -1956,6 +1960,11 @@ static irqreturn_t cherryview_irq_handle
 		 * signalled in iir */
 		valleyview_pipestat_irq_ack(dev_priv, iir, pipe_stats);
 
+		if (iir & (I915_LPE_PIPE_A_INTERRUPT |
+			   I915_LPE_PIPE_B_INTERRUPT |
+			   I915_LPE_PIPE_C_INTERRUPT))
+			intel_lpe_audio_irq_handler(dev_priv);
+
 		/*
 		 * VLV_IIR is single buffered, and reflects the level
 		 * from PIPESTAT/PORT_HOTPLUG_STAT, hence clear it last.
@@ -2897,6 +2906,7 @@ static void vlv_display_irq_postinstall(
 	u32 pipestat_mask;
 	u32 enable_mask;
 	enum pipe pipe;
+	u32 val;
 
 	pipestat_mask = PLANE_FLIP_DONE_INT_STATUS_VLV |
 			PIPE_CRC_DONE_INTERRUPT_STATUS;
@@ -2913,6 +2923,12 @@ static void vlv_display_irq_postinstall(
 
 	WARN_ON(dev_priv->irq_mask != ~0);
 
+	val = (I915_LPE_PIPE_A_INTERRUPT |
+		I915_LPE_PIPE_B_INTERRUPT |
+		I915_LPE_PIPE_C_INTERRUPT);
+
+	enable_mask |= val;
+
 	dev_priv->irq_mask = ~enable_mask;
 
 	GEN5_IRQ_INIT(VLV_, dev_priv->irq_mask, enable_mask);
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/gpu/drm/i915/i915_params.c linux-4.10.x/drivers/gpu/drm/i915/i915_params.c
--- linux-4.10.x.ori/drivers/gpu/drm/i915/i915_params.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/gpu/drm/i915/i915_params.c	2017-07-26 16:34:30.459536000 +0200
@@ -40,7 +40,10 @@ struct i915_params i915 __read_mostly =
 	.enable_ppgtt = -1,
 	.enable_psr = -1,
 	.alpha_support = IS_ENABLED(CONFIG_DRM_I915_ALPHA_SUPPORT),
-	.disable_power_well = -1,
+	/* gottwald@igel.com set default to not disable the powerwell per default because
+	 * there are some devices with non standard backlight controller (DLOG for example)
+	 * which do not switch on the backlight after a dpms (powerwell disabled) */
+	.disable_power_well = 0,
 	.enable_ips = 1,
 	.fastboot = 0,
 	.prefault_disable = 0,
@@ -63,8 +66,29 @@ struct i915_params i915 __read_mostly =
 	.inject_load_failure = 0,
 	.enable_dpcd_backlight = false,
 	.enable_gvt = false,
+	.igel_platform_string = "",
+	.lvds_enable = 1,
+	.tv_enable = 1,
+	.edp_is_dp = false,
 };
 
+/* nagel@igel.com: Provide a string specifying the IGEL hardware platform 
+ * should not be required anymore due to detection via DMI */
+module_param_named(igel_platform, i915.igel_platform_string, charp, 0000);
+MODULE_PARM_DESC(igel_platform, "Specify IGEL platform for IGEL specific tweaks");
+
+/* gottwald@igel.com: sometimes a dp is wrongly detected as edp which makes
+ * problems with hotplug. Try to determine this automatically failed so
+ * added module param to fix this. */
+module_param_named(edp_is_dp, i915.edp_is_dp, bool, 0444);
+MODULE_PARM_DESC(lvds, "eDP is DP (0 = disable, 1 = edp is dp)");
+
+module_param_named(lvds, i915.lvds_enable, int, 0444);
+MODULE_PARM_DESC(lvds, "LVDS enable (0 = disable)");
+
+module_param_named(tv, i915.tv_enable, int, 0444);
+MODULE_PARM_DESC(tv, "TV enable (0 = disable)");
+
 module_param_named(modeset, i915.modeset, int, 0400);
 MODULE_PARM_DESC(modeset,
 	"Use kernel modesetting [KMS] (0=disable, "
@@ -153,7 +177,7 @@ MODULE_PARM_DESC(alpha_support,
 module_param_named_unsafe(disable_power_well, i915.disable_power_well, int, 0400);
 MODULE_PARM_DESC(disable_power_well,
 	"Disable display power wells when possible "
-	"(-1=auto [default], 0=power wells always on, 1=power wells disabled when possible)");
+	"(-1=auto, 0=power wells always on [default], 1=power wells disabled when possible)");
 
 module_param_named_unsafe(enable_ips, i915.enable_ips, int, 0600);
 MODULE_PARM_DESC(enable_ips, "Enable IPS (default: true)");
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/gpu/drm/i915/i915_params.h linux-4.10.x/drivers/gpu/drm/i915/i915_params.h
--- linux-4.10.x.ori/drivers/gpu/drm/i915/i915_params.h	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/gpu/drm/i915/i915_params.h	2017-07-26 16:34:30.459536000 +0200
@@ -66,6 +66,10 @@ struct i915_params {
 	bool enable_dp_mst;
 	bool enable_dpcd_backlight;
 	bool enable_gvt;
+	unsigned int lvds_enable;
+	unsigned int tv_enable;
+	char *igel_platform_string;
+	bool edp_is_dp;
 };
 
 extern struct i915_params i915 __read_mostly;
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/gpu/drm/i915/i915_pci.c linux-4.10.x/drivers/gpu/drm/i915/i915_pci.c
--- linux-4.10.x.ori/drivers/gpu/drm/i915/i915_pci.c	2017-05-03 11:18:05.164927000 +0200
+++ linux-4.10.x/drivers/gpu/drm/i915/i915_pci.c	2017-05-03 11:18:05.164927000 +0200
@@ -27,6 +27,9 @@
 #include <linux/vga_switcheroo.h>
 
 #include "i915_drv.h"
+#include <linux/dmi.h>
+
+enum igel_platforms igel_platform = NO_IGEL_PLATFORM;
 
 #define GEN_DEFAULT_PIPEOFFSETS \
 	.pipe_offsets = { PIPE_A_OFFSET, PIPE_B_OFFSET, \
@@ -485,6 +488,22 @@ static struct pci_driver i915_pci_driver
 static int __init i915_init(void)
 {
 	bool use_kms = true;
+	const char *product;
+
+	product = dmi_get_system_info(DMI_PRODUCT_NAME);
+	
+	igel_platform = NO_IGEL_PLATFORM;
+
+	/* Assign IGEL platform enum value based on module parameter string */
+	if (!strcmp(i915.igel_platform_string, "IGEL_H830C")) {
+		igel_platform = IGEL_H830C;
+	} else if (product != NULL) {
+		/* gottwald@igel.com Detect IGEL platform according to the DMI data */
+		if (strstr(product, "TC215B"))
+			igel_platform = IGEL_TC215B;
+		else if (strstr(product, "H830C"))
+			igel_platform = IGEL_H830C;
+	}
 
 	/*
 	 * Enable KMS by default, unless explicitly overriden by
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/gpu/drm/i915/i915_reg.h linux-4.10.x/drivers/gpu/drm/i915/i915_reg.h
--- linux-4.10.x.ori/drivers/gpu/drm/i915/i915_reg.h	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/gpu/drm/i915/i915_reg.h	2017-04-21 17:01:32.706015000 +0200
@@ -2058,6 +2058,9 @@ enum skl_disp_power_wells {
 #define I915_ASLE_INTERRUPT				(1<<0)
 #define I915_BSD_USER_INTERRUPT				(1<<25)
 
+#define I915_HDMI_LPE_AUDIO_BASE	(VLV_DISPLAY_BASE + 0x65000)
+#define I915_HDMI_LPE_AUDIO_SIZE	0x1000
+
 #define GEN6_BSD_RNCID			_MMIO(0x12198)
 
 #define GEN7_FF_THREAD_MODE		_MMIO(0x20a0)
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/gpu/drm/i915/i915_suspend.c linux-4.10.x/drivers/gpu/drm/i915/i915_suspend.c
--- linux-4.10.x.ori/drivers/gpu/drm/i915/i915_suspend.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/gpu/drm/i915/i915_suspend.c	2017-04-10 11:27:25.836919000 +0200
@@ -64,6 +64,8 @@ int i915_save_state(struct drm_device *d
 
 	mutex_lock(&dev->struct_mutex);
 
+	intel_sdvo_save(dev); /* schneider@igel.com: SDVO state save */
+
 	i915_save_display(dev_priv);
 
 	if (IS_GEN4(dev_priv))
@@ -110,6 +112,8 @@ int i915_restore_state(struct drm_device
 
 	mutex_lock(&dev->struct_mutex);
 
+	intel_sdvo_restore(dev); /* schneider@igel.com: SDVO state restore */
+
 	i915_gem_restore_fences(dev_priv);
 
 	if (IS_GEN4(dev_priv))
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/gpu/drm/i915/intel_audio.c linux-4.10.x/drivers/gpu/drm/i915/intel_audio.c
--- linux-4.10.x.ori/drivers/gpu/drm/i915/intel_audio.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/gpu/drm/i915/intel_audio.c	2017-11-17 07:36:01.998407000 +0100
@@ -24,6 +24,7 @@
 #include <linux/kernel.h>
 #include <linux/component.h>
 #include <drm/i915_component.h>
+#include <drm/intel_lpe_audio.h>
 #include "intel_drv.h"
 
 #include <drm/drmP.h>
@@ -605,11 +606,6 @@ void intel_audio_codec_enable(struct int
 			 connector->encoder->base.id,
 			 connector->encoder->name);
 
-	/* ELD Conn_Type */
-	connector->eld[5] &= ~(3 << 2);
-	if (intel_crtc_has_dp_encoder(crtc_state))
-		connector->eld[5] |= (1 << 2);
-
 	connector->eld[6] = drm_av_sync_delay(connector, adjusted_mode) / 2;
 
 	if (dev_priv->display.audio_codec_enable)
@@ -630,6 +626,10 @@ void intel_audio_codec_enable(struct int
 	if (acomp && acomp->audio_ops && acomp->audio_ops->pin_eld_notify)
 		acomp->audio_ops->pin_eld_notify(acomp->audio_ops->audio_ptr,
 						 (int) port, (int) pipe);
+
+	if (HAS_LPE_AUDIO(dev_priv))
+		intel_lpe_audio_notify(dev_priv, connector->eld, port,
+			crtc_state->port_clock);
 }
 
 /**
@@ -663,6 +663,9 @@ void intel_audio_codec_disable(struct in
 	if (acomp && acomp->audio_ops && acomp->audio_ops->pin_eld_notify)
 		acomp->audio_ops->pin_eld_notify(acomp->audio_ops->audio_ptr,
 						 (int) port, (int) pipe);
+
+	if (HAS_LPE_AUDIO(dev_priv))
+		intel_lpe_audio_notify(dev_priv, NULL, port, 0);
 }
 
 /**
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/gpu/drm/i915/intel_display.c linux-4.10.x/drivers/gpu/drm/i915/intel_display.c
--- linux-4.10.x.ori/drivers/gpu/drm/i915/intel_display.c	2017-05-03 11:18:05.164927000 +0200
+++ linux-4.10.x/drivers/gpu/drm/i915/intel_display.c	2017-11-16 16:11:18.239316000 +0100
@@ -15534,6 +15534,25 @@ static void intel_setup_outputs(struct d
 
 		if (I915_READ(PCH_DP_D) & DP_DETECTED)
 			intel_dp_init(dev, PCH_DP_D, PORT_D);
+	} else if (IS_VALLEYVIEW(dev_priv) && IS_IGEL_H830C) {
+		/* nagel@igel.com:
+		 * On IGEL_H830C board, the DVI connector is init'd first and will get
+		 * numbered as 'HDMI1', as the DVI/DisplayPort connectors on the PCB are switched.
+		 * Because the DVI connector of the H820C got numbered as 'HDMI2',
+		 * this may cause switched monitors when migrating from a H820C to a H830C,
+		 * while using a dual-monitor setup.
+		 */
+		if (I915_READ(VLV_HDMIC) & SDVO_DETECTED) {
+			intel_hdmi_init(dev, VLV_HDMIC,	PORT_C);
+			if (I915_READ(VLV_DP_C) & DP_DETECTED)
+				intel_dp_init(dev, VLV_DP_C, PORT_C);
+		}
+
+		if (I915_READ(VLV_HDMIB) & SDVO_DETECTED) {
+			intel_hdmi_init(dev, VLV_HDMIB, PORT_B);
+			if (I915_READ(VLV_DP_B) & DP_DETECTED)
+				intel_dp_init(dev, VLV_DP_B, PORT_B);
+		}
 	} else if (IS_VALLEYVIEW(dev_priv) || IS_CHERRYVIEW(dev_priv)) {
 		bool has_edp, has_port;
 
@@ -16160,6 +16179,16 @@ static void quirk_backlight_present(stru
 	DRM_INFO("applying backlight present quirk\n");
 }
 
+/* Dell Wyse 3040 doesn't work well with some Dell monitors (E-series).
+ * Workaround this by skipping DP DPMS D3 transition.
+ */
+static void quirk_disable_dp_dpms_d3(struct drm_device *dev)
+{
+	struct drm_i915_private *dev_priv = to_i915(dev);
+	dev_priv->quirks |= QUIRK_SKIP_DP_DPMS_D3;
+	DRM_INFO("Applying Wyse 3040 quirk\n");
+}
+
 struct intel_quirk {
 	int device;
 	int subsystem_vendor;
@@ -16255,6 +16284,9 @@ static struct intel_quirk intel_quirks[]
 
 	/* Dell Chromebook 11 (2015 version) */
 	{ 0x0a16, 0x1028, 0x0a35, quirk_backlight_present },
+
+	/* Dell Wyse 3040 */
+	{ 0x22b0, 0x1028, 0x07c1, quirk_disable_dp_dpms_d3 },
 };
 
 static void intel_init_quirks(struct drm_device *dev)
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/gpu/drm/i915/intel_dp.c linux-4.10.x/drivers/gpu/drm/i915/intel_dp.c
--- linux-4.10.x.ori/drivers/gpu/drm/i915/intel_dp.c	2017-04-21 13:47:09.278670000 +0200
+++ linux-4.10.x/drivers/gpu/drm/i915/intel_dp.c	2017-11-16 16:12:29.499622000 +0100
@@ -41,6 +41,8 @@
 
 #define DP_LINK_CHECK_TIMEOUT	(10 * 1000)
 
+static void intel_dp_set_edid(struct intel_dp *intel_dp);
+
 /* Compliance test status bits  */
 #define INTEL_DP_RESOLUTION_SHIFT_MASK	0
 #define INTEL_DP_RESOLUTION_PREFERRED	(1 << INTEL_DP_RESOLUTION_SHIFT_MASK)
@@ -2570,7 +2572,8 @@ static void intel_disable_dp(struct inte
 	 * ensure that we have vdd while we switch off the panel. */
 	intel_edp_panel_vdd_on(intel_dp);
 	intel_edp_backlight_off(intel_dp);
-	intel_dp_sink_dpms(intel_dp, DRM_MODE_DPMS_OFF);
+	if (!(dev_priv->quirks & QUIRK_SKIP_DP_DPMS_D3))
+		intel_dp_sink_dpms(intel_dp, DRM_MODE_DPMS_OFF);
 	intel_edp_panel_off(intel_dp);
 
 	/* disable the port before the pipe on g4x */
@@ -2772,7 +2775,16 @@ static void intel_enable_dp(struct intel
 	intel_dp_start_link_train(intel_dp);
 	intel_dp_stop_link_train(intel_dp);
 
-	if (pipe_config->has_audio) {
+	/* gottwald@igel.com workaround for DP audio problems */
+
+	if (!crtc->config->has_audio) {
+		intel_dp_set_edid(intel_dp);
+		if (encoder->base.crtc && intel_dp->has_audio) {
+			intel_crtc_restore_mode(encoder->base.crtc);
+		}
+	}
+
+	if (pipe_config->has_audio || intel_dp->has_audio) {
 		DRM_DEBUG_DRIVER("Enabling DP audio on pipe %c\n",
 				 pipe_name(pipe));
 		intel_audio_codec_enable(encoder, pipe_config, conn_state);
@@ -4359,18 +4371,33 @@ intel_dp_long_pulse(struct intel_connect
 	enum drm_connector_status status;
 	enum intel_display_power_domain power_domain;
 	u8 sink_irq_vector = 0;
+	bool stat = true;
 
 	power_domain = intel_display_port_aux_power_domain(intel_encoder);
 	intel_display_power_get(to_i915(dev), power_domain);
 
 	/* Can't disconnect eDP, but you can close the lid... */
-	if (is_edp(intel_dp))
+	if (is_edp(intel_dp)) {
 		status = edp_detect(intel_dp);
-	else if (intel_digital_port_connected(to_i915(dev),
-					      dp_to_dig_port(intel_dp)))
-		status = intel_dp_detect_dpcd(intel_dp);
-	else
-		status = connector_status_disconnected;
+	} else {
+		stat = intel_digital_port_connected(to_i915(dev),
+						    dp_to_dig_port(intel_dp));
+
+		/* gottwald@igel.com some monitors (Samsung U28D590D) took some time after
+		 * a DPMS OFF/ON event before ibx_digital_port_connected is working again.
+		 * The detect workaround is set if the DP link train was sucessful.
+		 * So if detect_workaround is set and detect_workaround_timestamp is less
+		 * then 900 ms from now do not use ibx_digital_port_connected result
+		 */
+		if (stat)
+			status = intel_dp_detect_dpcd(intel_dp);
+		else if (intel_dp->detect_workaround == true &&
+			 ktime_to_ms(ktime_sub(ktime_get(), intel_dp->detect_workaround_timestamp)) <= 900)
+			status = intel_dp_detect_dpcd(intel_dp);
+		else
+			status = connector_status_disconnected;
+	}
+	intel_dp->detect_workaround = false;
 
 	if (status == connector_status_disconnected) {
 		intel_dp->compliance_test_active = 0;
@@ -4879,7 +4906,9 @@ bool intel_dp_is_edp(struct drm_i915_pri
 	if (INTEL_GEN(dev_priv) < 5)
 		return false;
 
-	if (port == PORT_A)
+	/* gottwald@igel.com this is somehow anoying this seems not to be handled correctly */
+	
+	if ((INTEL_GEN(dev_priv) < 9 || i915.edp_is_dp == 0) && port == PORT_A)
 		return true;
 
 	return intel_bios_is_port_edp(dev_priv, port);
@@ -5768,6 +5797,11 @@ intel_dp_init_connector(struct intel_dig
 		intel_dp_mst_encoder_init(intel_dig_port,
 					  intel_connector->base.base.id);
 
+	/* gottwald@igel.com init dp detect workaround */
+
+	intel_dp->detect_workaround = false;
+	intel_dp->detect_workaround_timestamp = ktime_get();
+
 	if (!intel_edp_init_connector(intel_dp, intel_connector)) {
 		intel_dp_aux_fini(intel_dp);
 		intel_dp_mst_encoder_cleanup(intel_dig_port);
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/gpu/drm/i915/intel_dp_link_training.c linux-4.10.x/drivers/gpu/drm/i915/intel_dp_link_training.c
--- linux-4.10.x.ori/drivers/gpu/drm/i915/intel_dp_link_training.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/gpu/drm/i915/intel_dp_link_training.c	2017-04-10 11:27:25.836919000 +0200
@@ -314,5 +314,12 @@ void
 intel_dp_start_link_train(struct intel_dp *intel_dp)
 {
 	intel_dp_link_training_clock_recovery(intel_dp);
-	intel_dp_link_training_channel_equalization(intel_dp);
+	if (intel_dp_link_training_channel_equalization(intel_dp)) {
+		/* gottwald@igel.com some monitors (Samsung U28D590D) took some time after
+		 * a DPMS OFF/ON event before ibx_digital_port_connected is working again.
+		 * The detect workaround is set if the DP link train was sucessful. */
+
+		intel_dp->detect_workaround = true;
+		intel_dp->detect_workaround_timestamp = ktime_get();
+	}
 }
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/gpu/drm/i915/intel_drv.h linux-4.10.x/drivers/gpu/drm/i915/intel_drv.h
--- linux-4.10.x.ori/drivers/gpu/drm/i915/intel_drv.h	2017-04-21 13:47:09.278670000 +0200
+++ linux-4.10.x/drivers/gpu/drm/i915/intel_drv.h	2017-04-21 13:47:09.278670000 +0200
@@ -940,6 +940,10 @@ struct intel_dp {
 	/* connector directly attached - won't be use for modeset in mst world */
 	struct intel_connector *attached_connector;
 
+	/* gottwald@igel.com variables for DPMS OFF/ON workaround */
+	bool detect_workaround;
+	ktime_t detect_workaround_timestamp;
+
 	/* mst connector list */
 	struct intel_dp_mst_encoder *mst_encoders[I915_MAX_PIPES];
 	struct drm_dp_mst_topology_mgr mst_mgr;
@@ -1817,6 +1821,9 @@ int intel_atomic_setup_scalers(struct dr
 	struct intel_crtc *intel_crtc,
 	struct intel_crtc_state *crtc_state);
 
+extern void intel_sdvo_save(struct drm_device *dev); /* schneider@igel.com: SDVO suspend helper */
+extern void intel_sdvo_restore(struct drm_device *dev); /* schneider@igel.com: SDVO resume helper */
+
 /* intel_atomic_plane.c */
 struct intel_plane_state *intel_create_plane_state(struct drm_plane *plane);
 struct drm_plane_state *intel_plane_duplicate_state(struct drm_plane *plane);
@@ -1833,4 +1840,5 @@ void intel_color_load_luts(struct drm_cr
 /* intel_lspcon.c */
 bool lspcon_init(struct intel_digital_port *intel_dig_port);
 void lspcon_resume(struct intel_lspcon *lspcon);
+
 #endif /* __INTEL_DRV_H__ */
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/gpu/drm/i915/intel_hdmi.c linux-4.10.x/drivers/gpu/drm/i915/intel_hdmi.c
--- linux-4.10.x.ori/drivers/gpu/drm/i915/intel_hdmi.c	2017-05-03 11:18:05.164927000 +0200
+++ linux-4.10.x/drivers/gpu/drm/i915/intel_hdmi.c	2017-05-03 11:18:05.164927000 +0200
@@ -36,6 +36,7 @@
 #include <drm/drm_edid.h>
 #include "intel_drv.h"
 #include <drm/i915_drm.h>
+#include <drm/intel_lpe_audio.h>
 #include "i915_drv.h"
 
 static struct drm_device *intel_hdmi_to_dev(struct intel_hdmi *intel_hdmi)
@@ -1461,6 +1462,13 @@ intel_hdmi_dp_dual_mode_detect(struct dr
 		      hdmi->dp_dual_mode.max_tmds_clock);
 }
 
+/* 
+ * lang@igel: 
+ * fix DVI Monitor detection on H830 DVI-I port, if a dvi dual link 
+ * cable is used together with a dvi dual link capable monitor 
+ */
+static int igel_hdmi_fix = 1;
+
 static bool
 intel_hdmi_set_edid(struct drm_connector *connector)
 {
@@ -1475,6 +1483,19 @@ intel_hdmi_set_edid(struct drm_connector
 			    intel_gmbus_get_adapter(dev_priv,
 			    intel_hdmi->ddc_bus));
 
+	/* 
+	 * lang@igel: 
+	 * fix DVI Monitor detection on H830 DVI-I port, if a dvi dual link 
+	 * cable is used together with a dvi dual link capable monitor 
+	 */
+	if (igel_hdmi_fix) {
+		if (! edid)
+			edid = drm_get_edid(connector,
+			    intel_gmbus_get_adapter(dev_priv,
+						    intel_hdmi->ddc_bus));
+		igel_hdmi_fix = 0;
+	}
+
 	intel_hdmi_dp_dual_mode_detect(connector, edid != NULL);
 
 	intel_display_power_put(dev_priv, POWER_DOMAIN_GMBUS);
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/gpu/drm/i915/intel_lpe_audio.c linux-4.10.x/drivers/gpu/drm/i915/intel_lpe_audio.c
--- linux-4.10.x.ori/drivers/gpu/drm/i915/intel_lpe_audio.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-4.10.x/drivers/gpu/drm/i915/intel_lpe_audio.c	2017-04-21 17:01:32.706015000 +0200
@@ -0,0 +1,389 @@
+/*
+ * Copyright © 2016 Intel Corporation
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the next
+ * paragraph) shall be included in all copies or substantial portions of the
+ * Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+ * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
+ * IN THE SOFTWARE.
+ *
+ * Authors:
+ *    Pierre-Louis Bossart <pierre-louis.bossart@linux.intel.com>
+ *    Jerome Anand <jerome.anand@intel.com>
+ *    based on VED patches
+ *
+ */
+
+/**
+ * DOC: LPE Audio integration for HDMI or DP playback
+ *
+ * Motivation:
+ * Atom platforms (e.g. valleyview and cherryTrail) integrates a DMA-based
+ * interface as an alternative to the traditional HDaudio path. While this
+ * mode is unrelated to the LPE aka SST audio engine, the documentation refers
+ * to this mode as LPE so we keep this notation for the sake of consistency.
+ *
+ * The interface is handled by a separate standalone driver maintained in the
+ * ALSA subsystem for simplicity. To minimize the interaction between the two
+ * subsystems, a bridge is setup between the hdmi-lpe-audio and i915:
+ * 1. Create a platform device to share MMIO/IRQ resources
+ * 2. Make the platform device child of i915 device for runtime PM.
+ * 3. Create IRQ chip to forward the LPE audio irqs.
+ * the hdmi-lpe-audio driver probes the lpe audio device and creates a new
+ * sound card
+ *
+ * Threats:
+ * Due to the restriction in Linux platform device model, user need manually
+ * uninstall the hdmi-lpe-audio driver before uninstalling i915 module,
+ * otherwise we might run into use-after-free issues after i915 removes the
+ * platform device: even though hdmi-lpe-audio driver is released, the modules
+ * is still in "installed" status.
+ *
+ * Implementation:
+ * The MMIO/REG platform resources are created according to the registers
+ * specification.
+ * When forwarding LPE audio irqs, the flow control handler selection depends
+ * on the platform, for example on valleyview handle_simple_irq is enough.
+ *
+ */
+
+#include <linux/acpi.h>
+#include <linux/device.h>
+#include <linux/pci.h>
+
+#include "i915_drv.h"
+#include <linux/delay.h>
+#include <drm/intel_lpe_audio.h>
+
+static struct platform_device *
+lpe_audio_platdev_create(struct drm_i915_private *dev_priv)
+{
+	int ret;
+	struct drm_device *dev = &dev_priv->drm;
+	struct platform_device_info pinfo = {};
+	struct resource *rsc;
+	struct platform_device *platdev;
+	struct intel_hdmi_lpe_audio_pdata *pdata;
+
+	pdata = kzalloc(sizeof(*pdata), GFP_KERNEL);
+	if (!pdata)
+		return ERR_PTR(-ENOMEM);
+
+	rsc = kcalloc(2, sizeof(*rsc), GFP_KERNEL);
+	if (!rsc) {
+		kfree(pdata);
+		return ERR_PTR(-ENOMEM);
+	}
+
+	rsc[0].start    = rsc[0].end = dev_priv->lpe_audio.irq;
+	rsc[0].flags    = IORESOURCE_IRQ;
+	rsc[0].name     = "hdmi-lpe-audio-irq";
+
+	rsc[1].start    = pci_resource_start(dev->pdev, 0) +
+		I915_HDMI_LPE_AUDIO_BASE;
+	rsc[1].end      = pci_resource_start(dev->pdev, 0) +
+		I915_HDMI_LPE_AUDIO_BASE + I915_HDMI_LPE_AUDIO_SIZE - 1;
+	rsc[1].flags    = IORESOURCE_MEM;
+	rsc[1].name     = "hdmi-lpe-audio-mmio";
+
+	pinfo.parent = dev->dev;
+	pinfo.name = "hdmi-lpe-audio";
+	pinfo.id = -1;
+	pinfo.res = rsc;
+	pinfo.num_res = 2;
+	pinfo.data = pdata;
+	pinfo.size_data = sizeof(*pdata);
+	pinfo.dma_mask = DMA_BIT_MASK(32);
+
+	spin_lock_init(&pdata->lpe_audio_slock);
+
+	platdev = platform_device_register_full(&pinfo);
+	if (IS_ERR(platdev)) {
+		ret = PTR_ERR(platdev);
+		DRM_ERROR("Failed to allocate LPE audio platform device\n");
+		goto err;
+	}
+
+	kfree(rsc);
+
+	return platdev;
+
+   err:
+	kfree(rsc);
+	kfree(pdata);
+	return ERR_PTR(ret);
+}
+
+static void lpe_audio_platdev_destroy(struct drm_i915_private *dev_priv)
+{
+	platform_device_unregister(dev_priv->lpe_audio.platdev);
+	kfree(dev_priv->lpe_audio.platdev->dev.dma_mask);
+}
+
+static void lpe_audio_irq_unmask(struct irq_data *d)
+{
+	struct drm_i915_private *dev_priv = d->chip_data;
+	unsigned long irqflags;
+	u32 val = (I915_LPE_PIPE_A_INTERRUPT |
+		I915_LPE_PIPE_B_INTERRUPT);
+
+	if (IS_CHERRYVIEW(dev_priv))
+		val |= I915_LPE_PIPE_C_INTERRUPT;
+
+	spin_lock_irqsave(&dev_priv->irq_lock, irqflags);
+
+	dev_priv->irq_mask &= ~val;
+	I915_WRITE(VLV_IIR, val);
+	I915_WRITE(VLV_IIR, val);
+	I915_WRITE(VLV_IMR, dev_priv->irq_mask);
+	POSTING_READ(VLV_IMR);
+
+	spin_unlock_irqrestore(&dev_priv->irq_lock, irqflags);
+}
+
+static void lpe_audio_irq_mask(struct irq_data *d)
+{
+	struct drm_i915_private *dev_priv = d->chip_data;
+	unsigned long irqflags;
+	u32 val = (I915_LPE_PIPE_A_INTERRUPT |
+		I915_LPE_PIPE_B_INTERRUPT);
+
+	if (IS_CHERRYVIEW(dev_priv))
+		val |= I915_LPE_PIPE_C_INTERRUPT;
+
+	spin_lock_irqsave(&dev_priv->irq_lock, irqflags);
+
+	dev_priv->irq_mask |= val;
+	I915_WRITE(VLV_IMR, dev_priv->irq_mask);
+	I915_WRITE(VLV_IIR, val);
+	I915_WRITE(VLV_IIR, val);
+	POSTING_READ(VLV_IIR);
+
+	spin_unlock_irqrestore(&dev_priv->irq_lock, irqflags);
+}
+
+static struct irq_chip lpe_audio_irqchip = {
+	.name = "hdmi_lpe_audio_irqchip",
+	.irq_mask = lpe_audio_irq_mask,
+	.irq_unmask = lpe_audio_irq_unmask,
+};
+
+static int lpe_audio_irq_init(struct drm_i915_private *dev_priv)
+{
+	int irq = dev_priv->lpe_audio.irq;
+
+	WARN_ON(!intel_irqs_enabled(dev_priv));
+	irq_set_chip_and_handler_name(irq,
+				&lpe_audio_irqchip,
+				handle_simple_irq,
+				"hdmi_lpe_audio_irq_handler");
+
+	return irq_set_chip_data(irq, dev_priv);
+}
+
+/**
+ * intel_lpe_audio_irq_handler() - forwards the LPE audio irq
+ * @dev_priv: the i915 drm device private data
+ *
+ * the LPE Audio irq is forwarded to the irq handler registered by LPE audio
+ * driver.
+ */
+void intel_lpe_audio_irq_handler(struct drm_i915_private *dev_priv)
+{
+	int ret;
+
+	if (!HAS_LPE_AUDIO(dev_priv))
+		return;
+
+	ret = generic_handle_irq(dev_priv->lpe_audio.irq);
+	if (ret)
+		DRM_ERROR_RATELIMITED("error handling LPE audio irq: %d\n",
+				ret);
+}
+
+/**
+ * intel_lpe_audio_detect() - check & setup lpe audio if present
+ * @dev_priv: the i915 drm device private data
+ *
+ * Detect if lpe audio is present
+ *
+ * Return: true if lpe audio present else Return = false
+ */
+bool intel_lpe_audio_detect(struct drm_i915_private *dev_priv)
+{
+	int lpe_present = false;
+
+	if (IS_VALLEYVIEW(dev_priv) || IS_CHERRYVIEW(dev_priv)) {
+		static const struct pci_device_id atom_hdaudio_ids[] = {
+			/* Baytrail */
+			{PCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x0f04)},
+			/* Braswell */
+			{PCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x2284)},
+			{}
+		};
+
+		if (!pci_dev_present(atom_hdaudio_ids)) {
+			DRM_INFO("%s\n", "HDaudio controller not detected, using LPE audio instead\n");
+			lpe_present = true;
+		}
+	}
+	return lpe_present;
+}
+
+/**
+ * intel_lpe_audio_setup() - setup the bridge between HDMI LPE Audio
+ * driver and i915
+ * @dev_priv: the i915 drm device private data
+ *
+ * set up the minimum required resources for the bridge: irq chip,
+ * platform resource and platform device. i915 device is set as parent
+ * of the new platform device.
+ *
+ * Return: 0 if successful. non-zero if allocation/initialization fails
+ */
+int intel_lpe_audio_setup(struct drm_i915_private *dev_priv)
+{
+	int ret;
+
+	dev_priv->lpe_audio.irq = irq_alloc_desc(0);
+	if (dev_priv->lpe_audio.irq < 0) {
+		DRM_ERROR("Failed to allocate IRQ desc: %d\n",
+			dev_priv->lpe_audio.irq);
+		ret = dev_priv->lpe_audio.irq;
+		goto err;
+	}
+
+	DRM_DEBUG("irq = %d\n", dev_priv->lpe_audio.irq);
+
+	ret = lpe_audio_irq_init(dev_priv);
+
+	if (ret) {
+		DRM_ERROR("Failed to initialize irqchip for lpe audio: %d\n",
+			ret);
+		goto err_free_irq;
+	}
+
+	dev_priv->lpe_audio.platdev = lpe_audio_platdev_create(dev_priv);
+
+	if (IS_ERR(dev_priv->lpe_audio.platdev)) {
+		ret = PTR_ERR(dev_priv->lpe_audio.platdev);
+		DRM_ERROR("Failed to create lpe audio platform device: %d\n",
+			ret);
+		goto err_free_irq;
+	}
+
+	return 0;
+err_free_irq:
+	irq_free_desc(dev_priv->lpe_audio.irq);
+err:
+	dev_priv->lpe_audio.irq = -1;
+	dev_priv->lpe_audio.platdev = NULL;
+	return ret;
+}
+
+
+/**
+ * intel_lpe_audio_init() - detect and setup the bridge between HDMI LPE Audio
+ * driver and i915
+ * @dev_priv: the i915 drm device private data
+ *
+ * Return: 0 if successful. non-zero if detection or
+ * llocation/initialization fails
+ */
+int intel_lpe_audio_init(struct drm_i915_private *dev_priv)
+{
+	int ret = -ENODEV;
+
+	if (intel_lpe_audio_detect(dev_priv)) {
+		ret = intel_lpe_audio_setup(dev_priv);
+		if (ret < 0)
+			DRM_ERROR("failed to setup LPE Audio bridge\n");
+	}
+	return ret;
+}
+
+/**
+ * intel_lpe_audio_teardown() - destroy the bridge between HDMI LPE
+ * audio driver and i915
+ * @dev_priv: the i915 drm device private data
+ *
+ * release all the resources for LPE audio <-> i915 bridge.
+ */
+void intel_lpe_audio_teardown(struct drm_i915_private *dev_priv)
+{
+	struct irq_desc *desc;
+
+	if (!HAS_LPE_AUDIO(dev_priv))
+		return;
+
+	desc = irq_to_desc(dev_priv->lpe_audio.irq);
+
+	lpe_audio_irq_mask(&desc->irq_data);
+
+	lpe_audio_platdev_destroy(dev_priv);
+
+	irq_free_desc(dev_priv->lpe_audio.irq);
+}
+
+
+/**
+ * intel_lpe_audio_notify() - notify lpe audio event
+ * audio driver and i915
+ * @dev_priv: the i915 drm device private data
+ * @eld : ELD data
+ * @port: port id
+ * @tmds_clk_speed: tmds clock frequency in Hz
+ * @connected: hdmi connected/disconnected
+ *
+ * Notify lpe audio driver of eld change.
+ */
+void intel_lpe_audio_notify(struct drm_i915_private *dev_priv,
+			void *eld, int port, int tmds_clk_speed)
+{
+	unsigned long irq_flags;
+	struct intel_hdmi_lpe_audio_pdata *pdata = NULL;
+
+	if (!HAS_LPE_AUDIO(dev_priv))
+		return;
+
+	pdata = dev_get_platdata(
+		&(dev_priv->lpe_audio.platdev->dev));
+
+	spin_lock_irqsave(&pdata->lpe_audio_slock, irq_flags);
+
+	if (eld != NULL) {
+		memcpy(pdata->eld.eld_data, eld,
+			HDMI_MAX_ELD_BYTES);
+		pdata->eld.port_id = port;
+		pdata->hdmi_connected = true;
+
+		if (tmds_clk_speed)
+			pdata->tmds_clock_speed = tmds_clk_speed;
+	} else {
+		memset(pdata->eld.eld_data, 0,
+			HDMI_MAX_ELD_BYTES);
+		pdata->hdmi_connected = false;
+	}
+
+	if (pdata->notify_audio_lpe)
+		pdata->notify_audio_lpe(
+			(eld != NULL) ? &pdata->eld : NULL);
+	else
+		pdata->notify_pending = true;
+
+	spin_unlock_irqrestore(&pdata->lpe_audio_slock,
+			irq_flags);
+}
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/gpu/drm/i915/intel_lvds.c linux-4.10.x/drivers/gpu/drm/i915/intel_lvds.c
--- linux-4.10.x.ori/drivers/gpu/drm/i915/intel_lvds.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/gpu/drm/i915/intel_lvds.c	2017-04-10 11:27:25.836919000 +0200
@@ -997,6 +997,12 @@ void intel_lvds_init(struct drm_device *
 	if (dmi_check_system(intel_no_lvds))
 		return;
 
+	/* lang@igel.de: Skip init if LVDS is disabled */
+	if (! i915.lvds_enable) {
+		DRM_INFO("LVDS is disabled by module parameter\n");
+		return;
+	}
+
 	if (HAS_PCH_SPLIT(dev_priv))
 		lvds_reg = PCH_LVDS;
 	else
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/gpu/drm/i915/intel_modes.c linux-4.10.x/drivers/gpu/drm/i915/intel_modes.c
--- linux-4.10.x.ori/drivers/gpu/drm/i915/intel_modes.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/gpu/drm/i915/intel_modes.c	2017-11-17 07:36:01.998407000 +0100
@@ -30,6 +30,21 @@
 #include "intel_drv.h"
 #include "i915_drv.h"
 
+static void intel_connector_update_eld_conn_type(struct drm_connector *connector)
+{
+	u8 conn_type;
+
+	if (connector->connector_type == DRM_MODE_CONNECTOR_DisplayPort ||
+	    connector->connector_type == DRM_MODE_CONNECTOR_eDP) {
+		conn_type = DRM_ELD_CONN_TYPE_DP;
+	} else {
+		conn_type = DRM_ELD_CONN_TYPE_HDMI;
+	}
+
+	connector->eld[DRM_ELD_SAD_COUNT_CONN_TYPE] &= ~DRM_ELD_CONN_TYPE_MASK;
+	connector->eld[DRM_ELD_SAD_COUNT_CONN_TYPE] |= conn_type;
+}
+
 /**
  * intel_connector_update_modes - update connector from edid
  * @connector: DRM connector device to use
@@ -44,6 +59,8 @@ int intel_connector_update_modes(struct
 	ret = drm_add_edid_modes(connector, edid);
 	drm_edid_to_eld(connector, edid);
 
+	intel_connector_update_eld_conn_type(connector);
+
 	return ret;
 }
 
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/gpu/drm/i915/intel_sdvo.c linux-4.10.x/drivers/gpu/drm/i915/intel_sdvo.c
--- linux-4.10.x.ori/drivers/gpu/drm/i915/intel_sdvo.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/gpu/drm/i915/intel_sdvo.c	2017-04-10 11:27:25.836919000 +0200
@@ -151,6 +151,12 @@ struct intel_sdvo {
 	 * the sdvo flag gets lost in round trip: dtd->adjusted_mode->dtd
 	 */
 	uint8_t dtd_sdvo_flags;
+
+	/**
+	 * schneider@igel.com: Vendor registers for save/restore (suspend/resume)
+	 */
+	bool    vendor_regs_valid;
+	uint8_t vendor_regs[0x100-SDVO_I2C_VENDOR_BEGIN];
 };
 
 struct intel_sdvo_connector {
@@ -302,6 +308,30 @@ static bool intel_sdvo_read_byte(struct
 	return false;
 }
 
+/* schneider@igel.com: intel_sdvo_write_byte allows to write single SDVO registers */
+static bool intel_sdvo_write_byte(struct intel_sdvo *intel_sdvo, u8 addr, u8 val)
+{
+	int ret;
+	uint8_t out_buf[2];
+	struct i2c_msg msg[] = {
+		{
+			.addr = intel_sdvo->slave_addr,
+			.flags = 0,
+			.len = 2,
+			.buf = out_buf,
+		}
+	};
+
+	out_buf[0] = addr;
+	out_buf[1] = val;
+
+	if ((ret = i2c_transfer(intel_sdvo->i2c, msg, 1)) == 1)
+		return true;
+
+	DRM_DEBUG_KMS("i2c WRITE transfer returned %d\n", ret);
+	return false;
+}
+
 #define SDVO_CMD_NAME_ENTRY(cmd) {cmd, #cmd}
 /** Mapping of command numbers to names, for debug output */
 static const struct _sdvo_cmd_name {
@@ -1772,6 +1802,17 @@ intel_sdvo_detect(struct drm_connector *
 			ret = connector_status_connected;
 	}
 
+	/* lang@igel.de: fix dual monitor with TC215 hardware */
+	if ((ret != connector_status_connected) &&
+	    (response & SDVO_LVDS_MASK)) {
+		struct drm_i915_private *dev_priv = connector->dev->dev_private;
+		if (dev_priv->vbt.sdvo_lvds_vbt_mode != NULL) {
+			DRM_INFO("%s: set LVDS connector_status_connected "
+			  "- VBT mode available\n", SDVO_NAME(intel_sdvo));
+			ret = connector_status_connected;
+		}
+	}
+
 	/* May update encoder flag for like clock for SDVO TV, etc.*/
 	if (ret == connector_status_connected) {
 		intel_sdvo->is_tv = false;
@@ -2208,6 +2249,71 @@ intel_sdvo_connector_unregister(struct d
 	intel_connector_unregister(connector);
 }
 
+/* schneider@igel.com: SDVO register save function for given connector */
+static void intel_sdvo_connector_save(struct drm_connector *connector)
+{
+	struct intel_sdvo *intel_sdvo = intel_attached_sdvo(connector);
+    int i;
+
+	/* Read the vendor regs */
+    for (i = SDVO_I2C_VENDOR_BEGIN; i < 0x100; i++) {
+        if (!intel_sdvo_read_byte(intel_sdvo, i, &intel_sdvo->vendor_regs[i-SDVO_I2C_VENDOR_BEGIN])) {
+            DRM_DEBUG_KMS("No SDVO device found on %s\n",
+                    SDVO_NAME(intel_sdvo));
+            break;
+        }
+        DRM_DEBUG_KMS("%s: %s: REG 0x%02X=0x%02X [READ]\n", __FUNCTION__, SDVO_NAME(intel_sdvo), i, intel_sdvo->vendor_regs[i-SDVO_I2C_VENDOR_BEGIN]);
+    }
+    intel_sdvo->vendor_regs_valid = true;
+}
+
+/* schneider@igel.com: SDVO register save function */
+void intel_sdvo_save(struct drm_device *dev)
+{
+    struct drm_connector *connector;
+
+    list_for_each_entry(connector, &dev->mode_config.connector_list, head) {
+        if(connector->funcs->save == intel_sdvo_connector_save) {
+            intel_sdvo_connector_save(connector);
+        }
+    }
+}
+
+/* schneider@igel.com: SDVO register restore function for given connector */
+static void intel_sdvo_connector_restore(struct drm_connector* connector)
+{
+	struct intel_sdvo *intel_sdvo = intel_attached_sdvo(connector);
+    int i;
+
+    if(!intel_sdvo->vendor_regs_valid) {
+        DRM_DEBUG_KMS("SDVO %s vendor regs have not been saved bevore\n",
+                SDVO_NAME(intel_sdvo));
+        return;
+    }
+
+	/* Write back the vendor regs */
+    for (i = SDVO_I2C_VENDOR_BEGIN; i < 0x100; i++) {
+        if (!intel_sdvo_write_byte(intel_sdvo, i, intel_sdvo->vendor_regs[i-SDVO_I2C_VENDOR_BEGIN])) {
+            DRM_DEBUG_KMS("No SDVO device found on %s\n",
+                    SDVO_NAME(intel_sdvo));
+            break;
+        }
+        DRM_DEBUG_KMS("%s: %s: REG 0x%02X=0x%02X [WRITE]\n", __FUNCTION__, SDVO_NAME(intel_sdvo), i, intel_sdvo->vendor_regs[i-SDVO_I2C_VENDOR_BEGIN]);
+    }
+}
+
+/* schneider@igel.com: SDVO register restore function */
+void intel_sdvo_restore(struct drm_device *dev)
+{
+    struct drm_connector *connector;
+
+    list_for_each_entry(connector, &dev->mode_config.connector_list, head) {
+        if(connector->funcs->restore == intel_sdvo_connector_restore) {
+            intel_sdvo_connector_restore(connector);
+        }
+    }
+}
+
 static const struct drm_connector_funcs intel_sdvo_connector_funcs = {
 	.dpms = drm_atomic_helper_connector_dpms,
 	.detect = intel_sdvo_detect,
@@ -2219,6 +2325,8 @@ static const struct drm_connector_funcs
 	.destroy = intel_sdvo_destroy,
 	.atomic_destroy_state = drm_atomic_helper_connector_destroy_state,
 	.atomic_duplicate_state = drm_atomic_helper_connector_duplicate_state,
+	.save = intel_sdvo_connector_save, /* schneider@igel.com: SDVO suspend helper */
+	.restore = intel_sdvo_connector_restore, /* schneider@igel.com: SDVO resume helper */
 };
 
 static const struct drm_connector_helper_funcs intel_sdvo_connector_helper_funcs = {
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/gpu/drm/i915/intel_tv.c linux-4.10.x/drivers/gpu/drm/i915/intel_tv.c
--- linux-4.10.x.ori/drivers/gpu/drm/i915/intel_tv.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/gpu/drm/i915/intel_tv.c	2017-04-10 11:27:25.836919000 +0200
@@ -1556,6 +1556,12 @@ intel_tv_init(struct drm_device *dev)
 		return;
 	}
 
+	/* lang@igel.de: Skip init if TV is disabled */
+	if (! i915.tv_enable) {
+		DRM_INFO("Integrated TV is disabled by module parameter\n");
+		return;
+	}
+
 	/*
 	 * Sanity check the TV output by checking to see if the
 	 * DAC register holds a value
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/gpu/drm/i915/Makefile linux-4.10.x/drivers/gpu/drm/i915/Makefile
--- linux-4.10.x.ori/drivers/gpu/drm/i915/Makefile	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/gpu/drm/i915/Makefile	2017-04-21 17:01:32.706015000 +0200
@@ -122,6 +122,9 @@ i915-y += intel_gvt.o
 include $(src)/gvt/Makefile
 endif
 
+# LPE Audio for VLV and CHT
+i915-y += intel_lpe_audio.o
+
 obj-$(CONFIG_DRM_I915) += i915.o
 
 CFLAGS_i915_trace_points.o := -I$(src)
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/gpu/drm/nouveau/nouveau_bo.c linux-4.10.x/drivers/gpu/drm/nouveau/nouveau_bo.c
--- linux-4.10.x.ori/drivers/gpu/drm/nouveau/nouveau_bo.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/gpu/drm/nouveau/nouveau_bo.c	2017-07-12 14:58:46.400789000 +0200
@@ -1194,7 +1194,8 @@ out:
 }
 
 static void
-nouveau_bo_move_ntfy(struct ttm_buffer_object *bo, struct ttm_mem_reg *new_mem)
+nouveau_bo_move_ntfy(struct ttm_buffer_object *bo, bool evict,
+		     struct ttm_mem_reg *new_mem)
 {
 	struct nouveau_bo *nvbo = nouveau_bo(bo);
 	struct nvkm_vma *vma;
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/gpu/drm/qxl/qxl_ttm.c linux-4.10.x/drivers/gpu/drm/qxl/qxl_ttm.c
--- linux-4.10.x.ori/drivers/gpu/drm/qxl/qxl_ttm.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/gpu/drm/qxl/qxl_ttm.c	2017-07-12 14:58:46.400789000 +0200
@@ -367,6 +367,7 @@ static int qxl_bo_move(struct ttm_buffer
 }
 
 static void qxl_bo_move_notify(struct ttm_buffer_object *bo,
+			       bool evict,
 			       struct ttm_mem_reg *new_mem)
 {
 	struct qxl_bo *qbo;
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/gpu/drm/radeon/atombios_dp.c linux-4.10.x/drivers/gpu/drm/radeon/atombios_dp.c
--- linux-4.10.x.ori/drivers/gpu/drm/radeon/atombios_dp.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/gpu/drm/radeon/atombios_dp.c	2017-04-10 11:27:25.836919000 +0200
@@ -359,11 +359,33 @@ static u8 radeon_dp_encoder_service(stru
 	return args.ucStatus;
 }
 
+/* lang@igel: If the sink supports it, try to set the power state */
+static void radeon_dp_sink_power_on(struct radeon_connector *radeon_connector)
+{
+	int ret, i;
+	u16 reg = DP_SET_POWER;
+	u8 val = DP_SET_POWER_D0;
+	
+	/*
+	 * When turning on, we need to retry for 1ms to give the sink
+	 * time to wake up.
+	 */
+	for (i = 0; i < 3; i++) {
+		ret = drm_dp_dpcd_writeb(&radeon_connector->ddc_bus->aux, reg, val);
+		if (ret == 1)
+			break;
+		msleep(1);
+	}
+}
+
 u8 radeon_dp_getsinktype(struct radeon_connector *radeon_connector)
 {
 	struct drm_device *dev = radeon_connector->base.dev;
 	struct radeon_device *rdev = dev->dev_private;
 
+	/* lang@igel: power up the sink */
+	radeon_dp_sink_power_on(radeon_connector);
+
 	return radeon_dp_encoder_service(rdev, ATOM_DP_ACTION_GET_SINK_TYPE, 0,
 					 radeon_connector->ddc_bus->rec.i2c_id, 0);
 }
@@ -833,6 +855,9 @@ void radeon_dp_link_train(struct drm_enc
 	else
 		dp_info.enc_id |= ATOM_DP_CONFIG_LINK_A;
 
+	/* lang@igel: power up the sink */
+	radeon_dp_sink_power_on(radeon_connector);
+
 	if (drm_dp_dpcd_readb(&radeon_connector->ddc_bus->aux, DP_MAX_LANE_COUNT, &tmp)
 	    == 1) {
 		if (ASIC_IS_DCE5(rdev) && (tmp & DP_TPS3_SUPPORTED))
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/gpu/drm/radeon/radeon_atombios.c linux-4.10.x/drivers/gpu/drm/radeon/radeon_atombios.c
--- linux-4.10.x.ori/drivers/gpu/drm/radeon/radeon_atombios.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/gpu/drm/radeon/radeon_atombios.c	2017-04-10 11:27:25.836919000 +0200
@@ -26,6 +26,7 @@
 #include <drm/drmP.h>
 #include <drm/radeon_drm.h>
 #include "radeon.h"
+#include <linux/dmi.h>
 
 #include "atom.h"
 #include "atom-bits.h"
@@ -287,7 +288,15 @@ static bool radeon_atom_apply_quirks(str
 				     uint16_t *line_mux,
 				     struct radeon_hpd *hpd)
 {
-
+	const char *product;
+	const char *vendor;
+	/* lang@igel.de: 
+	   if the user selected lvds=0 don't try and add the connector */
+	if ((*connector_type == DRM_MODE_CONNECTOR_LVDS) &&
+	    (radeon_lvds == 0)) {
+		DRM_INFO("apply quirk: LVDS is disabled by module parameter\n");
+		return false;
+	}
 	/* Asus M2A-VM HDMI board lists the DVI port as HDMI */
 	if ((dev->pdev->device == 0x791e) &&
 	    (dev->pdev->subsystem_vendor == 0x1043) &&
@@ -439,7 +448,6 @@ static bool radeon_atom_apply_quirks(str
 
 	/* Fujitsu D3003-S2 board lists DVI-I as DVI-D and VGA */
 	if (((dev->pdev->device == 0x9802) ||
-	     (dev->pdev->device == 0x9805) ||
 	     (dev->pdev->device == 0x9806)) &&
 	    (dev->pdev->subsystem_vendor == 0x1734) &&
 	    (dev->pdev->subsystem_device == 0x11bd)) {
@@ -451,6 +459,40 @@ static bool radeon_atom_apply_quirks(str
 		}
 	}
 
+	/* Fujitsu D3003-S2 board lists DVI-I as DVI-I and VGA */
+	if ((dev->pdev->device == 0x9805) &&
+	    (dev->pdev->subsystem_vendor == 0x1734) &&
+	    (dev->pdev->subsystem_device == 0x11bd)) {
+		if (*connector_type == DRM_MODE_CONNECTOR_VGA) {
+			/* gottwald@igel.com limit this only to the board which is mentioned in the 
+			 * BUG report https://bugs.freedesktop.org/show_bug.cgi?id=83184
+			 * this should fix the non working VGA port on Futro S700 devices */
+			product = dmi_get_system_info(DMI_BOARD_NAME);
+			if (product != NULL)
+				if (strstr(product, "D3003-S1"))
+					return false;
+		}
+	}
+
+	/* Handle IGEL M340C outputs correctly */
+	if ((dev->pdev->device == 0x9854) &&
+	    (dev->pdev->subsystem_vendor == 0x1002) &&
+	    (dev->pdev->subsystem_device == 0x9854)) {
+		if (! IS_IGEL_M340C) {
+			product = dmi_get_system_info(DMI_BOARD_NAME);
+			if (product != NULL)
+				if (strstr(product, "M340C")) 
+					igel_platform = IGEL_M340C;
+		}
+	}
+
+	if (IS_IGEL_M340C) {
+		if ((*connector_type == DRM_MODE_CONNECTOR_DisplayPort) &&
+		    (supported_device == ATOM_DEVICE_DFP2_SUPPORT) ) {
+			*connector_type = DRM_MODE_CONNECTOR_DVID;
+		}
+	}
+
 	return true;
 }
 
@@ -833,7 +875,8 @@ bool radeon_get_atom_connector_info_from
 						  igp_lane_info,
 						  connector_object_id,
 						  &hpd,
-						  &router);
+						  &router,
+						  0);
 
 		}
 	}
@@ -893,6 +936,7 @@ struct bios_connector {
 	int connector_type;
 	struct radeon_i2c_bus_rec ddc_bus;
 	struct radeon_hpd hpd;
+	int splitted_dvii;
 };
 
 bool radeon_get_atom_connector_info_from_supported_devices_table(struct
@@ -1057,14 +1101,31 @@ bool radeon_get_atom_connector_info_from
 						     (bios_connectors[j].devices & (ATOM_DEVICE_CRT_SUPPORT))) ||
 						    ((bios_connectors[j].devices & (ATOM_DEVICE_DFP_SUPPORT)) &&
 						     (bios_connectors[i].devices & (ATOM_DEVICE_CRT_SUPPORT)))) {
-							bios_connectors[i].devices |=
-								bios_connectors[j].devices;
-							bios_connectors[i].connector_type =
-								DRM_MODE_CONNECTOR_DVII;
-							if (bios_connectors[j].devices & (ATOM_DEVICE_DFP_SUPPORT))
-								bios_connectors[i].hpd =
-									bios_connectors[j].hpd;
-							bios_connectors[j].valid = false;
+							/* lang@igel: split DVI-I connector in analog + digital connector */
+							if (radeon_split_dvii) {
+								if (bios_connectors[i].splitted_dvii &&
+								bios_connectors[j].splitted_dvii)
+									continue;
+								DRM_INFO("split DVI-I connector in separate "
+								 "analog and digital connectors\n");
+								bios_connectors[i].splitted_dvii = 1;
+								bios_connectors[j].splitted_dvii = 1;
+								bios_connectors[i].connector_type = DRM_MODE_CONNECTOR_DVII;
+								bios_connectors[j].connector_type = DRM_MODE_CONNECTOR_DVII;
+								if (bios_connectors[j].devices & (ATOM_DEVICE_DFP_SUPPORT))
+								bios_connectors[i].hpd = bios_connectors[j].hpd;
+								if (bios_connectors[i].devices & (ATOM_DEVICE_DFP_SUPPORT))
+								bios_connectors[j].hpd = bios_connectors[i].hpd;
+							} else {
+								bios_connectors[i].devices |=
+									bios_connectors[j].devices;
+								bios_connectors[i].connector_type =
+									DRM_MODE_CONNECTOR_DVII;
+								if (bios_connectors[j].devices & (ATOM_DEVICE_DFP_SUPPORT))
+									bios_connectors[i].hpd =
+										bios_connectors[j].hpd;
+								bios_connectors[j].valid = false;
+							}
 						}
 					}
 				}
@@ -1088,7 +1149,8 @@ bool radeon_get_atom_connector_info_from
 						  0,
 						  connector_object_id,
 						  &bios_connectors[i].hpd,
-						  &router);
+						  &router,
+						  bios_connectors[i].splitted_dvii);
 		}
 	}
 
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/gpu/drm/radeon/radeon_connectors.c linux-4.10.x/drivers/gpu/drm/radeon/radeon_connectors.c
--- linux-4.10.x.ori/drivers/gpu/drm/radeon/radeon_connectors.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/gpu/drm/radeon/radeon_connectors.c	2017-04-10 11:27:25.836919000 +0200
@@ -51,6 +51,7 @@ void radeon_connector_hotplug(struct drm
 	struct drm_device *dev = connector->dev;
 	struct radeon_device *rdev = dev->dev_private;
 	struct radeon_connector *radeon_connector = to_radeon_connector(connector);
+	enum drm_connector_status status;
 
 	if (connector->connector_type == DRM_MODE_CONNECTOR_DisplayPort) {
 		struct radeon_connector_atom_dig *dig_connector =
@@ -63,6 +64,24 @@ void radeon_connector_hotplug(struct drm
 			return;
 		}
 	}
+
+	/* gottwald@igel.com update status of connector */
+
+	status = connector->status;
+
+	if (connector->force) {
+		if (connector->force == DRM_FORCE_ON)
+			connector->status = connector_status_connected;
+		else
+			connector->status = connector_status_disconnected;
+		if (connector->funcs->force)
+			connector->funcs->force(connector);
+	}
+
+	if (connector->status == connector_status_disconnected) {
+		drm_mode_connector_update_edid_property(connector, NULL);
+	}
+
 	/* bail if the connector does not have hpd pin, e.g.,
 	 * VGA, TV, etc.
 	 */
@@ -96,6 +115,18 @@ void radeon_connector_hotplug(struct drm
 			if (!radeon_hpd_sense(rdev, radeon_connector->hpd.hpd)) {
 				drm_helper_connector_dpms(connector, DRM_MODE_DPMS_OFF);
 			} else if (radeon_dp_needs_link_train(radeon_connector)) {
+				/*
+				 * lang@igel:
+				 * fix monitor dpms on, when connector is disconnected 
+				 */
+				if (connector->status != connector_status_connected)  {
+					enum drm_connector_status new_status;
+
+					new_status = connector->funcs->detect(connector, false);
+					DRM_INFO("run %s detection during hotplug: %s\n", 
+						 connector->name,
+						 drm_get_connector_status_name(new_status));
+				}
 				/* Don't try to start link training before we
 				 * have the dpcd */
 				if (!radeon_dp_getdpcd(radeon_connector))
@@ -1283,6 +1314,10 @@ radeon_dvi_detect(struct drm_connector *
 		radeon_connector->detected_by_load = false;
 		radeon_connector_free_edid(connector);
 		radeon_connector_get_edid(connector);
+		if (!radeon_connector->edid) {
+			msleep(500);
+			radeon_connector_get_edid(connector);
+		}
 
 		if (!radeon_connector->edid) {
 			DRM_ERROR("%s: probed a monitor but no|invalid EDID\n",
@@ -1306,9 +1341,12 @@ radeon_dvi_detect(struct drm_connector *
 			/* some oems have boards with separate digital and analog connectors
 			 * with a shared ddc line (often vga + hdmi)
 			 */
-			if ((!radeon_connector->use_digital) && radeon_connector->shared_ddc) {
+			if ((!radeon_connector->use_digital) &&
+			    (radeon_connector->shared_ddc || IS_IGEL_M340C)) {
 				radeon_connector_free_edid(connector);
 				ret = connector_status_disconnected;
+				if (IS_IGEL_M340C)
+					goto out;
 			} else {
 				ret = connector_status_connected;
 			}
@@ -1341,6 +1379,19 @@ radeon_dvi_detect(struct drm_connector *
 		}
 	}
 
+	/* lang@igel: split DVI-I connector in analog + digital connector:
+	   check if EDID fits to device type */
+	if (radeon_connector->splitted_dvii && (ret == connector_status_connected)) {
+		if ( (radeon_connector->use_digital && 
+		      ((radeon_connector->devices & (ATOM_DEVICE_DFP_SUPPORT)) == 0)) ||
+		     (! radeon_connector->use_digital && 
+		      ((radeon_connector->devices & (ATOM_DEVICE_CRT_SUPPORT)) == 0)) )
+			ret = connector_status_disconnected;
+	}
+	/* lang@igel: reset detected_by_load flag after EDID check */
+	if (radeon_connector->splitted_dvii && (ret == connector_status_connected))
+		radeon_connector->detected_by_load = false;
+
 	if ((ret == connector_status_connected) && (radeon_connector->use_digital == true))
 		goto out;
 
@@ -1359,6 +1410,15 @@ radeon_dvi_detect(struct drm_connector *
 		goto out;
 	}
 
+	/* lang@igel: split DVI-I connector in analog + digital connector:
+	   never do destructive polling, you can see a black screen on analog output */
+	if (radeon_connector->splitted_dvii &&
+	    radeon_connector->detected_by_load &&
+	    (connector->status == connector_status_connected)) {
+		ret = connector->status;
+		goto out;
+	}
+
 	/* find analog encoder */
 	if (radeon_connector->dac_load_detect) {
 		for (i = 0; i < DRM_CONNECTOR_MAX_ENCODER; i++) {
@@ -1745,7 +1805,9 @@ radeon_dp_detect(struct drm_connector *c
 		if (radeon_hpd_sense(rdev, radeon_connector->hpd.hpd)) {
 			ret = connector_status_connected;
 			if (radeon_dig_connector->dp_sink_type == CONNECTOR_OBJECT_ID_DISPLAYPORT) {
-				radeon_dp_getdpcd(radeon_connector);
+				/* lang@igel: if we do not get dpcd, the connector should be disconnected */
+				if (! radeon_dp_getdpcd(radeon_connector))
+					ret = connector_status_disconnected;
 				r = radeon_dp_mst_probe(radeon_connector);
 				if (r == 1)
 					ret = connector_status_disconnected;
@@ -1880,7 +1942,8 @@ radeon_add_atom_connector(struct drm_dev
 			  uint32_t igp_lane_info,
 			  uint16_t connector_object_id,
 			  struct radeon_hpd *hpd,
-			  struct radeon_router *router)
+			  struct radeon_router *router,
+			  int splitted_dvii)
 {
 	struct radeon_device *rdev = dev->dev_private;
 	struct drm_connector *connector;
@@ -1892,6 +1955,7 @@ radeon_add_atom_connector(struct drm_dev
 	bool shared_ddc = false;
 	bool is_dp_bridge = false;
 	bool has_aux = false;
+	bool dvii_shared = false;
 
 	if (connector_type == DRM_MODE_CONNECTOR_Unknown)
 		return;
@@ -1903,15 +1967,32 @@ radeon_add_atom_connector(struct drm_dev
 	    (radeon_tv == 0))
 		return;
 
+	if (connector_type == DRM_MODE_CONNECTOR_VGA) {
+		/* gottwald@igel.com Samsung NC241, NC221 and TC2 workaround to not detect DVI monitor also as VGA */
+		if ((dev->pdev->device == 0x9856 || dev->pdev->device == 0x9851) &&
+		    (dev->pdev->subsystem_vendor == 0x1022) &&
+		    (dev->pdev->subsystem_device == 0x1234)) {
+			list_for_each_entry(connector, &dev->mode_config.connector_list, head)
+				if (connector->connector_type == DRM_MODE_CONNECTOR_DVII)
+					dvii_shared = true;
+		} else if (IS_SAMSUNG_TC2) {
+			list_for_each_entry(connector, &dev->mode_config.connector_list, head)
+				if (connector->connector_type == DRM_MODE_CONNECTOR_DVII)
+					dvii_shared = true;
+		}
+	}
+
 	/* see if we already added it */
 	list_for_each_entry(connector, &dev->mode_config.connector_list, head) {
 		radeon_connector = to_radeon_connector(connector);
-		if (radeon_connector->connector_id == connector_id) {
+		if ((radeon_connector->connector_id == connector_id) &&
+		     ! splitted_dvii) {
 			radeon_connector->devices |= supported_device;
 			return;
 		}
 		if (radeon_connector->ddc_bus && i2c_bus->valid) {
-			if (radeon_connector->ddc_bus->rec.i2c_id == i2c_bus->i2c_id) {
+			if (((radeon_connector->ddc_bus->rec.i2c_id == i2c_bus->i2c_id) 
+			      || dvii_shared) && ! splitted_dvii) {
 				radeon_connector->shared_ddc = true;
 				shared_ddc = true;
 			}
@@ -1949,6 +2030,7 @@ radeon_add_atom_connector(struct drm_dev
 	radeon_connector->shared_ddc = shared_ddc;
 	radeon_connector->connector_object_id = connector_object_id;
 	radeon_connector->hpd = *hpd;
+	radeon_connector->splitted_dvii = splitted_dvii;
 
 	radeon_connector->router = *router;
 	if (router->ddc_valid || router->cd_valid) {
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/gpu/drm/radeon/radeon_device.c linux-4.10.x/drivers/gpu/drm/radeon/radeon_device.c
--- linux-4.10.x.ori/drivers/gpu/drm/radeon/radeon_device.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/gpu/drm/radeon/radeon_device.c	2017-04-10 11:27:25.836919000 +0200
@@ -1705,6 +1705,7 @@ int radeon_resume_kms(struct drm_device
 	struct radeon_device *rdev = dev->dev_private;
 	struct drm_crtc *crtc;
 	int r;
+	int i;
 
 	if (dev->switch_power_state == DRM_SWITCH_POWER_OFF)
 		return 0;
@@ -1781,9 +1782,21 @@ int radeon_resume_kms(struct drm_device
 	/* blat the mode back in */
 	if (fbcon) {
 		drm_helper_resume_force_mode(dev);
+		/* lang@igel: reinitialize cursors */
+		for (i = 0; i < rdev->num_crtc; i++) {
+			if (rdev->mode_info.crtcs[i]) {
+				radeon_cursor_reset(&rdev->mode_info.crtcs[i]->base);
+			}
+		}
 		/* turn on display hw */
 		drm_modeset_lock_all(dev);
 		list_for_each_entry(connector, &dev->mode_config.connector_list, head) {
+			/* lang@igel: reset detected_by_load, so the the connector is probed again */
+			struct radeon_connector *radeon_connector = to_radeon_connector(connector);
+
+			if (radeon_connector && radeon_connector->splitted_dvii)
+				radeon_connector->detected_by_load = false;
+
 			drm_helper_connector_dpms(connector, DRM_MODE_DPMS_ON);
 		}
 		drm_modeset_unlock_all(dev);
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/gpu/drm/radeon/radeon_display.c linux-4.10.x/drivers/gpu/drm/radeon/radeon_display.c
--- linux-4.10.x.ori/drivers/gpu/drm/radeon/radeon_display.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/gpu/drm/radeon/radeon_display.c	2017-04-10 11:27:25.836919000 +0200
@@ -719,6 +719,9 @@ static void radeon_crtc_init(struct drm_
 		radeon_atombios_init_crtc(dev, radeon_crtc);
 	else
 		radeon_legacy_init_crtc(dev, radeon_crtc);
+
+	/* lang@igel: initialize cursor registers */
+	radeon_crtc_cursor_set2(&radeon_crtc->base, NULL, 0, 0, 0, 0, 0);
 }
 
 static const char *encoder_names[38] = {
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/gpu/drm/radeon/radeon_drv.c linux-4.10.x/drivers/gpu/drm/radeon/radeon_drv.c
--- linux-4.10.x.ori/drivers/gpu/drm/radeon/radeon_drv.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/gpu/drm/radeon/radeon_drv.c	2017-04-10 11:27:25.836919000 +0200
@@ -40,6 +40,7 @@
 #include <linux/vga_switcheroo.h>
 #include <drm/drm_gem.h>
 #include <drm/drm_fb_helper.h>
+#include <linux/dmi.h>
 
 #include "drm_crtc_helper.h"
 #include "radeon_kfd.h"
@@ -181,6 +182,8 @@ int radeon_gart_size = -1; /* auto */
 int radeon_benchmarking = 0;
 int radeon_testing = 0;
 int radeon_connector_table = 0;
+int radeon_split_dvii = 1;
+int radeon_lvds = 1;
 int radeon_tv = 1;
 int radeon_audio = -1;
 int radeon_disp_priority = 0;
@@ -204,6 +207,8 @@ int radeon_mst = 0;
 int radeon_uvd = 1;
 int radeon_vce = 1;
 
+enum igel_platforms igel_platform = NO_IGEL_PLATFORM;
+
 MODULE_PARM_DESC(no_wb, "Disable AGP writeback for scratch registers");
 module_param_named(no_wb, radeon_no_wb, int, 0444);
 
@@ -234,6 +239,12 @@ module_param_named(test, radeon_testing,
 MODULE_PARM_DESC(connector_table, "Force connector table");
 module_param_named(connector_table, radeon_connector_table, int, 0444);
 
+MODULE_PARM_DESC(split_dvii, "Split DVI-I connector in 2 connectors (0 = disable)");
+module_param_named(split_dvii, radeon_split_dvii, int, 0444);
+
+MODULE_PARM_DESC(lvds, "LVDS enable (0 = disable)");
+module_param_named(lvds, radeon_lvds, int, 0444);
+
 MODULE_PARM_DESC(tv, "TV enable (0 = disable)");
 module_param_named(tv, radeon_tv, int, 0444);
 
@@ -595,10 +606,27 @@ static struct pci_driver radeon_kms_pci_
 
 static int __init radeon_init(void)
 {
+	const char *product;
+	const char *vendor;
 	if (vgacon_text_force() && radeon_modeset == -1) {
 		DRM_INFO("VGACON disable radeon kernel modesetting.\n");
 		radeon_modeset = 0;
 	}
+
+	if (igel_platform == NO_IGEL_PLATFORM) {
+		product = dmi_get_system_info(DMI_PRODUCT_NAME);
+		vendor = dmi_get_system_info(DMI_SYS_VENDOR);
+		if (product != NULL && vendor != NULL) {
+			if (strstr(product, "TC2") && 
+			strstr(vendor, "Samsung Electronics Co., Ltd")) {
+				igel_platform = SAMSUNG_TC2;
+			} else if (strstr(product, "M340C") && 
+			strstr(vendor, "IGEL Technology GmbH")) {
+				igel_platform = IGEL_M340C;
+			}
+		}
+	}
+
 	/* set to modesetting by default if not nomodeset */
 	if (radeon_modeset == -1)
 		radeon_modeset = 1;
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/gpu/drm/radeon/radeon_drv.h linux-4.10.x/drivers/gpu/drm/radeon/radeon_drv.h
--- linux-4.10.x.ori/drivers/gpu/drm/radeon/radeon_drv.h	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/gpu/drm/radeon/radeon_drv.h	2017-04-10 11:27:25.836919000 +0200
@@ -116,6 +116,17 @@
 #define DRIVER_MINOR		34
 #define DRIVER_PATCHLEVEL	0
 
+/* gottwald@igel.com: define enum for IGEL platforms,
+ * that require special treatment. Also in radeon.h */
+enum igel_platforms {
+	NO_IGEL_PLATFORM = -1,
+	IGEL_M340C,
+	SAMSUNG_TC2,
+};
+extern enum igel_platforms igel_platform;
+#define IS_IGEL_M340C (igel_platform==IGEL_M340C)
+#define IS_SAMSUNG_TC2 (igel_platform==SAMSUNG_TC2)
+
 long radeon_drm_ioctl(struct file *filp,
 		      unsigned int cmd, unsigned long arg);
 
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/gpu/drm/radeon/radeon_fb.c linux-4.10.x/drivers/gpu/drm/radeon/radeon_fb.c
--- linux-4.10.x.ori/drivers/gpu/drm/radeon/radeon_fb.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/gpu/drm/radeon/radeon_fb.c	2017-04-10 11:27:25.836919000 +0200
@@ -351,8 +351,9 @@ int radeon_fbdev_init(struct radeon_devi
 	if (list_empty(&rdev->ddev->mode_config.connector_list))
 		return 0;
 
-	/* select 8 bpp console on RN50 or 16MB cards */
-	if (ASIC_IS_RN50(rdev) || rdev->mc.real_vram_size <= (32*1024*1024))
+	/* gottwald@igel.com do not limit framebuffer to 8bpp */
+	/* select 8 bpp console on RN50 or 8MB cards */
+	if (ASIC_IS_RN50(rdev) || rdev->mc.real_vram_size <= (8*1024*1024))
 		bpp_sel = 8;
 
 	rfbdev = kzalloc(sizeof(struct radeon_fbdev), GFP_KERNEL);
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/gpu/drm/radeon/radeon.h linux-4.10.x/drivers/gpu/drm/radeon/radeon.h
--- linux-4.10.x.ori/drivers/gpu/drm/radeon/radeon.h	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/gpu/drm/radeon/radeon.h	2017-04-10 11:27:25.836919000 +0200
@@ -93,6 +93,8 @@ extern int radeon_gart_size;
 extern int radeon_benchmarking;
 extern int radeon_testing;
 extern int radeon_connector_table;
+extern int radeon_split_dvii;
+extern int radeon_lvds;
 extern int radeon_tv;
 extern int radeon_audio;
 extern int radeon_disp_priority;
@@ -116,6 +118,17 @@ extern int radeon_mst;
 extern int radeon_uvd;
 extern int radeon_vce;
 
+/* gottwald@igel.com: define enum for IGEL platforms,
+ * that require special treatment. Also in radeon_drv.h */
+enum igel_platforms {
+	NO_IGEL_PLATFORM = -1,
+	IGEL_M340C,
+	SAMSUNG_TC2
+};
+extern enum igel_platforms igel_platform;
+#define IS_IGEL_M340C (igel_platform==IGEL_M340C)
+#define IS_SAMSUNG_TC2 (igel_platform==SAMSUNG_TC2)
+
 /*
  * Copy from radeon_drv.h so we don't have to include both and have conflicting
  * symbol;
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/gpu/drm/radeon/radeon_irq_kms.c linux-4.10.x/drivers/gpu/drm/radeon/radeon_irq_kms.c
--- linux-4.10.x.ori/drivers/gpu/drm/radeon/radeon_irq_kms.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/gpu/drm/radeon/radeon_irq_kms.c	2017-04-10 11:27:25.836919000 +0200
@@ -90,6 +90,15 @@ static void radeon_hotplug_work_func(str
 			radeon_connector_hotplug(connector);
 	}
 	mutex_unlock(&mode_config->mutex);
+
+	/* gottwald@igel.com handle the hotplug */
+
+	if (mode_config->num_connector) {
+		list_for_each_entry(connector, &mode_config->connector_list, head) {
+			drm_kms_helper_hotplug_event(dev);
+		}
+	}
+	
 	/* Just fire off a uevent and let userspace tell us what to do */
 	drm_helper_hpd_irq_event(dev);
 }
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/gpu/drm/radeon/radeon_mode.h linux-4.10.x/drivers/gpu/drm/radeon/radeon_mode.h
--- linux-4.10.x.ori/drivers/gpu/drm/radeon/radeon_mode.h	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/gpu/drm/radeon/radeon_mode.h	2017-04-10 11:27:25.836919000 +0200
@@ -571,6 +571,8 @@ struct radeon_connector {
 	struct radeon_encoder *mst_encoder;
 	struct stream_attribs cur_stream_attribs[6];
 	int enabled_attribs;
+	/* lang@igel: split DVI-I connector in analog + digital connector */
+	int splitted_dvii;
 };
 
 struct radeon_framebuffer {
@@ -702,7 +704,8 @@ radeon_add_atom_connector(struct drm_dev
 			  uint32_t igp_lane_info,
 			  uint16_t connector_object_id,
 			  struct radeon_hpd *hpd,
-			  struct radeon_router *router);
+			  struct radeon_router *router,
+			  int splitted_dvii);
 extern void
 radeon_add_legacy_connector(struct drm_device *dev,
 			    uint32_t connector_id,
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/gpu/drm/radeon/radeon_object.c linux-4.10.x/drivers/gpu/drm/radeon/radeon_object.c
--- linux-4.10.x.ori/drivers/gpu/drm/radeon/radeon_object.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/gpu/drm/radeon/radeon_object.c	2017-07-12 14:58:46.400789000 +0200
@@ -765,6 +765,7 @@ int radeon_bo_check_tiling(struct radeon
 }
 
 void radeon_bo_move_notify(struct ttm_buffer_object *bo,
+			   bool evict,
 			   struct ttm_mem_reg *new_mem)
 {
 	struct radeon_bo *rbo;
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/gpu/drm/radeon/radeon_object.h linux-4.10.x/drivers/gpu/drm/radeon/radeon_object.h
--- linux-4.10.x.ori/drivers/gpu/drm/radeon/radeon_object.h	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/gpu/drm/radeon/radeon_object.h	2017-07-12 14:58:46.400789000 +0200
@@ -150,6 +150,7 @@ extern void radeon_bo_get_tiling_flags(s
 extern int radeon_bo_check_tiling(struct radeon_bo *bo, bool has_moved,
 				bool force_drop);
 extern void radeon_bo_move_notify(struct ttm_buffer_object *bo,
+				  bool evict,
 				  struct ttm_mem_reg *new_mem);
 extern int radeon_bo_fault_reserve_notify(struct ttm_buffer_object *bo);
 extern int radeon_bo_get_surface_reg(struct radeon_bo *bo);
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/gpu/drm/ttm/ttm_bo.c linux-4.10.x/drivers/gpu/drm/ttm/ttm_bo.c
--- linux-4.10.x.ori/drivers/gpu/drm/ttm/ttm_bo.c	2017-04-21 13:47:09.278670000 +0200
+++ linux-4.10.x/drivers/gpu/drm/ttm/ttm_bo.c	2017-07-12 14:58:46.400789000 +0200
@@ -342,7 +342,7 @@ static int ttm_bo_handle_move_mem(struct
 
 		if (bo->mem.mem_type == TTM_PL_SYSTEM) {
 			if (bdev->driver->move_notify)
-				bdev->driver->move_notify(bo, mem);
+				bdev->driver->move_notify(bo, evict, mem);
 			bo->mem = *mem;
 			mem->mm_node = NULL;
 			goto moved;
@@ -350,7 +350,7 @@ static int ttm_bo_handle_move_mem(struct
 	}
 
 	if (bdev->driver->move_notify)
-		bdev->driver->move_notify(bo, mem);
+		bdev->driver->move_notify(bo, evict, mem);
 
 	if (!(old_man->flags & TTM_MEMTYPE_FLAG_FIXED) &&
 	    !(new_man->flags & TTM_MEMTYPE_FLAG_FIXED))
@@ -366,7 +366,7 @@ static int ttm_bo_handle_move_mem(struct
 			struct ttm_mem_reg tmp_mem = *mem;
 			*mem = bo->mem;
 			bo->mem = tmp_mem;
-			bdev->driver->move_notify(bo, mem);
+			bdev->driver->move_notify(bo, false, mem);
 			bo->mem = *mem;
 			*mem = tmp_mem;
 		}
@@ -414,7 +414,7 @@ out_err:
 static void ttm_bo_cleanup_memtype_use(struct ttm_buffer_object *bo)
 {
 	if (bo->bdev->driver->move_notify)
-		bo->bdev->driver->move_notify(bo, NULL);
+		bo->bdev->driver->move_notify(bo, false, NULL);
 
 	ttm_tt_destroy(bo->ttm);
 	bo->ttm = NULL;
@@ -1785,3 +1785,5 @@ out_unlock:
 	mutex_unlock(&bo->wu_mutex);
 	return ret;
 }
+/* lang@igel: via kms driver still using it */
+EXPORT_SYMBOL(ttm_bo_wait_unreserved);
\ No newline at end of file
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/gpu/drm/virtio/virtgpu_ttm.c linux-4.10.x/drivers/gpu/drm/virtio/virtgpu_ttm.c
--- linux-4.10.x.ori/drivers/gpu/drm/virtio/virtgpu_ttm.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/gpu/drm/virtio/virtgpu_ttm.c	2017-07-12 14:58:46.400789000 +0200
@@ -386,6 +386,7 @@ static int virtio_gpu_bo_move(struct ttm
 }
 
 static void virtio_gpu_bo_move_notify(struct ttm_buffer_object *tbo,
+				      bool evict,
 				      struct ttm_mem_reg *new_mem)
 {
 	struct virtio_gpu_object *bo;
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/gpu/drm/vmwgfx/vmwgfx_buffer.c linux-4.10.x/drivers/gpu/drm/vmwgfx/vmwgfx_buffer.c
--- linux-4.10.x.ori/drivers/gpu/drm/vmwgfx/vmwgfx_buffer.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/gpu/drm/vmwgfx/vmwgfx_buffer.c	2017-07-12 14:58:46.400789000 +0200
@@ -825,6 +825,7 @@ static int vmw_ttm_fault_reserve_notify(
  * (currently only resources).
  */
 static void vmw_move_notify(struct ttm_buffer_object *bo,
+			    bool evict,
 			    struct ttm_mem_reg *mem)
 {
 	vmw_resource_move_notify(bo, mem);
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/hid/hid-core.c linux-4.10.x/drivers/hid/hid-core.c
--- linux-4.10.x.ori/drivers/hid/hid-core.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/hid/hid-core.c	2017-11-20 09:57:37.302118000 +0100
@@ -724,13 +724,7 @@ static void hid_scan_collection(struct h
 		hid->group = HID_GROUP_SENSOR_HUB;
 
 	if (hid->vendor == USB_VENDOR_ID_MICROSOFT &&
-	    (hid->product == USB_DEVICE_ID_MS_TYPE_COVER_PRO_3 ||
-	     hid->product == USB_DEVICE_ID_MS_TYPE_COVER_PRO_3_2 ||
-	     hid->product == USB_DEVICE_ID_MS_TYPE_COVER_PRO_3_JP ||
-	     hid->product == USB_DEVICE_ID_MS_TYPE_COVER_PRO_4 ||
-	     hid->product == USB_DEVICE_ID_MS_TYPE_COVER_PRO_4_2 ||
-	     hid->product == USB_DEVICE_ID_MS_TYPE_COVER_PRO_4_JP ||
-	     hid->product == USB_DEVICE_ID_MS_POWER_COVER) &&
+	    hid->product == USB_DEVICE_ID_MS_POWER_COVER &&
 	    hid->group == HID_GROUP_MULTITOUCH)
 		hid->group = HID_GROUP_GENERIC;
 
@@ -1769,6 +1763,8 @@ EXPORT_SYMBOL_GPL(hid_disconnect);
  * used as a driver. See hid_scan_report().
  */
 static const struct hid_device_id hid_have_special_driver[] = {
+	{ HID_USB_DEVICE(USB_VENDOR_ID_3DCONNEXION, USB_DEVICE_ID_3DCONNEXION_SM_W) },
+	{ HID_USB_DEVICE(USB_VENDOR_ID_3DCONNEXION, USB_DEVIDE_ID_3DCONNEXION_SM_PRO_W) },
 	{ HID_USB_DEVICE(USB_VENDOR_ID_A4TECH, USB_DEVICE_ID_A4TECH_WCP32PU) },
 	{ HID_USB_DEVICE(USB_VENDOR_ID_A4TECH, USB_DEVICE_ID_A4TECH_X5_005D) },
 	{ HID_USB_DEVICE(USB_VENDOR_ID_A4TECH, USB_DEVICE_ID_A4TECH_RP_649) },
@@ -1932,6 +1928,8 @@ static const struct hid_device_id hid_ha
 	{ HID_USB_DEVICE(USB_VENDOR_ID_LENOVO, USB_DEVICE_ID_LENOVO_CUSBKBD) },
 	{ HID_BLUETOOTH_DEVICE(USB_VENDOR_ID_LENOVO, USB_DEVICE_ID_LENOVO_CBTKBD) },
 	{ HID_USB_DEVICE(USB_VENDOR_ID_LENOVO, USB_DEVICE_ID_LENOVO_TPPRODOCK) },
+	{ HID_USB_DEVICE(USB_VENDOR_ID_LENOVO, USB_DEVICE_ID_LENOVO_WIRELESS_ESSENTIAL) },
+	{ HID_USB_DEVICE(USB_VENDOR_ID_LENOVO, USB_DEVICE_ID_LENOVO_WIRELESS_PROFESSIONAL) },
 #endif
 	{ HID_USB_DEVICE(USB_VENDOR_ID_LOGITECH, USB_DEVICE_ID_MX3000_RECEIVER) },
 	{ HID_USB_DEVICE(USB_VENDOR_ID_LOGITECH, USB_DEVICE_ID_S510_RECEIVER) },
@@ -1985,12 +1983,6 @@ static const struct hid_device_id hid_ha
 	{ HID_USB_DEVICE(USB_VENDOR_ID_MICROSOFT, USB_DEVICE_ID_MS_DIGITAL_MEDIA_3K) },
 	{ HID_USB_DEVICE(USB_VENDOR_ID_MICROSOFT, USB_DEVICE_ID_WIRELESS_OPTICAL_DESKTOP_3_0) },
 	{ HID_USB_DEVICE(USB_VENDOR_ID_MICROSOFT, USB_DEVICE_ID_MS_OFFICE_KB) },
-	{ HID_USB_DEVICE(USB_VENDOR_ID_MICROSOFT, USB_DEVICE_ID_MS_TYPE_COVER_PRO_3) },
-	{ HID_USB_DEVICE(USB_VENDOR_ID_MICROSOFT, USB_DEVICE_ID_MS_TYPE_COVER_PRO_3_2) },
-	{ HID_USB_DEVICE(USB_VENDOR_ID_MICROSOFT, USB_DEVICE_ID_MS_TYPE_COVER_PRO_3_JP) },
-	{ HID_USB_DEVICE(USB_VENDOR_ID_MICROSOFT, USB_DEVICE_ID_MS_TYPE_COVER_PRO_4) },
-	{ HID_USB_DEVICE(USB_VENDOR_ID_MICROSOFT, USB_DEVICE_ID_MS_TYPE_COVER_PRO_4_2) },
-	{ HID_USB_DEVICE(USB_VENDOR_ID_MICROSOFT, USB_DEVICE_ID_MS_TYPE_COVER_PRO_4_JP) },
 	{ HID_USB_DEVICE(USB_VENDOR_ID_MICROSOFT, USB_DEVICE_ID_MS_DIGITAL_MEDIA_7K) },
 	{ HID_USB_DEVICE(USB_VENDOR_ID_MICROSOFT, USB_DEVICE_ID_MS_DIGITAL_MEDIA_600) },
 	{ HID_USB_DEVICE(USB_VENDOR_ID_MICROSOFT, USB_DEVICE_ID_MS_DIGITAL_MEDIA_3KV1) },
@@ -2588,6 +2580,12 @@ bool hid_ignore(struct hid_device *hdev)
 		return true;
 
 	switch (hdev->vendor) {
+	/* gottwald@igel.com Better to use standard HID for this WACOM devices */
+	case USB_VENDOR_ID_WACOM:
+		if (hdev->product == USB_DEVICE_ID_WACOM_BAMBOO_PAD_CTH301 ||
+			hdev->product == USB_DEVICE_ID_WACOM_BAMBOO_PAD_CTH300)
+			return false;
+		break;
 	case USB_VENDOR_ID_CODEMERCS:
 		/* ignore all Code Mercenaries IOWarrior devices */
 		if (hdev->product >= USB_DEVICE_ID_CODEMERCS_IOW_FIRST &&
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/hid/hid-ids.h linux-4.10.x/drivers/hid/hid-ids.h
--- linux-4.10.x.ori/drivers/hid/hid-ids.h	2017-08-31 08:18:50.846242000 +0200
+++ linux-4.10.x/drivers/hid/hid-ids.h	2017-11-20 09:57:37.302118000 +0100
@@ -17,6 +17,10 @@
 #ifndef HID_IDS_H_FILE
 #define HID_IDS_H_FILE
 
+#define USB_VENDOR_ID_3DCONNEXION		0x256f
+#define USB_DEVICE_ID_3DCONNEXION_SM_W		0xc62e
+#define USB_DEVIDE_ID_3DCONNEXION_SM_PRO_W		0xc631
+
 #define USB_VENDOR_ID_3M		0x0596
 #define USB_DEVICE_ID_3M1968		0x0500
 #define USB_DEVICE_ID_3M2256		0x0502
@@ -633,6 +637,8 @@
 #define USB_DEVICE_ID_LENOVO_CUSBKBD	0x6047
 #define USB_DEVICE_ID_LENOVO_CBTKBD	0x6048
 #define USB_DEVICE_ID_LENOVO_TPPRODOCK	0x6067
+#define USB_DEVICE_ID_LENOVO_WIRELESS_ESSENTIAL 0x60a9
+#define USB_DEVICE_ID_LENOVO_WIRELESS_PROFESSIONAL 0x609b
 
 #define USB_VENDOR_ID_LG		0x1fd2
 #define USB_DEVICE_ID_LG_MULTITOUCH	0x0064
@@ -729,8 +735,10 @@
 #define USB_DEVICE_ID_MS_TOUCH_COVER_2   0x07a7
 #define USB_DEVICE_ID_MS_TYPE_COVER_2    0x07a9
 #define USB_DEVICE_ID_MS_TYPE_COVER_PRO_3    0x07dc
+#define USB_DEVICE_ID_MS_TYPE_COVER_PRO_3_1  0x07de
 #define USB_DEVICE_ID_MS_TYPE_COVER_PRO_3_2  0x07e2
 #define USB_DEVICE_ID_MS_TYPE_COVER_PRO_3_JP 0x07dd
+#define USB_DEVICE_ID_MS_SURFACE_BOOK     0x07cd
 #define USB_DEVICE_ID_MS_TYPE_COVER_PRO_4 0x07e4
 #define USB_DEVICE_ID_MS_TYPE_COVER_PRO_4_2 0x07e8
 #define USB_DEVICE_ID_MS_TYPE_COVER_PRO_4_JP 0x07e9
@@ -1046,6 +1054,8 @@
 #define USB_VENDOR_ID_WACOM		0x056a
 #define USB_DEVICE_ID_WACOM_GRAPHIRE_BLUETOOTH	0x81
 #define USB_DEVICE_ID_WACOM_INTUOS4_BLUETOOTH   0x00BD
+#define USB_DEVICE_ID_WACOM_BAMBOO_PAD_CTH301   0x0318
+#define USB_DEVICE_ID_WACOM_BAMBOO_PAD_CTH300   0x0319
 
 #define USB_VENDOR_ID_WALTOP				0x172f
 #define USB_DEVICE_ID_WALTOP_SLIM_TABLET_5_8_INCH	0x0032
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/hid/hid-input.c linux-4.10.x/drivers/hid/hid-input.c
--- linux-4.10.x.ori/drivers/hid/hid-input.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/hid/hid-input.c	2017-06-16 15:21:00.676525000 +0200
@@ -325,6 +325,10 @@ static const struct hid_device_id hid_ba
 	{ HID_BLUETOOTH_DEVICE(USB_VENDOR_ID_ELECOM,
 		USB_DEVICE_ID_ELECOM_BM084),
 	  HID_BATTERY_QUIRK_IGNORE },
+	{ HID_USB_DEVICE(USB_VENDOR_ID_3DCONNEXION, USB_DEVICE_ID_3DCONNEXION_SM_W),
+	  HID_BATTERY_QUIRK_IGNORE },
+	{ HID_USB_DEVICE(USB_VENDOR_ID_3DCONNEXION, USB_DEVIDE_ID_3DCONNEXION_SM_PRO_W),
+	  HID_BATTERY_QUIRK_IGNORE },
 	{}
 };
 
@@ -1186,7 +1190,12 @@ void hidinput_hid_event(struct hid_devic
 	    (!test_bit(usage->code, input->key)) == value)
 		input_event(input, EV_MSC, MSC_SCAN, usage->hid);
 
-	input_event(input, usage->type, usage->code, value);
+	/* freund@igel: fix TC236 touch with hid-core driver */
+	if (hid->vendor==USB_VENDOR_ID_XAT && hid->product==USB_DEVICE_ID_XAT_CSR
+	    && usage->type==EV_ABS && value==0)
+		dbg_hid("suppress EV_ABS with zero values on HID-TR-V1\n");
+	else
+		input_event(input, usage->type, usage->code, value);
 
 	if ((field->flags & HID_MAIN_ITEM_RELATIVE) &&
 	    usage->type == EV_KEY && value) {
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/hid/hid-lenovo.c linux-4.10.x/drivers/hid/hid-lenovo.c
--- linux-4.10.x.ori/drivers/hid/hid-lenovo.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/hid/hid-lenovo.c	2017-11-20 09:57:37.302118000 +0100
@@ -53,6 +53,52 @@ static const __u8 lenovo_pro_dock_need_f
 	0x2a, 0xff, 0xff,	/*  Usage Maximum (65535)		*/
 };
 
+static void fix_lenovo_hid_descriptor_primax(__u8 *rdesc)
+{
+	__u8 desc[80];
+	int i=0;
+
+	desc[22] = rdesc[24];
+	desc[23] = rdesc[25];
+	desc[24] = rdesc[22];
+	desc[25] = rdesc[23];
+	for (i=22;i<=25;i++) {
+		rdesc[i] = desc[i];
+	}
+	desc[28] = rdesc[36];
+	desc[29] = rdesc[37];
+	desc[30] = rdesc[34];
+	desc[31] = rdesc[35];
+	desc[32] = rdesc[28];
+	desc[33] = rdesc[29];
+	desc[34] = rdesc[30];
+	desc[35] = rdesc[31];
+	desc[36] = rdesc[32];
+	desc[37] = rdesc[33];
+	for (i=28;i<=37;i++) {
+		rdesc[i] = desc[i];
+	}
+	desc[46] = rdesc[60];
+	desc[47] = rdesc[61];
+	desc[48] = rdesc[58];
+	desc[49] = rdesc[59];
+	desc[50] = rdesc[46];
+	desc[51] = rdesc[47];
+	desc[52] = rdesc[48];
+	desc[53] = rdesc[49];
+	desc[54] = rdesc[50];
+	desc[55] = rdesc[56];
+	desc[56] = rdesc[57];
+	desc[57] = rdesc[51];
+	desc[58] = rdesc[52];
+	desc[59] = rdesc[53];
+	desc[60] = rdesc[54];
+	desc[61] = rdesc[55];
+	for (i=46;i<=61;i++) {
+		rdesc[i] = desc[i];
+	}
+}
+
 static __u8 *lenovo_report_fixup(struct hid_device *hdev, __u8 *rdesc,
 		unsigned int *rsize)
 {
@@ -69,6 +115,21 @@ static __u8 *lenovo_report_fixup(struct
 			rdesc[152] = 0x00;
 		}
 		break;
+	case USB_DEVICE_ID_LENOVO_WIRELESS_PROFESSIONAL:
+		if (*rsize == 80) {
+			// Not the keyboard if the rdesc[3] is not 0x06
+
+			if (rdesc[3] != 0x06)
+				return rdesc;
+
+			fix_lenovo_hid_descriptor_primax(rdesc);
+		}
+		break;
+	case USB_DEVICE_ID_LENOVO_WIRELESS_ESSENTIAL:
+		if (*rsize == 65) {
+			fix_lenovo_hid_descriptor_primax(rdesc);
+		}
+		break;
 	}
 	return rdesc;
 }
@@ -883,6 +944,8 @@ static const struct hid_device_id lenovo
 	{ HID_USB_DEVICE(USB_VENDOR_ID_LENOVO, USB_DEVICE_ID_LENOVO_CUSBKBD) },
 	{ HID_BLUETOOTH_DEVICE(USB_VENDOR_ID_LENOVO, USB_DEVICE_ID_LENOVO_CBTKBD) },
 	{ HID_USB_DEVICE(USB_VENDOR_ID_LENOVO, USB_DEVICE_ID_LENOVO_TPPRODOCK) },
+	{ HID_USB_DEVICE(USB_VENDOR_ID_LENOVO, USB_DEVICE_ID_LENOVO_WIRELESS_ESSENTIAL) },
+	{ HID_USB_DEVICE(USB_VENDOR_ID_LENOVO, USB_DEVICE_ID_LENOVO_WIRELESS_PROFESSIONAL) },
 	{ }
 };
 
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/hid/hid-microsoft.c linux-4.10.x/drivers/hid/hid-microsoft.c
--- linux-4.10.x.ori/drivers/hid/hid-microsoft.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/hid/hid-microsoft.c	2017-04-24 14:39:53.911391000 +0200
@@ -274,18 +274,6 @@ static const struct hid_device_id ms_dev
 		.driver_data = MS_NOGET },
 	{ HID_USB_DEVICE(USB_VENDOR_ID_MICROSOFT, USB_DEVICE_ID_MS_COMFORT_MOUSE_4500),
 		.driver_data = MS_DUPLICATE_USAGES },
-	{ HID_USB_DEVICE(USB_VENDOR_ID_MICROSOFT, USB_DEVICE_ID_MS_TYPE_COVER_PRO_3),
-		.driver_data = MS_HIDINPUT },
-	{ HID_USB_DEVICE(USB_VENDOR_ID_MICROSOFT, USB_DEVICE_ID_MS_TYPE_COVER_PRO_3_2),
-		.driver_data = MS_HIDINPUT },
-	{ HID_USB_DEVICE(USB_VENDOR_ID_MICROSOFT, USB_DEVICE_ID_MS_TYPE_COVER_PRO_3_JP),
-		.driver_data = MS_HIDINPUT },
-	{ HID_USB_DEVICE(USB_VENDOR_ID_MICROSOFT, USB_DEVICE_ID_MS_TYPE_COVER_PRO_4),
-		.driver_data = MS_HIDINPUT },
-	{ HID_USB_DEVICE(USB_VENDOR_ID_MICROSOFT, USB_DEVICE_ID_MS_TYPE_COVER_PRO_4_2),
-		.driver_data = MS_HIDINPUT },
-	{ HID_USB_DEVICE(USB_VENDOR_ID_MICROSOFT, USB_DEVICE_ID_MS_TYPE_COVER_PRO_4_JP),
-		.driver_data = MS_HIDINPUT },
 	{ HID_USB_DEVICE(USB_VENDOR_ID_MICROSOFT, USB_DEVICE_ID_MS_POWER_COVER),
 		.driver_data = MS_HIDINPUT },
 	{ HID_USB_DEVICE(USB_VENDOR_ID_MICROSOFT, USB_DEVICE_ID_MS_COMFORT_KEYBOARD),
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/hid/hid-multitouch.c linux-4.10.x/drivers/hid/hid-multitouch.c
--- linux-4.10.x.ori/drivers/hid/hid-multitouch.c	2017-08-31 08:18:50.846242000 +0200
+++ linux-4.10.x/drivers/hid/hid-multitouch.c	2017-08-31 08:18:50.846242000 +0200
@@ -1421,6 +1421,34 @@ static const struct hid_device_id mt_dev
 		MT_USB_DEVICE(USB_VENDOR_ID_ILITEK,
 			USB_DEVICE_ID_ILITEK_MULTITOUCH) },
 
+	/* Microsoft Type Cover */
+	{ .driver_data = MT_CLS_EXPORT_ALL_INPUTS,
+		MT_USB_DEVICE(USB_VENDOR_ID_MICROSOFT,
+			USB_DEVICE_ID_MS_TYPE_COVER_PRO_3) },
+	{ .driver_data = MT_CLS_EXPORT_ALL_INPUTS,
+		MT_USB_DEVICE(USB_VENDOR_ID_MICROSOFT,
+			USB_DEVICE_ID_MS_TYPE_COVER_PRO_3_1) },
+	{ .driver_data = MT_CLS_EXPORT_ALL_INPUTS,
+		MT_USB_DEVICE(USB_VENDOR_ID_MICROSOFT,
+			USB_DEVICE_ID_MS_TYPE_COVER_PRO_3_2) },
+	{ .driver_data = MT_CLS_EXPORT_ALL_INPUTS,
+		MT_USB_DEVICE(USB_VENDOR_ID_MICROSOFT,
+			USB_DEVICE_ID_MS_TYPE_COVER_PRO_3_JP) },
+	{ .driver_data = MT_CLS_EXPORT_ALL_INPUTS,
+		MT_USB_DEVICE(USB_VENDOR_ID_MICROSOFT,
+			USB_DEVICE_ID_MS_TYPE_COVER_PRO_4) },
+	{ .driver_data = MT_CLS_EXPORT_ALL_INPUTS,
+		MT_USB_DEVICE(USB_VENDOR_ID_MICROSOFT,
+			USB_DEVICE_ID_MS_TYPE_COVER_PRO_4_2) },
+	{ .driver_data = MT_CLS_EXPORT_ALL_INPUTS,
+		MT_USB_DEVICE(USB_VENDOR_ID_MICROSOFT,
+			USB_DEVICE_ID_MS_TYPE_COVER_PRO_4_JP) },
+
+	/* Microsoft Surface Book */
+	{ .driver_data = MT_CLS_EXPORT_ALL_INPUTS,
+		MT_USB_DEVICE(USB_VENDOR_ID_MICROSOFT,
+		USB_DEVICE_ID_MS_SURFACE_BOOK) },
+
 	/* MosArt panels */
 	{ .driver_data = MT_CLS_CONFIDENCE_MINUS_ONE,
 		MT_USB_DEVICE(USB_VENDOR_ID_ASUS,
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/hid/usbhid/hid-quirks.c linux-4.10.x/drivers/hid/usbhid/hid-quirks.c
--- linux-4.10.x.ori/drivers/hid/usbhid/hid-quirks.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/hid/usbhid/hid-quirks.c	2017-04-24 14:39:53.911391000 +0200
@@ -104,6 +104,7 @@ static const struct hid_blacklist {
 	{ USB_VENDOR_ID_MICROSOFT, USB_DEVICE_ID_MS_TYPE_COVER_2, HID_QUIRK_NO_INIT_REPORTS },
 	{ USB_VENDOR_ID_MICROSOFT, USB_DEVICE_ID_MS_TOUCH_COVER_2, HID_QUIRK_NO_INIT_REPORTS },
 	{ USB_VENDOR_ID_MICROSOFT, USB_DEVICE_ID_MS_TYPE_COVER_PRO_3, HID_QUIRK_NO_INIT_REPORTS },
+	{ USB_VENDOR_ID_MICROSOFT, USB_DEVICE_ID_MS_TYPE_COVER_PRO_3_1, HID_QUIRK_NO_INIT_REPORTS },
 	{ USB_VENDOR_ID_MICROSOFT, USB_DEVICE_ID_MS_TYPE_COVER_PRO_3_2, HID_QUIRK_NO_INIT_REPORTS },
 	{ USB_VENDOR_ID_MICROSOFT, USB_DEVICE_ID_MS_TYPE_COVER_PRO_3_JP, HID_QUIRK_NO_INIT_REPORTS },
 	{ USB_VENDOR_ID_MICROSOFT, USB_DEVICE_ID_MS_TYPE_COVER_PRO_4, HID_QUIRK_NO_INIT_REPORTS },
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/input/mouse/elantech.c linux-4.10.x/drivers/input/mouse/elantech.c
--- linux-4.10.x.ori/drivers/input/mouse/elantech.c	2017-05-24 07:18:02.975911000 +0200
+++ linux-4.10.x/drivers/input/mouse/elantech.c	2017-09-19 13:26:51.479624000 +0200
@@ -1118,8 +1118,10 @@ static int elantech_get_resolution_v4(st
  * Asus UX32VD             0x361f02        00, 15, 0e      clickpad
  * Avatar AVIU-145A2       0x361f00        ?               clickpad
  * Fujitsu LIFEBOOK E544   0x470f00        d0, 12, 09      2 hw buttons
+ * Fujitsu LIFEBOOK E546   0x470f00        50, 12, 09      2 hw buttons
  * Fujitsu LIFEBOOK E547   0x470f00        50, 12, 09      2 hw buttons
  * Fujitsu LIFEBOOK E554   0x570f01        40, 14, 0c      2 hw buttons
+ * Fujitsu LIFEBOOK E557   0x570f01        40, 14, 0c      2 hw buttons
  * Fujitsu T725            0x470f01        05, 12, 09      2 hw buttons
  * Fujitsu H730            0x570f00        c0, 14, 0c      3 hw buttons (**)
  * Gigabyte U2442          0x450f01        58, 17, 0c      2 hw buttons
@@ -1525,6 +1527,13 @@ static const struct dmi_system_id elante
 		},
 	},
 	{
+		/* Fujitsu LIFEBOOK E546 does not work with crc_enabled == 0 */
+		.matches = {
+			DMI_MATCH(DMI_SYS_VENDOR, "FUJITSU"),
+			DMI_MATCH(DMI_PRODUCT_NAME, "LIFEBOOK E546"),
+		},
+	},
+	{
 		/* Fujitsu LIFEBOOK E547 does not work with crc_enabled == 0 */
 		.matches = {
 			DMI_MATCH(DMI_SYS_VENDOR, "FUJITSU"),
@@ -1546,6 +1555,13 @@ static const struct dmi_system_id elante
 		},
 	},
 	{
+		/* Fujitsu LIFEBOOK E557 does not work with crc_enabled == 0 */
+		.matches = {
+			DMI_MATCH(DMI_SYS_VENDOR, "FUJITSU"),
+			DMI_MATCH(DMI_PRODUCT_NAME, "LIFEBOOK E557"),
+		},
+	},
+	{
 		/* Fujitsu LIFEBOOK U745 does not work with crc_enabled == 0 */
 		.matches = {
 			DMI_MATCH(DMI_SYS_VENDOR, "FUJITSU"),
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/input/touchscreen/Kconfig linux-4.10.x/drivers/input/touchscreen/Kconfig
--- linux-4.10.x.ori/drivers/input/touchscreen/Kconfig	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/input/touchscreen/Kconfig	2017-04-10 11:27:25.836919000 +0200
@@ -834,6 +834,7 @@ config TOUCHSCREEN_USB_COMPOSITE
 	  - Elo TouchSystems 2700 IntelliTouch
 	  - EasyTouch USB Touch Controller from Data Modul
 	  - e2i (Mimo monitors)
+	  - Reakin TS2005F USB Touch Controller
 
 	  Have a look at <http://linux.chapter7.ch/touchkit/> for
 	  a usage description and the required user-space stuff.
@@ -955,6 +956,11 @@ config TOUCHSCREEN_USB_EASYTOUCH
 	  Say Y here if you have an EasyTouch USB Touch controller.
 	  If unsure, say N.
 
+config TOUCHSCREEN_USB_REAKIN
+	default y
+	bool "Reakin device support" if EXPERT
+	depends on TOUCHSCREEN_USB_COMPOSITE
+
 config TOUCHSCREEN_TOUCHIT213
 	tristate "Sahara TouchIT-213 touchscreen"
 	select SERIO
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/input/touchscreen/usbtouchscreen.c linux-4.10.x/drivers/input/touchscreen/usbtouchscreen.c
--- linux-4.10.x.ori/drivers/input/touchscreen/usbtouchscreen.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/input/touchscreen/usbtouchscreen.c	2017-04-10 11:27:25.836919000 +0200
@@ -143,6 +143,7 @@ enum {
 	DEVTYPE_NEXIO,
 	DEVTYPE_ELO,
 	DEVTYPE_ETOUCH,
+	DEVTYPE_REAKIN,
 };
 
 #define USB_DEVICE_HID_CLASS(vend, prod) \
@@ -251,6 +252,10 @@ static const struct usb_device_id usbtou
 	{USB_DEVICE(0x7374, 0x0001), .driver_info = DEVTYPE_ETOUCH},
 #endif
 
+#ifdef CONFIG_TOUCHSCREEN_USB_REAKIN
+	{USB_DEVICE(0x16fd, 0x5453), .driver_info = DEVTYPE_REAKIN},
+#endif
+
 	{}
 };
 
@@ -302,6 +307,8 @@ static int e2i_read_data(struct usbtouch
 
 #define EGALAX_PKT_TYPE_MASK		0xFE
 #define EGALAX_PKT_TYPE_REPT		0x80
+/* lechner@igel.de, 15.10.2010: add support for new touchscreen controller in UD9 */
+#define EGALAX_PKT_TYPE_REPT2		0x02
 #define EGALAX_PKT_TYPE_DIAG		0x0A
 
 static int egalax_init(struct usbtouch_usb *usbtouch)
@@ -345,12 +352,23 @@ static int egalax_init(struct usbtouch_u
 
 static int egalax_read_data(struct usbtouch_usb *dev, unsigned char *pkt)
 {
-	if ((pkt[0] & EGALAX_PKT_TYPE_MASK) != EGALAX_PKT_TYPE_REPT)
+	if (((pkt[0] & EGALAX_PKT_TYPE_MASK) != EGALAX_PKT_TYPE_REPT)
+		&& ((pkt[0] & EGALAX_PKT_TYPE_MASK) != EGALAX_PKT_TYPE_REPT2)) {
 		return 0;
+	}
 
-	dev->x = ((pkt[3] & 0x0F) << 7) | (pkt[4] & 0x7F);
-	dev->y = ((pkt[1] & 0x0F) << 7) | (pkt[2] & 0x7F);
-	dev->touch = pkt[0] & 0x01;
+	switch (pkt[0] & EGALAX_PKT_TYPE_MASK) {
+	case EGALAX_PKT_TYPE_REPT:
+		dev->x = ((pkt[3] & 0x0F) << 7) | (pkt[4] & 0x7F);
+		dev->y = ((pkt[1] & 0x0F) << 7) | (pkt[2] & 0x7F);
+		dev->touch = pkt[0] & 0x01;
+		break;
+	case EGALAX_PKT_TYPE_REPT2:
+		dev->x = ((pkt[3] & 0x0F) << 8) | pkt[2];
+		dev->y = ((pkt[5] & 0x0F) << 8) | pkt[4];
+		dev->touch = pkt[1] & 0x01;
+		break;
+	}
 
 	return 1;
 }
@@ -361,6 +379,9 @@ static int egalax_get_pkt_len(unsigned c
 	case EGALAX_PKT_TYPE_REPT:
 		return 5;
 
+	case EGALAX_PKT_TYPE_REPT2:
+		return 6;
+
 	case EGALAX_PKT_TYPE_DIAG:
 		if (len < 2)
 			return -1;
@@ -1048,6 +1069,19 @@ static int nexio_read_data(struct usbtou
 }
 #endif
 
+/*****************************************************************************
+ * Reakin Part
+ */
+#ifdef CONFIG_TOUCHSCREEN_USB_REAKIN
+static int reakin_read_data(struct usbtouch_usb *dev, unsigned char *pkt)
+{
+	dev->x = ((pkt[2] & 0x0F) << 8) | pkt[1];
+	dev->y = ((pkt[4] & 0x0F) << 8) | pkt[3];
+	dev->touch = pkt[0] & 0x01;
+
+	return 1;
+}
+#endif
 
 /*****************************************************************************
  * ELO part
@@ -1296,6 +1330,17 @@ static struct usbtouch_device_info usbto
 		.read_data	= etouch_read_data,
 	},
 #endif
+
+#ifdef CONFIG_TOUCHSCREEN_USB_REAKIN
+	[DEVTYPE_REAKIN] = {
+		.min_xc		= 0x0,
+		.max_xc		= 0x03ff,
+		.min_yc		= 0x0,
+		.max_yc		= 0x03ff,
+		.rept_size	= 8,
+		.read_data	= reakin_read_data,
+	},
+#endif
 };
 
 
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/iommu/intel_irq_remapping.c linux-4.10.x/drivers/iommu/intel_irq_remapping.c
--- linux-4.10.x.ori/drivers/iommu/intel_irq_remapping.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/iommu/intel_irq_remapping.c	2017-06-21 11:26:54.470509000 +0200
@@ -13,6 +13,7 @@
 #include <linux/acpi.h>
 #include <linux/irqdomain.h>
 #include <linux/crash_dump.h>
+#include <linux/dmi.h>
 #include <asm/io_apic.h>
 #include <asm/smp.h>
 #include <asm/cpu.h>
@@ -286,6 +287,15 @@ static void set_irte_sid(struct irte *ir
 {
 	if (disable_sourceid_checking)
 		svt = SVT_NO_VERIFY;
+
+	if (dmi_match(DMI_PRODUCT_NAME, "MacBookPro13,1") ||
+	    dmi_match(DMI_PRODUCT_NAME, "MacBookPro13,2") ||
+	    dmi_match(DMI_PRODUCT_NAME, "MacBookPro13,3") ||
+	    dmi_match(DMI_PRODUCT_NAME, "MacBookPro14,1") ||
+	    dmi_match(DMI_PRODUCT_NAME, "MacBookPro14,2") ||
+	    dmi_match(DMI_PRODUCT_NAME, "MacBookPro14,3"))
+		svt = SVT_NO_VERIFY;
+
 	irte->svt = svt;
 	irte->sq = sq;
 	irte->sid = sid;
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/mmc/core/block.c linux-4.10.x/drivers/mmc/core/block.c
--- linux-4.10.x.ori/drivers/mmc/core/block.c	2017-04-21 13:47:09.278670000 +0200
+++ linux-4.10.x/drivers/mmc/core/block.c	2017-04-21 13:47:09.278670000 +0200
@@ -1893,6 +1893,11 @@ again:
 	 * messages to tell when the card is present.
 	 */
 
+	/* gottwald@igel.com set removable flag if MMC type is SD card (cardreader in laptop for example) */
+
+	if (card->type == MMC_TYPE_SD_COMBO || card->type == MMC_TYPE_SD || card->type == MMC_TYPE_SDIO)
+		md->disk->flags |= GENHD_FL_REMOVABLE;
+
 	snprintf(md->disk->disk_name, sizeof(md->disk->disk_name),
 		 "mmcblk%u%s", card->host->index, subname ? subname : "");
 
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/net/ethernet/broadcom/tg3.c linux-4.10.x/drivers/net/ethernet/broadcom/tg3.c
--- linux-4.10.x.ori/drivers/net/ethernet/broadcom/tg3.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/net/ethernet/broadcom/tg3.c	2017-04-10 11:27:25.836919000 +0200
@@ -67,6 +67,20 @@
 #define BAR_2	2
 
 #include "tg3.h"
+#include <linux/dmi.h>
+
+// Hardware with defective MSI support can be listed here !
+
+static struct dmi_system_id no_msi_dmi_table[] = {
+	{
+		.ident = "DELL-OptiPlex-FX160",
+		.matches = {
+			DMI_MATCH(DMI_SYS_VENDOR, "Dell Inc."),
+			DMI_MATCH(DMI_PRODUCT_NAME, "OptiPlex FX160"),
+		},
+	},	
+	{ NULL }
+};
 
 /* Functions & macros to verify TG3_FLAGS types */
 
@@ -11453,14 +11467,19 @@ static bool tg3_enable_msix(struct tg3 *
 
 static void tg3_ints_init(struct tg3 *tp)
 {
-	if ((tg3_flag(tp, SUPPORT_MSI) || tg3_flag(tp, SUPPORT_MSIX)) &&
-	    !tg3_flag(tp, TAGGED_STATUS)) {
-		/* All MSI supporting chips should support tagged
-		 * status.  Assert that this is the case.
-		 */
-		netdev_warn(tp->dev,
-			    "MSI without TAGGED_STATUS? Not using MSI\n");
-		goto defcfg;
+	/* lugmair@igel.com disable MSI usage on specific systems */
+	if (tg3_flag(tp, SUPPORT_MSI) || tg3_flag(tp, SUPPORT_MSIX)) {
+		if (!tg3_flag(tp, TAGGED_STATUS)) {
+			/* All MSI supporting chips should support tagged
+			 * status.  Assert that this is the case.
+			 */
+			netdev_warn(tp->dev,
+				    "MSI without TAGGED_STATUS? Not using MSI\n");
+			goto defcfg;
+		} else if (dmi_check_system(no_msi_dmi_table)) {
+			netdev_warn(tp->dev, "%s: Unsupported Hardware System found ! MSI Interrupts disabled ! \n", tp->dev->name); 
+			goto defcfg;
+		}
 	}
 
 	if (tg3_flag(tp, SUPPORT_MSIX) && tg3_enable_msix(tp))
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/net/ethernet/realtek/8139too.c linux-4.10.x/drivers/net/ethernet/realtek/8139too.c
--- linux-4.10.x.ori/drivers/net/ethernet/realtek/8139too.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/net/ethernet/realtek/8139too.c	2017-04-10 11:27:25.836919000 +0200
@@ -1102,6 +1102,11 @@ static int rtl8139_init_one(struct pci_d
 	if (rtl_chip_info[tp->chipset].flags & HasHltClk)
 		RTL_W8 (HltClk, 'H');	/* 'R' would leave the clock running. */
 
+	// lugmair@igel.com Kernel Patch
+	/* lang@igel.de: enable WOL */
+	if (rtl_chip_info[tp->chipset].flags & HasLWake)
+		device_set_wakeup_enable(&tp->pci_dev->dev, true);
+
 	return 0;
 
 err_out:
@@ -2376,6 +2381,11 @@ static int rtl8139_set_wol(struct net_de
 	if (wol->wolopts & WAKE_BCAST)
 		cfg5 |= Cfg5_BWF;
 	RTL_W8 (Config5, cfg5);	/* need not unlock via Cfg9346 */
+
+	// lugmair@igel.com Kernel patch
+	/* lang@igel.de: enable WOL */
+	device_set_wakeup_enable(&tp->pci_dev->dev, wol->wolopts);
+
 	spin_unlock_irq(&tp->lock);
 
 	return 0;
@@ -2619,8 +2629,13 @@ static int rtl8139_suspend (struct pci_d
 
 	pci_save_state (pdev);
 
-	if (!netif_running (dev))
+	// lugmair@igel.com Kernel patch
+	if (!netif_running (dev)) {
+		/* lang@igel.de: enable WOL from d3 state */
+		pci_wake_from_d3(pdev, true);
+		pci_set_power_state (pdev, PCI_D3hot);
 		return 0;
+	}
 
 	netif_device_detach (dev);
 
@@ -2636,6 +2651,10 @@ static int rtl8139_suspend (struct pci_d
 
 	spin_unlock_irqrestore (&tp->lock, flags);
 
+	// lugmair@igel.com Kernel patch
+	/* lang@igel.de: enable WOL from d3 state */
+	pci_wake_from_d3(pdev, true);
+
 	pci_set_power_state (pdev, PCI_D3hot);
 
 	return 0;
@@ -2646,10 +2665,13 @@ static int rtl8139_resume (struct pci_de
 {
 	struct net_device *dev = pci_get_drvdata (pdev);
 
+	/* lang@igel.de: disable WOL from d3 state */
+	pci_set_power_state (pdev, PCI_D0);
+	pci_wake_from_d3(pdev, false);
 	pci_restore_state (pdev);
 	if (!netif_running (dev))
 		return 0;
-	pci_set_power_state (pdev, PCI_D0);
+//	pci_set_power_state (pdev, PCI_D0);
 	rtl8139_init_ring (dev);
 	rtl8139_hw_start (dev);
 	netif_device_attach (dev);
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/net/ethernet/realtek/r8169.c linux-4.10.x/drivers/net/ethernet/realtek/r8169.c
--- linux-4.10.x.ori/drivers/net/ethernet/realtek/r8169.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/net/ethernet/realtek/r8169.c	2017-04-10 11:27:25.836919000 +0200
@@ -328,10 +328,12 @@ static const struct pci_device_id rtl816
 	{ PCI_DEVICE(PCI_VENDOR_ID_REALTEK,	0x8136), 0, 0, RTL_CFG_2 },
 	{ PCI_DEVICE(PCI_VENDOR_ID_REALTEK,	0x8161), 0, 0, RTL_CFG_1 },
 	{ PCI_DEVICE(PCI_VENDOR_ID_REALTEK,	0x8167), 0, 0, RTL_CFG_0 },
-	{ PCI_DEVICE(PCI_VENDOR_ID_REALTEK,	0x8168), 0, 0, RTL_CFG_1 },
+	/* lang@igel: for the realtek 0x8168 and dlink 0x4300/0x4b10 adapter, 
+	   the realtek vendor driver is used */
+	/*{ PCI_DEVICE(PCI_VENDOR_ID_REALTEK,	0x8168), 0, 0, RTL_CFG_1 },*/
 	{ PCI_DEVICE(PCI_VENDOR_ID_REALTEK,	0x8169), 0, 0, RTL_CFG_0 },
-	{ PCI_VENDOR_ID_DLINK,			0x4300,
-		PCI_VENDOR_ID_DLINK, 0x4b10,		 0, 0, RTL_CFG_1 },
+	/*{ PCI_VENDOR_ID_DLINK,			0x4300,
+		PCI_VENDOR_ID_DLINK, 0x4b10,		 0, 0, RTL_CFG_1 },*/
 	{ PCI_DEVICE(PCI_VENDOR_ID_DLINK,	0x4300), 0, 0, RTL_CFG_0 },
 	{ PCI_DEVICE(PCI_VENDOR_ID_DLINK,	0x4302), 0, 0, RTL_CFG_0 },
 	{ PCI_DEVICE(PCI_VENDOR_ID_AT,		0xc107), 0, 0, RTL_CFG_0 },
@@ -1696,6 +1698,14 @@ static void rtl8169_check_link_status(st
 
 #define WAKE_ANY (WAKE_PHY | WAKE_MAGIC | WAKE_UCAST | WAKE_BCAST | WAKE_MCAST)
 
+// lugmair@igel.com kernel patch
+/* 
+ *  waffler@igel.de :	for some reason the chip doesn't wake up
+ *			by any method if BCAST is involved
+ * 		        the hotfix is not to declare WAKE_BCAST as supported
+ */
+#define WAKE_SUP (WAKE_PHY | WAKE_MAGIC | WAKE_UCAST | WAKE_MCAST)
+
 static u32 __rtl8169_get_wol(struct rtl8169_private *tp)
 {
 	void __iomem *ioaddr = tp->mmio_addr;
@@ -1756,7 +1766,10 @@ static void rtl8169_get_wol(struct net_d
 
 	rtl_lock_work(tp);
 
-	wol->supported = WAKE_ANY;
+	// lugmair@igel.com Frage
+	/*lang@igel: remove WAKE_BCAST from supported list */
+	/*wol->supported = WAKE_ANY;*/
+	wol->supported = WAKE_SUP;
 	if (pm_runtime_active(d))
 		wol->wolopts = __rtl8169_get_wol(tp);
 	else
@@ -1933,24 +1946,45 @@ static int rtl8169_set_speed_xmii(struct
 	int giga_ctrl, bmcr;
 	int rc = -EINVAL;
 
+	// lugmair@igel.com Kernel patch
+	netif_info(tp, drv, dev, "set speed and duplex configuration mii based\n");
+
 	rtl_writephy(tp, 0x1f, 0x0000);
 
-	if (autoneg == AUTONEG_ENABLE) {
+	if ((autoneg == AUTONEG_ENABLE) || 
+	    (tp->mii.supports_gmii && (speed == SPEED_1000))) {
 		int auto_nego;
+		int force_speed_1000 = 0;
+
+		/*
+		 * lang@igel.de[01/04/11]: we want to configure the advertise
+		 * values with ethtool, if the network chip does not support
+		 * 1000Mbps, remove the 1000Mbps advertise values;
+		 * if 1000Mbps is forced: auto-negotiation is mandatory
+		 */
+		if ((autoneg != AUTONEG_ENABLE) && (speed == SPEED_1000)) {
+			force_speed_1000 = 1;
+			netif_info(tp, drv, dev, "speed 1000 forced, but autoneg mandatory\n");
+		}
+
+		netif_info(tp, drv, dev, "autoneg enabled\n");
 
 		auto_nego = rtl_readphy(tp, MII_ADVERTISE);
 		auto_nego &= ~(ADVERTISE_10HALF | ADVERTISE_10FULL |
 				ADVERTISE_100HALF | ADVERTISE_100FULL);
 
-		if (adv & ADVERTISED_10baseT_Half)
-			auto_nego |= ADVERTISE_10HALF;
-		if (adv & ADVERTISED_10baseT_Full)
-			auto_nego |= ADVERTISE_10FULL;
-		if (adv & ADVERTISED_100baseT_Half)
-			auto_nego |= ADVERTISE_100HALF;
-		if (adv & ADVERTISED_100baseT_Full)
-			auto_nego |= ADVERTISE_100FULL;
-
+		// lugmair@igel.com
+		// old way without autoneg
+		if (! force_speed_1000) {
+			if (adv & ADVERTISED_10baseT_Half)
+				auto_nego |= ADVERTISE_10HALF;
+			if (adv & ADVERTISED_10baseT_Full)
+				auto_nego |= ADVERTISE_10FULL;
+			if (adv & ADVERTISED_100baseT_Half)
+				auto_nego |= ADVERTISE_100HALF;
+			if (adv & ADVERTISED_100baseT_Full)
+				auto_nego |= ADVERTISE_100FULL;
+		}
 		auto_nego |= ADVERTISE_PAUSE_CAP | ADVERTISE_PAUSE_ASYM;
 
 		giga_ctrl = rtl_readphy(tp, MII_CTRL1000);
@@ -1958,15 +1992,35 @@ static int rtl8169_set_speed_xmii(struct
 
 		/* The 8100e/8101e/8102e do Fast Ethernet only. */
 		if (tp->mii.supports_gmii) {
-			if (adv & ADVERTISED_1000baseT_Half)
-				giga_ctrl |= ADVERTISE_1000HALF;
-			if (adv & ADVERTISED_1000baseT_Full)
-				giga_ctrl |= ADVERTISE_1000FULL;
+			/* lang@igel.de: r8169 does not support 1000baseT-HD;
+			   check if 1000Mbps is forced */
+			if (tp->mac_version > RTL_GIGA_MAC_VER_06) {
+				if ((adv & ADVERTISED_1000baseT_Half) || 
+				    force_speed_1000)
+					giga_ctrl |= ADVERTISE_1000HALF;
+			} else {
+				netif_info(tp, drv, dev, "PHY does not support 1000baseT-HD. "
+                                         "(mac_version=0x%02x)\n",
+                                         tp->mac_version);	
+			}
+			if ((adv & ADVERTISED_1000baseT_Full) || 
+			    force_speed_1000){
+					giga_ctrl |= ADVERTISE_1000FULL;
+			}
+
+			netif_info(tp, drv, dev, "PHY supports 1000Mbps. "
+					 "(mac_version=0x%02x)\n", 
+					 tp->mac_version);
 		} else if (adv & (ADVERTISED_1000baseT_Half |
-				  ADVERTISED_1000baseT_Full)) {
-			netif_info(tp, link, dev,
-				   "PHY does not support 1000Mbps\n");
-			goto out;
+	    		  ADVERTISED_1000baseT_Full) || force_speed_1000) {
+	
+			netif_info(tp, drv, dev, "PHY does not support 1000Mbps. "
+					 "(mac_version=0x%02x)\n",
+					 tp->mac_version);
+			/* lang@igel.de: continue without advertising 1000baseT;
+			if 1000baseT is forced -> return error */
+			if (force_speed_1000)
+				goto out;
 		}
 
 		bmcr = BMCR_ANENABLE | BMCR_ANRESTART;
@@ -1974,14 +2028,25 @@ static int rtl8169_set_speed_xmii(struct
 		rtl_writephy(tp, MII_ADVERTISE, auto_nego);
 		rtl_writephy(tp, MII_CTRL1000, giga_ctrl);
 	} else {
+		// lugmair@igel.com: kernel patch
+		netif_info(tp, drv, dev, "autoneg disabled\n");
 		giga_ctrl = 0;
 
-		if (speed == SPEED_10)
+		if (speed == SPEED_10) {
+			netif_info(tp, drv, dev, "speed 10\n");
 			bmcr = 0;
-		else if (speed == SPEED_100)
+		} else if (speed == SPEED_100) {
+			netif_info(tp, drv, dev, "speed 100\n");
 			bmcr = BMCR_SPEED100;
-		else
+		} else if (speed == SPEED_1000) {
+			netif_info(tp, drv, dev, "PHY does not support 1000Mbps. "
+					 "(mac_version=0x%02x), aborting\n",
+					 tp->mac_version);
+ 			goto out;
+		} else {
+			netif_info(tp, drv, dev, "speed invalid, aborting\n");
 			goto out;
+		}
 
 		if (duplex == DUPLEX_FULL)
 			bmcr |= BMCR_FULLDPLX;
@@ -4488,6 +4553,8 @@ static void rtl_rar_set(struct rtl8169_p
 
 static int rtl_set_mac_address(struct net_device *dev, void *p)
 {
+	/* lang@igel.de: do not change MAC address */
+#if 0
 	struct rtl8169_private *tp = netdev_priv(dev);
 	struct device *d = &tp->pci_dev->dev;
 	struct sockaddr *addr = p;
@@ -4505,6 +4572,9 @@ static int rtl_set_mac_address(struct ne
 	pm_runtime_put_noidle(d);
 
 	return 0;
+#else
+	return -EPERM;
+#endif
 }
 
 static int rtl8169_ioctl(struct net_device *dev, struct ifreq *ifr, int cmd)
@@ -4612,13 +4682,19 @@ static void rtl_wol_suspend_quirk(struct
 	void __iomem *ioaddr = tp->mmio_addr;
 
 	switch (tp->mac_version) {
-	case RTL_GIGA_MAC_VER_25:
-	case RTL_GIGA_MAC_VER_26:
+	// lugmair@igel.com kernel patches
+	/* lang@igel: use quirk also for: 8111c/8168c and  8111d/8168d */
+	case RTL_GIGA_MAC_VER_18 ... RTL_GIGA_MAC_VER_28:
 	case RTL_GIGA_MAC_VER_29:
 	case RTL_GIGA_MAC_VER_30:
+	case RTL_GIGA_MAC_VER_31:
 	case RTL_GIGA_MAC_VER_32:
 	case RTL_GIGA_MAC_VER_33:
 	case RTL_GIGA_MAC_VER_34:
+	/* lang@igel: use quirk also for: 8111f/8168f */
+	case RTL_GIGA_MAC_VER_35:
+	case RTL_GIGA_MAC_VER_36:
+		netif_info(tp, drv, tp->dev, "using rtl_wol_suspend_quirk\n");
 	case RTL_GIGA_MAC_VER_37:
 	case RTL_GIGA_MAC_VER_38:
 	case RTL_GIGA_MAC_VER_39:
@@ -7978,7 +8054,8 @@ static void rtl_shutdown(struct pci_dev
 	rtl8169_net_suspend(dev);
 
 	/* Restore original MAC address */
-	rtl_rar_set(tp, dev->perm_addr);
+	/* lang@igel.de: do not change MAC address */
+	/*rtl_rar_set(tp, dev->perm_addr);*/
 
 	rtl8169_hw_reset(tp);
 
@@ -8023,7 +8100,9 @@ static void rtl_remove_one(struct pci_de
 		pm_runtime_get_noresume(&pdev->dev);
 
 	/* restore original MAC address */
-	rtl_rar_set(tp, dev->perm_addr);
+	// lugmair@igel.com kernel patches
+	/* lang@igel.de: do not change MAC address */
+	/*rtl_rar_set(tp, dev->perm_addr);*/
 
 	rtl_disable_msi(pdev, tp);
 	rtl8169_release_board(pdev, dev, tp->mmio_addr);
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/net/wireless/ath/ath10k/ce.c linux-4.10.x/drivers/net/wireless/ath/ath10k/ce.c
--- linux-4.10.x.ori/drivers/net/wireless/ath/ath10k/ce.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/net/wireless/ath/ath10k/ce.c	2017-05-12 08:00:57.801800000 +0200
@@ -595,6 +595,7 @@ int ath10k_ce_completed_send_next_nolock
 	unsigned int nentries_mask = src_ring->nentries_mask;
 	unsigned int sw_index = src_ring->sw_index;
 	unsigned int read_index;
+	struct ce_desc *desc;
 
 	if (src_ring->hw_index == sw_index) {
 		/*
@@ -624,6 +625,9 @@ int ath10k_ce_completed_send_next_nolock
 
 	/* sanity */
 	src_ring->per_transfer_context[sw_index] = NULL;
+	desc = CE_SRC_RING_TO_DESC(src_ring->base_addr_owner_space,
+				   sw_index);
+	desc->nbytes = 0;
 
 	/* Update sw_index */
 	sw_index = CE_RING_IDX_INCR(nentries_mask, sw_index);
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/net/wireless/ath/ath10k/core.c linux-4.10.x/drivers/net/wireless/ath/ath10k/core.c
--- linux-4.10.x.ori/drivers/net/wireless/ath/ath10k/core.c	2017-07-26 08:43:46.546116000 +0200
+++ linux-4.10.x/drivers/net/wireless/ath/ath10k/core.c	2017-07-31 14:37:58.463848000 +0200
@@ -33,12 +33,17 @@
 #include "testmode.h"
 #include "wmi-ops.h"
 
-unsigned int ath10k_debug_mask;
+unsigned int ath10k_debug_mask = 0x0 | ATH10K_DBG_NO_DBGLOG;
 static unsigned int ath10k_cryptmode_param;
 static bool uart_print;
 static bool skip_otp;
 static bool rawmode;
 
+static int _modparam_override_eeprom_regdomain = -1;
+module_param_named(override_eeprom_regdomain,
+		   _modparam_override_eeprom_regdomain, int, 0444);
+MODULE_PARM_DESC(override_eeprom_regdomain, "Override regdomain hardcoded in EEPROM with this value (DANGEROUS).");
+
 module_param_named(debug_mask, ath10k_debug_mask, uint, 0644);
 module_param_named(cryptmode, ath10k_cryptmode_param, uint, 0644);
 module_param(uart_print, bool, 0644);
@@ -329,6 +334,20 @@ static const char *const ath10k_core_fw_
 	[ATH10K_FW_FEATURE_BTCOEX_PARAM] = "btcoex-param",
 	[ATH10K_FW_FEATURE_SKIP_NULL_FUNC_WAR] = "skip-null-func-war",
 	[ATH10K_FW_FEATURE_ALLOWS_MESH_BCAST] = "allows-mesh-bcast",
+	[ATH10K_FW_FEATURE_WMI_10X_CT] = "wmi-10.x-CT",
+	[ATH10K_FW_FEATURE_CT_RXSWCRYPT] = "rxswcrypt-CT",
+	[ATH10K_FW_FEATURE_HAS_TXSTATUS_NOACK] = "txstatus-noack",
+	[ATH10K_FW_FEATURE_CT_RATEMASK] = "ratemask-CT",
+	[ATH10K_FW_FEATURE_HAS_SAFE_BURST] = "safe-burst",
+	[ATH10K_FW_FEATURE_REGDUMP_CT] = "regdump-CT",
+	[ATH10K_FW_FEATURE_TXRATE_CT] = "txrate-CT",
+	[ATH10K_FW_FEATURE_FLUSH_ALL_CT] = "flush-all-CT",
+	[ATH10K_FW_FEATURE_PINGPONG_READ_CT] = "pingpong-CT",
+	[ATH10K_FW_FEATURE_SKIP_CH_RES_CT] = "ch-regs-CT",
+	[ATH10K_FW_FEATURE_NOP_CT] = "nop-CT",
+	[ATH10K_FW_FEATURE_HTT_MGT_CT] = "htt-mgt-CT",
+	[ATH10K_FW_FEATURE_SET_SPECIAL_CT] = "set-special-CT",
+	[ATH10K_FW_FEATURE_NO_BMISS_CT] = "no-bmiss-CT",
 };
 
 static unsigned int ath10k_core_get_fw_feature_str(char *buf,
@@ -386,6 +405,22 @@ static int ath10k_init_configure_target(
 		return ret;
 	}
 
+	/* Configure HTC credits logic. */
+	param_host = (TARGET_HTC_MAX_CONTROL_BUFFERS << 16);
+	param_host |= (TARGET_HTC_MAX_PENDING_TXCREDITS_RPTS << 20);
+
+	/* Max tx buffers (tx-credits), CT firmware only.
+	 * but normal .487 firmware will just ignore it fine.
+	 */
+	param_host |= (TARGET_HTC_MAX_TX_CREDITS_CT << 24);
+
+	ret = ath10k_bmi_write32(ar, hi_mbox_io_block_sz,
+				 param_host);
+	if (ret) {
+		ath10k_err(ar, "failed setting HTC mbox-io-block-sz\n");
+		return ret;
+	}
+
 	/* set the firmware mode to STA/IBSS/AP */
 	ret = ath10k_bmi_read32(ar, hi_option_flag, &param_host);
 	if (ret) {
@@ -696,8 +731,14 @@ static int ath10k_core_get_board_id_from
 		   "boot get otp board id result 0x%08x board_id %d chip_id %d\n",
 		   result, board_id, chip_id);
 
-	if ((result & ATH10K_BMI_BOARD_ID_STATUS_MASK) != 0)
+	/* gottwald@igel.com fix Q6174 issue (Dell Latitude) with patch from
+	 * https://patchwork.kernel.org/patch/9486941/ */
+
+	if ((result & ATH10K_BMI_BOARD_ID_STATUS_MASK) != 0 ||
+	    (board_id == 0)) {
+		ath10k_warn(ar, "board id does not exist in otp, ignore it\n");
 		return -EOPNOTSUPP;
+	}
 
 	ar->id.bmi_ids_valid = true;
 	ar->id.bmi_board_id = board_id;
@@ -880,6 +921,10 @@ static void ath10k_core_free_firmware_fi
 
 	ath10k_swap_code_seg_release(ar, &ar->normal_mode_fw.fw_file);
 
+	if (!IS_ERR(ar->fwcfg_file))
+		release_firmware(ar->fwcfg_file);
+	ar->fwcfg_file = NULL;
+
 	ar->normal_mode_fw.fw_file.otp_data = NULL;
 	ar->normal_mode_fw.fw_file.otp_len = 0;
 
@@ -903,9 +948,15 @@ static int ath10k_fetch_cal_file(struct
 	if (!IS_ERR(ar->pre_cal_file))
 		goto success;
 
-	/* cal-<bus>-<id>.bin */
-	scnprintf(filename, sizeof(filename), "cal-%s-%s.bin",
-		  ath10k_bus_str(ar->hif.bus), dev_name(ar->dev));
+	if (ar->fwcfg.calname[0]) {
+		/* Use user-specified file name. */
+		strncpy(filename, ar->fwcfg.calname, sizeof(filename));
+		filename[sizeof(filename) - 1] = 0;
+	} else {
+		/* cal-<bus>-<id>.bin */
+		scnprintf(filename, sizeof(filename), "cal-%s-%s.bin",
+			  ath10k_bus_str(ar->hif.bus), dev_name(ar->dev));
+	}
 
 	ar->cal_file = ath10k_fetch_fw_file(ar, ATH10K_FW_DIR, filename);
 	if (IS_ERR(ar->cal_file))
@@ -918,6 +969,224 @@ success:
 	return 0;
 }
 
+static int ath10k_fetch_fwcfg_file(struct ath10k *ar)
+{
+	char filename[100];
+	const char* buf;
+	size_t i = 0;
+	char val[100];
+	size_t key_idx;
+	size_t val_idx;
+	char c;
+	size_t sz;
+	long t;
+
+	ar->fwcfg.flags = 0;
+
+	/* fwcfg-<bus>-<id>.txt */
+	/* If this changes, change ath10k_read_fwinfo as well. */
+	scnprintf(filename, sizeof(filename), "fwcfg-%s-%s.txt",
+		  ath10k_bus_str(ar->hif.bus), dev_name(ar->dev));
+
+	ar->fwcfg_file = ath10k_fetch_fw_file(ar, ATH10K_FW_DIR, filename);
+	if (IS_ERR(ar->fwcfg_file)) {
+		/* FW config file is optional, don't be scary. */
+		ath10k_dbg(ar, ATH10K_DBG_BOOT,
+			   "Could not find firmware config file %s/%s, continuing with defaults.\n",
+			   ATH10K_FW_DIR, filename);
+		return PTR_ERR(ar->fwcfg_file);
+	}
+
+	ath10k_dbg(ar, ATH10K_DBG_BOOT, "found firmware config file %s/%s\n",
+		   ATH10K_FW_DIR, filename);
+
+	/* Now, attempt to parse results.
+	 * Format is key=value
+	 */
+	buf = (const char*)(ar->fwcfg_file->data);
+	while (i < ar->fwcfg_file->size) {
+start_again:
+		/* First, eat space, or entire line if we have # as first char */
+		c = buf[i];
+		while (isspace(c)) {
+			i++;
+			if (i >= ar->fwcfg_file->size)
+				goto done;
+			c = buf[i];
+		}
+		/* Eat comment ? */
+		if (c == '#') {
+			i++;
+			while (i < ar->fwcfg_file->size) {
+				c = buf[i];
+				i++;
+				if (c == '\n')
+					goto start_again;
+			}
+			/* Found no newline, must be done. */
+			goto done;
+		}
+
+		/* If here, we have start of token, store it in 'filename' to save space */
+		key_idx = 0;
+		while (i < ar->fwcfg_file->size) {
+			c = buf[i];
+			if (c == '=') {
+				i++;
+				c = buf[i];
+				/* Eat any space after the '=' sign. */
+				while (i < ar->fwcfg_file->size) {
+					if (!isspace(c)) {
+						break;
+					}
+					i++;
+					c = buf[i];
+				}
+				break;
+			}
+			if (isspace(c)) {
+				i++;
+				continue;
+			}
+			filename[key_idx] = c;
+			key_idx++;
+			if (key_idx >= sizeof(filename)) {
+				/* Too long, bail out. */
+				goto done;
+			}
+			i++;
+		}
+		filename[key_idx] = 0; /* null terminate */
+
+		/* We have found the key, now find the value */
+		val_idx = 0;
+		while (i < ar->fwcfg_file->size) {
+			c = buf[i];
+			if (isspace(c))
+				break;
+			val[val_idx] = c;
+			val_idx++;
+			if (val_idx >= sizeof(val)) {
+				/* Too long, bail out. */
+				goto done;
+			}
+			i++;
+		}
+		val[val_idx] = 0; /* null terminate value */
+
+		/* We have key and value now. */
+		ath10k_warn(ar, "fwcfg key: %s  val: %s\n",
+			    filename, val);
+
+		/* Assign key and values as appropriate */
+		if (strcasecmp(filename, "calname") == 0) {
+			sz = sizeof(ar->fwcfg.calname);
+			strncpy(ar->fwcfg.calname, val, sz);
+			ar->fwcfg.calname[sz - 1] = 0; /* ensure null term */
+		}
+		else if (strcasecmp(filename, "fwname") == 0) {
+			sz = sizeof(ar->fwcfg.fwname);
+			strncpy(ar->fwcfg.fwname, val, sz);
+			ar->fwcfg.fwname[sz - 1] = 0; /* ensure null term */
+		}
+		else if (strcasecmp(filename, "fwver") == 0) {
+			if (kstrtol(val, 0, &t) == 0) {
+				ar->fwcfg.fwver = t;
+				ar->fwcfg.flags |= ATH10K_FWCFG_FWVER;
+			}
+		}
+		else if (strcasecmp(filename, "vdevs") == 0) {
+			if (kstrtol(val, 0, &t) == 0) {
+				ar->fwcfg.vdevs = t;
+				ar->fwcfg.flags |= ATH10K_FWCFG_VDEVS;
+			}
+		}
+		else if (strcasecmp(filename, "stations") == 0) {
+			if (kstrtol(val, 0, &t) == 0) {
+				ar->fwcfg.stations = t;
+				ar->fwcfg.flags |= ATH10K_FWCFG_STATIONS;
+			}
+		}
+		else if (strcasecmp(filename, "peers") == 0) {
+			if (kstrtol(val, 0, &t) == 0) {
+				ar->fwcfg.peers = t;
+				ar->fwcfg.flags |= ATH10K_FWCFG_PEERS;
+			}
+		}
+		else if (strcasecmp(filename, "nohwcrypt") == 0) {
+			if (kstrtol(val, 0, &t) == 0) {
+				ar->fwcfg.nohwcrypt = t;
+				ar->fwcfg.flags |= ATH10K_FWCFG_NOHWCRYPT;
+			}
+		}
+		else if (strcasecmp(filename, "rate_ctrl_objs") == 0) {
+			if (kstrtol(val, 0, &t) == 0) {
+				ar->fwcfg.rate_ctrl_objs = t;
+				ar->fwcfg.flags |= ATH10K_FWCFG_RATE_CTRL_OBJS;
+			}
+		}
+		else if (strcasecmp(filename, "tx_desc") == 0) {
+			if (kstrtol(val, 0, &t) == 0) {
+				ar->fwcfg.tx_desc = t;
+				ar->fwcfg.flags |= ATH10K_FWCFG_TX_DESC;
+			}
+		}
+		else if (strcasecmp(filename, "max_nss") == 0) {
+			if (kstrtol(val, 0, &t) == 0) {
+				ar->fwcfg.max_nss = t;
+				ar->fwcfg.flags |= ATH10K_FWCFG_MAX_NSS;
+			}
+		}
+		else if (strcasecmp(filename, "tids") == 0) {
+			if (kstrtol(val, 0, &t) == 0) {
+				ar->fwcfg.num_tids = t;
+				ar->fwcfg.flags |= ATH10K_FWCFG_NUM_TIDS;
+			}
+		}
+		else if (strcasecmp(filename, "active_peers") == 0) {
+			if (kstrtol(val, 0, &t) == 0) {
+				ar->fwcfg.active_peers = t;
+				ar->fwcfg.flags |= ATH10K_FWCFG_ACTIVE_PEERS;
+			}
+		}
+		else if (strcasecmp(filename, "skid_limit") == 0) {
+			if (kstrtol(val, 0, &t) == 0) {
+				ar->fwcfg.skid_limit = t;
+				ar->fwcfg.flags |= ATH10K_FWCFG_SKID_LIMIT;
+			}
+		}
+		else if (strcasecmp(filename, "regdom") == 0) {
+			if (kstrtol(val, 0, &t) == 0) {
+				ar->fwcfg.regdom = t;
+				ar->fwcfg.flags |= ATH10K_FWCFG_REGDOM;
+			}
+		}
+		else if (strcasecmp(filename, "bmiss_vdevs") == 0) {
+			if (kstrtol(val, 0, &t) == 0) {
+				ar->fwcfg.bmiss_vdevs = t;
+				ar->fwcfg.flags |= ATH10K_FWCFG_BMISS_VDEVS;
+			}
+		}
+		else if (strcasecmp(filename, "max_amsdus") == 0) {
+			if (kstrtol(val, 0, &t) == 0) {
+				ar->fwcfg.max_amsdus = t;
+				ar->fwcfg.flags |= ATH10K_FWCFG_MAX_AMSDUS;
+				if (ar->fwcfg.max_amsdus > 31) {
+					ath10k_warn(ar, "Invalid fwcfg max_amsdus value: %d.  Must not be greater than 31.\n",
+						    ar->fwcfg.max_amsdus);
+					ar->fwcfg.max_amsdus = 31;
+				}
+			}
+		}
+		else {
+			ath10k_warn(ar, "Unknown fwcfg key name -:%s:-, val: %s\n",
+				    filename, val);
+		}
+	}
+done:
+	return 0;
+}
+
 static int ath10k_core_fetch_board_data_api_1(struct ath10k *ar)
 {
 	if (!ar->hw_params.fw.board) {
@@ -1125,6 +1394,10 @@ out:
 		goto err;
 	}
 
+	/* Save firmware board name so we can display it later. */
+	strlcpy(ar->normal_mode_fw.fw_file.fw_board_name, filename,
+		sizeof(ar->normal_mode_fw.fw_file.fw_board_name));
+
 	return 0;
 
 err:
@@ -1191,6 +1464,13 @@ success:
 	return 0;
 }
 
+struct ath10k_bss_rom_ie {
+	__le32 ram_addr;
+	__le32 ram_len;
+	__le32 rom_addr;
+	__le32 rom_len;
+} __packed;
+
 int ath10k_core_fetch_firmware_api_n(struct ath10k *ar, const char *name,
 				     struct ath10k_fw_file *fw_file)
 {
@@ -1199,6 +1479,7 @@ int ath10k_core_fetch_firmware_api_n(str
 	struct ath10k_fw_ie *hdr;
 	const u8 *data;
 	__le32 *timestamp, *version;
+	struct ath10k_bss_rom_ie *bss;
 
 	/* first fetch the firmware file (firmware-*.bin) */
 	fw_file->firmware = ath10k_fetch_fw_file(ar, ar->hw_params.fw.dir,
@@ -1316,6 +1597,12 @@ int ath10k_core_fetch_firmware_api_n(str
 
 			break;
 		case ATH10K_FW_IE_WMI_OP_VERSION:
+			/* Upstream stole the ID CT firmware was using, so add
+			 * hack-around to deal with backwards-compat. --Ben
+			 */
+			if (ie_len >= sizeof(*bss))
+				goto fw_ie_bss_info_ct;
+
 			if (ie_len != sizeof(u32))
 				break;
 
@@ -1344,6 +1631,40 @@ int ath10k_core_fetch_firmware_api_n(str
 			fw_file->codeswap_data = data;
 			fw_file->codeswap_len = ie_len;
 			break;
+		case ATH10K_FW_IE_BSS_INFO_CT:
+fw_ie_bss_info_ct:
+			if (ie_len < sizeof(*bss)) {
+				ath10k_warn(ar, "invalid ie len for bss-info (%zd)\n",
+					    ie_len);
+				break;
+			}
+			bss = (struct ath10k_bss_rom_ie *)(data);
+
+			fw_file->ram_bss_addr = le32_to_cpu(bss->ram_addr);
+			fw_file->ram_bss_len = le32_to_cpu(bss->ram_len);
+			ath10k_dbg(ar, ATH10K_DBG_BOOT,
+				   "found RAM BSS addr 0x%x length %d\n",
+				   fw_file->ram_bss_addr, fw_file->ram_bss_len);
+
+			if (fw_file->ram_bss_len > ATH10K_RAM_BSS_BUF_LEN) {
+				ath10k_warn(ar, "too long firmware RAM BSS length: %d\n",
+					    fw_file->ram_bss_len);
+				fw_file->ram_bss_len = 0;
+			}
+
+			fw_file->rom_bss_addr = le32_to_cpu(bss->rom_addr);
+			fw_file->rom_bss_len = le32_to_cpu(bss->rom_len);
+			ath10k_dbg(ar, ATH10K_DBG_BOOT,
+				   "found ROM BSS addr 0x%x length %d\n",
+				   fw_file->rom_bss_addr, fw_file->rom_bss_len);
+
+			if (fw_file->rom_bss_len > ATH10K_ROM_BSS_BUF_LEN) {
+				ath10k_warn(ar, "too long firmware ROM BSS length: %d\n",
+					    fw_file->rom_bss_len);
+				fw_file->rom_bss_len = 0;
+			}
+
+			break;
 		default:
 			ath10k_warn(ar, "Unknown FW IE: %u\n",
 				    le32_to_cpu(hdr->id));
@@ -1365,6 +1686,23 @@ int ath10k_core_fetch_firmware_api_n(str
 		goto err;
 	}
 
+	/* Only CT firmware has BSS stuff, so we can use this to fix up
+	 * flags for backwards and forwards compat with older/newer CT firmware.
+	 * (upstream stole some bits it was using)
+	 */
+	if (fw_file->rom_bss_addr) {
+		if (test_bit(5, fw_file->fw_features))
+			__set_bit(ATH10K_FW_FEATURE_WMI_10X_CT,
+				  fw_file->fw_features);
+
+		if (test_bit(6, fw_file->fw_features))
+			__set_bit(ATH10K_FW_FEATURE_CT_RXSWCRYPT,
+				  fw_file->fw_features);
+	}
+
+	/* Save firmware name so we can display it later. */
+	strlcpy(fw_file->fw_name, name, sizeof(fw_file->fw_name));
+
 	return 0;
 
 err:
@@ -1376,8 +1714,21 @@ static int ath10k_core_fetch_firmware_fi
 {
 	int ret;
 
-	/* calibration file is optional, don't check for any errors */
-	ath10k_fetch_cal_file(ar);
+	/* First, see if we have a special config file for this firmware. */
+	ath10k_fetch_fwcfg_file(ar);
+
+	/* Check for user-specified firmware name. */
+	if (ar->fwcfg.fwname[0] && (ar->fwcfg.flags & ATH10K_FWCFG_FWVER)) {
+		ar->fw_api = ar->fwcfg.fwver;
+		ath10k_dbg(ar, ATH10K_DBG_BOOT,
+			   "trying user-specified fw %s api %d\n",
+			   ar->fwcfg.fwname, ar->fw_api);
+
+		ret = ath10k_core_fetch_firmware_api_n(ar, ar->fwcfg.fwname,
+				&ar->normal_mode_fw.fw_file);
+		if (ret == 0)
+			goto success;
+	}
 
 	ar->fw_api = 5;
 	ath10k_dbg(ar, ATH10K_DBG_BOOT, "trying fw api %d\n", ar->fw_api);
@@ -1412,7 +1763,9 @@ static int ath10k_core_fetch_firmware_fi
 		return ret;
 
 success:
-	ath10k_dbg(ar, ATH10K_DBG_BOOT, "using fw api %d\n", ar->fw_api);
+	ath10k_dbg(ar, ATH10K_DBG_BOOT, "using fw api %d: %s/%s\n",
+		   ar->fw_api, ar->hw_params.fw.dir,
+		   ar->normal_mode_fw.fw_file.fw_name);
 
 	return 0;
 }
@@ -1567,7 +1920,8 @@ static int ath10k_init_uart(struct ath10
 		return ret;
 	}
 
-	ath10k_info(ar, "UART prints enabled\n");
+	ath10k_info(ar, "UART prints enabled: 19200, tx-pin: %d\n",
+		    ar->hw_params.uart_pin);
 	return 0;
 }
 
@@ -1743,8 +2097,51 @@ static int ath10k_core_init_firmware_fea
 		}
 	}
 
+	/* Backwards compatibility for firmwares without
+	 * ATH10K_FW_IE_HTT_OP_VERSION.
+	 */
+	if (fw_file->htt_op_version == ATH10K_FW_HTT_OP_VERSION_UNSET) {
+		switch (fw_file->wmi_op_version) {
+		case ATH10K_FW_WMI_OP_VERSION_MAIN:
+			fw_file->htt_op_version = ATH10K_FW_HTT_OP_VERSION_MAIN;
+			break;
+		case ATH10K_FW_WMI_OP_VERSION_10_1:
+		case ATH10K_FW_WMI_OP_VERSION_10_2:
+		case ATH10K_FW_WMI_OP_VERSION_10_2_4:
+			fw_file->htt_op_version = ATH10K_FW_HTT_OP_VERSION_10_1;
+			break;
+		case ATH10K_FW_WMI_OP_VERSION_TLV:
+			fw_file->htt_op_version = ATH10K_FW_HTT_OP_VERSION_TLV;
+			break;
+		case ATH10K_FW_WMI_OP_VERSION_10_4:
+		case ATH10K_FW_WMI_OP_VERSION_UNSET:
+		case ATH10K_FW_WMI_OP_VERSION_MAX:
+			WARN_ON(1);
+			return -EINVAL;
+		}
+	}
+
+	/* CT 10.1 firmware slowly added features, all mostly under one feature
+	 * flag.  But, for 10.2, I need to add features at a time so that we can
+	 * maintain ability to bisect the firmware and to have fine-grained support
+	 * for enabling/disabling firmware features.  For backwards-compt with 10.1
+	 * firmware, set all the flags here.
+	 */
+	if (test_bit(ATH10K_FW_FEATURE_WMI_10X_CT, fw_file->fw_features) &&
+	    (fw_file->wmi_op_version == ATH10K_FW_WMI_OP_VERSION_10_1)) {
+		__set_bit(ATH10K_FW_FEATURE_SET_SPECIAL_CT, fw_file->fw_features);
+		__set_bit(ATH10K_FW_FEATURE_REGDUMP_CT, fw_file->fw_features);
+		__set_bit(ATH10K_FW_FEATURE_TXRATE_CT, fw_file->fw_features);
+		__set_bit(ATH10K_FW_FEATURE_FLUSH_ALL_CT, fw_file->fw_features);
+		__set_bit(ATH10K_FW_FEATURE_PINGPONG_READ_CT, fw_file->fw_features);
+		__set_bit(ATH10K_FW_FEATURE_SKIP_CH_RES_CT, fw_file->fw_features);
+		__set_bit(ATH10K_FW_FEATURE_NOP_CT, fw_file->fw_features);
+	}
+
 	switch (fw_file->wmi_op_version) {
 	case ATH10K_FW_WMI_OP_VERSION_MAIN:
+		ar->bmiss_offload_max_vdev = TARGET_BMISS_OFFLOAD_MAX_VDEV;
+		ar->skid_limit = TARGET_AST_SKID_LIMIT;
 		ar->max_num_peers = TARGET_NUM_PEERS;
 		ar->max_num_stations = TARGET_NUM_STATIONS;
 		ar->max_num_vdevs = TARGET_NUM_VDEVS;
@@ -1752,23 +2149,55 @@ static int ath10k_core_init_firmware_fea
 		ar->fw_stats_req_mask = WMI_STAT_PDEV | WMI_STAT_VDEV |
 			WMI_STAT_PEER;
 		ar->max_spatial_stream = WMI_MAX_SPATIAL_STREAM;
+		ar->num_tids = TARGET_NUM_TIDS;
 		break;
 	case ATH10K_FW_WMI_OP_VERSION_10_1:
+		ar->bmiss_offload_max_vdev = TARGET_10X_BMISS_OFFLOAD_MAX_VDEV;
+		ar->skid_limit = TARGET_10X_AST_SKID_LIMIT;
+		ar->num_tids = TARGET_10X_NUM_TIDS;
+		if (test_bit(ATH10K_FW_FEATURE_WMI_10X_CT,
+			     fw_file->fw_features)) {
+			ar->skid_limit = TARGET_10X_AST_SKID_LIMIT_CT;
+			ar->max_num_peers = ath10k_modparam_target_num_peers_ct;
+			ar->max_num_stations = TARGET_10X_NUM_STATIONS;
+			ar->max_num_vdevs = ath10k_modparam_target_num_vdevs_ct;
+			ar->htt.max_num_pending_tx = ath10k_modparam_target_num_msdu_desc_ct;
+		} else {
+			ar->max_num_peers = TARGET_10X_NUM_PEERS;
+			ar->max_num_stations = TARGET_10X_NUM_STATIONS;
+			ar->max_num_vdevs = TARGET_10X_NUM_VDEVS;
+			ar->htt.max_num_pending_tx = TARGET_10X_NUM_MSDU_DESC;
+		}
+		ar->fw_stats_req_mask = WMI_STAT_PEER;
+		ar->max_spatial_stream = WMI_MAX_SPATIAL_STREAM;
+		break;
 	case ATH10K_FW_WMI_OP_VERSION_10_2:
 	case ATH10K_FW_WMI_OP_VERSION_10_2_4:
 		if (ath10k_peer_stats_enabled(ar)) {
 			ar->max_num_peers = TARGET_10X_TX_STATS_NUM_PEERS;
 			ar->max_num_stations = TARGET_10X_TX_STATS_NUM_STATIONS;
+			ar->num_tids = TARGET_10X_TX_STATS_NUM_TIDS;
 		} else {
 			ar->max_num_peers = TARGET_10X_NUM_PEERS;
 			ar->max_num_stations = TARGET_10X_NUM_STATIONS;
+			ar->num_tids = TARGET_10X_NUM_TIDS;
 		}
+		ar->bmiss_offload_max_vdev = TARGET_10X_BMISS_OFFLOAD_MAX_VDEV;
+		ar->skid_limit = TARGET_10X_AST_SKID_LIMIT;
 		ar->max_num_vdevs = TARGET_10X_NUM_VDEVS;
 		ar->htt.max_num_pending_tx = TARGET_10X_NUM_MSDU_DESC;
+
+		if (test_bit(ATH10K_FW_FEATURE_WMI_10X_CT,
+			     fw_file->fw_features)) {
+			ar->max_num_peers = ath10k_modparam_target_num_peers_ct;
+			ar->max_num_vdevs = ath10k_modparam_target_num_vdevs_ct;
+			ar->htt.max_num_pending_tx = ath10k_modparam_target_num_msdu_desc_ct;
+		}
 		ar->fw_stats_req_mask = WMI_STAT_PEER;
 		ar->max_spatial_stream = WMI_MAX_SPATIAL_STREAM;
 		break;
 	case ATH10K_FW_WMI_OP_VERSION_TLV:
+		ar->bmiss_offload_max_vdev = TARGET_10X_BMISS_OFFLOAD_MAX_VDEV;
 		ar->max_num_peers = TARGET_TLV_NUM_PEERS;
 		ar->max_num_stations = TARGET_TLV_NUM_STATIONS;
 		ar->max_num_vdevs = TARGET_TLV_NUM_VDEVS;
@@ -1780,6 +2209,8 @@ static int ath10k_core_init_firmware_fea
 		ar->max_spatial_stream = WMI_MAX_SPATIAL_STREAM;
 		break;
 	case ATH10K_FW_WMI_OP_VERSION_10_4:
+		ar->bmiss_offload_max_vdev = TARGET_10_4_BMISS_OFFLOAD_MAX_VDEV;
+		ar->skid_limit = TARGET_10_4_AST_SKID_LIMIT;
 		ar->max_num_peers = TARGET_10_4_NUM_PEERS;
 		ar->max_num_stations = TARGET_10_4_NUM_STATIONS;
 		ar->num_active_peers = TARGET_10_4_ACTIVE_PEERS;
@@ -1801,30 +2232,48 @@ static int ath10k_core_init_firmware_fea
 		return -EINVAL;
 	}
 
-	/* Backwards compatibility for firmwares without
-	 * ATH10K_FW_IE_HTT_OP_VERSION.
-	 */
-	if (fw_file->htt_op_version == ATH10K_FW_HTT_OP_VERSION_UNSET) {
-		switch (fw_file->wmi_op_version) {
-		case ATH10K_FW_WMI_OP_VERSION_MAIN:
-			fw_file->htt_op_version = ATH10K_FW_HTT_OP_VERSION_MAIN;
-			break;
-		case ATH10K_FW_WMI_OP_VERSION_10_1:
-		case ATH10K_FW_WMI_OP_VERSION_10_2:
-		case ATH10K_FW_WMI_OP_VERSION_10_2_4:
-			fw_file->htt_op_version = ATH10K_FW_HTT_OP_VERSION_10_1;
-			break;
-		case ATH10K_FW_WMI_OP_VERSION_TLV:
-			fw_file->htt_op_version = ATH10K_FW_HTT_OP_VERSION_TLV;
-			break;
-		case ATH10K_FW_WMI_OP_VERSION_10_4:
-		case ATH10K_FW_WMI_OP_VERSION_UNSET:
-		case ATH10K_FW_WMI_OP_VERSION_MAX:
-			ath10k_err(ar, "htt op version not found from fw meta data");
-			return -EINVAL;
-		}
+	ar->request_nohwcrypt = ath10k_modparam_nohwcrypt;
+	ar->num_ratectrl_objs = ath10k_modparam_target_num_rate_ctrl_objs_ct;
+	ar->eeprom_regdom = _modparam_override_eeprom_regdomain;
+
+	/* Apply user-specified over-rides, if any. */
+	if (ar->fwcfg.flags & ATH10K_FWCFG_VDEVS)
+		ar->max_num_vdevs = ar->fwcfg.vdevs;
+	if (ar->fwcfg.flags & ATH10K_FWCFG_PEERS)
+		ar->max_num_peers = ar->fwcfg.peers;
+	if (ar->fwcfg.flags & ATH10K_FWCFG_STATIONS)
+		ar->max_num_stations = ar->fwcfg.stations;
+	if (ar->fwcfg.flags & ATH10K_FWCFG_NOHWCRYPT)
+		ar->request_nohwcrypt = ar->fwcfg.nohwcrypt;
+	if (ar->fwcfg.flags & ATH10K_FWCFG_RATE_CTRL_OBJS)
+		ar->num_ratectrl_objs = ar->fwcfg.rate_ctrl_objs;
+	if (ar->fwcfg.flags & ATH10K_FWCFG_TX_DESC)
+		ar->htt.max_num_pending_tx = ar->fwcfg.tx_desc;
+	if (ar->fwcfg.flags & ATH10K_FWCFG_MAX_NSS)
+		ar->max_spatial_stream = ar->fwcfg.max_nss;
+	if (ar->fwcfg.flags & ATH10K_FWCFG_NUM_TIDS)
+		ar->num_tids = ar->fwcfg.num_tids;
+	if (ar->fwcfg.flags & ATH10K_FWCFG_ACTIVE_PEERS)
+		ar->num_active_peers = ar->fwcfg.active_peers;
+	if (ar->fwcfg.flags & ATH10K_FWCFG_SKID_LIMIT)
+		ar->skid_limit = ar->fwcfg.skid_limit;
+	if (ar->fwcfg.flags & ATH10K_FWCFG_REGDOM)
+		ar->eeprom_regdom = ar->fwcfg.regdom;
+	if (ar->fwcfg.flags & ATH10K_FWCFG_BMISS_VDEVS)
+		ar->bmiss_offload_max_vdev = ar->fwcfg.bmiss_vdevs;
+
+	if (!(test_bit(ATH10K_FLAG_RAW_MODE, &ar->dev_flags))) {
+		/* Don't disable raw-mode hack, but otherwise allow override */
+		if (ar->fwcfg.flags & ATH10K_FWCFG_MAX_AMSDUS)
+			ar->htt.max_num_amsdu = ar->fwcfg.max_amsdus;
 	}
 
+	/* Some firmware may compile out beacon-miss logic to save firmware RAM
+	 * and instruction RAM.
+	 */
+	if (test_bit(ATH10K_FW_FEATURE_NO_BMISS_CT, fw_file->fw_features))
+		ar->bmiss_offload_max_vdev = 0;
+
 	return 0;
 }
 
@@ -1882,6 +2331,7 @@ int ath10k_core_start(struct ath10k *ar,
 {
 	int status;
 	u32 val;
+	u32 i, band;
 
 	lockdep_assert_held(&ar->conf_mutex);
 
@@ -2099,6 +2549,78 @@ int ath10k_core_start(struct ath10k *ar,
 	if (status)
 		goto err_hif_stop;
 
+	if (test_bit(ATH10K_FW_FEATURE_HTT_MGT_CT,
+		     ar->running_fw->fw_file.fw_features)) {
+		ar->ct_all_pkts_htt = true;
+	}
+	else if (ar->running_fw->fw_file.wmi_op_version != ATH10K_FW_WMI_OP_VERSION_10_1) {
+		/* Older 10.1 firmware will not have the flag, and we check the HTT version
+		 * in htt_rx.c for it.  But, 10.4 has conflicting HTT version, so disable
+		 * this feature in newer firmware unless it explicitly has the HTT_MGT_CT feature
+		 * flag.
+		 */
+		ar->ct_all_pkts_htt = false;
+	}
+
+	if (test_bit(ATH10K_FW_FEATURE_SET_SPECIAL_CT,
+		     ar->running_fw->fw_file.fw_features)) {
+		/* Apply user-supplied configuration changes. */
+		/* Don't worry about failures..not much we can do, and not worth failing init even
+		 * if this fails.
+		 */
+		for (band = 0; band < 2; band++) {
+			u32 val;
+			for (i = 0; i<MIN_CCA_PWR_COUNT; i++) {
+				val = (band << 24) | (i << 16) | ar->eeprom_overrides.bands[band].minCcaPwrCT[i];
+				ath10k_wmi_pdev_set_special(ar, SET_SPECIAL_ID_NOISE_FLR_THRESH, val);
+			}
+
+			i = 4; /* enable-minccapwr-thresh type */
+			val = (band << 24) | (i << 16) | ar->eeprom_overrides.bands[band].enable_minccapwr_thresh;
+			ath10k_wmi_pdev_set_special(ar, SET_SPECIAL_ID_NOISE_FLR_THRESH, val);
+		}
+
+		/* TODO:  Should probably be per-band?? */
+		if (ar->eeprom_overrides.thresh62_ext) {
+			ath10k_wmi_pdev_set_special(ar, SET_SPECIAL_ID_THRESH62_EXT,
+						    ar->eeprom_overrides.thresh62_ext);
+		}
+
+		if (ar->eeprom_overrides.allow_ibss_amsdu) {
+			ath10k_wmi_pdev_set_special(ar, SET_SPECIAL_ID_IBSS_AMSDU_OK,
+						    ar->eeprom_overrides.allow_ibss_amsdu);
+		}
+
+		if (ar->eeprom_overrides.max_txpower != 0xFFFF)
+			ath10k_wmi_pdev_set_special(ar, SET_SPECIAL_ID_MAX_TXPOWER,
+						    ar->eeprom_overrides.max_txpower);
+
+		if (ar->eeprom_overrides.rc_rate_max_per_thr)
+			ath10k_wmi_pdev_set_special(ar, SET_SPECIAL_ID_RC_MAX_PER_THR,
+						    ar->eeprom_overrides.rc_rate_max_per_thr);
+
+		if (ar->eeprom_overrides.tx_sta_bw_mask)
+			ath10k_wmi_pdev_set_special(ar, SET_SPECIAL_ID_STA_TXBW_MASK,
+						    ar->eeprom_overrides.tx_sta_bw_mask);
+
+		if (ar->eeprom_overrides.pdev_xretry_th)
+			ath10k_wmi_pdev_set_special(ar, SET_SPECIAL_ID_PDEV_XRETRY_TH,
+						    ar->eeprom_overrides.pdev_xretry_th);
+
+		if (ar->eeprom_overrides.rifs_enable_override)
+			ath10k_wmi_pdev_set_special(ar, SET_SPECIAL_ID_RIFS_ENABLE,
+						    ar->eeprom_overrides.rifs_enable_override);
+		if (ar->eeprom_overrides.wmi_wd_keepalive_ms)
+			ath10k_wmi_pdev_set_special(ar, SET_SPECIAL_ID_WMI_WD,
+						    ar->eeprom_overrides.wmi_wd_keepalive_ms);
+		if (ar->eeprom_overrides.ct_pshack)
+			ath10k_wmi_pdev_set_special(ar, SET_SPECIAL_ID_PSHACK,
+						    ar->eeprom_overrides.ct_pshack);
+		if (ar->eeprom_overrides.ct_csi)
+			ath10k_wmi_pdev_set_special(ar, SET_SPECIAL_ID_CSI,
+						    ar->eeprom_overrides.ct_csi);
+	}
+
 	return 0;
 
 err_hif_stop:
@@ -2162,6 +2684,7 @@ static int ath10k_core_probe_fw(struct a
 {
 	struct bmi_target_info target_info;
 	int ret = 0;
+	int calret;
 
 	ret = ath10k_hif_power_up(ar);
 	if (ret) {
@@ -2185,6 +2708,9 @@ static int ath10k_core_probe_fw(struct a
 		goto err_power_down;
 	}
 
+	/* calibration file is optional, don't check for any errors */
+	calret = ath10k_fetch_cal_file(ar);
+
 	ret = ath10k_core_fetch_firmware_files(ar);
 	if (ret) {
 		ath10k_err(ar, "could not fetch firmware files (%d)\n", ret);
@@ -2207,11 +2733,14 @@ static int ath10k_core_probe_fw(struct a
 			   "could not load pre cal data: %d\n", ret);
 	}
 
-	ret = ath10k_core_get_board_id_from_otp(ar);
-	if (ret && ret != -EOPNOTSUPP) {
-		ath10k_err(ar, "failed to get board id from otp: %d\n",
-			   ret);
-		goto err_free_firmware_files;
+	/* otp and board file not needed if calibration data is present */
+	if (calret) {
+		ret = ath10k_core_get_board_id_from_otp(ar);
+		if (ret && ret != -EOPNOTSUPP) {
+			ath10k_err(ar, "failed to get board id from otp: %d\n",
+				ret);
+			goto err_free_firmware_files;
+		}
 	}
 
 	ret = ath10k_core_check_smbios(ar);
@@ -2335,6 +2864,16 @@ int ath10k_core_register(struct ath10k *
 }
 EXPORT_SYMBOL(ath10k_core_register);
 
+void ath10k_core_free_limits(struct ath10k* ar)
+{
+	int i;
+	for (i = 0; i < ARRAY_SIZE(ar->if_comb); i++) {
+		kfree(ar->if_comb[i].limits);
+	}
+	memset(&ar->if_comb, 0, sizeof(ar->if_comb));
+}
+EXPORT_SYMBOL(ath10k_core_free_limits);
+
 void ath10k_core_unregister(struct ath10k *ar)
 {
 	cancel_work_sync(&ar->register_work);
@@ -2359,6 +2898,8 @@ void ath10k_core_unregister(struct ath10
 	ath10k_core_free_firmware_files(ar);
 	ath10k_core_free_board_files(ar);
 
+	ath10k_core_free_limits(ar);
+
 	ath10k_debug_unregister(ar);
 }
 EXPORT_SYMBOL(ath10k_core_unregister);
@@ -2375,6 +2916,9 @@ struct ath10k *ath10k_core_create(size_t
 	if (!ar)
 		return NULL;
 
+	ar->eeprom_overrides.max_txpower = 0xFFFF;
+	ar->sta_xretry_kickout_thresh = DEFAULT_ATH10K_KICKOUT_THRESHOLD;
+
 	ar->ath_common.priv = ar;
 	ar->ath_common.hw = ar->hw;
 	ar->dev = dev;
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/net/wireless/ath/ath10k/core.h linux-4.10.x/drivers/net/wireless/ath/ath10k/core.h
--- linux-4.10.x.ori/drivers/net/wireless/ath/ath10k/core.h	2017-07-26 08:43:46.546116000 +0200
+++ linux-4.10.x/drivers/net/wireless/ath/ath10k/core.h	2017-07-26 08:43:46.546116000 +0200
@@ -54,7 +54,7 @@
 #define ATH10K_MAX_NUM_MGMT_PENDING 128
 
 /* number of failed packets (20 packets with 16 sw reties each) */
-#define ATH10K_KICKOUT_THRESHOLD (20 * 16)
+#define DEFAULT_ATH10K_KICKOUT_THRESHOLD (20 * 16)
 
 /*
  * Use insanely high numbers to make sure that the firmware implementation
@@ -290,6 +290,35 @@ struct ath10k_fw_stats {
 	struct list_head vdevs;
 	struct list_head peers;
 	struct list_head peers_extd;
+
+	/* Register and related dump, CT firmware only. */
+	u32 mac_filter_addr_l32;
+	u32 mac_filter_addr_u16;
+	u32 dcu_slot_time;
+	u32 phy_bb_mode_select;
+	u32 pcu_bssid_l32;
+	u32 pcu_bssid_u16;
+	u32 pcu_bssid2_l32;
+	u32 pcu_bssid2_u16;
+	u32 pcu_sta_addr_l32;
+	u32 pcu_sta_addr_u16;
+	u32 mac_dma_cfg;
+	u32 mac_dma_txcfg;
+	u32 pcu_rxfilter;
+	u32 phy_bb_gen_controls;
+	u32 dma_imr;
+	u32 dma_txrx_imr;
+	u32 sw_powermode;
+	u16 sw_chainmask_tx;
+	u16 sw_chainmask_rx;
+	u32 sw_opmode;
+	u32 sw_rxfilter;
+	u32 short_retries; // RTS packet retries
+	u32 long_retries; // Data packet retries
+	u32 adc_temp; /* ADC Temperature readings, one octet for each chain.
+		       * Value of 0x78 for 2,3 means not-read/not-active,
+		       * and 0x7B for 0,1 mean means the same.
+		       */
 };
 
 #define ATH10K_TPC_TABLE_TYPE_FLAG	1
@@ -331,6 +360,7 @@ struct ath10k_peer {
 	struct ieee80211_vif *vif;
 	struct ieee80211_sta *sta;
 
+	bool removed;
 	int vdev_id;
 	u8 addr[ETH_ALEN];
 	DECLARE_BITMAP(peer_ids, ATH10K_MAX_NUM_PEER_IDS);
@@ -422,9 +452,16 @@ struct ath10k_vif {
 	} u;
 
 	bool use_cts_prot;
-	bool nohwcrypt;
+	bool nohwcrypt; /* actual setting, based on firmware abilities, etc. */
 	int num_legacy_stations;
 	int txpower;
+	/* Firmware allows configuring rate of each of these traffic types.
+	 * 0xFF will mean value has not been set by user, and in that case,
+	 * we will auto-adjust the rates based on the legacy rate mask.
+	 **/
+	u8 mcast_rate[NUM_NL80211_BANDS];
+	u8 bcast_rate[NUM_NL80211_BANDS];
+	u8 mgt_rate[NUM_NL80211_BANDS];
 	struct wmi_wmm_params_all_arg wmm_params;
 	struct work_struct ap_csa_work;
 	struct delayed_work connection_loss_work;
@@ -436,6 +473,26 @@ struct ath10k_vif_iter {
 	struct ath10k_vif *arvif;
 };
 
+/* This will store at least the last 128 entries.  Each dbglog message
+ * is a max of 7 32-bit integers in length, but the length can be less
+ * than that as well.
+ */
+#define ATH10K_DBGLOG_DATA_LEN (128 * 7)
+struct ath10k_dbglog_entry_storage {
+	u32 head_idx; /* Where to write next chunk of data */
+	u32 tail_idx; /* Index of first msg */
+	__le32 data[ATH10K_DBGLOG_DATA_LEN];
+};
+
+/* Just enough info to decode firmware debug-log argument length */
+#define DBGLOG_NUM_ARGS_OFFSET           26
+#define DBGLOG_NUM_ARGS_MASK             0xFC000000 /* Bit 26-31 */
+#define DBGLOG_NUM_ARGS_MAX              5 /* firmware tool chain limit */
+
+/* estimated values, hopefully these are enough */
+#define ATH10K_ROM_BSS_BUF_LEN 30000
+#define ATH10K_RAM_BSS_BUF_LEN 55000
+
 /* used for crash-dump storage, protected by data-lock */
 struct ath10k_fw_crash_data {
 	bool crashed_since_read;
@@ -443,6 +500,12 @@ struct ath10k_fw_crash_data {
 	uuid_le uuid;
 	struct timespec timestamp;
 	__le32 registers[REG_DUMP_COUNT_QCA988X];
+	__le32 stack_buf[ATH10K_FW_STACK_SIZE / sizeof(__le32)];
+	__le32 exc_stack_buf[ATH10K_FW_STACK_SIZE / sizeof(__le32)];
+	__le32 stack_addr;
+	__le32 exc_stack_addr;
+	__le32 rom_bss_buf[ATH10K_ROM_BSS_BUF_LEN / sizeof(__le32)];
+	__le32 ram_bss_buf[ATH10K_RAM_BSS_BUF_LEN / sizeof(__le32)];
 };
 
 struct ath10k_debug {
@@ -454,6 +517,7 @@ struct ath10k_debug {
 
 	unsigned long htt_stats_mask;
 	struct delayed_work htt_stats_dwork;
+	struct delayed_work nop_dwork;
 	struct ath10k_dfs_stats dfs_stats;
 	struct ath_dfs_pool_stats dfs_pool_stats;
 
@@ -469,8 +533,22 @@ struct ath10k_debug {
 	u32 reg_addr;
 	u32 nf_cal_period;
 	void *cal_data;
+	u32 nop_id;
+
+	struct ath10k_dbglog_entry_storage dbglog_entry_data;
 
 	struct ath10k_fw_crash_data *fw_crash_data;
+
+	/* These counters are kept in software. */
+	u64 rx_bytes; /* counter, total received bytes */
+
+	u32 tx_ok; /* counter, OK tx status count. */
+	u32 tx_noack; /* counter, no-ack tx status count. */
+	u32 tx_discard; /* counter, discard tx status count. */
+	u64 tx_ok_bytes;
+	u64 tx_noack_bytes;
+	u64 tx_discard_bytes;
+	u64 tx_bytes; /* counter, total sent to firmware */
 };
 
 enum ath10k_state {
@@ -587,6 +665,57 @@ enum ath10k_fw_features {
 	 */
 	ATH10K_FW_FEATURE_ALLOWS_MESH_BCAST = 16,
 
+	/* tx-status has the noack bits (CT firmware version 14 and higher ) */
+	ATH10K_FW_FEATURE_HAS_TXSTATUS_NOACK = 30,
+
+	/* Firmware from Candela Technologies, enables more VIFs, etc */
+	ATH10K_FW_FEATURE_WMI_10X_CT = 31,
+
+	/* Firmware from Candela Technologies with rx-software-crypt.
+	 * Required for multiple stations connected to same AP when using
+	 * encryption (ie, commercial version of CT firmware) */
+	ATH10K_FW_FEATURE_CT_RXSWCRYPT = 32,
+
+	/* Firmware supports extended wmi_common_peer_assoc_complete_cmd that contains
+	 * an array of rate-disable masks.  This allows the host to have better control
+	 * over what rates the firmware will use.  CT Firmware only (v15 and higher)
+	 */
+	ATH10K_FW_FEATURE_CT_RATEMASK = 33,
+
+	/* Versions of firmware before approximately 10.2.4.72 would corrupt txop fields
+	 * during burst.  Since this is fixed now, add a flag to denote this.
+	 */
+	ATH10K_FW_FEATURE_HAS_SAFE_BURST = 34,
+
+	/* Register-dump is supported. */
+	ATH10K_FW_FEATURE_REGDUMP_CT = 35,
+
+	/* TX-Rate is reported. */
+	ATH10K_FW_FEATURE_TXRATE_CT = 36,
+
+	/* Firmware can flush all peers. */
+	ATH10K_FW_FEATURE_FLUSH_ALL_CT = 37,
+
+	/* Firmware can read memory with ping-pong protocol. */
+	ATH10K_FW_FEATURE_PINGPONG_READ_CT = 38,
+
+	/* Firmware can skip channel reservation. */
+	ATH10K_FW_FEATURE_SKIP_CH_RES_CT = 39,
+
+	/* Firmware supports NOPcan skip channel reservation. */
+	ATH10K_FW_FEATURE_NOP_CT = 40,
+
+	/* Firmware supports CT HTT MGT feature. */
+	ATH10K_FW_FEATURE_HTT_MGT_CT = 41,
+
+	/* Set-special cmd-id is supported. */
+	ATH10K_FW_FEATURE_SET_SPECIAL_CT = 42,
+
+	/* SW Beacon Miss is disabled in this kernel, so you have to
+	 * let mac80211 manage the connection.
+	 */
+	ATH10K_FW_FEATURE_NO_BMISS_CT = 43,
+
 	/* keep last */
 	ATH10K_FW_FEATURE_COUNT,
 };
@@ -683,6 +812,8 @@ enum ath10k_tx_pause_reason {
 
 struct ath10k_fw_file {
 	const struct firmware *firmware;
+	char fw_name[100];
+	char fw_board_name[100];
 
 	char fw_version[ETHTOOL_FWVERS_LEN];
 
@@ -700,6 +831,14 @@ struct ath10k_fw_file {
 	const void *codeswap_data;
 	size_t codeswap_len;
 
+	/* These are written to only during first firmware load from user
+	 * space so no need for any locking.
+	 */
+	u32 ram_bss_addr;
+	u32 ram_bss_len;
+	u32 rom_bss_addr;
+	u32 rom_bss_len;
+
 	/* The original idea of struct ath10k_fw_file was that it only
 	 * contains struct firmware and pointers to various parts (actual
 	 * firmware binary, otp, metadata etc) of the file. This seg_info
@@ -740,11 +879,15 @@ struct ath10k {
 	struct device *dev;
 	u8 mac_addr[ETH_ALEN];
 
+	struct ieee80211_iface_combination if_comb[8];
+
 	enum ath10k_hw_rev hw_rev;
 	u16 dev_id;
+	bool fw_powerup_failed; /* If true, might take reboot to recover. */
 	u32 chip_id;
 	u32 target_version;
 	u8 fw_version_major;
+	bool use_swcrypt; /* Firmware (and driver) supports rx-sw-crypt? */
 	u32 fw_version_minor;
 	u16 fw_version_release;
 	u16 fw_version_build;
@@ -761,6 +904,7 @@ struct ath10k {
 	bool ani_enabled;
 
 	bool p2p;
+	bool ct_all_pkts_htt; /* CT firmware only: native-wifi for all pkts */
 
 	struct {
 		enum ath10k_bus bus;
@@ -789,6 +933,42 @@ struct ath10k {
 	const struct firmware *pre_cal_file;
 	const struct firmware *cal_file;
 
+	const struct firmware *fwcfg_file;
+	struct {
+#define ATH10K_FWCFG_FWVER          (1<<0)
+#define ATH10K_FWCFG_VDEVS          (1<<1)
+#define ATH10K_FWCFG_PEERS          (1<<2)
+#define ATH10K_FWCFG_STATIONS       (1<<3)
+#define ATH10K_FWCFG_NOHWCRYPT      (1<<4)
+#define ATH10K_FWCFG_RATE_CTRL_OBJS (1<<5)
+#define ATH10K_FWCFG_TX_DESC        (1<<6)
+#define ATH10K_FWCFG_MAX_NSS        (1<<7)
+#define ATH10K_FWCFG_NUM_TIDS       (1<<8)
+#define ATH10K_FWCFG_ACTIVE_PEERS   (1<<9)
+#define ATH10K_FWCFG_SKID_LIMIT     (1<<10)
+#define ATH10K_FWCFG_REGDOM         (1<<11)
+#define ATH10K_FWCFG_BMISS_VDEVS    (1<<12)
+#define ATH10K_FWCFG_MAX_AMSDUS     (1<<13)
+
+		u32 flags; /* let us know which fields have been set */
+		char calname[100];
+		char fwname[100];
+		u32 fwver;
+		u32 vdevs;
+		u32 stations;
+		u32 peers;
+		u32 nohwcrypt;
+		u32 rate_ctrl_objs;
+		u32 tx_desc; /* max_num_pending_tx descriptors */
+		u32 max_nss; /* max_spatial_stream */
+		u32 num_tids;
+		u32 active_peers;
+		u32 skid_limit;
+		int regdom;
+		u32 bmiss_vdevs; /* To disable, set to 0 */
+		u32 max_amsdus;
+	} fwcfg;
+
 	struct {
 		u32 vendor;
 		u32 device;
@@ -842,10 +1022,12 @@ struct ath10k {
 	unsigned int filter_flags;
 	unsigned long dev_flags;
 	bool dfs_block_radar_events;
+	int install_key_rv; /* Store error code from key-install */
 
 	/* protected by conf_mutex */
 	bool radar_enabled;
 	int num_started_vdevs;
+	u32 sta_xretry_kickout_thresh;
 
 	/* Protected by conf-mutex */
 	u8 cfg_tx_chainmask;
@@ -883,6 +1065,11 @@ struct ath10k {
 	int max_num_tdls_vdevs;
 	int num_active_peers;
 	int num_tids;
+	bool request_nohwcrypt; /* desired setting */
+	u32 num_ratectrl_objs;
+	u32 skid_limit;
+	u32 bmiss_offload_max_vdev;
+	int eeprom_regdom;
 
 	struct work_struct svc_rdy_work;
 	struct sk_buff *svc_rdy_skb;
@@ -967,6 +1154,35 @@ struct ath10k {
 		u32 reg_ack_cts_timeout_orig;
 	} fw_coverage;
 
+	/* Index 0 is for 5Ghz, index 1 is for 2.4Ghz, CT firmware only. */
+	/* be sure to flush this to firmware after resets */
+	/* Includes various other backdoor hacks as well. */
+	struct {
+		struct {
+#define MIN_CCA_PWR_COUNT 3
+			u16 minCcaPwrCT[MIN_CCA_PWR_COUNT]; /* 0 means don't-set */
+			u8 noiseFloorThresh; /* 0 means don't-set */
+			/* Have to set this to 2 before minCcaPwr settings will be active.
+			 * Values:  0  don't-set, 1 disable, 2 enable
+			 */
+			u8 enable_minccapwr_thresh;
+		} bands[2];
+		u8 thresh62_ext;
+		u8 rc_rate_max_per_thr; /* Firmware rate-ctrl alg. tuning. */
+		u8 tx_sta_bw_mask; /* 0:  all, 0x1: 20Mhz, 0x2 40Mhz, 0x4 80Mhz */
+		bool allow_ibss_amsdu;
+		bool rifs_enable_override;
+		u16 max_txpower;
+		u16 pdev_xretry_th; /* Max failed retries before wifi chip is reset, 10.1 firmware default is 0x40 */
+		u32 wmi_wd_keepalive_ms; /* 0xFFFFFFFF means disable, otherwise, FW will assert after X ms of not receiving
+					  * a NOP keepalive from the driver.  Suggested value is 0xFFFFFFFF, or 8000+.
+					  * 0 means use whatever firmware defaults to (probably 8000).
+					  * Units are actually 1/1024 of a second, but pretty close to ms, at least.
+					  */
+		u32 ct_pshack;
+		u32 ct_csi;
+	} eeprom_overrides;
+
 	/* must be last */
 	u8 drv_priv[0] __aligned(sizeof(void *));
 };
@@ -980,6 +1196,9 @@ static inline bool ath10k_peer_stats_ena
 	return false;
 }
 
+#define MAX_AR 50
+extern struct ath10k* ar_array[MAX_AR];
+
 struct ath10k *ath10k_core_create(size_t priv_size, struct device *dev,
 				  enum ath10k_bus bus,
 				  enum ath10k_hw_rev hw_rev,
@@ -997,5 +1216,6 @@ int ath10k_wait_for_suspend(struct ath10
 void ath10k_core_stop(struct ath10k *ar);
 int ath10k_core_register(struct ath10k *ar, u32 chip_id);
 void ath10k_core_unregister(struct ath10k *ar);
+void ath10k_core_free_limits(struct ath10k* ar);
 
 #endif /* _CORE_H_ */
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/net/wireless/ath/ath10k/debug.c linux-4.10.x/drivers/net/wireless/ath/ath10k/debug.c
--- linux-4.10.x.ori/drivers/net/wireless/ath/ath10k/debug.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/net/wireless/ath/ath10k/debug.c	2017-05-12 08:00:57.801800000 +0200
@@ -26,20 +26,33 @@
 #include "debug.h"
 #include "hif.h"
 #include "wmi-ops.h"
+#include "mac.h"
 
 /* ms */
 #define ATH10K_DEBUG_HTT_STATS_INTERVAL 1000
 
 #define ATH10K_DEBUG_CAL_DATA_LEN 12064
 
+#define ATH10K_DEBUG_NOP_INTERVAL 2000 /* ms */
+
 #define ATH10K_FW_CRASH_DUMP_VERSION 1
 
 /**
  * enum ath10k_fw_crash_dump_type - types of data in the dump file
  * @ATH10K_FW_CRASH_DUMP_REGDUMP: Register crash dump in binary format
+ * @ATH10K_FW_ERROR_DUMP_DBGLOG:  Recent firmware debug log entries
+ * @ATH10K_FW_CRASH_DUMP_STACK:   Stack memory contents.
+ * @ATH10K_FW_CRASH_DUMP_EXC_STACK:   Exception stack memory contents.
+ * @ATH10K_FW_CRASH_DUMP_RAM_BSS:  BSS area for RAM code
+ * @ATH10K_FW_CRASH_DUMP_ROM_BSS:  BSS area for ROM code
  */
 enum ath10k_fw_crash_dump_type {
 	ATH10K_FW_CRASH_DUMP_REGISTERS = 0,
+	ATH10K_FW_CRASH_DUMP_DBGLOG = 1,
+	ATH10K_FW_CRASH_DUMP_STACK = 2,
+	ATH10K_FW_CRASH_DUMP_EXC_STACK = 3,
+	ATH10K_FW_CRASH_DUMP_RAM_BSS = 4,
+	ATH10K_FW_CRASH_DUMP_ROM_BSS = 5,
 
 	ATH10K_FW_CRASH_DUMP_MAX,
 };
@@ -104,13 +117,24 @@ struct ath10k_dump_file_data {
 	/* VERMAGIC_STRING */
 	char kernel_ver[64];
 
+	__le32 stack_addr;
+	__le32 exc_stack_addr;
+	__le32 rom_bss_addr;
+	__le32 ram_bss_addr;
+
 	/* room for growth w/out changing binary format */
-	u8 unused[128];
+	u8 unused[112];
 
 	/* struct ath10k_tlv_dump_data + more */
 	u8 data[0];
 } __packed;
 
+struct ath10k_dbglog_entry_storage_user {
+	__le32 head_idx; /* Where to write next chunk of data */
+	__le32 tail_idx; /* Index of first msg */
+	__le32 data[ATH10K_DBGLOG_DATA_LEN];
+} __packed;
+
 void ath10k_info(struct ath10k *ar, const char *fmt, ...)
 {
 	struct va_format vaf = {
@@ -120,7 +144,10 @@ void ath10k_info(struct ath10k *ar, cons
 
 	va_start(args, fmt);
 	vaf.va = &args;
-	dev_info(ar->dev, "%pV", &vaf);
+	if (ath10k_debug_mask & ATH10K_DBG_INFO_AS_DBG)
+		dev_printk(KERN_DEBUG, ar->dev, "%pV", &vaf);
+	else
+		dev_info(ar->dev, "%pV", &vaf);
 	trace_ath10k_log_info(ar, &vaf);
 	va_end(args);
 }
@@ -129,7 +156,7 @@ EXPORT_SYMBOL(ath10k_info);
 void ath10k_debug_print_hwfw_info(struct ath10k *ar)
 {
 	const struct firmware *firmware;
-	char fw_features[128] = {};
+	char fw_features[256] = {};
 	u32 crc = 0;
 
 	ath10k_core_get_fw_features_str(ar, fw_features, sizeof(fw_features));
@@ -196,6 +223,11 @@ void ath10k_print_driver_info(struct ath
 }
 EXPORT_SYMBOL(ath10k_print_driver_info);
 
+void ath10k_set_debug_mask(unsigned int v) {
+	ath10k_debug_mask = v;
+}
+EXPORT_SYMBOL(ath10k_set_debug_mask);
+
 void ath10k_err(struct ath10k *ar, const char *fmt, ...)
 {
 	struct va_format vaf = {
@@ -285,6 +317,114 @@ static const struct file_operations fops
 	.llseek = default_llseek,
 };
 
+static ssize_t ath10k_read_misc(struct file *file,
+				char __user *user_buf,
+				size_t count, loff_t *ppos)
+{
+	struct ath10k *ar = file->private_data;
+	char *buf;
+	unsigned int len = 0, buf_len = 1000;
+	ssize_t ret_cnt;
+
+	buf = kzalloc(buf_len, GFP_KERNEL);
+	if (!buf)
+		return -ENOMEM;
+
+	mutex_lock(&ar->conf_mutex);
+
+	if (len > buf_len)
+		len = buf_len;
+
+	/* Probably need some sort of locking on the tx-queue?? */
+	len = snprintf(buf, 1000, "off-channel qlen: %d\n",
+		       skb_queue_len(&ar->offchan_tx_queue));
+
+	ret_cnt = simple_read_from_buffer(user_buf, count, ppos, buf, len);
+
+	mutex_unlock(&ar->conf_mutex);
+
+	kfree(buf);
+	return ret_cnt;
+}
+
+static const struct file_operations fops_misc = {
+	.read = ath10k_read_misc,
+	.open = simple_open,
+	.owner = THIS_MODULE,
+	.llseek = default_llseek,
+};
+
+static ssize_t ath10k_read_fwinfo(struct file *file,
+				  char __user *user_buf,
+				  size_t count, loff_t *ppos)
+{
+	struct ath10k *ar = file->private_data;
+	char *buf;
+	unsigned int len = 0, buf_len = 1000;
+	ssize_t ret_cnt;
+
+	buf = kzalloc(buf_len, GFP_KERNEL);
+	if (!buf)
+		return -ENOMEM;
+
+	mutex_lock(&ar->conf_mutex);
+
+	len = snprintf(buf, buf_len, "directory: %s\nfirmware:  %s\nfwcfg:     fwcfg-%s-%s.txt\nbus:       %s\nfeatures:  ",
+		       ar->hw_params.fw.dir, ar->running_fw->fw_file.fw_name,
+		       ath10k_bus_str(ar->hif.bus), dev_name(ar->dev), dev_name(ar->dev));
+	ath10k_core_get_fw_features_str(ar, buf + len, buf_len - len);
+
+	/* Just to be safe */
+	buf[buf_len - 1] = 0;
+	len = strlen(buf);
+
+	len += snprintf(buf + len, buf_len - len, "\nversion:   %s\nhw_rev:    ",
+			ar->hw->wiphy->fw_version);
+	switch (ar->hw_rev) {
+	case ATH10K_HW_QCA9887:
+		len += snprintf(buf + len, buf_len - len, "9887\n");
+		break;
+	case ATH10K_HW_QCA988X:
+		len += snprintf(buf + len, buf_len - len, "988x\n");
+		break;
+	case ATH10K_HW_QCA9888:
+		len += snprintf(buf + len, buf_len - len, "9888\n");
+		break;
+	case ATH10K_HW_QCA6174:
+		len += snprintf(buf + len, buf_len - len, "6174\n");
+		break;
+	case ATH10K_HW_QCA99X0:
+		len += snprintf(buf + len, buf_len - len, "99x0\n");
+		break;
+	case ATH10K_HW_QCA9984:
+		len += snprintf(buf + len, buf_len - len, "9984\n");
+		break;
+	case ATH10K_HW_QCA9377:
+		len += snprintf(buf + len, buf_len - len, "9377\n");
+		break;
+	case ATH10K_HW_QCA4019:
+		len += snprintf(buf + len, buf_len - len, "4019\n");
+		break;
+	}
+
+	len += snprintf(buf + len, buf_len - len, "board:   %s\n",
+			ar->normal_mode_fw.fw_file.fw_board_name);
+
+	ret_cnt = simple_read_from_buffer(user_buf, count, ppos, buf, len);
+
+	mutex_unlock(&ar->conf_mutex);
+
+	kfree(buf);
+	return ret_cnt;
+}
+
+static const struct file_operations fops_fwinfo_services = {
+	.read = ath10k_read_fwinfo,
+	.open = simple_open,
+	.owner = THIS_MODULE,
+	.llseek = default_llseek,
+};
+
 static void ath10k_fw_stats_pdevs_free(struct list_head *head)
 {
 	struct ath10k_fw_stats_pdev *i, *tmp;
@@ -344,6 +484,7 @@ void ath10k_debug_fw_stats_process(struc
 	size_t num_peers;
 	size_t num_vdevs;
 	int ret;
+	const struct wmi_stats_event *ev = (void *)skb->data;
 
 	INIT_LIST_HEAD(&stats.pdevs);
 	INIT_LIST_HEAD(&stats.vdevs);
@@ -351,6 +492,103 @@ void ath10k_debug_fw_stats_process(struc
 	INIT_LIST_HEAD(&stats.peers_extd);
 
 	spin_lock_bh(&ar->data_lock);
+
+	/* CT Firmware only */
+	if (__le32_to_cpu(ev->stats_id) == WMI_REQUEST_REGISTER_DUMP) {
+		struct ath10k_reg_dump* regdump;
+		struct ath10k_fw_stats* sptr = &ar->debug.fw_stats;
+		int i;
+
+		if ((ar->running_fw->fw_file.wmi_op_version == ATH10K_FW_WMI_OP_VERSION_10_2) ||
+		    (ar->running_fw->fw_file.wmi_op_version == ATH10K_FW_WMI_OP_VERSION_10_4) ||
+		    (ar->running_fw->fw_file.wmi_op_version == ATH10K_FW_WMI_OP_VERSION_10_2_4)) {
+			const struct wmi_10_2_stats_event *ev2 = (void *)skb->data;
+			regdump = (struct ath10k_reg_dump*)(ev2->data);
+		} else {
+			/* Must be 10.1 */
+			regdump = (struct ath10k_reg_dump*)(ev->data);
+		}
+
+		for (i = 0; i < __le16_to_cpu(regdump->count); i++) {
+			switch (__le16_to_cpu(regdump->regpair[i].reg_id)) {
+			case REG_DUMP_NONE:
+				break;
+			case MAC_FILTER_ADDR_L32:
+				sptr->mac_filter_addr_l32 = __le32_to_cpu(regdump->regpair[i].reg_val);
+				break;
+			case MAC_FILTER_ADDR_U16:
+				sptr->mac_filter_addr_u16 = __le32_to_cpu(regdump->regpair[i].reg_val);
+				break;
+			case DCU_SLOT_TIME:
+				sptr->dcu_slot_time = __le32_to_cpu(regdump->regpair[i].reg_val);
+				break;
+			case PHY_BB_MODE_SELECT:
+				sptr->phy_bb_mode_select = __le32_to_cpu(regdump->regpair[i].reg_val);
+				break;
+			case PCU_BSSID_L32:
+				sptr->pcu_bssid_l32 = __le32_to_cpu(regdump->regpair[i].reg_val);
+				break;
+			case PCU_BSSID_U16:
+				sptr->pcu_bssid_u16 = __le32_to_cpu(regdump->regpair[i].reg_val);
+				break;
+			case PCU_BSSID2_L32:
+				sptr->pcu_bssid_l32 = __le32_to_cpu(regdump->regpair[i].reg_val);
+				break;
+			case PCU_BSSID2_U16:
+				sptr->pcu_bssid_u16 = __le32_to_cpu(regdump->regpair[i].reg_val);
+				break;
+			case PCU_STA_ADDR_U16:
+				sptr->pcu_sta_addr_u16 = __le32_to_cpu(regdump->regpair[i].reg_val);
+				break;
+			case MAC_DMA_CFG:
+				sptr->mac_dma_cfg = __le32_to_cpu(regdump->regpair[i].reg_val);
+				break;
+			case MAC_DMA_TXCFG:
+				sptr->mac_dma_txcfg = __le32_to_cpu(regdump->regpair[i].reg_val);
+				break;
+			case PCU_STA_ADDR_L32:
+				sptr->pcu_sta_addr_l32 = __le32_to_cpu(regdump->regpair[i].reg_val);
+				break;
+			case PCU_RXFILTER:
+				sptr->pcu_rxfilter = __le32_to_cpu(regdump->regpair[i].reg_val);
+				break;
+			case PHY_BB_GEN_CONTROLS:
+				sptr->phy_bb_gen_controls = __le32_to_cpu(regdump->regpair[i].reg_val);
+				break;
+			case DMA_IMR:
+				sptr->dma_imr = __le32_to_cpu(regdump->regpair[i].reg_val);
+				break;
+			case DMA_TXRX_IMR:
+				sptr->dma_txrx_imr = __le32_to_cpu(regdump->regpair[i].reg_val);
+				break;
+			case SW_POWERMODE:
+				sptr->sw_powermode = __le32_to_cpu(regdump->regpair[i].reg_val);
+				break;
+			case SW_CHAINMASK:
+				sptr->sw_chainmask_tx = (__le32_to_cpu(regdump->regpair[i].reg_val) >> 16);
+				sptr->sw_chainmask_rx = __le32_to_cpu(regdump->regpair[i].reg_val);
+				break;
+			case SW_OPMODE:
+				sptr->sw_opmode = __le32_to_cpu(regdump->regpair[i].reg_val);
+				break;
+			case SW_RXFILTER:
+				sptr->sw_rxfilter = __le32_to_cpu(regdump->regpair[i].reg_val);
+				break;
+			case SW_LONG_RETRIES:
+				sptr->long_retries = __le32_to_cpu(regdump->regpair[i].reg_val);
+				break;
+			case SW_SHORT_RETRIES:
+				sptr->short_retries = __le32_to_cpu(regdump->regpair[i].reg_val);
+				break;
+			case ADC_TEMP:
+				sptr->adc_temp = __le32_to_cpu(regdump->regpair[i].reg_val);
+				break;
+			}/* switch */
+		}
+		complete(&ar->debug.fw_stats_complete);
+		goto free;
+	}
+
 	ret = ath10k_wmi_pull_fw_stats(ar, skb, &stats);
 	if (ret) {
 		ath10k_warn(ar, "failed to pull fw stats: %d\n", ret);
@@ -431,7 +669,7 @@ free:
 
 static int ath10k_debug_fw_stats_request(struct ath10k *ar)
 {
-	unsigned long timeout, time_left;
+	unsigned long timeout;
 	int ret;
 
 	lockdep_assert_held(&ar->conf_mutex);
@@ -444,19 +682,9 @@ static int ath10k_debug_fw_stats_request
 		if (time_after(jiffies, timeout))
 			return -ETIMEDOUT;
 
-		reinit_completion(&ar->debug.fw_stats_complete);
-
-		ret = ath10k_wmi_request_stats(ar, ar->fw_stats_req_mask);
-		if (ret) {
-			ath10k_warn(ar, "could not request stats (%d)\n", ret);
+		ret = ath10k_refresh_peer_stats(ar);
+		if (ret)
 			return ret;
-		}
-
-		time_left =
-		wait_for_completion_timeout(&ar->debug.fw_stats_complete,
-					    1 * HZ);
-		if (!time_left)
-			return -ETIMEDOUT;
 
 		spin_lock_bh(&ar->data_lock);
 		if (ar->debug.fw_stats_done) {
@@ -520,6 +748,136 @@ static int ath10k_fw_stats_release(struc
 	return 0;
 }
 
+int ath10k_refresh_peer_stats_t(struct ath10k *ar, u32 type)
+{
+	int ret;
+	unsigned long time_left;
+
+	reinit_completion(&ar->debug.fw_stats_complete);
+	ret = ath10k_wmi_request_stats(ar, type);
+
+	if (ret) {
+		ath10k_warn(ar, "could not request stats (type %d ret %d)\n",
+			    type, ret);
+		return ret;
+	}
+
+	/* ret means 'time-left' here */
+	time_left =
+		wait_for_completion_timeout(&ar->debug.fw_stats_complete, 1*HZ);
+	if (time_left == 0)
+		return -ETIMEDOUT;
+
+	return 0;
+}
+
+int ath10k_refresh_peer_stats(struct ath10k *ar)
+{
+	return ath10k_refresh_peer_stats_t(ar, ar->fw_stats_req_mask);
+}
+
+int ath10k_refresh_target_regs(struct ath10k *ar)
+{
+	if (test_bit(ATH10K_FW_FEATURE_REGDUMP_CT,
+		     ar->running_fw->fw_file.fw_features))
+		return ath10k_refresh_peer_stats_t(ar, WMI_REQUEST_REGISTER_DUMP);
+	return 0; /* fail silently if firmware does not support this option. */
+}
+
+
+static ssize_t ath10k_read_fw_regs(struct file *file, char __user *user_buf,
+				   size_t count, loff_t *ppos)
+{
+	struct ath10k *ar = file->private_data;
+	struct ath10k_fw_stats *fw_regs;
+	char *buf = NULL;
+	unsigned int len = 0, buf_len = 8000;
+	ssize_t ret_cnt = 0;
+	int ret;
+
+	fw_regs = &ar->debug.fw_stats;
+
+	mutex_lock(&ar->conf_mutex);
+
+	if (ar->state != ATH10K_STATE_ON)
+		goto exit;
+
+	buf = kzalloc(buf_len, GFP_KERNEL);
+	if (!buf)
+		goto exit;
+
+	ret = ath10k_refresh_target_regs(ar);
+	if (ret)
+		goto exit;
+
+	spin_lock_bh(&ar->data_lock);
+	len += scnprintf(buf + len, buf_len - len, "\n");
+	len += scnprintf(buf + len, buf_len - len, "%30s\n",
+			 "ath10k Target Register Dump");
+	len += scnprintf(buf + len, buf_len - len, "%30s\n\n",
+				 "=================");
+
+	len += scnprintf(buf + len, buf_len - len, "%30s 0x%08x\n",
+			 "MAC-FILTER-ADDR-L32", fw_regs->mac_filter_addr_l32);
+	len += scnprintf(buf + len, buf_len - len, "%30s 0x%08x\n",
+			 "MAC-FILTER-ADDR-U16", fw_regs->mac_filter_addr_u16);
+	len += scnprintf(buf + len, buf_len - len, "%30s 0x%08x\n",
+			 "DCU-SLOT-TIME", fw_regs->dcu_slot_time);
+	len += scnprintf(buf + len, buf_len - len, "%30s 0x%08x\n",
+			 "PHY-MODE-SELECT", fw_regs->phy_bb_mode_select);
+	len += scnprintf(buf + len, buf_len - len, "%30s 0x%08x\n",
+			 "PHY-BB-GEN-CONTROLS", fw_regs->phy_bb_gen_controls);
+	len += scnprintf(buf + len, buf_len - len, "%30s 0x%08x\n",
+			 "DMA-IMR", fw_regs->dma_imr);
+	len += scnprintf(buf + len, buf_len - len, "%30s 0x%08x\n",
+			 "DMA-TXRX-IMR", fw_regs->dma_txrx_imr);
+	len += scnprintf(buf + len, buf_len - len, "%30s 0x%08x\n",
+			 "PCU-BSSID-L32", fw_regs->pcu_bssid_l32);
+	len += scnprintf(buf + len, buf_len - len, "%30s 0x%08x\n",
+			 "PCU-BSSID-U16", fw_regs->pcu_bssid_u16);
+	len += scnprintf(buf + len, buf_len - len, "%30s 0x%08x\n",
+			 "PCU-BSSID2-L32", fw_regs->pcu_bssid2_l32);
+	len += scnprintf(buf + len, buf_len - len, "%30s 0x%08x\n",
+			 "PCU-BSSID2-U16", fw_regs->pcu_bssid2_u16);
+	len += scnprintf(buf + len, buf_len - len, "%30s 0x%08x\n",
+			 "PCU-STA-ADDR-L32", fw_regs->pcu_sta_addr_l32);
+	len += scnprintf(buf + len, buf_len - len, "%30s 0x%08x\n",
+			 "PCU-STA-ADDR-U16", fw_regs->pcu_sta_addr_u16);
+	len += scnprintf(buf + len, buf_len - len, "%30s 0x%08x\n",
+			 "MAC-DMA-CFG", fw_regs->mac_dma_cfg);
+	len += scnprintf(buf + len, buf_len - len, "%30s 0x%08x\n",
+			 "MAC-DMA-TXCFG", fw_regs->mac_dma_txcfg);
+
+	len += scnprintf(buf + len, buf_len - len, "%30s 0x%08x\n",
+			 "SW-POWERMODE", fw_regs->sw_powermode);
+	len += scnprintf(buf + len, buf_len - len, "%30s 0x%08x\n",
+			 "SW-CHAINMASK-TX", (u32)(fw_regs->sw_chainmask_tx));
+	len += scnprintf(buf + len, buf_len - len, "%30s 0x%08x\n",
+			 "SW-CHAINMASK-RX", (u32)(fw_regs->sw_chainmask_rx));
+	len += scnprintf(buf + len, buf_len - len, "%30s 0x%08x\n",
+			 "SW-OPMODE", fw_regs->sw_opmode);
+
+	len += scnprintf(buf + len, buf_len - len, "%30s 0x%08x\n",
+			 "MAC-PCU-RXFILTER", fw_regs->pcu_rxfilter);
+	len += scnprintf(buf + len, buf_len - len, "%30s 0x%08x\n",
+			 "SW-RXFILTER", fw_regs->sw_rxfilter);
+	len += scnprintf(buf + len, buf_len - len, "%30s 0x%08x\n",
+			 "ADC-TEMP", fw_regs->adc_temp);
+
+	spin_unlock_bh(&ar->data_lock);
+
+	if (len > buf_len)
+		len = buf_len;
+
+	ret_cnt = simple_read_from_buffer(user_buf, count, ppos, buf, len);
+
+exit:
+	mutex_unlock(&ar->conf_mutex);
+	kfree(buf);
+	return ret_cnt;
+}
+
+
 static ssize_t ath10k_fw_stats_read(struct file *file, char __user *user_buf,
 				    size_t count, loff_t *ppos)
 {
@@ -598,6 +956,13 @@ static int ath10k_debug_fw_assert(struct
 				   ar->wmi.cmd->vdev_install_key_cmdid);
 }
 
+static const struct file_operations fops_fw_regs = {
+	.read = ath10k_read_fw_regs,
+	.open = simple_open,
+	.owner = THIS_MODULE,
+	.llseek = default_llseek,
+};
+
 static ssize_t ath10k_read_simulate_fw_crash(struct file *file,
 					     char __user *user_buf,
 					     size_t count, loff_t *ppos)
@@ -687,6 +1052,248 @@ static const struct file_operations fops
 	.llseek = default_llseek,
 };
 
+static ssize_t ath10k_read_debug_level(struct file *file,
+				       char __user *user_buf,
+				       size_t count, loff_t *ppos)
+{
+	int sz;
+	const char buf[] =
+		"To change debug level, set value adding up desired flags:\n"
+		"PCI:                0x1\n"
+		"WMI:                0x2\n"
+		"HTC:                0x4\n"
+		"HTT:                0x8\n"
+		"MAC:               0x10\n"
+		"BOOT:              0x20\n"
+		"PCI-DUMP:          0x40\n"
+		"HTT-DUMP:          0x80\n"
+		"MGMT:             0x100\n"
+		"DATA:             0x200\n"
+		"BMI:              0x400\n"
+		"REGULATORY:       0x800\n"
+		"TESTMODE:        0x1000\n"
+		"WMI-PRINT:       0x2000\n"
+		"PCI-PS:          0x4000\n"
+		"AHB:             0x8000\n"
+		"NO-FW-DBGLOG:0x10000000\n"
+		"MAC2:        0x20000000\n"
+		"INFO-AS-DBG: 0x40000000\n"
+		"FW:          0x80000000\n"
+		"ALL:         0xFFFFFFFF\n";
+	char wbuf[sizeof(buf) + 60];
+	sz = snprintf(wbuf, sizeof(wbuf), "Current debug level: 0x%x\n\n%s",
+		      ath10k_debug_mask, buf);
+	wbuf[sizeof(wbuf) - 1] = 0;
+
+	return simple_read_from_buffer(user_buf, count, ppos, wbuf, sz);
+}
+
+/* Set logging level.
+ */
+static ssize_t ath10k_write_debug_level(struct file *file,
+					const char __user *user_buf,
+					size_t count, loff_t *ppos)
+{
+	struct ath10k *ar = file->private_data;
+	int ret;
+	unsigned long mask;
+
+	ret = kstrtoul_from_user(user_buf, count, 0, &mask);
+	if (ret)
+		return ret;
+
+	ath10k_warn(ar, "Setting debug-mask to: 0x%lx  old: 0x%x\n",
+		    mask, ath10k_debug_mask);
+	ath10k_debug_mask = mask;
+	return count;
+}
+
+static const struct file_operations fops_debug_level = {
+	.read = ath10k_read_debug_level,
+	.write = ath10k_write_debug_level,
+	.open = simple_open,
+	.owner = THIS_MODULE,
+	.llseek = default_llseek,
+};
+
+static ssize_t ath10k_read_set_rates(struct file *file,
+				     char __user *user_buf,
+				     size_t count, loff_t *ppos)
+{
+	const char buf[] =
+		"This is to set fixed bcast, mcast, and beacon rates.  Normal rate-ctrl\n"
+		"is handled through normal API using 'iw', etc.\n"
+		"To set a value, you specify the dev-name, type, band and rate-code:\n"
+		"types: bcast, mcast, beacon\n"
+		"bands: 2, 5, 60\n"
+		"rate-codes: 0x43 1M, 0x42 2M, 0x41 5.5M, 0x40 11M, 0x3 6M, 0x7 9M, 0x2 12M, 0x6 18M, 0x1 24M, 0x5 36M, 0x0 48M, 0x4 54M, 0xFF default\n"
+		" For example, to set beacon to 18Mbps on wlan0:  echo \"wlan0 beacon 2 0x6\" > /debug/..../set_rates\n";
+
+	return simple_read_from_buffer(user_buf, count, ppos, buf, strlen(buf));
+}
+
+/* Set the rates for specific types of traffic.
+ */
+static ssize_t ath10k_write_set_rates(struct file *file,
+				      const char __user *user_buf,
+				      size_t count, loff_t *ppos)
+{
+	struct ath10k *ar = file->private_data;
+	char buf[80];
+	int ret;
+	struct ath10k_vif *arvif;
+	struct ieee80211_vif *vif;
+	unsigned int vdev_id = 0xFFFF;
+	char* bufptr = buf;
+	long rc;
+	int cfg_band;
+	struct cfg80211_chan_def def;
+	char dev_name_match[IFNAMSIZ + 2];
+	struct wireless_dev *wdev;
+	int set_rate_type;
+
+	memset(buf, 0, sizeof(buf));
+
+	simple_write_to_buffer(buf, sizeof(buf) - 1, ppos, user_buf, count);
+
+	/* make sure that buf is null terminated */
+	buf[sizeof(buf) - 1] = 0;
+
+	/* drop the possible '\n' from the end */
+	if (buf[count - 1] == '\n')
+		buf[count - 1] = 0;
+
+	mutex_lock(&ar->conf_mutex);
+
+	/* Ignore empty lines, 'echo' appends them sometimes at least. */
+	if (buf[0] == 0) {
+		ret = count;
+		goto exit;
+	}
+
+	/* String starts with vdev name, ie 'wlan0'  Find the proper vif that
+	 * matches the name.
+	 */
+	list_for_each_entry(arvif, &ar->arvifs, list) {
+		vif = arvif->vif;
+		wdev = ieee80211_vif_to_wdev(vif);
+
+		if (!wdev)
+			continue;
+		snprintf(dev_name_match, sizeof(dev_name_match) - 1, "%s ", wdev->netdev->name);
+		if (strncmp(dev_name_match, buf, strlen(dev_name_match)) == 0) {
+			vdev_id = arvif->vdev_id;
+			bufptr = buf + strlen(dev_name_match);
+			break;
+		}
+	}
+
+	if (vdev_id == 0xFFFF) {
+		ath10k_warn(ar, "set-rate, unknown netdev name: %s\n", buf);
+		ret = -EINVAL;
+		goto exit;
+	}
+
+	/* Now, check the type. */
+	if (strncmp(bufptr, "beacon ", strlen("beacon ")) == 0) {
+		set_rate_type = ar->wmi.vdev_param->mgmt_rate;
+		bufptr += strlen("beacon ");
+	}
+	else if (strncmp(bufptr, "bcast ", strlen("bcast ")) == 0) {
+		set_rate_type = ar->wmi.vdev_param->bcast_data_rate;
+		bufptr += strlen("bcast ");
+	}
+	else if (strncmp(bufptr, "mcast ", strlen("mcast ")) == 0) {
+		set_rate_type = ar->wmi.vdev_param->mcast_data_rate;
+		bufptr += strlen("mcast ");
+	}
+	else {
+		ath10k_warn(ar, "set-rate, invalid rate type: %s\n",
+			    bufptr);
+		ret = -EINVAL;
+		goto exit;
+	}
+
+	/* And the band */
+	if (strncmp(bufptr, "2 ", 2) == 0) {
+		cfg_band = NL80211_BAND_2GHZ;
+		bufptr += 2;
+	}
+	else if (strncmp(bufptr, "5 ", 2) == 0) {
+		cfg_band = NL80211_BAND_5GHZ;
+		bufptr += 2;
+	}
+	else if (strncmp(bufptr, "60 ", 3) == 0) {
+		cfg_band = NL80211_BAND_60GHZ;
+		bufptr += 3;
+	}
+	else {
+		ath10k_warn(ar, "set-rate, invalid band: %s\n",
+			    bufptr);
+		ret = -EINVAL;
+		goto exit;
+	}
+
+	/* Parse the rate-code. */
+	ret = kstrtol(bufptr, 0, &rc);
+	if (ret != 0) {
+		ath10k_warn(ar, "set-rate, invalid rate-code: %s\n", bufptr);
+		goto exit;
+	}
+
+	/* Store the value so we can re-apply it if firmware is restarted. */
+	if (set_rate_type == ar->wmi.vdev_param->mgmt_rate)
+		arvif->mgt_rate[cfg_band] = rc;
+	else if (set_rate_type == ar->wmi.vdev_param->bcast_data_rate)
+		arvif->bcast_rate[cfg_band] = rc;
+	else if (set_rate_type == ar->wmi.vdev_param->mcast_data_rate)
+		arvif->mcast_rate[cfg_band] = rc;
+
+	if (ar->state != ATH10K_STATE_ON &&
+	    ar->state != ATH10K_STATE_RESTARTED) {
+		/* OK, we will set it when vdev comes up */
+		ath10k_warn(ar, "set-rates, deferred-state is down, vdev %i type: 0x%x rc: 0x%lx band: %d\n",
+			    arvif->vdev_id, set_rate_type, rc, cfg_band);
+		goto exit;
+	}
+
+	if (ath10k_mac_vif_chan(vif, &def) == 0) {
+		if (def.chan->band != cfg_band) {
+			/* We stored value, will apply it later if we move to the
+			 * different band.
+			 */
+			ath10k_warn(ar, "set-rates, deferred-other-band, vdev %i type: 0x%x rc: 0x%lx band: %d\n",
+				    arvif->vdev_id, set_rate_type, rc, cfg_band);
+			goto exit;
+		}
+	}
+
+	/* and finally, send results to the firmware. */
+	ret = ath10k_wmi_vdev_set_param(ar, arvif->vdev_id, set_rate_type, rc);
+	if (ret) {
+		ath10k_warn(ar, "set-rates: vdev %i failed to set fixed rate, param 0x%x rate-code 0x%02lx\n",
+			    arvif->vdev_id, set_rate_type, rc);
+		return ret;
+	}
+
+	ath10k_warn(ar, "set-rates, vdev %i type: 0x%x rc: 0x%lx band: %d\n",
+		    arvif->vdev_id, set_rate_type, rc, cfg_band);
+
+	ret = count;
+
+exit:
+	mutex_unlock(&ar->conf_mutex);
+	return ret;
+}
+
+static const struct file_operations fops_set_rates = {
+	.read = ath10k_read_set_rates,
+	.write = ath10k_write_set_rates,
+	.open = simple_open,
+	.owner = THIS_MODULE,
+	.llseek = default_llseek,
+};
+
 static ssize_t ath10k_read_chip_id(struct file *file, char __user *user_buf,
 				   size_t count, loff_t *ppos)
 {
@@ -713,7 +1320,6 @@ ath10k_debug_get_new_fw_crash_data(struc
 
 	lockdep_assert_held(&ar->data_lock);
 
-	crash_data->crashed_since_read = true;
 	uuid_le_gen(&crash_data->uuid);
 	getnstimeofday(&crash_data->timestamp);
 
@@ -721,17 +1327,100 @@ ath10k_debug_get_new_fw_crash_data(struc
 }
 EXPORT_SYMBOL(ath10k_debug_get_new_fw_crash_data);
 
+static void ath10k_dbg_drop_dbg_buffer(struct ath10k *ar)
+{
+	/* Find next message boundary */
+	u32 lg_hdr;
+	int acnt;
+	int tail_idx = ar->debug.dbglog_entry_data.tail_idx;
+	int h_idx = (tail_idx + 1) % ATH10K_DBGLOG_DATA_LEN;
+
+	lockdep_assert_held(&ar->data_lock);
+
+	/* Log header is second 32-bit word */
+	lg_hdr = le32_to_cpu(ar->debug.dbglog_entry_data.data[h_idx]);
+
+	acnt = (lg_hdr & DBGLOG_NUM_ARGS_MASK) >> DBGLOG_NUM_ARGS_OFFSET;
+
+	if (acnt > DBGLOG_NUM_ARGS_MAX) {
+		/* Some sort of corruption it seems, recover as best we can. */
+		/* silently ignore problem */
+#if 0
+		ath10k_err(ar, "invalid dbglog arg-count: %i %i %i\n",
+			   acnt, ar->debug.dbglog_entry_data.tail_idx,
+			   ar->debug.dbglog_entry_data.head_idx);
+#endif
+		ar->debug.dbglog_entry_data.tail_idx =
+			ar->debug.dbglog_entry_data.head_idx;
+		return;
+	}
+
+	/* Move forward over the args and the two header fields */
+	ar->debug.dbglog_entry_data.tail_idx =
+		(tail_idx + acnt + 2) % ATH10K_DBGLOG_DATA_LEN;
+}
+
+void ath10k_dbg_save_fw_dbg_buffer(struct ath10k *ar, __le32 *buffer, int len)
+{
+	int i;
+	int z;
+
+	lockdep_assert_held(&ar->data_lock);
+
+	z = ar->debug.dbglog_entry_data.head_idx;
+
+	/* Don't save any new logs until user-space reads this. */
+	if (ar->debug.fw_crash_data &&
+	    ar->debug.fw_crash_data->crashed_since_read) {
+		ath10k_warn(ar, "dropping dbg buffer due to crash since read\n");
+		return;
+	}
+
+	for (i = 0; i < len; i++) {
+		ar->debug.dbglog_entry_data.data[z] = buffer[i];
+		z++;
+		if (z >= ATH10K_DBGLOG_DATA_LEN)
+			z = 0;
+
+		/* If we are about to over-write an old message, move the
+		 * tail_idx to the next message.  If idx's are same, we
+		 * are empty.
+		 */
+		if (z == ar->debug.dbglog_entry_data.tail_idx)
+			ath10k_dbg_drop_dbg_buffer(ar);
+
+		ar->debug.dbglog_entry_data.head_idx = z;
+	}
+}
+EXPORT_SYMBOL(ath10k_dbg_save_fw_dbg_buffer);
+
 static struct ath10k_dump_file_data *ath10k_build_dump_file(struct ath10k *ar)
 {
 	struct ath10k_fw_crash_data *crash_data = ar->debug.fw_crash_data;
 	struct ath10k_dump_file_data *dump_data;
 	struct ath10k_tlv_dump_data *dump_tlv;
+	struct ath10k_dbglog_entry_storage_user *dbglog_storage;
 	int hdr_len = sizeof(*dump_data);
 	unsigned int len, sofar = 0;
 	unsigned char *buf;
+	int tmp;
+
+	BUILD_BUG_ON(sizeof(struct ath10k_dbglog_entry_storage) !=
+		     sizeof(struct ath10k_dbglog_entry_storage_user));
 
 	len = hdr_len;
 	len += sizeof(*dump_tlv) + sizeof(crash_data->registers);
+	len += sizeof(*dump_tlv) + sizeof(ar->debug.dbglog_entry_data);
+	len += sizeof(*dump_tlv) + sizeof(crash_data->stack_buf);
+	len += sizeof(*dump_tlv) + sizeof(crash_data->exc_stack_buf);
+
+	if (ar->running_fw->fw_file.ram_bss_addr &&
+	    ar->running_fw->fw_file.ram_bss_len)
+		len += sizeof(*dump_tlv) + ar->running_fw->fw_file.ram_bss_len;
+
+	if (ar->running_fw->fw_file.rom_bss_addr &&
+	    ar->running_fw->fw_file.rom_bss_len)
+		len += sizeof(*dump_tlv) + ar->running_fw->fw_file.rom_bss_len;
 
 	sofar += hdr_len;
 
@@ -771,6 +1460,12 @@ static struct ath10k_dump_file_data *ath
 	dump_data->ht_cap_info = cpu_to_le32(ar->ht_cap_info);
 	dump_data->vht_cap_info = cpu_to_le32(ar->vht_cap_info);
 	dump_data->num_rf_chains = cpu_to_le32(ar->num_rf_chains);
+	dump_data->stack_addr = cpu_to_le32(crash_data->stack_addr);
+	dump_data->exc_stack_addr = cpu_to_le32(crash_data->exc_stack_addr);
+	dump_data->rom_bss_addr =
+		cpu_to_le32(ar->running_fw->fw_file.rom_bss_addr);
+	dump_data->ram_bss_addr =
+		cpu_to_le32(ar->running_fw->fw_file.ram_bss_addr);
 
 	strlcpy(dump_data->fw_ver, ar->hw->wiphy->fw_version,
 		sizeof(dump_data->fw_ver));
@@ -790,8 +1485,60 @@ static struct ath10k_dump_file_data *ath
 	       sizeof(crash_data->registers));
 	sofar += sizeof(*dump_tlv) + sizeof(crash_data->registers);
 
+	/* Gather dbg-log */
+	tmp = sizeof(ar->debug.dbglog_entry_data);
+	dump_tlv = (struct ath10k_tlv_dump_data *)(buf + sofar);
+	dump_tlv->type = cpu_to_le32(ATH10K_FW_CRASH_DUMP_DBGLOG);
+	dump_tlv->tlv_len = cpu_to_le32(tmp);
+	dbglog_storage =
+		(struct ath10k_dbglog_entry_storage_user *)(dump_tlv->tlv_data);
+	memcpy(dbglog_storage->data, ar->debug.dbglog_entry_data.data,
+	       sizeof(dbglog_storage->data));
+	dbglog_storage->head_idx =
+		cpu_to_le32(ar->debug.dbglog_entry_data.head_idx);
+	dbglog_storage->tail_idx =
+		cpu_to_le32(ar->debug.dbglog_entry_data.tail_idx);
+	sofar += sizeof(*dump_tlv) + tmp;
+
+	/* Gather firmware stack dump */
+	tmp = sizeof(crash_data->stack_buf);
+	dump_tlv = (struct ath10k_tlv_dump_data *)(buf + sofar);
+	dump_tlv->type = cpu_to_le32(ATH10K_FW_CRASH_DUMP_STACK);
+	dump_tlv->tlv_len = cpu_to_le32(tmp);
+	memcpy(dump_tlv->tlv_data, crash_data->stack_buf, tmp);
+	sofar += sizeof(*dump_tlv) + tmp;
+
+	/* Gather firmware exception stack dump */
+	tmp = sizeof(crash_data->exc_stack_buf);
+	dump_tlv = (struct ath10k_tlv_dump_data *)(buf + sofar);
+	dump_tlv->type = cpu_to_le32(ATH10K_FW_CRASH_DUMP_EXC_STACK);
+	dump_tlv->tlv_len = cpu_to_le32(tmp);
+	memcpy(dump_tlv->tlv_data, crash_data->exc_stack_buf, tmp);
+	sofar += sizeof(*dump_tlv) + tmp;
+
+	if (ar->running_fw->fw_file.ram_bss_addr &&
+	    ar->running_fw->fw_file.ram_bss_len) {
+		tmp = ar->running_fw->fw_file.ram_bss_len;
+		dump_tlv = (struct ath10k_tlv_dump_data *)(buf + sofar);
+		dump_tlv->type = cpu_to_le32(ATH10K_FW_CRASH_DUMP_RAM_BSS);
+		dump_tlv->tlv_len = cpu_to_le32(tmp);
+		memcpy(dump_tlv->tlv_data, crash_data->ram_bss_buf, tmp);
+		sofar += sizeof(*dump_tlv) + tmp;
+	}
+
+	if (ar->running_fw->fw_file.rom_bss_addr &&
+	    ar->running_fw->fw_file.rom_bss_len) {
+		tmp = ar->running_fw->fw_file.rom_bss_len;
+		dump_tlv = (struct ath10k_tlv_dump_data *)(buf + sofar);
+		dump_tlv->type = cpu_to_le32(ATH10K_FW_CRASH_DUMP_ROM_BSS);
+		dump_tlv->tlv_len = cpu_to_le32(tmp);
+		memcpy(dump_tlv->tlv_data, crash_data->rom_bss_buf, tmp);
+		sofar += sizeof(*dump_tlv) + tmp;
+	}
+
 	ar->debug.fw_crash_data->crashed_since_read = false;
 
+	WARN_ON(sofar != len);
 	spin_unlock_bh(&ar->data_lock);
 
 	return dump_data;
@@ -1109,6 +1856,27 @@ static void ath10k_debug_htt_stats_dwork
 	mutex_unlock(&ar->conf_mutex);
 }
 
+static void ath10k_debug_nop_dwork(struct work_struct *work)
+{
+	struct ath10k *ar = container_of(work, struct ath10k,
+					 debug.nop_dwork.work);
+
+	mutex_lock(&ar->conf_mutex);
+
+	if (ar->state == ATH10K_STATE_ON) {
+		int ret = ath10k_wmi_request_nop(ar);
+		if (ret) {
+			ath10k_warn(ar, "failed to send wmi nop: %d\n", ret);
+		}
+	}
+
+	/* Re-arm periodic work. */
+	queue_delayed_work(ar->workqueue, &ar->debug.nop_dwork,
+			   msecs_to_jiffies(ATH10K_DEBUG_NOP_INTERVAL));
+
+	mutex_unlock(&ar->conf_mutex);
+}
+
 static ssize_t ath10k_read_htt_stats_mask(struct file *file,
 					  char __user *user_buf,
 					  size_t count, loff_t *ppos)
@@ -1292,12 +2060,18 @@ exit:
 
 /* This generally cooresponds to the debugfs fw_stats file */
 static const char ath10k_gstrings_stats[][ETH_GSTRING_LEN] = {
-	"tx_pkts_nic",
-	"tx_bytes_nic",
-	"rx_pkts_nic",
-	"rx_bytes_nic",
+	"tx_hw_reaped", /* from firmware, tx-pkts count */
+	"tx_pkts_nic", /* from driver, tx-ok pkts */
+	"tx_bytes_nic", /* from driver, tx-ok bytes */
+	"tx_bytes_to_fw", /* sent to firmware, counts all failures */
+	"rx_pkts_nic", /* From firmware...maybe should be from driver for symmetry? */
+	"rx_bytes_nic", /* from driver, firmware does not keep this stat. */
 	"d_noise_floor",
-	"d_cycle_count",
+	"d_cycle_count", /* this is duty cycle counter, basically channel-time. 88MHz clock */
+	"d_tx_cycle_count", /* tx cycle count */
+	"d_rx_cycle_count", /* rx cycle count */
+	"d_busy_count", /* Total channel busy time cycles (called 'clear' by firmware) */
+	"d_flags", /* 0x1:  hw has shifted cycle-count wrap, see ath10k_hw_fill_survey_time */
 	"d_phy_error",
 	"d_rts_bad",
 	"d_rts_good",
@@ -1317,6 +2091,10 @@ static const char ath10k_gstrings_stats[
 	"d_tx_excessive_retries",
 	"d_tx_hw_rate",
 	"d_tx_dropped_sw_retries",
+	"d_tx_noack", /* reported by driver */
+	"d_tx_noack_bytes", /* reported by driver */
+	"d_tx_discard", /* reported by driver */
+	"d_tx_discard_bytes", /* reported by driver */
 	"d_tx_illegal_rate",
 	"d_tx_continuous_xretries",
 	"d_tx_timeout",
@@ -1338,6 +2116,10 @@ static const char ath10k_gstrings_stats[
 	"d_fw_crash_count",
 	"d_fw_warm_reset_count",
 	"d_fw_cold_reset_count",
+	"d_fw_powerup_failed", /* boolean */
+	"d_short_tx_retries", /* RTS tx retries */
+	"d_long_tx_retries", /* DATA tx retries */
+	"d_fw_adc_temp", /* ADC Temperature readings. */
 };
 
 #define ATH10K_SSTATS_LEN ARRAY_SIZE(ath10k_gstrings_stats)
@@ -1368,10 +2150,12 @@ void ath10k_debug_get_et_stats(struct ie
 	static const struct ath10k_fw_stats_pdev zero_stats = {};
 	const struct ath10k_fw_stats_pdev *pdev_stats;
 	int i = 0, ret;
+	u64 d_flags = 0;
 
 	mutex_lock(&ar->conf_mutex);
 
 	if (ar->state == ATH10K_STATE_ON) {
+		ath10k_refresh_target_regs(ar); /* Request some CT FW stats. */
 		ret = ath10k_debug_fw_stats_request(ar);
 		if (ret) {
 			/* just print a warning and try to use older results */
@@ -1391,12 +2175,21 @@ void ath10k_debug_get_et_stats(struct ie
 
 	spin_lock_bh(&ar->data_lock);
 
+	if (ar->hw_params.cc_wraparound_type == ATH10K_HW_CC_WRAP_SHIFTED_ALL)
+		d_flags |= 0x1;
+
 	data[i++] = pdev_stats->hw_reaped; /* ppdu reaped */
-	data[i++] = 0; /* tx bytes */
+	data[i++] = ar->debug.tx_ok;
+	data[i++] = ar->debug.tx_ok_bytes;
+	data[i++] = ar->debug.tx_bytes;
 	data[i++] = pdev_stats->htt_mpdus;
-	data[i++] = 0; /* rx bytes */
+	data[i++] = ar->debug.rx_bytes;
 	data[i++] = pdev_stats->ch_noise_floor;
 	data[i++] = pdev_stats->cycle_count;
+	data[i++] = pdev_stats->tx_frame_count;
+	data[i++] = pdev_stats->rx_frame_count;
+	data[i++] = pdev_stats->rx_clear_count; /* yes, this appears to actually be 'busy' count */
+	data[i++] = d_flags; /* give user-space a chance to decode cycle counters */
 	data[i++] = pdev_stats->phy_err_count;
 	data[i++] = pdev_stats->rts_bad;
 	data[i++] = pdev_stats->rts_good;
@@ -1416,6 +2209,10 @@ void ath10k_debug_get_et_stats(struct ie
 	data[i++] = pdev_stats->tx_ko;
 	data[i++] = pdev_stats->data_rc;
 	data[i++] = pdev_stats->sw_retry_failure;
+	data[i++] = ar->debug.tx_noack;
+	data[i++] = ar->debug.tx_noack_bytes;
+	data[i++] = ar->debug.tx_discard;
+	data[i++] = ar->debug.tx_discard_bytes;
 	data[i++] = pdev_stats->illgl_rate_phy_err;
 	data[i++] = pdev_stats->pdev_cont_xretry;
 	data[i++] = pdev_stats->pdev_tx_timeout;
@@ -1437,6 +2234,10 @@ void ath10k_debug_get_et_stats(struct ie
 	data[i++] = ar->stats.fw_crash_counter;
 	data[i++] = ar->stats.fw_warm_reset_counter;
 	data[i++] = ar->stats.fw_cold_reset_counter;
+	data[i++] = ar->fw_powerup_failed;
+	data[i++] = ar->debug.fw_stats.short_retries;
+	data[i++] = ar->debug.fw_stats.long_retries;
+	data[i++] = ar->debug.fw_stats.adc_temp;
 
 	spin_unlock_bh(&ar->data_lock);
 
@@ -2085,6 +2886,203 @@ static const struct file_operations fops
 	.open = simple_open
 };
 
+static ssize_t ath10k_write_thresh62_ext(struct file *file,
+					 const char __user *ubuf,
+					 size_t count, loff_t *ppos)
+{
+	struct ath10k *ar = file->private_data;
+	u8 val;
+	int ret = 0;
+
+	if (kstrtou8_from_user(ubuf, count, 0, &val))
+		return -EINVAL;
+
+	mutex_lock(&ar->conf_mutex);
+	ar->eeprom_overrides.thresh62_ext = val;
+	ret = ath10k_wmi_pdev_set_special(ar, SET_SPECIAL_ID_THRESH62_EXT, val);
+	mutex_unlock(&ar->conf_mutex);
+
+	return ret ?: count;
+}
+
+static ssize_t ath10k_read_thresh62_ext(struct file *file,
+					char __user *ubuf,
+					size_t count, loff_t *ppos)
+{
+	char buf[32];
+	struct ath10k *ar = file->private_data;
+	int len = 0;
+
+	mutex_lock(&ar->conf_mutex);
+	len = scnprintf(buf, sizeof(buf) - len, "%d\n",
+			ar->eeprom_overrides.thresh62_ext);
+	mutex_unlock(&ar->conf_mutex);
+
+	return simple_read_from_buffer(ubuf, count, ppos, buf, len);
+}
+
+static const struct file_operations fops_thresh62_ext = {
+	.read = ath10k_read_thresh62_ext,
+	.write = ath10k_write_thresh62_ext,
+	.open = simple_open
+};
+
+static ssize_t ath10k_write_ct_special(struct file *file,
+				       const char __user *ubuf,
+				       size_t count, loff_t *ppos)
+{
+	struct ath10k *ar = file->private_data;
+	u64 tmp;
+	u32 id;
+	u32 val;
+	int ret = 0;
+
+	if (kstrtou64_from_user(ubuf, count, 0, &tmp))
+		return -EINVAL;
+
+	id = tmp >> 32;
+	val = tmp & 0xFFFFFFFF;
+
+	mutex_lock(&ar->conf_mutex);
+	if (id == SET_SPECIAL_ID_THRESH62_EXT) {
+		ar->eeprom_overrides.thresh62_ext = val;
+	}
+	else if (id == SET_SPECIAL_ID_NOISE_FLR_THRESH) {
+		u8 band = val >> 24;
+		u8 type = (val >> 16) & 0xFF;
+		if ((band > 2) || (type > CT_CCA_TYPE_MAX)) {
+			ret = -EINVAL;
+			goto unlock;
+		}
+		if (type <= CT_CCA_TYPE_MIN2)
+			ar->eeprom_overrides.bands[band].minCcaPwrCT[type] = val & 0xFFFF;
+		else if (type == CT_CCA_TYPE_NOISE_FLOOR)
+			ar->eeprom_overrides.bands[band].noiseFloorThresh = val & 0xFFFF;
+		else if (type == CT_CCA_TYPE_EN_MINCCAPWR)
+			ar->eeprom_overrides.bands[band].enable_minccapwr_thresh = val & 0xFFFF;
+	}
+	else if (id == SET_SPECIAL_ID_IBSS_AMSDU_OK) {
+		ar->eeprom_overrides.allow_ibss_amsdu = !!val;
+	}
+	else if (id == SET_SPECIAL_ID_MAX_TXPOWER) {
+		/* This can only be set once, and is designed to be
+		 * a way to try to ensure that no other tools can
+		 * accidently or otherwise set the power in the firmware
+		 * higher.
+		 */
+		if (ar->eeprom_overrides.max_txpower == 0xFFFF) {
+			ar->eeprom_overrides.max_txpower = val;
+			ath10k_warn(ar, "Latching max-txpower to: %d (%d dBm)\n", val, val/2);
+		}
+		else {
+			ath10k_err(ar, "Cannot re-set max-txpower, old: %d  new: %d (%d dBm)\n",
+				   ar->eeprom_overrides.max_txpower, val, val/2);
+			ret = -EPERM;
+			goto unlock;
+		}
+	}
+	else if (id == SET_SPECIAL_ID_RC_MAX_PER_THR) {
+		ar->eeprom_overrides.rc_rate_max_per_thr = val;
+	}
+	else if (id == SET_SPECIAL_ID_STA_TXBW_MASK) {
+		/* Specify Station tx bandwidth mask (20, 40, 80Mhz). */
+		ar->eeprom_overrides.tx_sta_bw_mask = val;
+		ath10k_warn(ar, "Setting sta-tx-bw-mask to 0x%x\n", val);
+	}
+	else if (id == SET_SPECIAL_ID_PDEV_XRETRY_TH) {
+		/* Set the threshold for resetting phy due to failed retries, U16 */
+		ar->eeprom_overrides.pdev_xretry_th = val;
+		ath10k_warn(ar, "Setting pdev-xretry-th to 0x%x\n", val);
+	}
+	else if (id == SET_SPECIAL_ID_RIFS_ENABLE) {
+		/* Enable(1)/disable(0) baseband RIFS. */
+		ar->eeprom_overrides.rifs_enable_override = val;
+		ath10k_warn(ar, "Setting RIFS enable override to 0x%x\n", val);
+	}
+	else if (id == SET_SPECIAL_ID_WMI_WD) {
+		ar->eeprom_overrides.wmi_wd_keepalive_ms = val;
+		ath10k_warn(ar, "Setting WMI WD to 0x%x\n", val);
+		if (val == 0)
+			goto unlock; /* 0 means don't set */
+
+		if (val == 0xFFFFFFFF)
+			val = 0; /* 0xFFFFFFFF means disable, FW uses 0 to mean disable */
+	}
+	else if (id == SET_SPECIAL_ID_PSHACK) {
+		ar->eeprom_overrides.ct_pshack = val;
+		ath10k_warn(ar, "Setting CT-PSHACK override to 0x%x\n", val);
+	}
+	else if (id == SET_SPECIAL_ID_CSI) {
+		ar->eeprom_overrides.ct_csi = val;
+		ath10k_warn(ar, "Setting CT-CSI dump override to 0x%x\n", val);
+	}
+	/* Below here are local driver hacks, and not necessarily passed directly to firmware. */
+	else if (id == 0x1001) {
+		/* Set station failed-transmit kickout threshold. */
+		ar->sta_xretry_kickout_thresh = val;
+
+		ath10k_warn(ar, "Setting pdev sta-xretry-kickout-thresh to 0x%x\n",
+			    val);
+
+		ath10k_mac_set_pdev_kickout(ar);
+		goto unlock;
+	}
+	/* else, pass it through to firmware...but will not be stored locally, so
+	 * won't survive through firmware reboots, etc.
+	 */
+
+	/* Send it to the firmware. */
+	ret = ath10k_wmi_pdev_set_special(ar, id, val);
+unlock:
+	mutex_unlock(&ar->conf_mutex);
+
+	return ret ?: count;
+}
+
+static ssize_t ath10k_read_ct_special(struct file *file,
+				      char __user *user_buf,
+				      size_t count, loff_t *ppos)
+{
+	const char buf[] =
+		"BE WARNED:  You should understand the values before setting anything here.\n"
+		"You could put your NIC out of spec or maybe even break the hardware if you\n"
+		"put in bad values.\n\n"
+		"Value is u64, encoded thus:\n"
+		"id = t64 >> 32\n"
+		"val = t64 & 0xFFFFFFFF\n"
+		"id: 3 THRESH62_EXT (both bands use same value currently)\n"
+		"  value = val & 0xFF;\n"
+		"id: 4 CCA-Values, encoded as below:\n"
+		"  band = val >> 24;  //(0 5Ghz, 1 2.4Ghz)\n"
+		"  type = (val >> 16) & 0xFF; // 0-2 minCcaPwr[type], 3 noiseFloorThresh\n"
+		"         4 enable_minccapwr_thresh\n"
+		"  value = val & 0xFFFF;\n"
+		"    Unless otherwise specified, 0 means don't set.\n"
+		"    enable-minccapwr-thresh:  1 disabled, 2 enabled.\n"
+		"id: 5 Allow-AMSDU-IBSS, 1 enabled, 0 disabled, global setting.\n"
+		"id: 6 Max TX-Power, 0-65535:  Latch max-tx-power, in 0.5 dbM Units.\n"
+		"id: 7 RC max PER Threshold: 0-256 (50 is default). Tune with Care.\n"
+		"id: 8 STA-TX-BW-MASK,  0:  all, 0x1: 20Mhz, 0x2 40Mhz, 0x4 80Mhz \n"
+		"id: 9 pdev failed retry threshold, U16, 10.1 firmware default is 0x40\n"
+		"id: 0xA Enable(1)/Disable(0) baseband RIFS.  Default is disabled.\n"
+		"id: 0xB WMI WD Keepalive(ms): 0xFFFFFFFF disables, otherwise suggest 8000+.\n"
+		"id: 0xC Power-Save hack:  0x1 ignore PS sleep message from STA\n"
+		"id:                       0x2 mark mcast as 'data-is-buffered' regardless\n"
+		"id: 0xD Enable CSI reporting for at least probe requests.\n"
+		"\nBelow here are not actually sent to firmware directly, but configure the driver.\n"
+		"id: 0x1001 set sta-kickout threshold due to tx-failures (0 means disable.  Default is 20 * 16.)\n"
+		"\n";
+
+	return simple_read_from_buffer(user_buf, count, ppos, buf, strlen(buf));
+}
+
+static const struct file_operations fops_ct_special = {
+	.read = ath10k_read_ct_special,
+	.write = ath10k_write_ct_special,
+	.open = simple_open
+};
+
+
 static ssize_t ath10k_write_quiet_period(struct file *file,
 					 const char __user *ubuf,
 					 size_t count, loff_t *ppos)
@@ -2376,6 +3374,11 @@ int ath10k_debug_register(struct ath10k
 		return -ENOMEM;
 	}
 
+	INIT_DELAYED_WORK(&ar->debug.nop_dwork, ath10k_debug_nop_dwork);
+
+	queue_delayed_work(ar->workqueue, &ar->debug.nop_dwork,
+			   msecs_to_jiffies(ATH10K_DEBUG_NOP_INTERVAL));
+
 	INIT_DELAYED_WORK(&ar->debug.htt_stats_dwork,
 			  ath10k_debug_htt_stats_dwork);
 
@@ -2388,18 +3391,33 @@ int ath10k_debug_register(struct ath10k
 	debugfs_create_file("fw_reset_stats", S_IRUSR, ar->debug.debugfs_phy,
 			    ar, &fops_fw_reset_stats);
 
+	debugfs_create_file("fw_regs", S_IRUSR, ar->debug.debugfs_phy, ar,
+			    &fops_fw_regs);
+
 	debugfs_create_file("wmi_services", S_IRUSR, ar->debug.debugfs_phy, ar,
 			    &fops_wmi_services);
 
+	debugfs_create_file("set_rates", S_IRUSR | S_IWUSR, ar->debug.debugfs_phy,
+			    ar, &fops_set_rates);
+
+	debugfs_create_file("firmware_info", S_IRUSR, ar->debug.debugfs_phy, ar,
+			    &fops_fwinfo_services);
+
 	debugfs_create_file("simulate_fw_crash", S_IRUSR | S_IWUSR,
 			    ar->debug.debugfs_phy, ar, &fops_simulate_fw_crash);
 
+	debugfs_create_file("misc", S_IRUSR, ar->debug.debugfs_phy, ar,
+			    &fops_misc);
+
 	debugfs_create_file("fw_crash_dump", S_IRUSR, ar->debug.debugfs_phy,
 			    ar, &fops_fw_crash_dump);
 
 	debugfs_create_file("reg_addr", S_IRUSR | S_IWUSR,
 			    ar->debug.debugfs_phy, ar, &fops_reg_addr);
 
+	debugfs_create_file("debug_level", S_IRUSR, ar->debug.debugfs_phy,
+			    ar, &fops_debug_level);
+
 	debugfs_create_file("reg_value", S_IRUSR | S_IWUSR,
 			    ar->debug.debugfs_phy, ar, &fops_reg_value);
 
@@ -2451,6 +3469,12 @@ int ath10k_debug_register(struct ath10k
 	debugfs_create_file("tpc_stats", S_IRUSR,
 			    ar->debug.debugfs_phy, ar, &fops_tpc_stats);
 
+	debugfs_create_file("thresh62_ext", S_IRUGO | S_IWUSR,
+			    ar->debug.debugfs_phy, ar, &fops_thresh62_ext);
+
+	debugfs_create_file("ct_special", S_IRUGO | S_IWUSR,
+			    ar->debug.debugfs_phy, ar, &fops_ct_special);
+
 	if (test_bit(WMI_SERVICE_COEX_GPIO, ar->wmi.svc_map))
 		debugfs_create_file("btcoex", S_IRUGO | S_IWUSR,
 				    ar->debug.debugfs_phy, ar, &fops_btcoex);
@@ -2468,6 +3492,7 @@ int ath10k_debug_register(struct ath10k
 
 void ath10k_debug_unregister(struct ath10k *ar)
 {
+	cancel_delayed_work_sync(&ar->debug.nop_dwork);
 	cancel_delayed_work_sync(&ar->debug.htt_stats_dwork);
 }
 
@@ -2528,3 +3553,75 @@ void ath10k_dbg_dump(struct ath10k *ar,
 EXPORT_SYMBOL(ath10k_dbg_dump);
 
 #endif /* CONFIG_ATH10K_DEBUG */
+
+void ath10k_dbg_print_fw_dbg_buffer(struct ath10k *ar, __le32 *ibuf, int len,
+				    const char* lvl)
+{
+	/* Print out raw hex, external tools can decode if
+	 * they care.
+	 * TODO:  Add ar identifier to messages.
+	 */
+	int q = 0;
+
+	dev_printk(lvl, ar->dev, "ath10k_pci ATH10K_DBG_BUFFER:\n");
+	while (q < len) {
+		if (q + 8 <= len) {
+			printk("%sath10k: [%04d]: %08X %08X %08X %08X %08X %08X %08X %08X\n",
+			       lvl, q,
+			       ibuf[q], ibuf[q+1], ibuf[q+2], ibuf[q+3],
+			       ibuf[q+4], ibuf[q+5], ibuf[q+6], ibuf[q+7]);
+			q += 8;
+		}
+		else if (q + 7 <= len) {
+			printk("%sath10k: [%04d]: %08X %08X %08X %08X %08X %08X %08X\n",
+			       lvl, q,
+			       ibuf[q], ibuf[q+1], ibuf[q+2], ibuf[q+3],
+			       ibuf[q+4], ibuf[q+5], ibuf[q+6]);
+			q += 7;
+		}
+		else if (q + 6 <= len) {
+			printk("%sath10k: [%04d]: %08X %08X %08X %08X %08X %08X\n",
+			       lvl, q,
+			       ibuf[q], ibuf[q+1], ibuf[q+2], ibuf[q+3],
+			       ibuf[q+4], ibuf[q+5]);
+			q += 6;
+		}
+		else if (q + 5 <= len) {
+			printk("%sath10k: [%04d]: %08X %08X %08X %08X %08X\n",
+			       lvl, q,
+			       ibuf[q], ibuf[q+1], ibuf[q+2], ibuf[q+3],
+			       ibuf[q+4]);
+			q += 5;
+		}
+		else if (q + 4 <= len) {
+			printk("%sath10k: [%04d]: %08X %08X %08X %08X\n",
+			       lvl, q,
+			       ibuf[q], ibuf[q+1], ibuf[q+2], ibuf[q+3]);
+			q += 4;
+		}
+		else if (q + 3 <= len) {
+			printk("%sath10k: [%04d]: %08X %08X %08X\n",
+			       lvl, q,
+			       ibuf[q], ibuf[q+1], ibuf[q+2]);
+			q += 3;
+		}
+		else if (q + 2 <= len) {
+			printk("%sath10k: [%04d]: %08X %08X\n",
+			       lvl, q,
+			       ibuf[q], ibuf[q+1]);
+			q += 2;
+		}
+		else if (q + 1 <= len) {
+			printk("%sath10k: [%04d]: %08X\n",
+			       lvl, q,
+			       ibuf[q]);
+			q += 1;
+		}
+		else {
+			break;
+		}
+	}/* while */
+
+	dev_printk(lvl, ar->dev, "ATH10K_END\n");
+}
+EXPORT_SYMBOL(ath10k_dbg_print_fw_dbg_buffer);
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/net/wireless/ath/ath10k/debug.h linux-4.10.x/drivers/net/wireless/ath/ath10k/debug.h
--- linux-4.10.x.ori/drivers/net/wireless/ath/ath10k/debug.h	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/net/wireless/ath/ath10k/debug.h	2017-05-12 08:00:57.801800000 +0200
@@ -21,6 +21,10 @@
 #include <linux/types.h>
 #include "trace.h"
 
+/**
+ * ATH10K_DBG_INFO_AS_DBG: use dev_dbg instead of dev_info
+ *       for ath10k_info messages
+ */
 enum ath10k_debug_mask {
 	ATH10K_DBG_PCI		= 0x00000001,
 	ATH10K_DBG_WMI		= 0x00000002,
@@ -38,6 +42,10 @@ enum ath10k_debug_mask {
 	ATH10K_DBG_WMI_PRINT	= 0x00002000,
 	ATH10K_DBG_PCI_PS	= 0x00004000,
 	ATH10K_DBG_AHB		= 0x00008000,
+	ATH10K_DBG_NO_DBGLOG    = 0x10000000, /* Don't print DBGLOG firmware hex messages in kernel logs. */
+	ATH10K_DBG_MAC2	        = 0x20000000, /* more verbose MAC debugging */
+	ATH10K_DBG_INFO_AS_DBG	= 0x40000000,
+	ATH10K_DBG_FW		= 0x80000000,
 	ATH10K_DBG_ANY		= 0xffffffff,
 };
 
@@ -69,6 +77,7 @@ void ath10k_debug_print_hwfw_info(struct
 void ath10k_debug_print_board_info(struct ath10k *ar);
 void ath10k_debug_print_boot_info(struct ath10k *ar);
 void ath10k_print_driver_info(struct ath10k *ar);
+void ath10k_set_debug_mask(unsigned int v);
 
 #ifdef CONFIG_ATH10K_DEBUGFS
 int ath10k_debug_start(struct ath10k *ar);
@@ -105,8 +114,12 @@ static inline u32 ath10k_debug_get_fw_db
 	return ar->debug.fw_dbglog_level;
 }
 
+void ath10k_dbg_save_fw_dbg_buffer(struct ath10k *ar, __le32 *buffer, int len);
 #else
-
+static inline void ath10k_dbg_save_fw_dbg_buffer(struct ath10k *ar,
+						 __le32 *buffer, int len)
+{
+}
 static inline int ath10k_debug_start(struct ath10k *ar)
 {
 	return 0;
@@ -213,4 +226,9 @@ static inline void ath10k_dbg_dump(struc
 {
 }
 #endif /* CONFIG_ATH10K_DEBUG */
+
+int ath10k_refresh_peer_stats(struct ath10k *ar);
+void ath10k_dbg_print_fw_dbg_buffer(struct ath10k *ar, __le32 *buffer,
+				    int len, const char* lvl);
+
 #endif /* _DEBUG_H_ */
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/net/wireless/ath/ath10k/hif.h linux-4.10.x/drivers/net/wireless/ath/ath10k/hif.h
--- linux-4.10.x.ori/drivers/net/wireless/ath/ath10k/hif.h	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/net/wireless/ath/ath10k/hif.h	2017-05-12 08:00:57.801800000 +0200
@@ -78,6 +78,9 @@ struct ath10k_hif_ops {
 
 	void (*write32)(struct ath10k *ar, u32 address, u32 value);
 
+	/* We think firmware has crashed, attempt to gather logs and recover. */
+	void (*fw_crashed_dump)(struct ath10k *ar);
+
 	/* Power up the device and enter BMI transfer mode for FW download */
 	int (*power_up)(struct ath10k *ar);
 
@@ -195,6 +198,17 @@ static inline u32 ath10k_hif_read32(stru
 	return ar->hif.ops->read32(ar, address);
 }
 
+static inline int ath10k_hif_fw_crashed_dump(struct ath10k *ar)
+{
+	if (!ar->hif.ops->fw_crashed_dump) {
+		ath10k_warn(ar, "hif fw_crashed_dump\n");
+		return -EINVAL;
+	}
+
+	ar->hif.ops->fw_crashed_dump(ar);
+	return 0;
+}
+
 static inline void ath10k_hif_write32(struct ath10k *ar,
 				      u32 address, u32 data)
 {
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/net/wireless/ath/ath10k/htc.c linux-4.10.x/drivers/net/wireless/ath/ath10k/htc.c
--- linux-4.10.x.ori/drivers/net/wireless/ath/ath10k/htc.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/net/wireless/ath/ath10k/htc.c	2017-05-12 08:00:57.801800000 +0200
@@ -124,9 +124,18 @@ int ath10k_htc_send(struct ath10k_htc *h
 			goto err_pull;
 		}
 		ep->tx_credits -= credits;
-		ath10k_dbg(ar, ATH10K_DBG_HTC,
-			   "htc ep %d consumed %d credits (total %d)\n",
-			   eid, credits, ep->tx_credits);
+		if (eid == ar->wmi.eid) {
+			struct wmi_cmd_hdr* hdr;
+			hdr = (struct wmi_cmd_hdr*)(skb->data + sizeof(struct ath10k_htc_hdr));
+			ath10k_dbg(ar, ATH10K_DBG_HTC,
+				   "htc ep %d consumed %d credits (total %d, wmi-cmd 0x%x)\n",
+				   eid, credits, ep->tx_credits, __le32_to_cpu(hdr->cmd_id));
+		}
+		else {
+			ath10k_dbg(ar, ATH10K_DBG_HTC,
+				   "htc ep %d consumed %d credits (total %d)\n",
+				   eid, credits, ep->tx_credits);
+		}
 		spin_unlock_bh(&htc->tx_lock);
 	}
 
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/net/wireless/ath/ath10k/htt.c linux-4.10.x/drivers/net/wireless/ath/ath10k/htt.c
--- linux-4.10.x.ori/drivers/net/wireless/ath/ath10k/htt.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/net/wireless/ath/ath10k/htt.c	2017-05-12 08:00:57.801800000 +0200
@@ -269,8 +269,8 @@ int ath10k_htt_setup(struct ath10k_htt *
 					     htt->max_num_ampdu,
 					     htt->max_num_amsdu);
 	if (status) {
-		ath10k_warn(ar, "failed to setup amsdu/ampdu limit: %d\n",
-			    status);
+		ath10k_warn(ar, "failed to setup amsdu=%d/ampdu=%d limit: %d\n",
+			    htt->max_num_ampdu, htt->max_num_amsdu, status);
 		return status;
 	}
 
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/net/wireless/ath/ath10k/htt.h linux-4.10.x/drivers/net/wireless/ath/ath10k/htt.h
--- linux-4.10.x.ori/drivers/net/wireless/ath/ath10k/htt.h	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/net/wireless/ath/ath10k/htt.h	2017-05-12 08:00:57.801800000 +0200
@@ -310,7 +310,9 @@ struct htt_mgmt_tx_desc {
 enum htt_mgmt_tx_status {
 	HTT_MGMT_TX_STATUS_OK    = 0,
 	HTT_MGMT_TX_STATUS_RETRY = 1,
-	HTT_MGMT_TX_STATUS_DROP  = 2
+	HTT_MGMT_TX_STATUS_DROP  = 2,
+	HTT_MGMT_TX_STATUS_TXFILT = 3 /* Seems to be logically similar to
+					 RETRY failure. */
 };
 
 /*=== target -> host messages ===============================================*/
@@ -704,8 +706,9 @@ enum htt_security_types {
 };
 
 enum htt_security_flags {
-#define HTT_SECURITY_TYPE_MASK 0x7F
+#define HTT_SECURITY_TYPE_MASK 0x3F
 #define HTT_SECURITY_TYPE_LSB  0
+	HTT_SECURITY_IS_FAILURE = 1 << 6, /* CT firmware only */
 	HTT_SECURITY_IS_UNICAST = 1 << 7
 };
 
@@ -714,7 +717,9 @@ struct htt_security_indication {
 		/* dont use bitfields; undefined behaviour */
 		u8 flags; /* %htt_security_flags */
 		struct {
-			u8 security_type:7, /* %htt_security_types */
+			u8 security_type:6, /* %htt_security_types */
+			   is_failure:1, /* does this response indicate failure
+					    (CT Firmware) */
 			   is_unicast:1;
 		} __packed;
 	} __packed;
@@ -766,10 +771,33 @@ struct htt_data_tx_completion {
 		} __packed;
 	} __packed;
 	u8 num_msdus;
-	u8 rsvd0;
+	u8 flag_ack_rssi_filled:1, /* For 10.4 firmware */
+	   flag_reserved:5,
+	   flag_tx_rate_filled:1, /* CT firmware only currently */
+	   flag_reserved2:1;
 	__le16 msdus[0]; /* variable length based on %num_msdus */
 } __packed;
 
+struct msdu_rx_compl_info_ct {
+	__le16 id; /* msdu id */
+	u8 tx_rate_code; /* what rate index the firmware reports transmitting at. */
+	u8 tx_rate_flags; /* what rate flags, See ATH10K_RC_FLAG_SGI, etc */
+};
+
+struct htt_data_tx_completion_ct {
+	union {
+		u8 flags;
+		struct {
+			u8 status:3,
+			   tid:4,
+			   tid_invalid:1;
+		} __packed;
+	} __packed;
+	u8 num_msdus;
+	u8 rsvd0;
+	struct msdu_rx_compl_info_ct msdus[0]; /* variable length based on %num_msdus */
+} __packed;
+
 struct htt_tx_compl_ind_base {
 	u32 hdr;
 	u16 payload[1/*or more*/];
@@ -1526,6 +1554,7 @@ struct htt_resp {
 		struct htt_ver_resp ver_resp;
 		struct htt_mgmt_tx_completion mgmt_tx_completion;
 		struct htt_data_tx_completion data_tx_completion;
+		struct htt_data_tx_completion_ct data_tx_completion_ct;
 		struct htt_rx_indication rx_ind;
 		struct htt_rx_fragment_indication rx_frag_ind;
 		struct htt_rx_peer_map peer_map;
@@ -1551,9 +1580,25 @@ struct htt_resp {
 
 /*** host side structures follow ***/
 
+/* tx-rate flags field definitions, see firmware whal_desc.h */
+/* First two bits are for tx-completion report. */
+#define ATH10K_RC_FLAG_TXOK       0x00 /* Pkt transmitted OK */
+#define ATH10K_RC_FLAG_XRETRY     0x01 /* Pkt failed to transmit, too many retries. */
+#define ATH10K_RC_FLAG_DROP       0x02 /* Dropped due to tid flush, local buffer exhaustion, etc. */
+
+#define ATH10K_RC_FLAG_SGI        0x08 /* use HT SGI if set */
+#define ATH10K_RC_FLAG_STBC       0x10 /* use HT STBC if set */
+#define ATH10K_RC_FLAG_40MHZ      0x20 /* 40 mhz mode */
+#define ATH10K_RC_FLAG_80MHZ      0x40 /* 80 mhz mode */
+#define ATH10K_RC_FLAG_160MHZ     0x80 /* 160 mhz mode */
+
+
 struct htt_tx_done {
 	u16 msdu_id;
 	u16 status;
+	u8 tx_rate_code; /* CT firmware only, see firmware ar_desc_wifi_ip01.h (search for 0x44) */
+	u8 tx_rate_flags; /* CT firmware only, see flag defs above */
+	s16 ack_rssi;
 };
 
 enum htt_tx_compl_state {
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/net/wireless/ath/ath10k/htt_rx.c linux-4.10.x/drivers/net/wireless/ath/ath10k/htt_rx.c
--- linux-4.10.x.ori/drivers/net/wireless/ath/ath10k/htt_rx.c	2017-08-31 08:18:50.846242000 +0200
+++ linux-4.10.x/drivers/net/wireless/ath/ath10k/htt_rx.c	2017-08-31 08:18:50.846242000 +0200
@@ -702,6 +702,10 @@ static void ath10k_htt_rx_h_rates(struct
 		/* 80MHZ */
 		case 2:
 			status->vht_flag |= RX_VHT_FLAG_80MHZ;
+			break;
+		case 3:
+			status->vht_flag |= RX_VHT_FLAG_160MHZ;
+			break;
 		}
 
 		status->flag |= RX_FLAG_VHT;
@@ -743,7 +747,7 @@ ath10k_htt_rx_h_peer_channel(struct ath1
 	if (WARN_ON_ONCE(!arvif))
 		return NULL;
 
-	if (ath10k_mac_vif_chan(arvif->vif, &def))
+	if (WARN_ON_ONCE(ath10k_mac_vif_chan(arvif->vif, &def)))
 		return NULL;
 
 	return def.chan;
@@ -939,7 +943,7 @@ static void ath10k_process_rx(struct ath
 	*status = *rx_status;
 
 	ath10k_dbg(ar, ATH10K_DBG_DATA,
-		   "rx skb %pK len %u peer %pM %s %s sn %u %s%s%s%s%s %srate_idx %u vht_nss %u freq %u band %u flag 0x%llx fcs-err %i mic-err %i amsdu-more %i\n",
+		   "rx skb %pK len %u peer %pM %s %s sn %u %s%s%s%s%s%s %srate_idx %u vht_nss %u freq %u band %u flag 0x%llx fcs-err %i mic-err %i amsdu-more %i\n",
 		   skb,
 		   skb->len,
 		   ieee80211_get_SA(hdr),
@@ -953,6 +957,7 @@ static void ath10k_process_rx(struct ath
 		   status->flag & RX_FLAG_VHT ? "vht" : "",
 		   status->flag & RX_FLAG_40MHZ ? "40" : "",
 		   status->vht_flag & RX_VHT_FLAG_80MHZ ? "80" : "",
+		   status->vht_flag & RX_VHT_FLAG_160MHZ ? "160" : "",
 		   status->flag & RX_FLAG_SHORT_GI ? "sgi " : "",
 		   status->rate_idx,
 		   status->vht_nss,
@@ -1018,6 +1023,12 @@ static void ath10k_htt_rx_h_undecap_raw(
 	if (unlikely(WARN_ON_ONCE(!(is_first && is_last))))
 		return;
 
+	/* We see zero length msdus, not sure why.  At least don't
+	 * try to trim it further.
+	 */
+	if (unlikely(msdu->len < 4))
+		return;
+
 	skb_trim(msdu, msdu->len - FCS_LEN);
 
 	/* In most cases this will be true for sniffed frames. It makes sense
@@ -1397,6 +1408,9 @@ static void ath10k_htt_rx_h_mpdu(struct
 }
 
 	skb_queue_walk(amsdu, msdu) {
+#ifdef CONFIG_ATH10K_DEBUGFS
+		ar->debug.rx_bytes += msdu->len;
+#endif
 		ath10k_htt_rx_h_csum_offload(msdu);
 		ath10k_htt_rx_h_undecap(ar, msdu, status, first_hdr, enctype,
 					is_decrypted);
@@ -1627,26 +1641,98 @@ static void ath10k_htt_rx_tx_compl_ind(s
 		break;
 	}
 
-	ath10k_dbg(ar, ATH10K_DBG_HTT, "htt tx completion num_msdus %d\n",
-		   resp->data_tx_completion.num_msdus);
+	ath10k_dbg(ar, ATH10K_DBG_HTT,
+		   "htt tx completion num_msdus %d status: %d  discard: %d  no-ack: %d\n",
+		   resp->data_tx_completion.num_msdus, status,
+		   tx_done.status == HTT_TX_COMPL_STATE_DISCARD,
+		   tx_done.status == HTT_TX_COMPL_STATE_NOACK);
+
+	if (test_bit(ATH10K_FW_FEATURE_TXRATE_CT,
+		     ar->running_fw->fw_file.fw_features) &&
+	    ar->running_fw->fw_file.wmi_op_version != ATH10K_FW_WMI_OP_VERSION_10_4) {
+		/* CT firmware reports tx-rate-kbps as well as the msdu id */
+		for (i = 0; i < resp->data_tx_completion_ct.num_msdus; i++) {
+			msdu_id = resp->data_tx_completion_ct.msdus[i].id;
+			tx_done.msdu_id = __le16_to_cpu(msdu_id);
+			tx_done.tx_rate_code = resp->data_tx_completion_ct.msdus[i].tx_rate_code;
+			tx_done.tx_rate_flags = resp->data_tx_completion_ct.msdus[i].tx_rate_flags;
+
+			/* kfifo_put: In practice firmware shouldn't fire off per-CE
+			 * interrupt and main interrupt (MSI/-X range case) for the same
+			 * HTC service so it should be safe to use kfifo_put w/o lock.
+			 *
+			 * From kfifo_put() documentation:
+			 *  Note that with only one concurrent reader and one concurrent
+			 *  writer, you don't need extra locking to use these macro.
+			 */
+			if (!kfifo_put(&htt->txdone_fifo, tx_done)) {
+				ath10k_warn(ar, "txdone fifo overrun, msdu_id %d status %d\n",
+					    tx_done.msdu_id, tx_done.status);
+				ath10k_txrx_tx_unref(htt, &tx_done);
+			}
 
-	for (i = 0; i < resp->data_tx_completion.num_msdus; i++) {
-		msdu_id = resp->data_tx_completion.msdus[i];
-		tx_done.msdu_id = __le16_to_cpu(msdu_id);
-
-		/* kfifo_put: In practice firmware shouldn't fire off per-CE
-		 * interrupt and main interrupt (MSI/-X range case) for the same
-		 * HTC service so it should be safe to use kfifo_put w/o lock.
-		 *
-		 * From kfifo_put() documentation:
-		 *  Note that with only one concurrent reader and one concurrent
-		 *  writer, you don't need extra locking to use these macro.
+		}
+	} else if (resp->data_tx_completion.flag_ack_rssi_filled) {
+		/* Round up, firmware will align to 32-bit boundaries */
+		int storage_idx = (resp->data_tx_completion_ct.num_msdus + 1) & ~1;
+		__le16 ack_rssi;
+		__le16 rate_info;
+		/* 10.4 firmware may report the ack rssi.  If so, it is
+		 * a series of uint16 appended on the end of the report.
+		 * And, 10.4 CT firmware may also report tx-rate, which
+		 * will again be a series of uint16 appended on the end.
 		 */
-		if (!kfifo_put(&htt->txdone_fifo, tx_done)) {
-			ath10k_warn(ar, "txdone fifo overrun, msdu_id %d status %d\n",
-				    tx_done.msdu_id, tx_done.status);
+		if (WARN_ON_ONCE(skb->len < ((storage_idx * 2) + sizeof(struct htt_data_tx_completion)))) {
+			ath10k_err(ar, "Invalid length for ack-rssi report, skb->len: %d  storage_idx: %d msdu: %d\n",
+				   skb->len, storage_idx, resp->data_tx_completion_ct.num_msdus);
+			goto do_generic;
+		}
+
+		if (resp->data_tx_completion.flag_tx_rate_filled &&
+		    WARN_ON_ONCE(skb->len < ((storage_idx * 3) + sizeof(struct htt_data_tx_completion)))) {
+			ath10k_err(ar, "Invalid length for tx-rates report, skb->len: %d  storage_idx: %d msdu: %d\n",
+				   skb->len, storage_idx, resp->data_tx_completion_ct.num_msdus);
+			goto do_generic;
+		}
+
+		tx_done.tx_rate_code = 0;
+		tx_done.tx_rate_flags = 0;
+		for (i = 0; i < resp->data_tx_completion_ct.num_msdus; i++) {
+			msdu_id = resp->data_tx_completion.msdus[i];
+			tx_done.msdu_id = __le16_to_cpu(msdu_id);
+			ack_rssi = resp->data_tx_completion.msdus[storage_idx + i];
+			tx_done.ack_rssi = __le16_to_cpu(ack_rssi);
+			if (resp->data_tx_completion.flag_tx_rate_filled) {
+				rate_info = resp->data_tx_completion.msdus[storage_idx * 2 + i];
+				rate_info = __le16_to_cpu(rate_info);
+				tx_done.tx_rate_code = rate_info >> 8;
+				tx_done.tx_rate_flags = rate_info & 0xFF;
+			}
 			ath10k_txrx_tx_unref(htt, &tx_done);
 		}
+	} else {
+do_generic:
+		/* Upstream firmware does not report any tx-rate */
+		tx_done.tx_rate_code = 0;
+		tx_done.tx_rate_flags = 0;
+		for (i = 0; i < resp->data_tx_completion.num_msdus; i++) {
+			msdu_id = resp->data_tx_completion.msdus[i];
+			tx_done.msdu_id = __le16_to_cpu(msdu_id);
+
+			/* kfifo_put: In practice firmware shouldn't fire off per-CE
+			 * interrupt and main interrupt (MSI/-X range case) for the same
+			 * HTC service so it should be safe to use kfifo_put w/o lock.
+			 *
+			 * From kfifo_put() documentation:
+			 *  Note that with only one concurrent reader and one concurrent
+			 *  writer, you don't need extra locking to use these macro.
+			 */
+			if (!kfifo_put(&htt->txdone_fifo, tx_done)) {
+				ath10k_warn(ar, "txdone fifo overrun, msdu_id %d status %d\n",
+					    tx_done.msdu_id, tx_done.status);
+				ath10k_txrx_tx_unref(htt, &tx_done);
+			}
+		}
 	}
 }
 
@@ -2023,8 +2109,9 @@ static void ath10k_htt_rx_tx_fetch_ind(s
 		 */
 
 		if (unlikely(!txq)) {
-			ath10k_warn(ar, "failed to lookup txq for peer_id %hu tid %hhu\n",
-				    peer_id, tid);
+			if (net_ratelimit())
+				ath10k_warn(ar, "fetch-ind: failed to lookup txq for peer_id %hu tid %hhu\n",
+					    peer_id, tid);
 			continue;
 		}
 
@@ -2180,8 +2267,9 @@ static void ath10k_htt_rx_tx_mode_switch
 		 */
 
 		if (unlikely(!txq)) {
-			ath10k_warn(ar, "failed to lookup txq for peer_id %hu tid %hhu\n",
-				    peer_id, tid);
+			if (net_ratelimit())
+				ath10k_warn(ar, "mode-switch: failed to lookup txq for peer_id %hu tid %hhu\n",
+					    peer_id, tid);
 			continue;
 		}
 
@@ -2353,6 +2441,16 @@ bool ath10k_htt_t2h_msg_handler(struct a
 	case HTT_T2H_MSG_TYPE_VERSION_CONF: {
 		htt->target_version_major = resp->ver_resp.major;
 		htt->target_version_minor = resp->ver_resp.minor;
+
+		/* CT firmware with HTT-MGT?  No official firmware has this
+		 * htt version combination as far as I am aware. --Ben
+		 */
+		if ((htt->target_version_major == 2 &&
+		     htt->target_version_minor == 2))
+			ar->ct_all_pkts_htt = true;
+		else
+			ar->ct_all_pkts_htt = false;
+
 		complete(&htt->target_version_received);
 		break;
 	}
@@ -2380,6 +2478,8 @@ bool ath10k_htt_t2h_msg_handler(struct a
 		int status = __le32_to_cpu(resp->mgmt_tx_completion.status);
 
 		tx_done.msdu_id = __le32_to_cpu(resp->mgmt_tx_completion.desc_id);
+		tx_done.tx_rate_code = 0;
+		tx_done.tx_rate_flags = 0;
 
 		switch (status) {
 		case HTT_MGMT_TX_STATUS_OK:
@@ -2388,6 +2488,9 @@ bool ath10k_htt_t2h_msg_handler(struct a
 		case HTT_MGMT_TX_STATUS_RETRY:
 			tx_done.status = HTT_TX_COMPL_STATE_NOACK;
 			break;
+		case HTT_MGMT_TX_STATUS_TXFILT:
+			tx_done.status = HTT_TX_COMPL_STATE_NOACK;
+			break;
 		case HTT_MGMT_TX_STATUS_DROP:
 			tx_done.status = HTT_TX_COMPL_STATE_DISCARD;
 			break;
@@ -2410,9 +2513,23 @@ bool ath10k_htt_t2h_msg_handler(struct a
 
 		ath10k_dbg(ar, ATH10K_DBG_HTT,
 			   "sec ind peer_id %d unicast %d type %d\n",
-			  __le16_to_cpu(ev->peer_id),
-			  !!(ev->flags & HTT_SECURITY_IS_UNICAST),
-			  MS(ev->flags, HTT_SECURITY_TYPE));
+			   __le16_to_cpu(ev->peer_id),
+			   !!(ev->flags & HTT_SECURITY_IS_UNICAST),
+			   MS(ev->flags, HTT_SECURITY_TYPE));
+
+		/* CT firmware adds way to determine failure of key set, without
+		 * just timing things out.  Indication of failure is determined
+		 * by the 6th bit of the security-type being set.
+		 */
+		if (ev->flags & HTT_SECURITY_IS_FAILURE) {
+			ath10k_warn(ar, "Firmware failed to set security key, peer_id: %d unicast %d type %d\n",
+				    __le16_to_cpu(ev->peer_id),
+				    !!(ev->flags & HTT_SECURITY_IS_UNICAST),
+				    MS(ev->flags, HTT_SECURITY_TYPE));
+			ar->install_key_rv = -EINVAL;
+		} else {
+			ar->install_key_rv = 0;
+		}
 		complete(&ar->install_key_done);
 		break;
 	}
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/net/wireless/ath/ath10k/htt_tx.c linux-4.10.x/drivers/net/wireless/ath/ath10k/htt_tx.c
--- linux-4.10.x.ori/drivers/net/wireless/ath/ath10k/htt_tx.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/net/wireless/ath/ath10k/htt_tx.c	2017-05-12 08:00:57.801800000 +0200
@@ -811,6 +811,9 @@ static u8 ath10k_htt_tx_get_tid(struct s
 
 	if (!is_eth && ieee80211_is_mgmt(hdr->frame_control))
 		return HTT_DATA_TX_EXT_TID_MGMT;
+
+	else if (ieee80211_is_nullfunc(hdr->frame_control))
+		return HTT_DATA_TX_EXT_TID_NON_QOS_MCAST_BCAST;
 	else if (cb->flags & ATH10K_SKB_F_QOS)
 		return skb->priority % IEEE80211_QOS_CTL_TID_MASK;
 	else
@@ -878,6 +881,10 @@ int ath10k_htt_mgmt_tx(struct ath10k_htt
 	if (res)
 		goto err_unmap_msdu;
 
+#ifdef CONFIG_ATH10K_DEBUGFS
+	ar->debug.tx_bytes += msdu->len;
+#endif
+
 	return 0;
 
 err_unmap_msdu:
@@ -1080,6 +1087,10 @@ int ath10k_htt_tx(struct ath10k_htt *htt
 	if (res)
 		goto err_unmap_msdu;
 
+#ifdef CONFIG_ATH10K_DEBUGFS
+	ar->debug.tx_bytes += msdu->len;
+#endif
+
 	return 0;
 
 err_unmap_msdu:
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/net/wireless/ath/ath10k/hw.h linux-4.10.x/drivers/net/wireless/ath/ath10k/hw.h
--- linux-4.10.x.ori/drivers/net/wireless/ath/ath10k/hw.h	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/net/wireless/ath/ath10k/hw.h	2017-05-12 08:00:57.801800000 +0200
@@ -148,6 +148,8 @@ enum qca9377_chip_id_rev {
 
 #define REG_DUMP_COUNT_QCA988X 60
 
+#define ATH10K_FW_STACK_SIZE 4096
+
 struct ath10k_fw_ie {
 	__le32 id;
 	__le32 len;
@@ -173,6 +175,8 @@ enum ath10k_fw_ie_type {
 
 	/* Code swap image for firmware binary */
 	ATH10K_FW_IE_FW_CODE_SWAP_IMAGE = 7,
+
+	ATH10K_FW_IE_BSS_INFO_CT = 30,
 };
 
 enum ath10k_fw_wmi_op_version {
@@ -480,6 +484,26 @@ ath10k_rx_desc_get_l3_pad_bytes(struct a
 						 (TARGET_10X_NUM_VDEVS))
 #define TARGET_10X_TX_STATS_NUM_PEERS		((TARGET_10X_TX_STATS_NUM_STATIONS) + \
 						 (TARGET_10X_NUM_VDEVS))
+
+/* Over-rides for Candela Technologies firmware */
+#define DEF_TARGET_10X_NUM_VDEVS_CT		16 /* Can support up to 64 with proper config of other settings.
+						    * override w/module parm or fwcfg file */
+/* NOTE:  AST can really hold 4 keys, and there can be some temporarily in use as well.  So this
+ * needs to be pretty large.  256 works in my testing with 64 station vdevs (360 works better). --Ben
+ */
+#define TARGET_10X_AST_SKID_LIMIT_CT		360 /*((ath10k_modparam_target_num_peers_ct * TARGET_10X_NUM_PEER_AST)*/
+#define TARGET_10X_NUM_PEER_KEYS_CT             (WMI_MAX_KEY_INDEX + 1) /* 4 */
+
+/* Related to HTC buffers */
+/* return any credit immediately */
+#define TARGET_HTC_MAX_PENDING_TXCREDITS_RPTS   1
+/* 8 ctrl buffers for sending info to host */
+#define TARGET_HTC_MAX_CONTROL_BUFFERS          6
+/* Only CT firmware will actually use this value.  Each buffer is close to 2K
+ * of firmware RAM, so not sure if increasing this is worth the RAM cost.
+ */
+#define TARGET_HTC_MAX_TX_CREDITS_CT            2
+
 #define TARGET_10X_NUM_OFFLOAD_PEERS		0
 #define TARGET_10X_NUM_OFFLOAD_REORDER_BUFS	0
 #define TARGET_10X_NUM_PEER_KEYS		2
@@ -713,6 +737,7 @@ ath10k_rx_desc_get_l3_pad_bytes(struct a
 #define PCIE_INTR_ENABLE_ADDRESS		0x0008
 #define PCIE_INTR_CAUSE_ADDRESS			0x000c
 #define PCIE_INTR_CLR_ADDRESS			ar->regs->pcie_intr_clr_address
+#define SCRATCH_2_ADDRESS                       0x002c
 #define SCRATCH_3_ADDRESS			ar->regs->scratch_3_address
 #define CPU_INTR_ADDRESS			0x0010
 
@@ -724,6 +749,10 @@ ath10k_rx_desc_get_l3_pad_bytes(struct a
 #define FW_IND_INITIALIZED			2
 #define FW_IND_HOST_READY			0x80000000
 
+/* CT firmware only */
+#define FW_IND_SCRATCH2_WR      (1<<14) /* scratch2 has data written to it */
+#define FW_IND_SCRATCH2_RD      (1<<15) /* scratch2 has been read (by host) */
+
 /* HOST_REG interrupt from firmware */
 #define PCIE_INTR_FIRMWARE_MASK			ar->regs->pcie_intr_fw_mask
 #define PCIE_INTR_CE_MASK_ALL			ar->regs->pcie_intr_ce_mask_all
@@ -840,4 +869,25 @@ ath10k_rx_desc_get_l3_pad_bytes(struct a
 #define WAVE1_PHYCLK_USEC_MASK			0x0000007F
 #define WAVE1_PHYCLK_USEC_LSB			0
 
+/* Target debug log related defines and structs */
+
+/* Target is 32-bit CPU, so we just use u32 for
+ * the pointers.  The memory space is relative to the
+ * target, not the host.  Values are converted to host
+ * byte order when reading from firmware.
+ */
+struct ath10k_fw_dbglog_buf {
+	__le32 next; /* pointer to ath10k_fw_dbglog_buf. */
+	__le32 buffer; /* pointer to u8 buffer */
+	__le32 bufsize;
+	__le32 length;
+	__le32 count;
+	__le32 free;
+} __packed;
+
+struct ath10k_fw_dbglog_hdr {
+	__le32 dbuf; /* pointer to ath10k_fw_dbglog_buf */
+	__le32 dropped;
+} __packed;
+
 #endif /* _HW_H_ */
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/net/wireless/ath/ath10k/mac.c linux-4.10.x/drivers/net/wireless/ath/ath10k/mac.c
--- linux-4.10.x.ori/drivers/net/wireless/ath/ath10k/mac.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/net/wireless/ath/ath10k/mac.c	2017-05-12 08:00:57.801800000 +0200
@@ -20,6 +20,7 @@
 #include <net/mac80211.h>
 #include <linux/etherdevice.h>
 #include <linux/acpi.h>
+#include <linux/module.h>
 
 #include "hif.h"
 #include "core.h"
@@ -207,6 +208,42 @@ int ath10k_mac_ext_resource_config(struc
 	return 0;
 }
 
+/* 0:  Full hardware crypt
+ * 1:  Tx hardware crypt, but expect rx software crypt (use native wifi tx type)
+ */
+int ath10k_modparam_nohwcrypt;
+module_param_named(nohwcrypt, ath10k_modparam_nohwcrypt, int, 0444);
+MODULE_PARM_DESC(nohwcrypt, "Disable hardware rx decrypt feature");
+int ath10k_modparam_target_num_vdevs_ct = DEF_TARGET_10X_NUM_VDEVS_CT;
+module_param_named(num_vdevs_ct, ath10k_modparam_target_num_vdevs_ct, int, 0444);
+MODULE_PARM_DESC(num_vdevs_ct, "Maximum vdevs to request from firmware");
+
+/* More than 127 seems to cause issues when using HW de-crypt, so default to 127. */
+int ath10k_modparam_target_num_peers_ct = 127;
+module_param_named(num_peers_ct, ath10k_modparam_target_num_peers_ct, int, 0444);
+MODULE_PARM_DESC(num_peers_ct, "Maximum peers to request from firmware");
+
+/* These consume a fair bit of RAM on target. */
+int ath10k_modparam_target_num_msdu_desc_ct = TARGET_10X_NUM_MSDU_DESC;
+module_param_named(num_msdu_desc_ct, ath10k_modparam_target_num_msdu_desc_ct, int, 0444);
+MODULE_PARM_DESC(num_msdu_desc_ct, "Maximum MSDU Descriptors in firmware (must be multiple of 8)");
+
+/* The firmware tries to cache rate-ctrl objects in the host (driver) memory.  But,
+ * with lots of active stations, this appears to cause constant cache swapping and
+ * in the end, rate-ctrl fails to work well at all.
+ * CT Firmware has lots of RAM savings, especially when using fewer than 64 vdevs,
+ * so allow users to configure more than the default (currently 32) of in-ram
+ * rate-ctrl objects.  As long as firmware RAM is available, allocating as many
+ * rate-ctrl objects as possible (up to number of peers) is probably a good idea.
+ * This setting should be harmless in all CT firmware, but it will only have an
+ * effect in beta-16 firmware and later.  Setting value to 0 means use firmware
+ * defaults.
+ */
+int ath10k_modparam_target_num_rate_ctrl_objs_ct = 0;
+module_param_named(num_rate_ctrl_objs_ct, ath10k_modparam_target_num_rate_ctrl_objs_ct, int, 0444);
+MODULE_PARM_DESC(num_rate_ctrl_objs_ct, "Number of rate-ctrl objects to cache in firmware RAM");
+
+
 /**********/
 /* Crypto */
 /**********/
@@ -225,6 +262,7 @@ static int ath10k_send_key(struct ath10k
 		.key_flags = flags,
 		.macaddr = macaddr,
 	};
+	int ret1, ret2;
 
 	lockdep_assert_held(&arvif->ar->conf_mutex);
 
@@ -258,7 +296,13 @@ static int ath10k_send_key(struct ath10k
 		arg.key_data = NULL;
 	}
 
-	return ath10k_wmi_vdev_install_key(arvif->ar, &arg);
+	ret1 = ath10k_wmi_vdev_install_key(arvif->ar, &arg);
+	ret2 = ath10k_wmi_barrier(ar);
+	if (ret2) {
+		ath10k_err(ar, "failed to ping firmware: %d\n", ret2);
+		return ret2;
+	}
+	return ret1;
 }
 
 static int ath10k_install_key(struct ath10k_vif *arvif,
@@ -285,7 +329,8 @@ static int ath10k_install_key(struct ath
 	if (time_left == 0)
 		return -ETIMEDOUT;
 
-	return 0;
+	ret = ar->install_key_rv;
+	return ret;
 }
 
 static int ath10k_install_peer_wep_keys(struct ath10k_vif *arvif,
@@ -569,10 +614,14 @@ chan_to_phymode(const struct cfg80211_ch
 		case NL80211_CHAN_WIDTH_80:
 			phymode = MODE_11AC_VHT80;
 			break;
+		case NL80211_CHAN_WIDTH_160:
+			phymode = MODE_11AC_VHT160;
+			break;
+		case NL80211_CHAN_WIDTH_80P80:
+			phymode = MODE_11AC_VHT80_80;
+			break;
 		case NL80211_CHAN_WIDTH_5:
 		case NL80211_CHAN_WIDTH_10:
-		case NL80211_CHAN_WIDTH_80P80:
-		case NL80211_CHAN_WIDTH_160:
 			phymode = MODE_UNKNOWN;
 			break;
 		}
@@ -688,8 +737,11 @@ static int ath10k_peer_create(struct ath
 	list_for_each_entry(arvif, &ar->arvifs, list)
 		num_peers++;
 
-	if (num_peers >= ar->max_num_peers)
+	if (num_peers >= ar->max_num_peers) {
+		ath10k_warn(ar, "failed to create peer %pM for vdev %d, too-many-peers (ar->num_peers: %d  num_peers: %d  max_peers: %d)\n",
+			    sta->addr, vdev_id, ar->num_peers, num_peers, ar->max_num_peers);
 		return -ENOBUFS;
+	}
 
 	ret = ath10k_wmi_peer_create(ar, vdev_id, addr, peer_type);
 	if (ret) {
@@ -726,21 +778,26 @@ static int ath10k_peer_create(struct ath
 	return 0;
 }
 
+int ath10k_mac_set_pdev_kickout(struct ath10k *ar)
+{
+	u32 param = ar->wmi.pdev_param->sta_kickout_th;
+	int rv;
+
+	rv = ath10k_wmi_pdev_set_param(ar, param,
+				       ar->sta_xretry_kickout_thresh);
+	if (rv) {
+		ath10k_warn(ar, "failed to set sta kickout threshold to %d: %d\n",
+			    ar->sta_xretry_kickout_thresh, rv);
+	}
+	return rv;
+}
+
 static int ath10k_mac_set_kickout(struct ath10k_vif *arvif)
 {
 	struct ath10k *ar = arvif->ar;
 	u32 param;
 	int ret;
 
-	param = ar->wmi.pdev_param->sta_kickout_th;
-	ret = ath10k_wmi_pdev_set_param(ar, param,
-					ATH10K_KICKOUT_THRESHOLD);
-	if (ret) {
-		ath10k_warn(ar, "failed to set kickout threshold on vdev %i: %d\n",
-			    arvif->vdev_id, ret);
-		return ret;
-	}
-
 	param = ar->wmi.vdev_param->ap_keepalive_min_idle_inactive_time_secs;
 	ret = ath10k_wmi_vdev_set_param(ar, arvif->vdev_id, param,
 					ATH10K_KEEPALIVE_MIN_IDLE);
@@ -783,14 +840,20 @@ static int ath10k_mac_set_rts(struct ath
 static int ath10k_peer_delete(struct ath10k *ar, u32 vdev_id, const u8 *addr)
 {
 	int ret;
+	int tries = 3;
 
 	lockdep_assert_held(&ar->conf_mutex);
 
-	ret = ath10k_wmi_peer_delete(ar, vdev_id, addr);
-	if (ret)
-		return ret;
+	do {
+		ret = ath10k_wmi_peer_delete(ar, vdev_id, addr);
+		if (ret)
+			return ret;
+
+		ret = ath10k_wait_for_peer_deleted(ar, vdev_id, addr);
+		if (ret == 0) /* else, try again, maybe FW dropped a msg? */
+			break;
+	} while (--tries);
 
-	ret = ath10k_wait_for_peer_deleted(ar, vdev_id, addr);
 	if (ret)
 		return ret;
 
@@ -817,6 +880,8 @@ static void ath10k_peer_cleanup(struct a
 
 		for_each_set_bit(peer_id, peer->peer_ids,
 				 ATH10K_MAX_NUM_PEER_IDS) {
+			ath10k_warn(ar, "removing peer mapping %pM peer-id: %d\n",
+				    peer->addr, peer_id);
 			ar->peer_map[peer_id] = NULL;
 		}
 
@@ -838,6 +903,24 @@ static void ath10k_peer_cleanup(struct a
 	spin_unlock_bh(&ar->data_lock);
 }
 
+void ath10k_dump_peer_info(struct ath10k *ar)
+{
+	struct ath10k_peer *peer;
+	int peer_id;
+
+	lockdep_assert_held(&ar->data_lock);
+
+	list_for_each_entry(peer, &ar->peers, list) {
+		ath10k_warn(ar, "peer: %p vdev: %d  addr: %pM\n",
+			    peer, peer->vdev_id, peer->addr);
+		for_each_set_bit(peer_id, peer->peer_ids,
+				 ATH10K_MAX_NUM_PEER_IDS) {
+			ath10k_warn(ar, "  peer %pM peer-id: %d\n",
+				    peer->addr, peer_id);
+		}
+	}
+}
+
 static void ath10k_peer_cleanup_all(struct ath10k *ar)
 {
 	struct ath10k_peer *peer, *tmp;
@@ -847,6 +930,8 @@ static void ath10k_peer_cleanup_all(stru
 
 	spin_lock_bh(&ar->data_lock);
 	list_for_each_entry_safe(peer, tmp, &ar->peers, list) {
+		ath10k_warn(ar, "removing peer, cleanup-all, deleting: peer %p vdev: %d addr: %pM \n",
+			    peer, peer->vdev_id, peer->addr);
 		list_del(&peer->list);
 		kfree(peer);
 	}
@@ -971,6 +1056,7 @@ static int ath10k_monitor_vdev_start(str
 	arg.vdev_id = vdev_id;
 	arg.channel.freq = channel->center_freq;
 	arg.channel.band_center_freq1 = chandef->center_freq1;
+	arg.channel.band_center_freq2 = chandef->center_freq2;
 
 	/* TODO setup this dynamically, what in case we
 	   don't have any vifs? */
@@ -1384,6 +1470,7 @@ static int ath10k_vdev_start_restart(str
 
 	arg.channel.freq = chandef->chan->center_freq;
 	arg.channel.band_center_freq1 = chandef->center_freq1;
+	arg.channel.band_center_freq2 = chandef->center_freq2;
 	arg.channel.mode = chan_to_phymode(chandef);
 
 	arg.channel.min_power = 0;
@@ -1391,6 +1478,22 @@ static int ath10k_vdev_start_restart(str
 	arg.channel.max_reg_power = chandef->chan->max_reg_power * 2;
 	arg.channel.max_antenna_gain = chandef->chan->max_antenna_gain * 2;
 
+	/* CT Firmware can support 32+ VDEVS, but can only support
+	 * beacon-ing devs with dev ids 0 - 31 due to firmware limitations.
+	 * Create VAPs first and all should be well...likely most people
+	 * won't ever hit this anyway, but some day the vdev ID allocation
+	 * could be made smarter to make it more likely to work no matter the
+	 * order the vdevs are created. --Ben
+	 */
+	if ((arvif->vdev_type == WMI_VDEV_TYPE_AP) ||
+	    (arvif->vdev_type == WMI_VDEV_TYPE_IBSS)) {
+		if (arg.vdev_id > 31) {
+			ath10k_warn(ar, "failed to start vdev %i  Beaconing VIFS must have IDs <= 31 to work-around firmware limitations.\n",
+				    arg.vdev_id);
+			return -EINVAL;
+		}
+	}
+
 	if (arvif->vdev_type == WMI_VDEV_TYPE_AP) {
 		arg.ssid = arvif->u.ap.ssid;
 		arg.ssid_len = arvif->u.ap.ssid_len;
@@ -2177,6 +2280,194 @@ ath10k_peer_assoc_h_vht_masked(const u16
 	return true;
 }
 
+static void ath10k_set_rate_enabled(int rix, u8 *rt_array, int val) {
+	int idx = rix / 8;
+	int bit = rix - (idx * 8);
+
+	//pr_err(" rix: %d  idx: %d  bit: %d\n", rix, idx, bit);
+	if (WARN_ON_ONCE(idx >= RATE_OVERRIDES_COUNT))
+		return;
+
+	if (val) {
+		rt_array[idx] |= (1<<bit);
+	}
+	else {
+		rt_array[idx] &= ~(1<<bit);
+	}
+}
+
+static void ath10k_peer_assoc_h_rate_overrides(struct ath10k *ar,
+					       struct ieee80211_vif *vif,
+					       struct ieee80211_sta *sta,
+					       struct wmi_peer_assoc_complete_arg *arg)
+{
+	struct ath10k_vif *arvif = ath10k_vif_to_arvif(vif);
+	const struct ieee80211_supported_band *sband;
+	const struct ieee80211_rate *rates;
+	struct cfg80211_chan_def def;
+	enum nl80211_band band;
+	u32 ratemask;
+	int i;
+	int j;
+	int hw_rix;
+	bool ok160 = false;
+
+	/* So, what we really want here is the max number of chains the firmware
+	 * is compiled for.  But, since we can have 3x3 firmware run on 2x2 chips,
+	 * then we need to hack on this in gruesome ways.  Better have the hack here
+	 * than try to extend FW's ability to send that value I think.
+	 */
+	int hw_nss = ar->num_rf_chains;
+	if (! test_bit(ATH10K_FW_FEATURE_CT_RATEMASK,
+		       ar->running_fw->fw_file.fw_features))
+		return;
+
+	/* Ignore devices not known to be supported, this is a minor feature and
+	 * not worth breaking systems for users that don't need it.
+	 */
+	if (!((ar->dev_id == QCA9887_1_0_DEVICE_ID) ||
+	      (ar->dev_id == QCA988X_2_0_DEVICE_ID) ||
+	      (ar->dev_id == QCA99X0_2_0_DEVICE_ID) ||
+	      (ar->dev_id == QCA9984_1_0_DEVICE_ID))) {
+		ath10k_warn(ar, "rate-override:  Skipping un-supported device-id, hw-nss: %d dev-id: 0x%x\n",
+			    hw_nss, ar->dev_id);
+		return;
+	}
+
+	if (ar->dev_id == QCA9984_1_0_DEVICE_ID) {
+		ok160 = true;
+	}
+
+	if (hw_nss < 3) {
+		/* Maybe 2x2 NIC booting 3x3 988x firmware? */
+		/* 9887 is weird, NSS = 1, but FW rate-table is compiled for 3x3 evidently */
+		if ((ar->dev_id == QCA988X_2_0_DEVICE_ID) ||
+		    (ar->dev_id == QCA9887_1_0_DEVICE_ID)) {
+			hw_nss = 3;
+		}
+	}
+
+	lockdep_assert_held(&ar->conf_mutex);
+
+	if (WARN_ON(ath10k_mac_vif_chan(vif, &def)))
+		return;
+
+	band = def.chan->band;
+	sband = ar->hw->wiphy->bands[band];
+	ratemask = arvif->bitrate_mask.control[band].legacy;
+	rates = sband->bitrates;
+
+	ath10k_warn(ar, "band: %d  ratemask: 0x%x  hw-nss: %d dev-id: 0x%x\n",
+		    band, ratemask, hw_nss, ar->dev_id);
+
+	arg->has_rate_overrides = true;
+
+	/* Clear the rateset */
+	memset(arg->rate_overrides, 0x0, sizeof(arg->rate_overrides));
+
+	/* Legacy rates */
+	for (i = 0; i < sband->n_bitrates; i++, ratemask >>= 1, rates++) {
+		if (!(ratemask & 1))
+			continue;
+
+		if (ath10k_mac_bitrate_is_cck(rates->bitrate)) {
+			hw_rix = rates->hw_value;
+		}
+		else {
+			/* ofdm rates start at rix 4 */
+			hw_rix = rates->hw_value + 4;
+		}
+		ath10k_dbg(ar, ATH10K_DBG_MAC2,
+			   "set-enabled, bitrate: %d  i: %d  hw-value: %d hw-rix: %d\n",
+			   rates->bitrate, i, rates->hw_value, hw_rix);
+		ath10k_set_rate_enabled(hw_rix, arg->rate_overrides, 1);
+	}
+
+	/* HT rate logic (ath10k AR98XX, at least, uses 3x3 rateset).  First set
+	 * of 3 is HT20, second set is HT40.  No way to specify HT20 vs HT40
+	 * using normal rate-set info as far as I can tell, so set both to the
+	 * same value.
+	 */
+	for (i = 0; i < hw_nss; i++) {
+		unsigned int mcs = arvif->bitrate_mask.control[band].ht_mcs[i];
+		ath10k_dbg(ar, ATH10K_DBG_MAC2, "ht-mcs [%i]: 0x%x\n", i, mcs);
+		for (j = 0; j<8; j++) {
+			if (mcs & (1<<j)) {
+				hw_rix = 12 + i * 8 + j;
+				ath10k_dbg(ar, ATH10K_DBG_MAC2,
+					   "set-enabled, ht: hw-rix: %d, %d  i: %d j: %d\n",
+					   hw_rix, hw_rix + hw_nss * 8, i, j);
+				ath10k_set_rate_enabled(hw_rix, arg->rate_overrides, 1);
+				/* Set HT40 rateset too */
+				ath10k_set_rate_enabled(hw_rix + hw_nss * 8, arg->rate_overrides, 1);
+			}
+		}
+	}
+
+	/* VHT rate logic (ath10k AR98XX, at least, uses 3x3 rateset).
+	 * One set of rates for each of 20, 40, 80Mhz bandwidth.
+	 * Each set has 10 rates for each of 1, 2, and 3 streams.
+	 * No way to specify HT20 vs HT40 vs HT80
+	 * using normal rate-set info as far as I can tell, so set all three to the
+	 * same value.
+	 */
+	/* NOTE: VHT has some illegal rates (VHT-20 MCS 9 at 1x1 and 2x2, and MCS6 at VHT-80).  If user has
+	 * specified only these rates, then the rateset for that bandwidth will be null, and that will
+	 * crash the firmware.  So, try to set the nearest thing.
+	 */
+
+
+	for (i = 0; i < hw_nss; i++) {
+		unsigned int mcs = arvif->bitrate_mask.control[band].vht_mcs[i];
+		ath10k_dbg(ar, ATH10K_DBG_MAC2, "vht-mcs [%i]: 0x%x\n", i, mcs);
+		for (j = 0; j<10; j++) {
+			if (mcs & (1<<j)) {
+				int hw_rix_20_40, hw_rix_80;
+				hw_rix = 12 + (hw_nss * 2) * 8 + i * 10 + j;
+				hw_rix_20_40 = hw_rix;
+				hw_rix_80 = hw_rix;
+				if ((i < 2) && (j == 9)) {
+					/* Requested invalid rate:  mcs-9 for 1x1 or 2x2, use nearest. */
+					hw_rix_20_40 = 12 + (hw_nss * 2) * 8 + i * 10 + 8;
+				}
+				if ((i == 2) && (j == 6)) {
+					/* Requested invalid rate:  mcs-6 for 80Mhz, use nearest. */
+					hw_rix_80 = 12 + (hw_nss * 2) * 8 + i * 10 + 5;
+				}
+				ath10k_dbg(ar, ATH10K_DBG_MAC2,
+					   "set-enabled, vht: hw-rix-20-40: %d, hw-rix-80: %d  orig-hw-rix: %d  %d, %d  i: %d j: %d\n",
+					   hw_rix_20_40, hw_rix_80, hw_rix, hw_rix + hw_nss * 10, hw_rix + hw_nss * 2 * 10, i, j);
+				ath10k_set_rate_enabled(hw_rix_20_40, arg->rate_overrides, 1);
+				/* Set HT40 rateset too */
+				ath10k_set_rate_enabled(hw_rix_20_40 + hw_nss * 10, arg->rate_overrides, 1);
+				/* Set HT80 rateset too */
+				ath10k_set_rate_enabled(hw_rix_80 + hw_nss * 2 * 10, arg->rate_overrides, 1);
+				/* And for NICs that support 160Mhz, set those */
+				if (ok160)
+					ath10k_set_rate_enabled(hw_rix + hw_nss * 3 * 10, arg->rate_overrides, 1);
+			}
+		}
+	}
+
+	for (i = 0; i < sizeof(arg->rate_overrides); i++) {
+		if (arg->rate_overrides[i] != 0xFF) {
+			ath10k_dbg(ar, ATH10K_DBG_MAC2, "vif: %d rate-overrides[%d]: 0x%x\n",
+				   arvif->vdev_id, i, arg->rate_overrides[i]);
+		}
+	}
+}
+
+static u8 get_nss_from_chainmask(u16 chain_mask)
+{
+	if ((chain_mask & 0xf) == 0xf)
+		return 4;
+	else if ((chain_mask & 0x7) == 0x7)
+		return 3;
+	else if ((chain_mask & 0x3) == 0x3)
+		return 2;
+	return 1;
+}
+
 static void ath10k_peer_assoc_h_ht(struct ath10k *ar,
 				   struct ieee80211_vif *vif,
 				   struct ieee80211_sta *sta,
@@ -2200,6 +2491,11 @@ static void ath10k_peer_assoc_h_ht(struc
 	if (!ht_cap->ht_supported)
 		return;
 
+	/* TODO:  We need to have a distinction between tx bitrate
+	 * masks and advertised bitrate masks.  This code is trying
+	 * to use tx bitrate as advertised bitrate, and that causes
+	 * some problems and/or requires hack-arounds. --Ben
+	 */
 	band = def.chan->band;
 	ht_mcs_mask = arvif->bitrate_mask.control[band].ht_mcs;
 	vht_mcs_mask = arvif->bitrate_mask.control[band].vht_mcs;
@@ -2259,6 +2555,18 @@ static void ath10k_peer_assoc_h_ht(struc
 			arg->peer_ht_rates.rates[n++] = i;
 		}
 
+	/* User may have used 'iw' or similar to configure VHT rates
+	 * and no HT rates.  In that case, our NSS would be incorrect
+	 * without this code below.
+	 */
+	for (i = max_nss; i < NL80211_VHT_NSS_MAX; i++) {
+		ath10k_dbg(ar, ATH10K_DBG_MAC, "max-nss: %d i: %d mask: 0x%x\n",
+			   max_nss, i, vht_mcs_mask[i]);
+		if (vht_mcs_mask[i])
+			max_nss = i + 1;
+	}
+	max_nss = min(max_nss, get_nss_from_chainmask(ar->cfg_tx_chainmask));
+
 	/*
 	 * This is a workaround for HT-enabled STAs which break the spec
 	 * and have no HT capabilities RX mask (no HT RX MCS map).
@@ -2267,8 +2575,12 @@ static void ath10k_peer_assoc_h_ht(struc
 	 * MCS 0 through 7 are mandatory in 20MHz with 800 ns GI at all STAs.
 	 *
 	 * Firmware asserts if such situation occurs.
+	 *
+	 * CT Firmware with the RATEMASK feature flag does NOT assert and handles
+	 * this just fine, so no work-arounds for it. --Ben
 	 */
-	if (n == 0) {
+	if (n == 0 && !test_bit(ATH10K_FW_FEATURE_CT_RATEMASK,
+				ar->running_fw->fw_file.fw_features)) {
 		arg->peer_ht_rates.num_rates = 8;
 		for (i = 0; i < arg->peer_ht_rates.num_rates; i++)
 			arg->peer_ht_rates.rates[i] = i;
@@ -2351,7 +2663,7 @@ static int ath10k_peer_assoc_qos_ap(stru
 }
 
 static u16
-ath10k_peer_assoc_h_vht_limit(u16 tx_mcs_set,
+ath10k_peer_assoc_h_vht_limit(struct ath10k *ar, u16 tx_mcs_set,
 			      const u16 vht_mcs_limit[NL80211_VHT_NSS_MAX])
 {
 	int idx_limit;
@@ -2377,6 +2689,11 @@ ath10k_peer_assoc_h_vht_limit(u16 tx_mcs
 		case 5: /* fall through */
 		case 6: /* fall through */
 		default:
+			if (test_bit(ATH10K_FW_FEATURE_CT_RATEMASK,
+				     ar->running_fw->fw_file.fw_features)) {
+				mcs = IEEE80211_VHT_MCS_SUPPORT_0_7;
+				break;
+			}
 			/* see ath10k_mac_can_set_bitrate_mask() */
 			WARN_ON(1);
 			/* fall through */
@@ -2447,6 +2764,9 @@ static void ath10k_peer_assoc_h_vht(stru
 	if (sta->bandwidth == IEEE80211_STA_RX_BW_80)
 		arg->peer_flags |= ar->wmi.peer_flags->bw80;
 
+	if (sta->bandwidth == IEEE80211_STA_RX_BW_160)
+		arg->peer_flags |= ar->wmi.peer_flags->bw160;
+
 	arg->peer_vht_rates.rx_max_rate =
 		__le16_to_cpu(vht_cap->vht_mcs.rx_highest);
 	arg->peer_vht_rates.rx_mcs_set =
@@ -2454,10 +2774,25 @@ static void ath10k_peer_assoc_h_vht(stru
 	arg->peer_vht_rates.tx_max_rate =
 		__le16_to_cpu(vht_cap->vht_mcs.tx_highest);
 	arg->peer_vht_rates.tx_mcs_set = ath10k_peer_assoc_h_vht_limit(
-		__le16_to_cpu(vht_cap->vht_mcs.tx_mcs_map), vht_mcs_mask);
+		ar, __le16_to_cpu(vht_cap->vht_mcs.tx_mcs_map), vht_mcs_mask);
 
-	ath10k_dbg(ar, ATH10K_DBG_MAC, "mac vht peer %pM max_mpdu %d flags 0x%x\n",
-		   sta->addr, arg->peer_max_mpdu, arg->peer_flags);
+	ath10k_dbg(ar, ATH10K_DBG_MAC, "mac vht peer %pM max_mpdu %d flags 0x%x rx-max-rate: 0x%x rx-mcs: 0x%x tx-max-rate: 0x%x tx-mcs: 0x%x\n",
+		   sta->addr, arg->peer_max_mpdu, arg->peer_flags,
+		   arg->peer_vht_rates.rx_max_rate, arg->peer_vht_rates.rx_mcs_set,
+		   arg->peer_vht_rates.tx_max_rate, arg->peer_vht_rates.tx_mcs_set);
+
+	if ((arg->peer_vht_rates.rx_max_rate) &&
+	    (sta->vht_cap.cap & IEEE80211_VHT_CAP_SUPP_CHAN_WIDTH_MASK)) {
+		if ((arg->peer_num_spatial_streams > 1) &&
+		    (arg->peer_vht_rates.rx_max_rate == 1560)) {
+			/* Must be 2x2 at 160Mhz is all it can do. */
+			arg->peer_bw_rxnss_override = 2;
+		}
+		else if (arg->peer_vht_rates.rx_max_rate == 780) {
+			/* Can only do 1x2 at 160Mhz (Long Guard Interval) */
+			arg->peer_bw_rxnss_override = 1;
+		}
+	}
 }
 
 static void ath10k_peer_assoc_h_qos(struct ath10k *ar,
@@ -2494,10 +2829,98 @@ static void ath10k_peer_assoc_h_qos(stru
 		   arvif->ar->wmi.peer_flags->qos));
 }
 
-static bool ath10k_mac_sta_has_ofdm_only(struct ieee80211_sta *sta)
+static bool ath10k_mac_vif_has_any_cck(struct ath10k *ar,
+				       struct ieee80211_vif *vif,
+				       u8 bandmask)
+{
+	struct ath10k_vif *arvif = ath10k_vif_to_arvif(vif);
+	u32 msk = 0;
+	int i;
+	for (i = 0; i < NUM_NL80211_BANDS; i++) {
+		if (bandmask & (1 << i)) {
+			msk |= arvif->bitrate_mask.control[i].legacy;
+		}
+	}
+	/* Only 2Ghz band has CCK support */
+	/* We have 12 bits of legacy rates, first 4 are /b (CCK) rates. */
+	ath10k_dbg(ar, ATH10K_DBG_MAC, "has-any-cck, arvif-legacy-24: 0x%x  mask: 0x%x\n",
+		   arvif->bitrate_mask.control[NL80211_BAND_2GHZ].legacy,
+		   msk);
+	return (msk & 0xf);
+}
+
+static bool ath10k_mac_vif_has_any_ofdm(struct ath10k *ar,
+					struct ieee80211_vif *vif,
+					int bandmask)
+{
+	struct ath10k_vif *arvif = ath10k_vif_to_arvif(vif);
+	u32 msk = 0;
+	int i;
+	for (i = 0; i < NUM_NL80211_BANDS; i++) {
+		if (bandmask & (1 << i)) {
+			msk |= arvif->bitrate_mask.control[i].legacy;
+		}
+	}
+	/* We have 12 bits of legacy rates, first 4 are /b (CCK) rates. */
+	ath10k_dbg(ar, ATH10K_DBG_MAC, "has-any-ofdm, arvif-legacy-24: 0x%x  legacy-5: 0x%x  mask: 0x%x\n",
+		   arvif->bitrate_mask.control[NL80211_BAND_2GHZ].legacy,
+		   arvif->bitrate_mask.control[NL80211_BAND_5GHZ].legacy,
+		   msk);
+	return (msk & 0xff0);
+}
+
+static bool ath10k_mac_vif_has_any_ht(struct ath10k *ar, struct ieee80211_vif *vif)
+{
+	struct ath10k_vif *arvif = ath10k_vif_to_arvif(vif);
+	int i;
+	for (i = 0; i<IEEE80211_HT_MCS_MASK_LEN; i++) {
+		if (arvif->bitrate_mask.control[NL80211_BAND_2GHZ].ht_mcs[i] ||
+		    arvif->bitrate_mask.control[NL80211_BAND_5GHZ].ht_mcs[i]) {
+			ath10k_dbg(ar, ATH10K_DBG_MAC, "has-any-ht, i: %d  2.4: 0x%x  5: 0x%x\n",
+				   i, arvif->bitrate_mask.control[NL80211_BAND_2GHZ].ht_mcs[i],
+				   arvif->bitrate_mask.control[NL80211_BAND_5GHZ].ht_mcs[i]);
+			return true;
+		}
+	}
+	ath10k_dbg(ar, ATH10K_DBG_MAC, "No HT rates enabled.\n");
+	return false;
+}
+
+static bool ath10k_mac_vif_has_any_vht(struct ath10k *ar, struct ieee80211_vif *vif)
+{
+	struct ath10k_vif *arvif = ath10k_vif_to_arvif(vif);
+	int i;
+	for (i = 0; i<ARRAY_SIZE(arvif->bitrate_mask.control[NL80211_BAND_2GHZ].vht_mcs); i++) {
+		if (arvif->bitrate_mask.control[NL80211_BAND_2GHZ].vht_mcs[i] ||
+		    arvif->bitrate_mask.control[NL80211_BAND_5GHZ].vht_mcs[i]) {
+			ath10k_dbg(ar, ATH10K_DBG_MAC, "has-any-vht, i: %d  2.4: 0x%x  5: 0x%x\n",
+				   i, arvif->bitrate_mask.control[NL80211_BAND_2GHZ].vht_mcs[i],
+				   arvif->bitrate_mask.control[NL80211_BAND_5GHZ].vht_mcs[i]);
+			return true;
+		}
+	}
+	ath10k_dbg(ar, ATH10K_DBG_MAC, "No VHT rates enabled.\n");
+	return false;
+}
+
+static bool ath10k_mac_sta_has_ofdm_only(struct ieee80211_vif *vif,
+					 struct ieee80211_sta *sta)
 {
-	return sta->supp_rates[NL80211_BAND_2GHZ] >>
-	       ATH10K_MAC_FIRST_OFDM_RATE_IDX;
+	struct ath10k_vif *arvif = ath10k_vif_to_arvif(vif);
+	u32 msk = arvif->bitrate_mask.control[NL80211_BAND_2GHZ].legacy &
+		sta->supp_rates[NL80211_BAND_2GHZ];
+	/* We have 12 bits of legacy rates, first 4 are /b (CCK) rates. */
+	return (msk & 0xff0) && !(msk & 0xf);
+}
+
+static bool ath10k_mac_sta_has_ofdm_and_cck(struct ieee80211_vif *vif,
+					    struct ieee80211_sta *sta)
+{
+	struct ath10k_vif *arvif = ath10k_vif_to_arvif(vif);
+	u32 msk = arvif->bitrate_mask.control[NL80211_BAND_2GHZ].legacy &
+		sta->supp_rates[NL80211_BAND_2GHZ];
+	/* We have 12 bits of legacy rates, first 4 are /b (CCK) rates. */
+	return ((msk & 0xf) && (msk & 0xff0));
 }
 
 static void ath10k_peer_assoc_h_phymode(struct ath10k *ar,
@@ -2533,8 +2956,10 @@ static void ath10k_peer_assoc_h_phymode(
 				phymode = MODE_11NG_HT40;
 			else
 				phymode = MODE_11NG_HT20;
-		} else if (ath10k_mac_sta_has_ofdm_only(sta)) {
+		} else if (ath10k_mac_sta_has_ofdm_and_cck(vif, sta)) {
 			phymode = MODE_11G;
+		} else if (ath10k_mac_sta_has_ofdm_only(vif, sta)) {
+			phymode = MODE_11GONLY;
 		} else {
 			phymode = MODE_11B;
 		}
@@ -2548,7 +2973,17 @@ static void ath10k_peer_assoc_h_phymode(
 		    !ath10k_peer_assoc_h_vht_masked(vht_mcs_mask)) {
 			if (sta->bandwidth == IEEE80211_STA_RX_BW_80)
 				phymode = MODE_11AC_VHT80;
-			else if (sta->bandwidth == IEEE80211_STA_RX_BW_40)
+			else if (sta->bandwidth == IEEE80211_STA_RX_BW_160) {
+				phymode = MODE_11AC_VHT160;
+				switch (sta->vht_cap.cap & IEEE80211_VHT_CAP_SUPP_CHAN_WIDTH_MASK) {
+				case IEEE80211_VHT_CAP_SUPP_CHAN_WIDTH_160MHZ:
+					phymode = MODE_11AC_VHT160;
+				break;
+				case IEEE80211_VHT_CAP_SUPP_CHAN_WIDTH_160_80PLUS80MHZ:
+					phymode = MODE_11AC_VHT80_80;
+				break;
+				}
+			} else if (sta->bandwidth == IEEE80211_STA_RX_BW_40)
 				phymode = MODE_11AC_VHT40;
 			else if (sta->bandwidth == IEEE80211_STA_RX_BW_20)
 				phymode = MODE_11AC_VHT20;
@@ -2567,8 +3002,9 @@ static void ath10k_peer_assoc_h_phymode(
 		break;
 	}
 
-	ath10k_dbg(ar, ATH10K_DBG_MAC, "mac peer %pM phymode %s\n",
-		   sta->addr, ath10k_wmi_phymode_str(phymode));
+	ath10k_dbg(ar, ATH10K_DBG_MAC, "mac peer %pM phymode %s  legacy-supp-rates: 0x%x  arvif-legacy-rates: 0x%x vht-supp: %d\n",
+		   sta->addr, ath10k_wmi_phymode_str(phymode), sta->supp_rates[band],
+		   arvif->bitrate_mask.control[band].legacy, sta->vht_cap.vht_supported);
 
 	arg->peer_phymode = phymode;
 	WARN_ON(phymode == MODE_UNKNOWN);
@@ -2591,6 +3027,8 @@ static int ath10k_peer_assoc_prepare(str
 	ath10k_peer_assoc_h_qos(ar, vif, sta, arg);
 	ath10k_peer_assoc_h_phymode(ar, vif, sta, arg);
 
+	ath10k_peer_assoc_h_rate_overrides(ar, vif, sta, arg);
+
 	return 0;
 }
 
@@ -2751,8 +3189,8 @@ static void ath10k_bss_assoc(struct ieee
 	}
 
 	ath10k_dbg(ar, ATH10K_DBG_MAC,
-		   "mac vdev %d up (associated) bssid %pM aid %d\n",
-		   arvif->vdev_id, bss_conf->bssid, bss_conf->aid);
+		   "mac vdev %d up (associated) bssid %pM aid %d bandwidth %d\n",
+		   arvif->vdev_id, bss_conf->bssid, bss_conf->aid, ap_sta->bandwidth);
 
 	WARN_ON(arvif->is_up);
 
@@ -2813,6 +3251,150 @@ static void ath10k_bss_disassoc(struct i
 	cancel_delayed_work_sync(&arvif->connection_loss_work);
 }
 
+/* Convert hw_rate from ratectrl to 'rate-code' that firmware
+ * can understand.
+ */
+static u8 ath10k_convert_hw_rate_to_rc(u8 hw_rate, int bitrate)
+{
+	int preamble;
+	if (ath10k_mac_bitrate_is_cck(bitrate))
+		preamble = WMI_RATE_PREAMBLE_CCK;
+	else
+		preamble = WMI_RATE_PREAMBLE_OFDM;
+
+	return (preamble << 6) | hw_rate;
+}
+
+static void ath10k_check_apply_special_rates(struct ath10k *ar,
+					     struct ath10k_vif *arvif)
+{
+	struct ieee80211_hw *hw = ar->hw;
+	const struct ieee80211_supported_band *sband;
+	struct ieee80211_vif *vif = arvif->vif;
+	struct cfg80211_chan_def def;
+	enum nl80211_band band;
+	u32 ratemask;
+	u8 mcast_rt = WMI_FIXED_RATE_NONE;
+	u8 bcast_rt = WMI_FIXED_RATE_NONE;
+	u8 mgt_rt = WMI_FIXED_RATE_NONE;
+	int i;
+	int ret;
+
+	lockdep_assert_held(&ar->conf_mutex);
+
+	if (ath10k_mac_vif_chan(vif, &def))
+		band = NL80211_BAND_2GHZ;
+	else
+		band = def.chan->band;
+
+	sband = hw->wiphy->bands[band];
+	ratemask = arvif->bitrate_mask.control[band].legacy;
+
+	/* 10.1.467 Firmware defaults:
+	   5Ghz or p2p mode: 6Mbps mgt, bcast, mcast
+	   2.4Ghz: 1Mbps for mgt, 11Mbps for bcast, mcast
+	*/
+
+	/* Check for user-specified rates. */
+	if (arvif->mcast_rate[band] != WMI_FIXED_RATE_NONE)
+		mcast_rt = arvif->mcast_rate[band];
+
+	if (arvif->bcast_rate[band] != WMI_FIXED_RATE_NONE)
+		bcast_rt = arvif->bcast_rate[band];
+
+	if (arvif->mgt_rate[band] != WMI_FIXED_RATE_NONE)
+		mgt_rt = arvif->mgt_rate[band];
+
+	/* If we don't have user-specified rates, then find rates that work within
+	 * the configured ratemask.
+	 */
+
+	/* Mgt uses lowest available rate. */
+	if (mgt_rt == WMI_FIXED_RATE_NONE) {
+		for (i = 0; i < ath10k_g_rates_size; i++) {
+			if (ratemask & (1<<i)) {
+				/* found it */
+				mgt_rt = ath10k_convert_hw_rate_to_rc(sband->bitrates[i].hw_value,
+								      sband->bitrates[i].bitrate);
+				break;
+			}
+		}
+	}
+
+	if (band == NL80211_BAND_2GHZ) {
+		/* Use 11Mbps for mcast, bcast if possible, else fall back to first available. */
+		u8 first_rt = WMI_FIXED_RATE_NONE;
+		for (i = 0; i < ath10k_g_rates_size; i++) {
+			if (ratemask & (1<<i)) {
+				if (first_rt == WMI_FIXED_RATE_NONE)
+					first_rt = ath10k_convert_hw_rate_to_rc(sband->bitrates[i].hw_value,
+										sband->bitrates[i].bitrate);
+				if (sband->bitrates[i].bitrate == 110) {
+					if (bcast_rt == WMI_FIXED_RATE_NONE)
+						bcast_rt = ath10k_convert_hw_rate_to_rc(sband->bitrates[i].hw_value,
+											sband->bitrates[i].bitrate);
+					if (mcast_rt == WMI_FIXED_RATE_NONE)
+						mcast_rt = ath10k_convert_hw_rate_to_rc(sband->bitrates[i].hw_value,
+											sband->bitrates[i].bitrate);
+					goto found_preferred24;
+				}
+			}
+		}
+
+		/* If here, we did not find preferred rate, use first found. */
+		if (bcast_rt == WMI_FIXED_RATE_NONE)
+			bcast_rt = first_rt;
+		if (mcast_rt == WMI_FIXED_RATE_NONE)
+			mcast_rt = first_rt;
+	}
+
+found_preferred24:
+	if (band == NL80211_BAND_5GHZ) {
+		for (i = 0; i < ath10k_g_rates_size; i++) {
+			if (ratemask & (1<<i)) {
+				/* found it */
+				if (bcast_rt == WMI_FIXED_RATE_NONE)
+					bcast_rt = ath10k_convert_hw_rate_to_rc(sband->bitrates[i].hw_value,
+										sband->bitrates[i].bitrate);
+				if (mcast_rt == WMI_FIXED_RATE_NONE)
+					mcast_rt = ath10k_convert_hw_rate_to_rc(sband->bitrates[i].hw_value,
+										sband->bitrates[i].bitrate);
+				break;
+			}
+		}
+	}
+
+	ath10k_dbg(ar, ATH10K_DBG_MAC, "apply-special-rates: ratemask: 0x%x mcast: 0x%x  bcast: 0x%x  mgmt: 0x%x band: %d\n",
+		   ratemask, mcast_rt, bcast_rt, mgt_rt, band);
+
+	if (mcast_rt != WMI_FIXED_RATE_NONE) {
+		ret = ath10k_wmi_vdev_set_param(ar, arvif->vdev_id,
+						ar->wmi.vdev_param->mcast_data_rate,
+						mcast_rt);
+		if (ret)
+			ath10k_warn(ar, "failed to set mcast rate param 0x%02x: %d\n",
+				    mcast_rt, ret);
+	}
+
+	if (bcast_rt != WMI_FIXED_RATE_NONE) {
+		ret = ath10k_wmi_vdev_set_param(ar, arvif->vdev_id,
+						ar->wmi.vdev_param->bcast_data_rate,
+						bcast_rt);
+		if (ret)
+			ath10k_warn(ar, "failed to set bcast rate param 0x%02x: %d\n",
+				    bcast_rt, ret);
+	}
+
+	if (mgt_rt != WMI_FIXED_RATE_NONE) {
+		ret = ath10k_wmi_vdev_set_param(ar, arvif->vdev_id,
+						ar->wmi.vdev_param->mgmt_rate,
+						mgt_rt);
+		if (ret)
+			ath10k_warn(ar, "failed to set mgt rate param 0x%02x: %d\n",
+				    mgt_rt, ret);
+	}
+}
+
 static int ath10k_station_assoc(struct ath10k *ar,
 				struct ieee80211_vif *vif,
 				struct ieee80211_sta *sta,
@@ -2831,6 +3413,8 @@ static int ath10k_station_assoc(struct a
 		return ret;
 	}
 
+	ath10k_check_apply_special_rates(ar, arvif);
+
 	ret = ath10k_wmi_peer_assoc(ar, &peer_arg);
 	if (ret) {
 		ath10k_warn(ar, "failed to run peer assoc for STA %pM vdev %i: %d\n",
@@ -3045,8 +3629,13 @@ static void ath10k_regd_update(struct at
 	if (IS_ENABLED(CONFIG_ATH10K_DFS_CERTIFIED) && ar->dfs_detector) {
 		nl_dfs_reg = ar->dfs_detector->region;
 		wmi_dfs_reg = ath10k_mac_get_dfs_region(nl_dfs_reg);
+		ath10k_dbg(ar, ATH10K_DBG_REGULATORY,
+			   "nl_dfs_reg: %i  wmi_dfs_reg: %i\n",
+			    nl_dfs_reg, wmi_dfs_reg);
 	} else {
 		wmi_dfs_reg = WMI_UNINIT_DFS_DOMAIN;
+		ath10k_dbg(ar, ATH10K_DBG_REGULATORY,
+			   "not DFS_CERTIFIED or no dfs_detector.\n");
 	}
 
 	/* Target allows setting up per-band regdomain but ath_common provides
@@ -3072,7 +3661,7 @@ static void ath10k_reg_notifier(struct w
 	ath_reg_notifier_apply(wiphy, request, &ar->ath_common.regulatory);
 
 	if (IS_ENABLED(CONFIG_ATH10K_DFS_CERTIFIED) && ar->dfs_detector) {
-		ath10k_dbg(ar, ATH10K_DBG_REGULATORY, "dfs region 0x%x\n",
+		ath10k_dbg(ar, ATH10K_DBG_REGULATORY, "reg-notifier: dfs region 0x%x\n",
 			   request->dfs_region);
 		result = ar->dfs_detector->set_dfs_domain(ar->dfs_detector,
 							  request->dfs_region);
@@ -3237,6 +3826,12 @@ ath10k_mac_tx_h_get_txmode(struct ath10k
 	if (!vif || vif->type == NL80211_IFTYPE_MONITOR)
 		return ATH10K_HW_TXRX_RAW;
 
+	/* CT Firmware with HTT-TX support sends all frames, including
+	 * management frames, over HTT in NATIVE-WIFI format.
+	 */
+	if (ar->ct_all_pkts_htt)
+		goto do_native_mgt_ct;
+
 	if (ieee80211_is_mgmt(fc))
 		return ATH10K_HW_TXRX_MGMT;
 
@@ -3270,6 +3865,7 @@ ath10k_mac_tx_h_get_txmode(struct ath10k
 	 *
 	 * FIXME: Check if raw mode works with TDLS.
 	 */
+do_native_mgt_ct:
 	if (ieee80211_is_data_present(fc) && sta && sta->tdls)
 		return ATH10K_HW_TXRX_ETHERNET;
 
@@ -3482,8 +4078,9 @@ static int ath10k_mac_tx_submit(struct a
 	}
 
 	if (ret) {
-		ath10k_warn(ar, "failed to transmit packet, dropping: %d\n",
-			    ret);
+		if (net_ratelimit())
+			ath10k_warn(ar, "failed to transmit packet, dropping: %d\n",
+				    ret);
 		ieee80211_free_txskb(ar->hw, skb);
 	}
 
@@ -3694,23 +4291,51 @@ void ath10k_mgmt_over_wmi_tx_work(struct
 	}
 }
 
-static void ath10k_mac_txq_init(struct ieee80211_txq *txq)
+static void ath10k_mac_txq_init(struct ath10k *ar, struct ieee80211_txq *txq)
 {
 	struct ath10k_txq *artxq;
+	struct ath10k_txq *tmp, *walker;
+	struct ieee80211_txq *txq_tmp;
+	int i = 0;
 
 	if (!txq)
 		return;
 
 	artxq = (void *)txq->drv_priv;
+
+	spin_lock_bh(&ar->txqs_lock);
+
+	/* Remove from ar->txqs in case it still exists there. */
+	list_for_each_entry_safe(walker, tmp, &ar->txqs, list) {
+		txq_tmp = container_of((void *)walker, struct ieee80211_txq,
+				       drv_priv);
+		if ((++i % 10000) == 0) {
+			ath10k_err(ar, "txq-init: Checking txq_tmp: %p i: %d\n", txq_tmp, i);
+			ath10k_err(ar, "txq-init: txqs: %p walker->list: %p w->next: %p  w->prev: %p ar->txqs: %p\n",
+				   &ar->txqs, &(walker->list), walker->list.next, walker->list.prev, &ar->txqs);
+		}
+
+		if (txq_tmp == txq) {
+			WARN_ON_ONCE(1);
+			ath10k_err(ar, "txq-init: Found txq when it should be deleted, txq_tmp: %p  txq: %p\n",
+				   txq_tmp, txq);
+			list_del(&walker->list);
+		}
+	}
+	spin_unlock_bh(&ar->txqs_lock);
+
 	INIT_LIST_HEAD(&artxq->list);
 }
 
 static void ath10k_mac_txq_unref(struct ath10k *ar, struct ieee80211_txq *txq)
 {
 	struct ath10k_txq *artxq;
+	struct ath10k_txq *tmp, *walker;
 	struct ath10k_skb_cb *cb;
 	struct sk_buff *msdu;
+	struct ieee80211_txq *txq_tmp;
 	int msdu_id;
+	int i = 0;
 
 	if (!txq)
 		return;
@@ -3719,6 +4344,24 @@ static void ath10k_mac_txq_unref(struct
 	spin_lock_bh(&ar->txqs_lock);
 	if (!list_empty(&artxq->list))
 		list_del_init(&artxq->list);
+
+	/* Remove from ar->txqs in case it still exists there. */
+	list_for_each_entry_safe(walker, tmp, &ar->txqs, list) {
+		txq_tmp = container_of((void *)walker, struct ieee80211_txq,
+				       drv_priv);
+		if ((++i % 10000) == 0) {
+			ath10k_err(ar, "Checking txq_tmp: %p i: %d\n", txq_tmp, i);
+			ath10k_err(ar, "txqs: %p walker->list: %p w->next: %p  w->prev: %p ar->txqs: %p\n",
+				   &ar->txqs, &(walker->list), walker->list.next, walker->list.prev, &ar->txqs);
+		}
+
+		if (txq_tmp == txq) {
+			WARN_ON_ONCE(1);
+			ath10k_err(ar, "Found txq when it should be deleted, txq_tmp: %p  txq: %p\n",
+				   txq_tmp, txq);
+			list_del(&walker->list);
+		}
+	}
 	spin_unlock_bh(&ar->txqs_lock);
 
 	spin_lock_bh(&ar->htt.tx_lock);
@@ -3742,6 +4385,9 @@ struct ieee80211_txq *ath10k_mac_txq_loo
 	if (!peer)
 		return NULL;
 
+	if (peer->removed)
+		return NULL;
+
 	if (peer->sta)
 		return peer->sta->txq[tid];
 	else if (peer->vif)
@@ -3852,6 +4498,7 @@ void ath10k_mac_tx_push_pending(struct a
 	struct ath10k_txq *last;
 	int ret;
 	int max;
+	int loop_max = 2000;
 
 	if (ar->htt.num_pending_tx >= (ar->htt.max_num_pending_tx / 2))
 		return;
@@ -3865,6 +4512,11 @@ void ath10k_mac_tx_push_pending(struct a
 		txq = container_of((void *)artxq, struct ieee80211_txq,
 				   drv_priv);
 
+		if (--loop_max == 0) {
+			ath10k_err(ar, "Looped 2000 times in tx_push_pending, bailing out.\n");
+			break;
+		}
+
 		/* Prevent aggressive sta/tid taking over tx queue */
 		max = 16;
 		ret = 0;
@@ -4023,6 +4675,8 @@ static int ath10k_start_scan(struct ath1
 
 	lockdep_assert_held(&ar->conf_mutex);
 
+	ath10k_dbg(ar, ATH10K_DBG_MAC, "start-scan, flags: 0x%x\n",
+		   arg->scan_ctrl_flags);
 	ret = ath10k_wmi_start_scan(ar, arg);
 	if (ret)
 		return ret;
@@ -4279,6 +4933,11 @@ static struct ieee80211_sta_vht_cap ath1
 		vht_cap.cap |= val;
 	}
 
+	if ((ar->vht_cap_info & IEEE80211_VHT_CAP_SHORT_GI_160) &&
+	    ((ar->vht_cap_info & IEEE80211_VHT_CAP_SUPP_CHAN_WIDTH_MASK) == 0)) {
+		vht_cap.cap |= IEEE80211_VHT_CAP_SUPP_CHAN_WIDTH_160MHZ;
+	}
+
 	mcs_map = 0;
 	for (i = 0; i < 8; i++) {
 		if ((i < ar->num_rf_chains) && (ar->cfg_tx_chainmask & BIT(i)))
@@ -4293,6 +4952,21 @@ static struct ieee80211_sta_vht_cap ath1
 	vht_cap.vht_mcs.rx_mcs_map = cpu_to_le16(mcs_map);
 	vht_cap.vht_mcs.tx_mcs_map = cpu_to_le16(mcs_map);
 
+	/* If we are supporting 160Mhz or 80+80, then the NIC may be able to do a restricted NSS
+	 * for 160 or 80+80 vs what it can do for 80Mhz.  Give user-space a clue if that is the
+	 * case.
+	 */
+	if (vht_cap.cap & IEEE80211_VHT_CAP_SUPP_CHAN_WIDTH_MASK) {
+		/* Something more than 80Mhz at least */
+		if (ar->dev_id == QCA9984_1_0_DEVICE_ID) {
+			/* Can do only 2x2 VHT160 or 80+80.
+			 * 1560Mbps is 4x4 80Mhz or 2x2 160Mhz, long-guard-interval
+			 */
+			vht_cap.vht_mcs.rx_highest = 1560;
+			vht_cap.vht_mcs.tx_highest = 1560;
+		}
+	}
+
 	return vht_cap;
 }
 
@@ -4374,6 +5048,9 @@ static void ath10k_mac_setup_ht_vht_cap(
 	if (ar->phy_capability & WHAL_WLAN_11G_CAPABILITY) {
 		band = &ar->mac.sbands[NL80211_BAND_2GHZ];
 		band->ht_cap = ht_cap;
+
+		/* Enable the VHT support at 2.4 GHz */
+		band->vht_cap = vht_cap;
 	}
 	if (ar->phy_capability & WHAL_WLAN_11A_CAPABILITY) {
 		band = &ar->mac.sbands[NL80211_BAND_5GHZ];
@@ -4712,21 +5389,11 @@ static int ath10k_config(struct ieee8021
 	return ret;
 }
 
-static u32 get_nss_from_chainmask(u16 chain_mask)
-{
-	if ((chain_mask & 0xf) == 0xf)
-		return 4;
-	else if ((chain_mask & 0x7) == 0x7)
-		return 3;
-	else if ((chain_mask & 0x3) == 0x3)
-		return 2;
-	return 1;
-}
-
 static int ath10k_mac_set_txbf_conf(struct ath10k_vif *arvif)
 {
 	u32 value = 0;
 	struct ath10k *ar = arvif->ar;
+	struct ieee80211_vif *vif = arvif->vif;
 	int nsts;
 	int sound_dim;
 
@@ -4746,17 +5413,21 @@ static int ath10k_mac_set_txbf_conf(stru
 	if (!value)
 		return 0;
 
-	if (ar->vht_cap_info & IEEE80211_VHT_CAP_SU_BEAMFORMER_CAPABLE)
+	if ((ar->vht_cap_info & IEEE80211_VHT_CAP_SU_BEAMFORMER_CAPABLE) &&
+	    (vif->type != NL80211_IFTYPE_STATION))
 		value |= WMI_VDEV_PARAM_TXBF_SU_TX_BFER;
 
-	if (ar->vht_cap_info & IEEE80211_VHT_CAP_MU_BEAMFORMER_CAPABLE)
+	if ((ar->vht_cap_info & IEEE80211_VHT_CAP_MU_BEAMFORMER_CAPABLE) &&
+	    (vif->type != NL80211_IFTYPE_STATION))
 		value |= (WMI_VDEV_PARAM_TXBF_MU_TX_BFER |
 			  WMI_VDEV_PARAM_TXBF_SU_TX_BFER);
 
-	if (ar->vht_cap_info & IEEE80211_VHT_CAP_SU_BEAMFORMEE_CAPABLE)
+	if ((ar->vht_cap_info & IEEE80211_VHT_CAP_SU_BEAMFORMEE_CAPABLE) &&
+	    (vif->type == NL80211_IFTYPE_STATION))
 		value |= WMI_VDEV_PARAM_TXBF_SU_TX_BFEE;
 
-	if (ar->vht_cap_info & IEEE80211_VHT_CAP_MU_BEAMFORMEE_CAPABLE)
+	if ((ar->vht_cap_info & IEEE80211_VHT_CAP_MU_BEAMFORMEE_CAPABLE) &&
+		(vif->type == NL80211_IFTYPE_STATION))
 		value |= (WMI_VDEV_PARAM_TXBF_MU_TX_BFEE |
 			  WMI_VDEV_PARAM_TXBF_SU_TX_BFEE);
 
@@ -4789,7 +5460,11 @@ static int ath10k_add_interface(struct i
 	mutex_lock(&ar->conf_mutex);
 
 	memset(arvif, 0, sizeof(*arvif));
-	ath10k_mac_txq_init(vif->txq);
+	ath10k_mac_txq_init(ar, vif->txq);
+
+	memset(&arvif->bcast_rate, WMI_FIXED_RATE_NONE, sizeof(arvif->bcast_rate));
+	memset(&arvif->mcast_rate, WMI_FIXED_RATE_NONE, sizeof(arvif->mcast_rate));
+	memset(&arvif->mgt_rate, WMI_FIXED_RATE_NONE, sizeof(arvif->mgt_rate));
 
 	arvif->ar = ar;
 	arvif->vif = vif;
@@ -5002,6 +5677,10 @@ static int ath10k_add_interface(struct i
 		arvif->peer_id = HTT_INVALID_PEERID;
 	}
 
+	ret = ath10k_mac_set_pdev_kickout(ar);
+	if (ret)
+		return ret;
+
 	if (arvif->vdev_type == WMI_VDEV_TYPE_AP) {
 		ret = ath10k_mac_set_kickout(arvif);
 		if (ret) {
@@ -5146,8 +5825,9 @@ static void ath10k_remove_interface(stru
 		kfree(arvif->u.ap.noa_data);
 	}
 
-	ath10k_dbg(ar, ATH10K_DBG_MAC, "mac vdev %i delete (remove interface)\n",
-		   arvif->vdev_id);
+	ath10k_dbg(ar, ATH10K_DBG_MAC,
+		   "mac vdev %i delete (remove interface), vif: %p  arvif: %p\n",
+		   arvif->vdev_id, vif, arvif);
 
 	ret = ath10k_wmi_vdev_delete(ar, arvif->vdev_id);
 	if (ret)
@@ -5177,8 +5857,8 @@ static void ath10k_remove_interface(stru
 			continue;
 
 		if (peer->vif == vif) {
-			ath10k_warn(ar, "found vif peer %pM entry on vdev %i after it was supposedly removed\n",
-				    vif->addr, arvif->vdev_id);
+			ath10k_warn(ar, "found vif peer %pM id: %d entry on vdev %i after it was supposedly removed\n",
+				    vif->addr, i, arvif->vdev_id);
 			peer->vif = NULL;
 		}
 	}
@@ -5417,6 +6097,30 @@ static void ath10k_bss_info_changed(stru
 	mutex_unlock(&ar->conf_mutex);
 }
 
+static u32 ath10k_calc_ct_scan_flags(struct ath10k *ar,
+				     struct ieee80211_vif *vif)
+{
+	u32 rv = 0;
+
+	if (test_bit(ATH10K_FW_FEATURE_WMI_10X_CT,
+		     ar->running_fw->fw_file.fw_features)) {
+		if (ar->running_fw->fw_file.wmi_op_version == ATH10K_FW_WMI_OP_VERSION_10_4) {
+			if (!ath10k_mac_vif_has_any_ht(ar, vif))
+				rv |= WMI_SCAN_DISABLE_HT_4;
+
+			if (!ath10k_mac_vif_has_any_vht(ar, vif))
+				rv |= WMI_SCAN_DISABLE_VHT_4;
+		} else {
+			if (!ath10k_mac_vif_has_any_ht(ar, vif))
+				rv |= WMI_SCAN_DISABLE_HT;
+
+			if (!ath10k_mac_vif_has_any_vht(ar, vif))
+				rv |= WMI_SCAN_DISABLE_VHT;
+		}
+	}
+	return rv;
+}
+
 static void ath10k_mac_op_set_coverage_class(struct ieee80211_hw *hw, s16 value)
 {
 	struct ath10k *ar = hw->priv;
@@ -5441,6 +6145,7 @@ static int ath10k_hw_scan(struct ieee802
 	struct wmi_start_scan_arg arg;
 	int ret = 0;
 	int i;
+	bool skip_legacy_rates = false;
 
 	mutex_lock(&ar->conf_mutex);
 
@@ -5470,6 +6175,24 @@ static int ath10k_hw_scan(struct ieee802
 	arg.vdev_id = arvif->vdev_id;
 	arg.scan_id = ATH10K_SCAN_ID;
 
+	arg.scan_ctrl_flags |= ath10k_calc_ct_scan_flags(ar, vif);
+
+	if (test_bit(ATH10K_FW_FEATURE_CT_RATEMASK,
+		     ar->running_fw->fw_file.fw_features)) {
+		/* Firmware with this feature fixes a bug in firmware
+		 * that would not allow one to disable CCK and OFDM rates.
+		 * Host stack sets up the IEs, so tell firmware to leave it
+		 * alone.
+		 */
+		skip_legacy_rates = true;
+	}
+
+	if (!skip_legacy_rates) {
+		if (!req->no_cck)
+			arg.scan_ctrl_flags |= WMI_SCAN_ADD_CCK_RATES;
+		arg.scan_ctrl_flags |= WMI_SCAN_ADD_OFDM_RATES;
+	}
+
 	if (req->ie_len) {
 		arg.ie_len = req->ie_len;
 		memcpy(arg.ie, req->ie, arg.ie_len);
@@ -5585,8 +6308,12 @@ static int ath10k_set_key(struct ieee802
 	if (arvif->nohwcrypt)
 		return 1;
 
-	if (key->keyidx > WMI_MAX_KEY_INDEX)
+	if (key->keyidx > WMI_MAX_KEY_INDEX) {
+		if (cmd != DISABLE_KEY)
+			ath10k_warn(ar, "failed to install key, idx out of range: %d > %d, vdev: %d\n",
+				    key->keyidx, WMI_MAX_KEY_INDEX, arvif->vdev_id);
 		return -ENOSPC;
+	}
 
 	mutex_lock(&ar->conf_mutex);
 
@@ -5812,9 +6539,10 @@ static void ath10k_sta_rc_update_wk(stru
 	}
 
 	if (changed & IEEE80211_RC_SUPP_RATES_CHANGED ||
+	    changed & IEEE80211_RC_SMPS_CHANGED ||
 	    changed & IEEE80211_RC_NSS_CHANGED) {
-		ath10k_dbg(ar, ATH10K_DBG_MAC, "mac update sta %pM supp rates/nss\n",
-			   sta->addr);
+		ath10k_dbg(ar, ATH10K_DBG_MAC, "mac update sta %pM supp rates/nss bandwidth: %d\n",
+			   sta->addr, sta->bandwidth);
 
 		err = ath10k_station_assoc(ar, arvif->vif, sta, true);
 		if (err)
@@ -5929,7 +6657,7 @@ static int ath10k_sta_state(struct ieee8
 		INIT_WORK(&arsta->update_wk, ath10k_sta_rc_update_wk);
 
 		for (i = 0; i < ARRAY_SIZE(sta->txq); i++)
-			ath10k_mac_txq_init(sta->txq[i]);
+			ath10k_mac_txq_init(ar, sta->txq[i]);
 	}
 
 	/* cancel must be done outside the mutex to avoid deadlock */
@@ -6099,8 +6827,8 @@ static int ath10k_sta_state(struct ieee8
 		/*
 		 * New association.
 		 */
-		ath10k_dbg(ar, ATH10K_DBG_MAC, "mac sta %pM associated\n",
-			   sta->addr);
+		ath10k_dbg(ar, ATH10K_DBG_MAC, "mac sta %pM associated, bandwidth: %d\n",
+			   sta->addr, sta->bandwidth);
 
 		ret = ath10k_station_assoc(ar, vif, sta, false);
 		if (ret)
@@ -6112,8 +6840,8 @@ static int ath10k_sta_state(struct ieee8
 		/*
 		 * Tdls station authorized.
 		 */
-		ath10k_dbg(ar, ATH10K_DBG_MAC, "mac tdls sta %pM authorized\n",
-			   sta->addr);
+		ath10k_dbg(ar, ATH10K_DBG_MAC, "mac tdls sta %pM authorized, bandwidth: %d\n",
+			   sta->addr, sta->bandwidth);
 
 		ret = ath10k_station_assoc(ar, vif, sta, false);
 		if (ret) {
@@ -6379,6 +7107,14 @@ static int ath10k_remain_on_channel(stru
 	arg.scan_ctrl_flags |= WMI_SCAN_FILTER_PROBE_REQ;
 	arg.burst_duration_ms = duration;
 
+	if (ath10k_mac_vif_has_any_cck(ar, vif, (1 << chan->band)))
+		arg.scan_ctrl_flags |= WMI_SCAN_ADD_CCK_RATES;
+
+	if (ath10k_mac_vif_has_any_ofdm(ar, vif, (1 << chan->band)))
+		arg.scan_ctrl_flags |= WMI_SCAN_ADD_OFDM_RATES;
+
+	arg.scan_ctrl_flags |= ath10k_calc_ct_scan_flags(ar, vif);
+
 	ret = ath10k_start_scan(ar, &arg);
 	if (ret) {
 		ath10k_warn(ar, "failed to start roc scan: %d\n", ret);
@@ -6477,10 +7213,22 @@ static void ath10k_flush(struct ieee8021
 	struct ath10k *ar = hw->priv;
 	bool skip;
 	long time_left;
+	u8 peer_addr[ETH_ALEN] = {0};
+	struct ath10k_vif *arvif = NULL;
+	u32 vid = 0xFFFFFFFF;
+
+	if (vif) {
+		arvif = ath10k_vif_to_arvif(vif);
+		vid = arvif->vdev_id;
+	}
+
+	ath10k_dbg(ar, ATH10K_DBG_MAC, "mac flush vdev %d drop %d queues 0x%x\n",
+		   arvif ? arvif->vdev_id : -1, drop, queues);
 
 	/* mac80211 doesn't care if we really xmit queued frames or not
 	 * we'll collect those frames either way if we stop/delete vdevs */
-	if (drop)
+	if (drop && !test_bit(ATH10K_FW_FEATURE_FLUSH_ALL_CT,
+			      ar->running_fw->fw_file.fw_features))
 		return;
 
 	mutex_lock(&ar->conf_mutex);
@@ -6488,6 +7236,33 @@ static void ath10k_flush(struct ieee8021
 	if (ar->state == ATH10K_STATE_WEDGED)
 		goto skip;
 
+	/* NOTE:  As of Aug 10, CT firmware supports flushing a single vdev
+	 * by passing the vdev_id, and leaving peer_addr all zeros.  But the logic
+	 * below would need to be changed to check if all pkts for a particular
+	 * vdev have been flushed instead of the entire tx-q being flushed.
+	 *
+	 * In addition, this logic could be called even if 'drop' is requested.
+	 * This might make the system act more optimally.
+	 *
+	 * --Ben
+	 */
+
+	/* If we are CT firmware, ask it to flush all tids on all peers on
+	 * all vdevs.  Normal firmware will just crash if you do this.
+	 */
+	if (test_bit(ATH10K_FW_FEATURE_FLUSH_ALL_CT,
+		     ar->running_fw->fw_file.fw_features)) {
+		ath10k_wmi_peer_flush(ar, vid, peer_addr, 0xFFFFFFFF);
+		/* I am not sure the wave-2 push-tx logic works right with
+		 * flushing, so just bail out after making the proper
+		 * request to firmware.  From comment above, I guess this is just
+		 * like dropping all frames anyway.
+		 */
+		if (drop || test_bit(ATH10K_FW_FEATURE_PEER_FLOW_CONTROL,
+				     ar->running_fw->fw_file.fw_features))
+			goto skip;
+	}
+
 	time_left = wait_event_timeout(ar->htt.empty_tx_wq, ({
 			bool empty;
 
@@ -6739,7 +7514,8 @@ ath10k_mac_bitrate_mask_get_single_rate(
 }
 
 static int ath10k_mac_set_fixed_rate_params(struct ath10k_vif *arvif,
-					    u8 rate, u8 nss, u8 sgi, u8 ldpc)
+					    u8 rate, u8 nss, u8 sgi, u8 ldpc,
+					    enum nl80211_band band)
 {
 	struct ath10k *ar = arvif->ar;
 	u32 vdev_param;
@@ -6753,8 +7529,8 @@ static int ath10k_mac_set_fixed_rate_par
 	vdev_param = ar->wmi.vdev_param->fixed_rate;
 	ret = ath10k_wmi_vdev_set_param(ar, arvif->vdev_id, vdev_param, rate);
 	if (ret) {
-		ath10k_warn(ar, "failed to set fixed rate param 0x%02x: %d\n",
-			    rate, ret);
+		ath10k_warn(ar, "vdev %i failed to set fixed rate, param 0x%x rate 0x%02x nss %hhu sgi %hhu: %d\n",
+			    arvif->vdev_id, vdev_param, rate, nss, sgi, ret);
 		return ret;
 	}
 
@@ -6790,6 +7566,13 @@ ath10k_mac_can_set_bitrate_mask(struct a
 	int i;
 	u16 vht_mcs;
 
+	/* CT firmware has improvements that allows this to function
+	 * properly.
+	 */
+	if (test_bit(ATH10K_FW_FEATURE_CT_RATEMASK,
+		     ar->running_fw->fw_file.fw_features))
+		return true;
+
 	/* Due to firmware limitation in WMI_PEER_ASSOC_CMDID it is impossible
 	 * to express all VHT MCS rate masks. Effectively only the following
 	 * ranges can be used: none, 0-7, 0-8 and 0-9.
@@ -6829,6 +7612,27 @@ static void ath10k_mac_set_bitrate_mask_
 	ieee80211_queue_work(ar->hw, &arsta->update_wk);
 }
 
+static void ath10k_dbg_print_bitrate_mask(struct ath10k *ar,
+					  const struct cfg80211_bitrate_mask *mask,
+					  enum nl80211_band band) {
+	ath10k_dbg(ar, ATH10K_DBG_MAC, "mask: band: %i  legacy: 0x%x  gi: %d\n",
+		   band, mask->control[band].legacy,
+		   mask->control[band].gi);
+	BUILD_BUG_ON(IEEE80211_HT_MCS_MASK_LEN != 10);
+	ath10k_dbg(ar, ATH10K_DBG_MAC, "ht_mcs: %02hx %02hx %02hx %02hx %02hx %02hx %02hx %02hx %02hx %02hx\n",
+		   mask->control[band].ht_mcs[0], mask->control[band].ht_mcs[1],
+		   mask->control[band].ht_mcs[2], mask->control[band].ht_mcs[3],
+		   mask->control[band].ht_mcs[4], mask->control[band].ht_mcs[5],
+		   mask->control[band].ht_mcs[6], mask->control[band].ht_mcs[7],
+		   mask->control[band].ht_mcs[8], mask->control[band].ht_mcs[9]);
+	BUILD_BUG_ON(NL80211_VHT_NSS_MAX != 8);
+	ath10k_dbg(ar, ATH10K_DBG_MAC, "vht_mcs: %04hx %04hx %04hx %04hx %04hx %04hx %04hx %04hx\n",
+		   mask->control[band].vht_mcs[0], mask->control[band].vht_mcs[1],
+		   mask->control[band].vht_mcs[2], mask->control[band].vht_mcs[3],
+		   mask->control[band].vht_mcs[4], mask->control[band].vht_mcs[5],
+		   mask->control[band].vht_mcs[6], mask->control[band].vht_mcs[7]);
+}
+
 static int ath10k_mac_op_set_bitrate_mask(struct ieee80211_hw *hw,
 					  struct ieee80211_vif *vif,
 					  const struct cfg80211_bitrate_mask *mask)
@@ -6846,10 +7650,22 @@ static int ath10k_mac_op_set_bitrate_mas
 	int single_nss;
 	int ret;
 
-	if (ath10k_mac_vif_chan(vif, &def))
-		return -EPERM;
+	if (ath10k_mac_vif_chan(vif, &def)) {
+		/* No channel context.  But, we want to be able to set
+		 * some rates before we send probe requests, so just
+		 * assume 2Ghz if the desired channel is not already known.
+		 */
+		band = NL80211_BAND_2GHZ;
+	}
+	else {
+		band = def.chan->band;
+	}
+
+	ath10k_dbg(ar, ATH10K_DBG_MAC, "set bitrate mask, vid: %d  band: %d\n",
+		   arvif->vdev_id, band);
+	ath10k_dbg_print_bitrate_mask(ar, mask, 0);
+	ath10k_dbg_print_bitrate_mask(ar, mask, 1);
 
-	band = def.chan->band;
 	ht_mcs_mask = mask->control[band].ht_mcs;
 	vht_mcs_mask = mask->control[band].vht_mcs;
 	ldpc = !!(ar->ht_cap_info & WMI_HT_CAP_LDPC);
@@ -6866,10 +7682,12 @@ static int ath10k_mac_op_set_bitrate_mas
 				    arvif->vdev_id, ret);
 			return ret;
 		}
+		arvif->bitrate_mask = *mask;
 	} else if (ath10k_mac_bitrate_mask_get_single_nss(ar, band, mask,
 							  &single_nss)) {
 		rate = WMI_FIXED_RATE_NONE;
 		nss = single_nss;
+		arvif->bitrate_mask = *mask;
 	} else {
 		rate = WMI_FIXED_RATE_NONE;
 		nss = min(ar->num_rf_chains,
@@ -6891,13 +7709,19 @@ static int ath10k_mac_op_set_bitrate_mas
 
 	mutex_lock(&ar->conf_mutex);
 
-	ret = ath10k_mac_set_fixed_rate_params(arvif, rate, nss, sgi, ldpc);
+	ret = ath10k_mac_set_fixed_rate_params(arvif, rate, nss, sgi, ldpc, band);
 	if (ret) {
 		ath10k_warn(ar, "failed to set fixed rate params on vdev %i: %d\n",
 			    arvif->vdev_id, ret);
 		goto exit;
 	}
 
+	/* Setting the usable ratemask may have invalidated previous default
+	 * settings for the special rates (bcast, mcast, mgmt), so re-apply
+	 * them now.
+	 */
+	ath10k_check_apply_special_rates(ar, arvif);
+
 exit:
 	mutex_unlock(&ar->conf_mutex);
 
@@ -6934,6 +7758,9 @@ static void ath10k_sta_rc_update(struct
 			bw = WMI_PEER_CHWIDTH_80MHZ;
 			break;
 		case IEEE80211_STA_RX_BW_160:
+			bw = WMI_PEER_CHWIDTH_160MHZ;
+			break;
+		default:
 			ath10k_warn(ar, "Invalid bandwidth %d in rc update for %pM\n",
 				    sta->bandwidth, sta->addr);
 			bw = WMI_PEER_CHWIDTH_20MHZ;
@@ -7434,6 +8261,20 @@ ath10k_mac_op_switch_vif_chanctx(struct
 	return 0;
 }
 
+static void ath10k_mac_op_sta_pre_rcu_remove(struct ieee80211_hw *hw,
+					     struct ieee80211_vif *vif,
+					     struct ieee80211_sta *sta)
+{
+	struct ath10k *ar;
+	struct ath10k_peer *peer;
+
+	ar = hw->priv;
+
+	list_for_each_entry(peer, &ar->peers, list)
+		if (peer->sta == sta)
+			peer->removed = true;
+}
+
 static const struct ieee80211_ops ath10k_ops = {
 	.tx				= ath10k_mac_op_tx,
 	.wake_tx_queue			= ath10k_mac_op_wake_tx_queue,
@@ -7474,6 +8315,7 @@ static const struct ieee80211_ops ath10k
 	.assign_vif_chanctx		= ath10k_mac_op_assign_vif_chanctx,
 	.unassign_vif_chanctx		= ath10k_mac_op_unassign_vif_chanctx,
 	.switch_vif_chanctx		= ath10k_mac_op_switch_vif_chanctx,
+	.sta_pre_rcu_remove		= ath10k_mac_op_sta_pre_rcu_remove,
 
 	CFG80211_TESTMODE_CMD(ath10k_tm_cmd)
 
@@ -7618,7 +8460,27 @@ static const struct ieee80211_iface_limi
 	},
 };
 
-static const struct ieee80211_iface_combination ath10k_if_comb[] = {
+static struct ieee80211_iface_limit ath10k_10x_ct_if_limits[] = {
+	{
+	.max	= DEF_TARGET_10X_NUM_VDEVS_CT,
+	.types	= BIT(NL80211_IFTYPE_STATION)
+		| BIT(NL80211_IFTYPE_P2P_CLIENT)
+	},
+	{
+	.max	= 3,
+	.types	= BIT(NL80211_IFTYPE_P2P_GO)
+	},
+	{
+	.max	= 7,
+	.types	= BIT(NL80211_IFTYPE_AP)
+	},
+	{
+	.max	= 1,
+	.types	= BIT(NL80211_IFTYPE_ADHOC)
+	},
+};
+
+static struct ieee80211_iface_combination ath10k_if_comb[] = {
 	{
 		.limits = ath10k_if_limits,
 		.n_limits = ARRAY_SIZE(ath10k_if_limits),
@@ -7628,7 +8490,7 @@ static const struct ieee80211_iface_comb
 	},
 };
 
-static const struct ieee80211_iface_combination ath10k_10x_if_comb[] = {
+static struct ieee80211_iface_combination ath10k_10x_if_comb[] = {
 	{
 		.limits = ath10k_10x_if_limits,
 		.n_limits = ARRAY_SIZE(ath10k_10x_if_limits),
@@ -7698,6 +8560,22 @@ static const struct ieee80211_iface_limi
 	},
 };
 
+static struct ieee80211_iface_combination ath10k_10x_ct_if_comb[] = {
+	{
+		.limits = ath10k_10x_ct_if_limits,
+		.n_limits = ARRAY_SIZE(ath10k_10x_ct_if_limits),
+		.max_interfaces = DEF_TARGET_10X_NUM_VDEVS_CT,
+		.num_different_channels = 1,
+		.beacon_int_infra_match = true,
+#ifdef CONFIG_ATH10K_DFS_CERTIFIED
+		.radar_detect_widths =	BIT(NL80211_CHAN_WIDTH_20_NOHT) |
+					BIT(NL80211_CHAN_WIDTH_20) |
+					BIT(NL80211_CHAN_WIDTH_40) |
+					BIT(NL80211_CHAN_WIDTH_80),
+#endif
+	},
+};
+
 /* FIXME: This is not thouroughly tested. These combinations may over- or
  * underestimate hw/fw capabilities.
  */
@@ -7767,6 +8645,41 @@ static const struct ieee80211_iface_comb
 	},
 };
 
+static struct ieee80211_iface_limit ath10k_10_4_ct_if_limits[] = {
+	{
+		.max = 1,
+		.types = BIT(NL80211_IFTYPE_STATION),
+	},
+	{
+		.max	= 16,
+		.types	= BIT(NL80211_IFTYPE_AP)
+#ifdef CONFIG_MAC80211_MESH
+			| BIT(NL80211_IFTYPE_MESH_POINT)
+#endif
+	},
+	{
+	.max	= 1,
+	.types	= BIT(NL80211_IFTYPE_ADHOC)
+	},
+};
+
+static struct ieee80211_iface_combination ath10k_10_4_ct_if_comb[] = {
+	{
+		.limits = ath10k_10_4_ct_if_limits,
+		.n_limits = ARRAY_SIZE(ath10k_10_4_ct_if_limits),
+		.max_interfaces = 16,
+		.num_different_channels = 1,
+		.beacon_int_infra_match = true,
+#ifdef CONFIG_ATH10K_DFS_CERTIFIED
+		.radar_detect_widths =	BIT(NL80211_CHAN_WIDTH_20_NOHT) |
+					BIT(NL80211_CHAN_WIDTH_20) |
+					BIT(NL80211_CHAN_WIDTH_40) |
+					BIT(NL80211_CHAN_WIDTH_160) | /* TODO:  Verify --Ben */
+					BIT(NL80211_CHAN_WIDTH_80),
+#endif
+	},
+};
+
 static void ath10k_get_arvif_iter(void *data, u8 *mac,
 				  struct ieee80211_vif *vif)
 {
@@ -7798,6 +8711,53 @@ struct ath10k_vif *ath10k_get_arvif(stru
 	return arvif_iter.arvif;
 }
 
+/* Force over-ride const logic in core so we don't have to patch core. */
+#define ATH_ASSIGN_CONST_U16(a,b)                   \
+   do {                                             \
+      u16* __val_p = (u16*)(&(a));                  \
+      *__val_p = b;                                 \
+   } while (0)
+
+
+int ath10k_copy_comb(struct ath10k* ar,
+		     const struct ieee80211_iface_combination* comb,
+		     int array_len)
+{
+	int i;
+	int ln;
+
+	/* Clean out any existing combinations. */
+	ath10k_core_free_limits(ar);
+
+	memcpy(&ar->if_comb, comb, sizeof(*comb) * array_len);
+	for (i = 0; i<array_len; i++) {
+		ln = comb[i].n_limits * sizeof(*(comb[i].limits));
+		ar->if_comb[i].limits = kzalloc(ln, GFP_KERNEL);
+		if (!ar->if_comb[i].limits)
+			return -ENOMEM;
+		memcpy((void*)(ar->if_comb[i].limits), comb[i].limits, ln);
+	}
+
+	ar->hw->wiphy->iface_combinations = ar->if_comb;
+	ar->hw->wiphy->n_iface_combinations = array_len;
+	return 0;
+}
+
+#ifdef CPTCFG_MAC80211_LEDS
+static const struct ieee80211_tpt_blink ath10k_tpt_blink[] = {
+	{ .throughput = 0 * 1024, .blink_time = 334 },
+	{ .throughput = 1 * 1024, .blink_time = 260 },
+	{ .throughput = 2 * 1024, .blink_time = 220 },
+	{ .throughput = 5 * 1024, .blink_time = 190 },
+	{ .throughput = 10 * 1024, .blink_time = 170 },
+	{ .throughput = 25 * 1024, .blink_time = 150 },
+	{ .throughput = 54 * 1024, .blink_time = 130 },
+	{ .throughput = 120 * 1024, .blink_time = 110 },
+	{ .throughput = 265 * 1024, .blink_time = 80 },
+	{ .throughput = 586 * 1024, .blink_time = 50 },
+};
+#endif
+
 #define WRD_METHOD "WRDD"
 #define WRDD_WIFI  (0x07)
 
@@ -7988,7 +8948,8 @@ int ath10k_mac_register(struct ath10k *a
 	ieee80211_hw_set(ar->hw, AP_LINK_PS);
 	ieee80211_hw_set(ar->hw, SPECTRUM_MGMT);
 	ieee80211_hw_set(ar->hw, SUPPORT_FAST_XMIT);
-	ieee80211_hw_set(ar->hw, CONNECTION_MONITOR);
+	if (ar->bmiss_offload_max_vdev > 0)
+		ieee80211_hw_set(ar->hw, CONNECTION_MONITOR);
 	ieee80211_hw_set(ar->hw, SUPPORTS_PER_STA_GTK);
 	ieee80211_hw_set(ar->hw, WANT_MONITOR_VIF);
 	ieee80211_hw_set(ar->hw, CHANCTX_STA_CSA);
@@ -8067,35 +9028,90 @@ int ath10k_mac_register(struct ath10k *a
 
 	switch (ar->running_fw->fw_file.wmi_op_version) {
 	case ATH10K_FW_WMI_OP_VERSION_MAIN:
-		ar->hw->wiphy->iface_combinations = ath10k_if_comb;
-		ar->hw->wiphy->n_iface_combinations =
-			ARRAY_SIZE(ath10k_if_comb);
+		ret = ath10k_copy_comb(ar, ath10k_if_comb, ARRAY_SIZE(ath10k_if_comb));
 		ar->hw->wiphy->interface_modes |= BIT(NL80211_IFTYPE_ADHOC);
 		break;
 	case ATH10K_FW_WMI_OP_VERSION_TLV:
 		if (test_bit(WMI_SERVICE_ADAPTIVE_OCS, ar->wmi.svc_map)) {
-			ar->hw->wiphy->iface_combinations =
-				ath10k_tlv_qcs_if_comb;
-			ar->hw->wiphy->n_iface_combinations =
-				ARRAY_SIZE(ath10k_tlv_qcs_if_comb);
+			ret = ath10k_copy_comb(ar, ath10k_tlv_qcs_if_comb,
+					       ARRAY_SIZE(ath10k_tlv_qcs_if_comb));
 		} else {
-			ar->hw->wiphy->iface_combinations = ath10k_tlv_if_comb;
-			ar->hw->wiphy->n_iface_combinations =
-				ARRAY_SIZE(ath10k_tlv_if_comb);
+			ret = ath10k_copy_comb(ar, ath10k_tlv_if_comb,
+					       ARRAY_SIZE(ath10k_tlv_if_comb));
 		}
 		ar->hw->wiphy->interface_modes |= BIT(NL80211_IFTYPE_ADHOC);
 		break;
 	case ATH10K_FW_WMI_OP_VERSION_10_1:
+		if (test_bit(ATH10K_FW_FEATURE_WMI_10X_CT,
+			     ar->normal_mode_fw.fw_file.fw_features)) {
+			ret = ath10k_copy_comb(ar, ath10k_10x_ct_if_comb,
+					       ARRAY_SIZE(ath10k_10x_ct_if_comb));
+			if (ret != 0)
+				goto err_free;
+
+			ATH_ASSIGN_CONST_U16(ar->if_comb[0].limits[0].max, ar->max_num_vdevs);
+			ar->if_comb[0].max_interfaces = ar->max_num_vdevs;
+			ar->hw->wiphy->interface_modes |= BIT(NL80211_IFTYPE_ADHOC);
+
+			/* CT firmware can do tx-sw-crypt if properly configured */
+			if (test_bit(ATH10K_FW_FEATURE_CT_RXSWCRYPT,
+				     ar->running_fw->fw_file.fw_features) &&
+			    ath10k_modparam_nohwcrypt)
+				__clear_bit(IEEE80211_HW_SW_CRYPTO_CONTROL, ar->hw->flags);
+		} else {
+			ret = ath10k_copy_comb(ar, ath10k_10x_if_comb,
+					       ARRAY_SIZE(ath10k_10x_if_comb));
+		}
+		break;
 	case ATH10K_FW_WMI_OP_VERSION_10_2:
 	case ATH10K_FW_WMI_OP_VERSION_10_2_4:
-		ar->hw->wiphy->iface_combinations = ath10k_10x_if_comb;
-		ar->hw->wiphy->n_iface_combinations =
-			ARRAY_SIZE(ath10k_10x_if_comb);
+		if (test_bit(ATH10K_FW_FEATURE_WMI_10X_CT,
+			     ar->running_fw->fw_file.fw_features)) {
+			ret = ath10k_copy_comb(ar, ath10k_10x_ct_if_comb,
+					       ARRAY_SIZE(ath10k_10x_ct_if_comb));
+			if (ret != 0)
+				goto err_free;
+
+			ATH_ASSIGN_CONST_U16(ar->if_comb[0].limits[0].max, ar->max_num_vdevs);
+			ar->if_comb[0].max_interfaces = ar->max_num_vdevs;
+
+			ar->hw->wiphy->interface_modes |= BIT(NL80211_IFTYPE_ADHOC);
+
+			/* CT firmware can do tx-sw-crypt if properly configured */
+			if (test_bit(ATH10K_FW_FEATURE_CT_RXSWCRYPT,
+				     ar->running_fw->fw_file.fw_features) &&
+			    ath10k_modparam_nohwcrypt)
+				__clear_bit(IEEE80211_HW_SW_CRYPTO_CONTROL, ar->hw->flags);
+		} else {
+			ret = ath10k_copy_comb(ar, ath10k_10x_if_comb,
+					       ARRAY_SIZE(ath10k_10x_if_comb));
+		}
 		break;
 	case ATH10K_FW_WMI_OP_VERSION_10_4:
-		ar->hw->wiphy->iface_combinations = ath10k_10_4_if_comb;
-		ar->hw->wiphy->n_iface_combinations =
-			ARRAY_SIZE(ath10k_10_4_if_comb);
+		if (test_bit(ATH10K_FW_FEATURE_WMI_10X_CT,
+			     ar->running_fw->fw_file.fw_features)) {
+			ret = ath10k_copy_comb(ar, ath10k_10_4_ct_if_comb,
+					       ARRAY_SIZE(ath10k_10_4_ct_if_comb));
+			if (ret != 0)
+				goto err_free;
+
+			ATH_ASSIGN_CONST_U16(ar->if_comb[0].limits[0].max, ar->max_num_vdevs);
+			ar->if_comb[0].max_interfaces = ar->max_num_vdevs;
+
+			if (ar->if_comb[0].limits[1].max > ar->max_num_vdevs)
+				ATH_ASSIGN_CONST_U16(ar->if_comb[0].limits[1].max, ar->max_num_vdevs);
+
+			ar->hw->wiphy->interface_modes |= BIT(NL80211_IFTYPE_ADHOC);
+
+			/* CT firmware can do tx-sw-crypt if properly configured */
+			if (test_bit(ATH10K_FW_FEATURE_CT_RXSWCRYPT,
+				     ar->running_fw->fw_file.fw_features) &&
+			    ath10k_modparam_nohwcrypt)
+				__clear_bit(IEEE80211_HW_SW_CRYPTO_CONTROL, ar->hw->flags);
+		} else {
+			ret = ath10k_copy_comb(ar, ath10k_10_4_if_comb,
+					       ARRAY_SIZE(ath10k_10_4_if_comb));
+		}
 		break;
 	case ATH10K_FW_WMI_OP_VERSION_UNSET:
 	case ATH10K_FW_WMI_OP_VERSION_MAX:
@@ -8104,6 +9120,9 @@ int ath10k_mac_register(struct ath10k *a
 		goto err_free;
 	}
 
+	if (ret != 0)
+		goto err_free;
+
 	if (!test_bit(ATH10K_FLAG_RAW_MODE, &ar->dev_flags))
 		ar->hw->netdev_features = NETIF_F_HW_CSUM;
 
@@ -8146,6 +9165,12 @@ int ath10k_mac_register(struct ath10k *a
 	ar->hw->wiphy->cipher_suites = cipher_suites;
 	ar->hw->wiphy->n_cipher_suites = ARRAY_SIZE(cipher_suites);
 
+#ifdef CPTCFG_MAC80211_LEDS
+	ieee80211_create_tpt_led_trigger(ar->hw,
+		IEEE80211_TPT_LEDTRIG_FL_RADIO, ath10k_tpt_blink,
+		ARRAY_SIZE(ath10k_tpt_blink));
+#endif
+
 	ret = ieee80211_register_hw(ar->hw);
 	if (ret) {
 		ath10k_err(ar, "failed to register ieee80211: %d\n", ret);
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/net/wireless/ath/ath10k/mac.h linux-4.10.x/drivers/net/wireless/ath/ath10k/mac.h
--- linux-4.10.x.ori/drivers/net/wireless/ath/ath10k/mac.h	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/net/wireless/ath/ath10k/mac.h	2017-05-12 08:00:57.801800000 +0200
@@ -26,6 +26,12 @@
 enum wmi_tlv_tx_pause_id;
 enum wmi_tlv_tx_pause_action;
 
+extern int ath10k_modparam_nohwcrypt;
+extern int ath10k_modparam_target_num_vdevs_ct;
+extern int ath10k_modparam_target_num_peers_ct;
+extern int ath10k_modparam_target_num_msdu_desc_ct;
+extern int ath10k_modparam_target_num_rate_ctrl_objs_ct;
+
 struct ath10k_generic_iter {
 	struct ath10k *ar;
 	int ret;
@@ -82,6 +88,7 @@ struct ieee80211_txq *ath10k_mac_txq_loo
 					    u16 peer_id,
 					    u8 tid);
 int ath10k_mac_ext_resource_config(struct ath10k *ar, u32 val);
+void ath10k_dump_peer_info(struct ath10k *ar);
 
 static inline struct ath10k_vif *ath10k_vif_to_arvif(struct ieee80211_vif *vif)
 {
@@ -106,4 +113,6 @@ static inline void ath10k_tx_h_seq_no(st
 	}
 }
 
+int ath10k_mac_set_pdev_kickout(struct ath10k *ar);
+
 #endif /* _MAC_H_ */
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/net/wireless/ath/ath10k/pci.c linux-4.10.x/drivers/net/wireless/ath/ath10k/pci.c
--- linux-4.10.x.ori/drivers/net/wireless/ath/ath10k/pci.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/net/wireless/ath/ath10k/pci.c	2017-05-12 08:00:57.801800000 +0200
@@ -1001,6 +1001,22 @@ static int ath10k_pci_diag_read32(struct
 	return ret;
 }
 
+static int __ath10k_pci_diag_read_hi_addr(struct ath10k *ar, __le32 *dest,
+					  u32 src)
+{
+	u32 host_addr;
+	int ret;
+
+	host_addr = host_interest_item_address(src);
+
+	ret = ath10k_pci_diag_read32(ar, host_addr, dest);
+	if (ret != 0) {
+		ath10k_warn(ar, "failed to get memcpy hi address for firmware address %d: %d\n",
+			    src, ret);
+	}
+	return ret;
+}
+
 static int __ath10k_pci_diag_read_hi(struct ath10k *ar, void *dest,
 				     u32 src, u32 len)
 {
@@ -1029,6 +1045,9 @@ static int __ath10k_pci_diag_read_hi(str
 #define ath10k_pci_diag_read_hi(ar, dest, src, len)		\
 	__ath10k_pci_diag_read_hi(ar, dest, HI_ITEM(src), len)
 
+#define ath10k_pci_diag_read_hi_addr(ar, dest, src)		\
+	__ath10k_pci_diag_read_hi_addr(ar, dest, HI_ITEM(src))
+
 int ath10k_pci_diag_write_mem(struct ath10k *ar, u32 address,
 			      const void *data, int nbytes)
 {
@@ -1421,6 +1440,139 @@ u16 ath10k_pci_hif_get_free_queue_number
 	return ath10k_ce_num_free_src_entries(ar_pci->pipe_info[pipe].ce_hdl);
 }
 
+static void ath10k_pci_dump_bss_ram(struct ath10k *ar,
+				    struct ath10k_fw_crash_data *crash_data)
+{
+	int ret;
+
+	if (!crash_data)
+		return;
+
+	lockdep_assert_held(&ar->data_lock);
+
+	if (!ar->running_fw->fw_file.ram_bss_addr)
+		return;
+
+	if (!ar->running_fw->fw_file.ram_bss_len)
+		return;
+
+	ret = ath10k_pci_diag_read_mem(ar, ar->running_fw->fw_file.ram_bss_addr,
+				       crash_data->ram_bss_buf,
+				       ar->running_fw->fw_file.ram_bss_len);
+	if (ret)
+		ath10k_warn(ar,
+			    "failed to read firmware RAM BSS memory from %d (%d B): %d\n",
+			    ar->running_fw->fw_file.ram_bss_addr, ar->running_fw->fw_file.ram_bss_len, ret);
+}
+
+static void ath10k_pci_dump_bss_rom(struct ath10k *ar,
+				    struct ath10k_fw_crash_data *crash_data)
+{
+	int ret;
+
+	if (!crash_data)
+		return;
+
+	lockdep_assert_held(&ar->data_lock);
+
+	if (!ar->running_fw->fw_file.rom_bss_addr)
+		return;
+
+	if (!ar->running_fw->fw_file.rom_bss_len)
+		return;
+
+	ret = ath10k_pci_diag_read_mem(ar, ar->running_fw->fw_file.rom_bss_addr,
+				       crash_data->rom_bss_buf,
+				       ar->running_fw->fw_file.rom_bss_len);
+	if (ret)
+		ath10k_warn(ar,
+			    "failed to read firmware ROM BSS memory from %d (%d B): %d\n",
+			    ar->running_fw->fw_file.rom_bss_addr, ar->running_fw->fw_file.rom_bss_len, ret);
+}
+
+/* Save the main firmware stack */
+static void ath10k_pci_dump_stack(struct ath10k *ar,
+				  struct ath10k_fw_crash_data *crash_data)
+{
+	if (!crash_data)
+		return;
+
+	lockdep_assert_held(&ar->data_lock);
+	BUILD_BUG_ON(ATH10K_FW_STACK_SIZE % 4);
+
+	ath10k_pci_diag_read_hi(ar, crash_data->stack_buf,
+				hi_stack, ATH10K_FW_STACK_SIZE);
+	ath10k_pci_diag_read_hi_addr(ar, &crash_data->stack_addr, hi_stack);
+}
+
+/* Save the exception firmware stack */
+static void ath10k_pci_dump_exc_stack(struct ath10k *ar,
+				      struct ath10k_fw_crash_data *crash_data)
+{
+	if (!crash_data)
+		return;
+
+	lockdep_assert_held(&ar->data_lock);
+
+	ath10k_pci_diag_read_hi(ar, crash_data->exc_stack_buf,
+				hi_err_stack, ATH10K_FW_STACK_SIZE);
+
+	ath10k_pci_diag_read_hi_addr(ar, &crash_data->exc_stack_addr,
+				     hi_err_stack);
+}
+
+/* Only CT firmware can do this.  Attempt to read crash dump over pci
+ * registers since normal CE transport is not working.
+ */
+static int ath10k_ct_fw_crash_regs_harder(struct ath10k *ar,
+					  __le32 *reg_dump_values,
+					  int len)
+{
+	u32 val;
+	int i;
+	int q;
+#define MAX_SPIN_TRIES 1000000
+
+	if (!test_bit(ATH10K_FW_FEATURE_PINGPONG_READ_CT,
+		      ar->running_fw->fw_file.fw_features)) {
+		return -EINVAL;
+	}
+
+	ath10k_warn(ar, "in crash-regs-harder\n");
+
+	for (i = 0; i<MAX_SPIN_TRIES; i++) {
+		val = ath10k_pci_read32(ar, FW_INDICATOR_ADDRESS);
+		if (val & FW_IND_SCRATCH2_WR)
+			goto pingpong;
+	}
+
+	ath10k_warn(ar, "in crash-regs-harder, firmware did not provide indicator: 0x%x\n", val);
+	return -EBUSY;
+
+pingpong:
+	ath10k_warn(ar, "Trying to read crash dump over pingpong registers, len %d\n", len);
+	/* Firmware is trying to send us info it seems. */
+	for (q = 0; q<len; q++) {
+		reg_dump_values[q] = ath10k_pci_read32(ar, SOC_CORE_BASE_ADDRESS + SCRATCH_2_ADDRESS);
+		val = ath10k_pci_read32(ar, FW_INDICATOR_ADDRESS);
+		val |= FW_IND_SCRATCH2_RD; /* tell firmware we read it */
+		val &= ~FW_IND_SCRATCH2_WR; /* clear firmware's write flag */
+		ath10k_pci_write32(ar, FW_INDICATOR_ADDRESS, val);
+
+		for (i = 0; i<MAX_SPIN_TRIES; i++) {
+			val = ath10k_pci_read32(ar, FW_INDICATOR_ADDRESS);
+			if (val & FW_IND_SCRATCH2_WR)
+				break;
+		}
+		if (!(val & FW_IND_SCRATCH2_WR)) {
+			ath10k_err(ar, "failed to read reg %i via pingpong method.\n",
+				   q);
+			return 0; // partial read is better than nothing I guess
+		}
+	}
+	return 0;
+}
+
 static void ath10k_pci_dump_registers(struct ath10k *ar,
 				      struct ath10k_fw_crash_data *crash_data)
 {
@@ -1433,8 +1585,58 @@ static void ath10k_pci_dump_registers(st
 				      hi_failure_state,
 				      REG_DUMP_COUNT_QCA988X * sizeof(__le32));
 	if (ret) {
+		__le32 *buffer;
+		int len = 1500; /* length in bytes for firmware dbglog buffer */
+		struct ath10k_fw_dbglog_buf dbuf;
+
 		ath10k_err(ar, "failed to read firmware dump area: %d\n", ret);
-		return;
+
+		/* Try to read this directly over registers...only works on new
+		 * CT firmware.
+		 */
+		ret = ath10k_ct_fw_crash_regs_harder(ar, reg_dump_values, REG_DUMP_COUNT_QCA988X);
+		if (ret)
+			return;
+
+		/* Try to read the debug-log buffers as well. */
+		buffer = kzalloc(len, GFP_ATOMIC);
+
+		if (!buffer)
+			goto free_and_cont;
+
+		if (ath10k_ct_fw_crash_regs_harder(ar, (__le32 *)(&dbuf), sizeof(dbuf)/4))
+			goto free_and_cont;
+
+		/* wow, it worked! */
+		len = le32_to_cpu(dbuf.length);
+		if (len > 1500) {
+			ath10k_err(ar, "dbuf length is greater than 1500: %d\n", len);
+			len = 1500;
+		}
+		if (ath10k_ct_fw_crash_regs_harder(ar, buffer, len/4))
+			goto free_and_cont;
+
+		ath10k_dbg_save_fw_dbg_buffer(ar, buffer, len/4);
+		ath10k_dbg_print_fw_dbg_buffer(ar, buffer, len/4, KERN_ERR);
+
+		/* See if the second one is available */
+		if (ath10k_ct_fw_crash_regs_harder(ar, (__le32 *)(&dbuf), sizeof(dbuf)/4))
+			goto free_and_cont;
+
+		len = le32_to_cpu(dbuf.length);
+		if (len > 1500) {
+			ath10k_err(ar, "dbuf[2] length is greater than 1500: %d\n", len);
+			len = 1500;
+		}
+
+		if (ath10k_ct_fw_crash_regs_harder(ar, buffer, len/4))
+			goto free_and_cont;
+
+		ath10k_dbg_save_fw_dbg_buffer(ar, buffer, len/4);
+		ath10k_dbg_print_fw_dbg_buffer(ar, buffer, len/4, KERN_ERR);
+
+	free_and_cont:
+		kfree(buffer);
 	}
 
 	BUILD_BUG_ON(REG_DUMP_COUNT_QCA988X % 4);
@@ -1455,6 +1657,103 @@ static void ath10k_pci_dump_registers(st
 		crash_data->registers[i] = reg_dump_values[i];
 }
 
+/**
+ * Read any not-yet-delivered debug-log buffers on the target
+ * and save them to storage in the host driver.  Typically
+ * only done on crash, as firmware will normally deliver
+ * logs periodically on its own if it is functioning
+ * properly.
+ */
+static void ath10k_pci_dump_dbglog(struct ath10k *ar)
+{
+	struct ath10k_fw_dbglog_hdr dbg_hdr;
+	u32 dbufp; /* pointer in target memory space */
+	struct ath10k_fw_dbglog_buf dbuf;
+	u8 *buffer;
+	int ret;
+	int i;
+	int len;
+
+	ret = ath10k_pci_diag_read_hi(ar, &dbg_hdr, hi_dbglog_hdr,
+				      sizeof(dbg_hdr));
+	if (ret != 0) {
+		ath10k_err(ar, "failed to dump debug log area: %d\n", ret);
+		return;
+	}
+
+	ath10k_warn(ar, "debug log header, dbuf: 0x%x  dropped: %i\n",
+		    le32_to_cpu(dbg_hdr.dbuf), le32_to_cpu(dbg_hdr.dropped));
+	dbufp = le32_to_cpu(dbg_hdr.dbuf);
+
+	/* i is for logging purposes and sanity check in case firmware buffers
+	 * are corrupted and will not properly terminate the list.
+	 * In standard firmware, it appears there are no more than 2
+	 * buffers, so 10 should be safe upper limit even if firmware
+	 * changes quite a bit.
+	 */
+	i = 0;
+	while (dbufp && i < 10) {
+		ret = ath10k_pci_diag_read_mem(ar, dbufp, &dbuf, sizeof(dbuf));
+		if (ret != 0) {
+			ath10k_err(ar, "failed to read debug log area: %d (addr 0x%x)\n",
+				   ret, dbufp);
+			return;
+		}
+
+		len = le32_to_cpu(dbuf.length);
+
+		ath10k_warn(ar, "[%i] next: 0x%x buf: 0x%x sz: %i len: %i count: %i free: %i\n",
+			    i, le32_to_cpu(dbuf.next), le32_to_cpu(dbuf.buffer),
+			    le32_to_cpu(dbuf.bufsize), len,
+			    le32_to_cpu(dbuf.count), le32_to_cpu(dbuf.free));
+		if (dbuf.buffer == 0 || len == 0)
+			goto next;
+
+		/* Pick arbitrary upper bound in case firmware is corrupted for
+		 * whatever reason.
+		 */
+		if (len > 4096) {
+			ath10k_err(ar,
+				   "debuglog buf length is out of bounds: %d\n",
+				   len);
+			/* Do not trust the next pointer either... */
+			return;
+		}
+
+		buffer = kmalloc(len, GFP_ATOMIC);
+
+		if (!buffer)
+			goto next;
+
+		ret = ath10k_pci_diag_read_mem(ar, le32_to_cpu(dbuf.buffer),
+					       buffer, len);
+		if (ret != 0) {
+			ath10k_err(ar, "failed to read debug log buffer: %d (addr 0x%x)\n",
+				   ret, le32_to_cpu(dbuf.buffer));
+			kfree(buffer);
+			return;
+		}
+
+		WARN_ON(len & 0x3);
+
+		ath10k_dbg_save_fw_dbg_buffer(ar, (__le32 *)(buffer), len >> 2);
+		ath10k_dbg_print_fw_dbg_buffer(ar, (__le32 *)(buffer),
+					       len / sizeof(__le32),
+					       KERN_ERR);
+		kfree(buffer);
+
+next:
+		dbufp = le32_to_cpu(dbuf.next);
+		if (dbufp == le32_to_cpu(dbg_hdr.dbuf)) {
+			/* It is a circular buffer it seems, bail if next
+			 * is head
+			 */
+			break;
+		}
+		i++;
+	} /* While we have a debug buffer to read */
+}
+
 static void ath10k_pci_fw_crashed_dump(struct ath10k *ar)
 {
 	struct ath10k_fw_crash_data *crash_data;
@@ -1474,6 +1773,13 @@ static void ath10k_pci_fw_crashed_dump(s
 	ath10k_err(ar, "firmware crashed! (uuid %s)\n", uuid);
 	ath10k_print_driver_info(ar);
 	ath10k_pci_dump_registers(ar, crash_data);
+	ath10k_pci_dump_dbglog(ar);
+	ath10k_pci_dump_stack(ar, crash_data);
+	ath10k_pci_dump_exc_stack(ar, crash_data);
+	ath10k_pci_dump_bss_ram(ar, crash_data);
+	ath10k_pci_dump_bss_rom(ar, crash_data);
+	if (crash_data)
+		crash_data->crashed_since_read = true;
 
 	spin_unlock_bh(&ar->data_lock);
 
@@ -2533,10 +2839,13 @@ static int ath10k_pci_hif_power_up(struc
 	}
 	napi_enable(&ar->napi);
 
+	ar->fw_powerup_failed = false;
+
 	return 0;
 
 err_ce:
 	ath10k_pci_ce_deinit(ar);
+	ar->fw_powerup_failed = true;
 
 err_sleep:
 	return ret;
@@ -2744,6 +3053,7 @@ static const struct ath10k_hif_ops ath10
 	.power_down		= ath10k_pci_hif_power_down,
 	.read32			= ath10k_pci_read32,
 	.write32		= ath10k_pci_write32,
+	.fw_crashed_dump        = ath10k_pci_fw_crashed_dump,
 #ifdef CONFIG_PM
 	.suspend		= ath10k_pci_hif_suspend,
 	.resume			= ath10k_pci_hif_resume,
@@ -3171,6 +3481,9 @@ static int ath10k_pci_probe(struct pci_d
 	int (*pci_soft_reset)(struct ath10k *ar);
 	int (*pci_hard_reset)(struct ath10k *ar);
 
+	printk(KERN_INFO "ath10k driver, optimized for CT firmware, probing pci device: 0x%x.\n",
+	       pci_dev->device);
+
 	switch (pci_dev->device) {
 	case QCA988X_2_0_DEVICE_ID:
 		hw_rev = ATH10K_HW_QCA988X;
@@ -3400,12 +3713,16 @@ MODULE_FIRMWARE(QCA988X_HW_2_0_FW_DIR "/
 MODULE_FIRMWARE(QCA988X_HW_2_0_FW_DIR "/" ATH10K_FW_API4_FILE);
 MODULE_FIRMWARE(QCA988X_HW_2_0_FW_DIR "/" ATH10K_FW_API5_FILE);
 MODULE_FIRMWARE(QCA988X_HW_2_0_FW_DIR "/" QCA988X_HW_2_0_BOARD_DATA_FILE);
+/* gottwald@igel.com board-2.bin does not exists anywhere
 MODULE_FIRMWARE(QCA988X_HW_2_0_FW_DIR "/" ATH10K_BOARD_API2_FILE);
+*/
 
 /* QCA9887 1.0 firmware files */
 MODULE_FIRMWARE(QCA9887_HW_1_0_FW_DIR "/" ATH10K_FW_API5_FILE);
 MODULE_FIRMWARE(QCA9887_HW_1_0_FW_DIR "/" QCA9887_HW_1_0_BOARD_DATA_FILE);
+/* gottwald@igel.com board-2.bin does not exists anywhere
 MODULE_FIRMWARE(QCA9887_HW_1_0_FW_DIR "/" ATH10K_BOARD_API2_FILE);
+*/
 
 /* QCA6174 2.1 firmware files */
 MODULE_FIRMWARE(QCA6174_HW_2_1_FW_DIR "/" ATH10K_FW_API4_FILE);
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/net/wireless/ath/ath10k/targaddrs.h linux-4.10.x/drivers/net/wireless/ath/ath10k/targaddrs.h
--- linux-4.10.x.ori/drivers/net/wireless/ath/ath10k/targaddrs.h	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/net/wireless/ath/ath10k/targaddrs.h	2017-05-12 08:00:57.801800000 +0200
@@ -109,6 +109,12 @@ struct host_interest {
 	u32 hi_desired_baud_rate;			/* 0x60 */
 	u32 hi_dbglog_config;				/* 0x64 */
 	u32 hi_end_ram_reserve_sz;			/* 0x68 */
+	/* This controls the HTC pipe init setup.
+	 * 0x0F0000 ( x >> 16 & 0xf) is mask of ctrl-buffers-allocated.
+	 * 0xF00000 ( x >> 20 & 0xf) is mask of max-ep-pending-credit-rpts.
+	 * 0xFF000000 (x >> 24 & 0xff) is tx-credits in CT firmware only.
+	 * The rest appears un-used.
+	 */
 	u32 hi_mbox_io_block_sz;			/* 0x6c */
 
 	u32 hi_num_bpatch_streams;			/* 0x70 -- unused */
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/net/wireless/ath/ath10k/txrx.c linux-4.10.x/drivers/net/wireless/ath/ath10k/txrx.c
--- linux-4.10.x.ori/drivers/net/wireless/ath/ath10k/txrx.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/net/wireless/ath/ath10k/txrx.c	2017-05-12 08:00:57.801800000 +0200
@@ -49,6 +49,76 @@ out:
 	spin_unlock_bh(&ar->data_lock);
 }
 
+static u8 cck_rateidx[] = {
+	3, 2 , 1, 0
+};
+#define cck_rateidx_size (ARRAY_SIZE(cck_rateidx))
+
+static u8 ofdm_rateidx[] = {
+	10, 8 , 6, 4, 11, 9, 7, 5
+};
+#define ofdm_rateidx_size (ARRAY_SIZE(ofdm_rateidx))
+
+static void ath10k_set_tx_rate_status(struct ath10k *ar,
+				      struct ieee80211_tx_rate *rate,
+				      const struct htt_tx_done *tx_done)
+{
+	struct ieee80211_channel *ch = ar->scan_channel;
+	u8 nss = (tx_done->tx_rate_code >> 4) & 0x3;
+	u8 hw_rate = tx_done->tx_rate_code & 0xF;
+
+	if (!ch)
+		ch = ar->rx_channel;
+
+	rate->count = 1;
+	rate->idx = -1; /* Will set it properly below if rate-code is sane. */
+
+	switch ((tx_done->tx_rate_code >> 6) & 0x3) {
+	case WMI_RATE_PREAMBLE_CCK:
+		if (likely(hw_rate < cck_rateidx_size))
+			rate->idx = cck_rateidx[hw_rate];
+		else
+			rate->idx = cck_rateidx[0];
+		break;
+
+        case WMI_RATE_PREAMBLE_OFDM:
+		if (likely(hw_rate < ofdm_rateidx_size))
+			rate->idx = ofdm_rateidx[hw_rate];
+		else
+			rate->idx = ofdm_rateidx[4];
+
+		/* If we are on 5Ghz, then idx must be decreased by
+		 * 4 since the CCK rates are not available on 5Ghz.
+		 */
+		if (ch && (ch->band == NL80211_BAND_5GHZ))
+			rate->idx -= 4;
+		break;
+	}/* switch OFDM/CCK */
+
+	if ((tx_done->tx_rate_code & 0xcc) == 0x44)
+		rate->flags |= IEEE80211_TX_RC_USE_SHORT_PREAMBLE;
+
+	if ((tx_done->tx_rate_code & 0xc0) == 0x80) {
+		rate->flags |= IEEE80211_TX_RC_MCS;
+		rate->idx = hw_rate + (nss * 8);
+	}
+
+	if ((tx_done->tx_rate_code & 0xc0) == 0xc0) {
+		rate->flags |= IEEE80211_TX_RC_VHT_MCS;
+		/* TODO-BEN:  Not sure this is correct. */
+		rate->idx = (nss << 4) | hw_rate;
+	}
+
+	if (tx_done->tx_rate_flags & ATH10K_RC_FLAG_40MHZ)
+		rate->flags |= IEEE80211_TX_RC_40_MHZ_WIDTH;
+	if (tx_done->tx_rate_flags & ATH10K_RC_FLAG_80MHZ)
+		rate->flags |= IEEE80211_TX_RC_80_MHZ_WIDTH;
+	if (tx_done->tx_rate_flags & ATH10K_RC_FLAG_160MHZ)
+		rate->flags |= IEEE80211_TX_RC_160_MHZ_WIDTH;
+	if (tx_done->tx_rate_flags & ATH10K_RC_FLAG_SGI)
+		rate->flags |= IEEE80211_TX_RC_SHORT_GI;
+}
+
 int ath10k_txrx_tx_unref(struct ath10k_htt *htt,
 			 const struct htt_tx_done *tx_done)
 {
@@ -59,6 +129,7 @@ int ath10k_txrx_tx_unref(struct ath10k_h
 	struct ath10k_skb_cb *skb_cb;
 	struct ath10k_txq *artxq;
 	struct sk_buff *msdu;
+	bool tx_failed = false;
 
 	ath10k_dbg(ar, ATH10K_DBG_HTT,
 		   "htt tx completion msdu_id %u status %d\n",
@@ -102,20 +173,59 @@ int ath10k_txrx_tx_unref(struct ath10k_h
 	trace_ath10k_txrx_tx_unref(ar, tx_done->msdu_id);
 
 	if (tx_done->status == HTT_TX_COMPL_STATE_DISCARD) {
+#ifdef CONFIG_ATH10K_DEBUG
+		ar->debug.tx_discard++;
+		ar->debug.tx_discard_bytes += msdu->len;
+#endif
 		ieee80211_free_txskb(htt->ar->hw, msdu);
 		return 0;
 	}
 
+	info->status.ack_signal = tx_done->ack_rssi;
+
 	if (!(info->flags & IEEE80211_TX_CTL_NO_ACK))
 		info->flags |= IEEE80211_TX_STAT_ACK;
 
 	if (tx_done->status == HTT_TX_COMPL_STATE_NOACK)
-		info->flags &= ~IEEE80211_TX_STAT_ACK;
+		tx_failed = true;
 
 	if ((tx_done->status == HTT_TX_COMPL_STATE_ACK) &&
 	    (info->flags & IEEE80211_TX_CTL_NO_ACK))
 		info->flags |= IEEE80211_TX_STAT_NOACK_TRANSMITTED;
 
+	if (tx_done->tx_rate_code || tx_done->tx_rate_flags) {
+		ath10k_set_tx_rate_status(ar, &info->status.rates[0], tx_done);
+
+		/* Only in version 14 and higher of CT firmware */
+		if (test_bit(ATH10K_FW_FEATURE_HAS_TXSTATUS_NOACK,
+			     ar->running_fw->fw_file.fw_features)) {
+			/* Deal with tx-completion status */
+			if ((tx_done->tx_rate_flags & 0x3) == ATH10K_RC_FLAG_XRETRY) {
+#ifdef CONFIG_ATH10K_DEBUG
+				ar->debug.tx_noack++;
+				ar->debug.tx_noack_bytes += msdu->len;
+#endif
+				tx_failed = true;
+			}
+			/* TODO:  Report drops differently. */
+			if ((tx_done->tx_rate_flags & 0x3) == ATH10K_RC_FLAG_DROP)
+				tx_failed = true;
+		}
+	} else {
+		info->status.rates[0].idx = -1;
+	}
+
+
+	if (tx_failed) {
+		info->flags &= ~IEEE80211_TX_STAT_ACK;
+	}
+#ifdef CONFIG_ATH10K_DEBUG
+	else {
+		ar->debug.tx_ok++;
+		ar->debug.tx_ok_bytes += msdu->len;
+	}
+#endif
+
 	ieee80211_tx_status(htt->ar->hw, msdu);
 	/* we do not own the msdu anymore */
 
@@ -168,7 +278,7 @@ static int ath10k_wait_for_peer_common(s
 
 			(mapped == expect_mapped ||
 			 test_bit(ATH10K_FLAG_CRASH_FLUSH, &ar->dev_flags));
-		}), 3 * HZ);
+		}), 1 * HZ);
 
 	if (time_left == 0)
 		return -ETIMEDOUT;
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/net/wireless/ath/ath10k/wmi.c linux-4.10.x/drivers/net/wireless/ath/ath10k/wmi.c
--- linux-4.10.x.ori/drivers/net/wireless/ath/ath10k/wmi.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/net/wireless/ath/ath10k/wmi.c	2017-05-12 08:00:57.801800000 +0200
@@ -17,6 +17,7 @@
 
 #include <linux/skbuff.h>
 #include <linux/ctype.h>
+#include <linux/module.h>
 
 #include "core.h"
 #include "htc.h"
@@ -28,6 +29,7 @@
 #include "wmi-ops.h"
 #include "p2p.h"
 #include "hw.h"
+#include "hif.h"
 
 #define ATH10K_WMI_BARRIER_ECHO_ID 0xBA991E9
 #define ATH10K_WMI_BARRIER_TIMEOUT_HZ (3 * HZ)
@@ -1574,6 +1576,7 @@ static const struct wmi_peer_flags_map w
 	.bw80 = WMI_PEER_80MHZ,
 	.vht_2g = WMI_PEER_VHT_2G,
 	.pmf = WMI_PEER_PMF,
+	.bw160 = WMI_PEER_160MHZ,
 };
 
 static const struct wmi_peer_flags_map wmi_10x_peer_flags_map = {
@@ -1591,6 +1594,7 @@ static const struct wmi_peer_flags_map w
 	.spatial_mux = WMI_10X_PEER_SPATIAL_MUX,
 	.vht = WMI_10X_PEER_VHT,
 	.bw80 = WMI_10X_PEER_80MHZ,
+	.bw160 = WMI_10X_PEER_160MHZ,
 };
 
 static const struct wmi_peer_flags_map wmi_10_2_peer_flags_map = {
@@ -1610,10 +1614,41 @@ static const struct wmi_peer_flags_map w
 	.bw80 = WMI_10_2_PEER_80MHZ,
 	.vht_2g = WMI_10_2_PEER_VHT_2G,
 	.pmf = WMI_10_2_PEER_PMF,
+	.bw160 = WMI_10_2_PEER_160MHZ,
 };
 
-void ath10k_wmi_put_wmi_channel(struct wmi_channel *ch,
-				const struct wmi_channel_arg *arg)
+static bool ath10k_ok_skip_ch_reservation(struct ath10k *ar, u32 vdev_id)
+{
+	struct ath10k_vif *arvif;
+	bool rv = false;
+
+	if (! test_bit(ATH10K_FW_FEATURE_SKIP_CH_RES_CT,
+		       ar->running_fw->fw_file.fw_features))
+		return rv;
+
+	list_for_each_entry(arvif, &ar->arvifs, list) {
+		if (!arvif->is_up)
+			continue;
+
+		if (arvif->vdev_id == vdev_id) {
+			if (arvif->vdev_type != WMI_VDEV_TYPE_STA)
+				return false;
+			continue;
+		}
+
+		/* If there is another station up, then assume
+		 * requested station must use same channel.
+		 */
+		if (arvif->vdev_type == WMI_VDEV_TYPE_STA)
+			rv = true;
+	}
+	return rv;
+}
+
+void ath10k_wmi_put_wmi_channel(struct ath10k *ar,
+				struct wmi_channel *ch,
+				const struct wmi_channel_arg *arg,
+				u32 vdev_id)
 {
 	u32 flags = 0;
 
@@ -1632,9 +1667,16 @@ void ath10k_wmi_put_wmi_channel(struct w
 	if (arg->chan_radar)
 		flags |= WMI_CHAN_FLAG_DFS;
 
+	if (ath10k_ok_skip_ch_reservation(ar, vdev_id))
+		/* Disable having firmware request on-channel reservation */
+		flags |= WMI_CHAN_FLAG_NO_RESERVE_CH;
+
 	ch->mhz = __cpu_to_le32(arg->freq);
 	ch->band_center_freq1 = __cpu_to_le32(arg->band_center_freq1);
-	ch->band_center_freq2 = 0;
+	if (arg->mode == MODE_11AC_VHT80_80)
+		ch->band_center_freq2 = __cpu_to_le32(arg->band_center_freq2);
+	else
+		ch->band_center_freq2 = 0;
 	ch->min_power = arg->min_power;
 	ch->max_power = arg->max_power;
 	ch->reg_power = arg->max_reg_power;
@@ -1731,6 +1773,15 @@ static void ath10k_wmi_tx_beacon_nowait(
 	bool deliver_cab;
 	int ret;
 
+	/* I saw a kasan warning here, looks like arvif and/or ar might have been
+	 * NULL, add something to catch this if it happens again.
+	 */
+	if ((((unsigned long)(arvif)) < 8000) || (((unsigned long)(ar)) < 8000)) {
+		pr_err("tx-beacon-nowait:  arvif: %p  ar: %p\n", arvif, ar);
+		BUG_ON(((unsigned long)(arvif)) < 8000);
+		BUG_ON(((unsigned long)(ar)) < 8000);
+	}
+
 	spin_lock_bh(&ar->data_lock);
 
 	bcn = arvif->beacon;
@@ -1796,12 +1847,14 @@ static void ath10k_wmi_op_ep_tx_credits(
 int ath10k_wmi_cmd_send(struct ath10k *ar, struct sk_buff *skb, u32 cmd_id)
 {
 	int ret = -EOPNOTSUPP;
+	int retry = 1000;
 
 	might_sleep();
 
 	if (cmd_id == WMI_CMD_UNSUPPORTED) {
 		ath10k_warn(ar, "wmi command %d is not supported by firmware\n",
 			    cmd_id);
+		dev_kfree_skb_any(skb);
 		return ret;
 	}
 
@@ -1809,7 +1862,19 @@ int ath10k_wmi_cmd_send(struct ath10k *a
 		/* try to send pending beacons first. they take priority */
 		ath10k_wmi_tx_beacons_nowait(ar);
 
-		ret = ath10k_wmi_cmd_send_nowait(ar, skb, cmd_id);
+		while (--retry) {
+			ret = ath10k_wmi_cmd_send_nowait(ar, skb, cmd_id);
+			if ((ret == -ENOBUFS) &&
+			    !test_bit(ATH10K_FLAG_CRASH_FLUSH, &ar->dev_flags)) {
+				/* CE transport logic is full, maybe we cannot reap entries fast
+				 * enough?
+				 */
+				ath10k_err(ar, "CE transport is full, sleeping for 1ms\n");
+				msleep(1);
+				continue;
+			}
+			break;
+		}
 
 		if (ret && test_bit(ATH10K_FLAG_CRASH_FLUSH, &ar->dev_flags))
 			ret = -ESHUTDOWN;
@@ -1820,6 +1885,13 @@ int ath10k_wmi_cmd_send(struct ath10k *a
 	if (ret)
 		dev_kfree_skb_any(skb);
 
+	if (ret == -EAGAIN) {
+		/* Firmware is not responding after 3 seconds, might as well try to kill it. */
+		ath10k_err(ar, "Cannot communicate with firmware, attempting to fake crash and restart firmware.\n");
+		ath10k_hif_fw_crashed_dump(ar);
+		set_bit(ATH10K_FLAG_CRASH_FLUSH, &ar->dev_flags);
+	}
+
 	return ret;
 }
 
@@ -1907,7 +1979,8 @@ static void ath10k_wmi_event_scan_starte
 	}
 }
 
-static void ath10k_wmi_event_scan_start_failed(struct ath10k *ar)
+static void ath10k_wmi_event_scan_start_failed(struct ath10k *ar,
+					       enum wmi_scan_completion_reason reason)
 {
 	lockdep_assert_held(&ar->data_lock);
 
@@ -1921,6 +1994,15 @@ static void ath10k_wmi_event_scan_start_
 		break;
 	case ATH10K_SCAN_STARTING:
 		complete(&ar->scan.started);
+		if (reason == WMI_SCAN_REASON_BUSY) {
+			/* Kick firmware to get us back in sync */
+			struct wmi_stop_scan_arg arg = {
+				.req_id = 1, /* FIXME */
+				.req_type = WMI_SCAN_STOP_ONE,
+				.u.scan_id = ATH10K_SCAN_ID,
+			};
+			ath10k_wmi_stop_scan(ar, &arg);
+		}
 		__ath10k_scan_finish(ar);
 		break;
 	}
@@ -2010,6 +2092,8 @@ ath10k_wmi_event_scan_type_str(enum wmi_
 			return "completed [timedout]";
 		case WMI_SCAN_REASON_INTERNAL_FAILURE:
 			return "completed [internal err]";
+		case WMI_SCAN_REASON_BUSY:
+			return "completed [failed, busy]";
 		case WMI_SCAN_REASON_MAX:
 			break;
 		}
@@ -2098,8 +2182,11 @@ int ath10k_wmi_event_scan(struct ath10k
 		ath10k_wmi_event_scan_foreign_chan(ar, freq);
 		break;
 	case WMI_SCAN_EVENT_START_FAILED:
-		ath10k_warn(ar, "received scan start failure event\n");
-		ath10k_wmi_event_scan_start_failed(ar);
+		ath10k_warn(ar, "scan-start-failed event %s type %d reason %d freq %d req_id %d scan_id %d vdev_id %d state %s (%d)\n",
+			    ath10k_wmi_event_scan_type_str(event_type, reason),
+			    event_type, reason, freq, req_id, scan_id, vdev_id,
+			    ath10k_scan_state_str(ar->scan.state), ar->scan.state);
+		ath10k_wmi_event_scan_start_failed(ar, reason);
 		break;
 	case WMI_SCAN_EVENT_DEQUEUED:
 	case WMI_SCAN_EVENT_PREEMPTED:
@@ -2534,14 +2621,118 @@ void ath10k_wmi_event_echo(struct ath10k
 
 int ath10k_wmi_event_debug_mesg(struct ath10k *ar, struct sk_buff *skb)
 {
+	struct ath10k_fw_dbglog_report *ev;
+
 	ath10k_dbg(ar, ATH10K_DBG_WMI, "wmi event debug mesg len %d\n",
 		   skb->len);
 
 	trace_ath10k_wmi_dbglog(ar, skb->data, skb->len);
+	ev = (struct ath10k_fw_dbglog_report *)skb->data;
+
+	spin_lock_bh(&ar->data_lock);
+	/* First 4 bytes are a messages-dropped-due-to-overflow counter,
+	 * and should not be recorded in the dbglog buffer, so we skip
+	 * them.
+	 */
+	WARN_ON(skb->len & 0x3);
+	ath10k_dbg_save_fw_dbg_buffer(ar, ev->messages,
+				      (skb->len - 4)/sizeof(__le32));
+	spin_unlock_bh(&ar->data_lock);
+
+	if (ath10k_debug_mask & ATH10K_DBG_NO_DBGLOG)
+		return 0;
+
+	if (ev->dropped_count)
+		ath10k_warn(ar, "WARNING: Dropped dbglog buffers: %d\n", __le32_to_cpu(ev->dropped_count));
+
+	if (ath10k_debug_mask & ATH10K_DBG_FW)
+		ath10k_dbg_print_fw_dbg_buffer(ar, ev->messages,
+					       (skb->len - 4)/sizeof(__le32),
+					       KERN_INFO);
+	else
+		ath10k_dbg_print_fw_dbg_buffer(ar, ev->messages,
+					       (skb->len - 4)/sizeof(__le32),
+					       KERN_DEBUG);
 
 	return 0;
 }
 
+int ath10k_wmi_event_csi_mesg(struct ath10k *ar, struct sk_buff *skb)
+{
+	__le32 *ibuf;
+	int q = 0;
+	int len;
+	const char* lvl = KERN_INFO;
+
+	ath10k_dbg(ar, ATH10K_DBG_WMI, "wmi event csi mesg len %d\n",
+		   skb->len);
+
+	ibuf = (__le32*)(skb->data);
+	len = skb->len / 4;
+
+	dev_printk(lvl, ar->dev, "ath10k_pci ATH10K_CSI_BUFFER:\n");
+	while (q < len) {
+		if (q + 8 <= len) {
+			printk("%sath10k: [%04d]: %08X %08X %08X %08X %08X %08X %08X %08X\n",
+			       lvl, q,
+			       ibuf[q], ibuf[q+1], ibuf[q+2], ibuf[q+3],
+			       ibuf[q+4], ibuf[q+5], ibuf[q+6], ibuf[q+7]);
+			q += 8;
+		}
+		else if (q + 7 <= len) {
+			printk("%sath10k: [%04d]: %08X %08X %08X %08X %08X %08X %08X\n",
+			       lvl, q,
+			       ibuf[q], ibuf[q+1], ibuf[q+2], ibuf[q+3],
+			       ibuf[q+4], ibuf[q+5], ibuf[q+6]);
+			q += 7;
+		}
+		else if (q + 6 <= len) {
+			printk("%sath10k: [%04d]: %08X %08X %08X %08X %08X %08X\n",
+			       lvl, q,
+			       ibuf[q], ibuf[q+1], ibuf[q+2], ibuf[q+3],
+			       ibuf[q+4], ibuf[q+5]);
+			q += 6;
+		}
+		else if (q + 5 <= len) {
+			printk("%sath10k: [%04d]: %08X %08X %08X %08X %08X\n",
+			       lvl, q,
+			       ibuf[q], ibuf[q+1], ibuf[q+2], ibuf[q+3],
+			       ibuf[q+4]);
+			q += 5;
+		}
+		else if (q + 4 <= len) {
+			printk("%sath10k: [%04d]: %08X %08X %08X %08X\n",
+			       lvl, q,
+			       ibuf[q], ibuf[q+1], ibuf[q+2], ibuf[q+3]);
+			q += 4;
+		}
+		else if (q + 3 <= len) {
+			printk("%sath10k: [%04d]: %08X %08X %08X\n",
+			       lvl, q,
+			       ibuf[q], ibuf[q+1], ibuf[q+2]);
+			q += 3;
+		}
+		else if (q + 2 <= len) {
+			printk("%sath10k: [%04d]: %08X %08X\n",
+			       lvl, q,
+			       ibuf[q], ibuf[q+1]);
+			q += 2;
+		}
+		else if (q + 1 <= len) {
+			printk("%sath10k: [%04d]: %08X\n",
+			       lvl, q,
+			       ibuf[q]);
+			q += 1;
+		}
+		else {
+			break;
+		}
+	}/* while */
+
+	dev_printk(lvl, ar->dev, "ATH10K_END\n");
+	return 0;
+}
+
 void ath10k_wmi_pull_pdev_stats_base(const struct wmi_pdev_stats_base *src,
 				     struct ath10k_fw_stats_pdev *dst)
 {
@@ -3127,6 +3318,9 @@ ath10k_wmi_op_pull_peer_kick_ev(struct a
 	skb_pull(skb, sizeof(*ev));
 	arg->mac_addr = ev->peer_macaddr.addr;
 
+	/* CT Firmware may sneak in some info in the un-used space. */
+	arg->unused_hi = __le32_to_cpu(ev->peer_macaddr.word1) >> 16;
+
 	return 0;
 }
 
@@ -4083,7 +4277,7 @@ void ath10k_wmi_event_profile_match(stru
 
 void ath10k_wmi_event_debug_print(struct ath10k *ar, struct sk_buff *skb)
 {
-	char buf[101], c;
+	char buf[WMI_MAX_DEBUG_MESG + 1], c;
 	int i;
 
 	for (i = 0; i < sizeof(buf) - 1; i++) {
@@ -4111,7 +4305,7 @@ void ath10k_wmi_event_debug_print(struct
 	/* the last byte is always reserved for the null character */
 	buf[i] = '\0';
 
-	ath10k_dbg(ar, ATH10K_DBG_WMI_PRINT, "wmi print '%s'\n", buf);
+	ath10k_info(ar, "wmi print '%s'\n", buf);
 }
 
 void ath10k_wmi_event_pdev_qvit(struct ath10k *ar, struct sk_buff *skb)
@@ -4674,11 +4868,18 @@ static void ath10k_wmi_event_service_rea
 	ar->fw_version_build = (__le32_to_cpu(arg.sw_ver1) & 0x0000ffff);
 	ar->phy_capability = __le32_to_cpu(arg.phy_capab);
 	ar->num_rf_chains = __le32_to_cpu(arg.num_rf_chains);
-	ar->hw_eeprom_rd = __le32_to_cpu(arg.eeprom_rd);
+	ar->ath_common.regulatory.current_rd = __le32_to_cpu(arg.eeprom_rd);
 
 	ath10k_dbg_dump(ar, ATH10K_DBG_WMI, NULL, "wmi svc: ",
 			arg.service_map, arg.service_map_len);
 
+	// RX Sw Crypt mode, which uses raw receive and disables some HW rx logic,
+	// appears to break receiving MU-MIMO properly, so tweak that here.
+	if (test_bit(ATH10K_FW_FEATURE_CT_RXSWCRYPT,
+		     ar->running_fw->fw_file.fw_features) &&
+	    ar->request_nohwcrypt)
+		ar->vht_cap_info &= ~IEEE80211_VHT_CAP_MU_BEAMFORMEE_CAPABLE;
+
 	if (ar->num_rf_chains > ar->max_spatial_stream) {
 		ath10k_warn(ar, "hardware advertises support for more spatial streams than it should (%d > %d)\n",
 			    ar->num_rf_chains, ar->max_spatial_stream);
@@ -4700,6 +4901,21 @@ static void ath10k_wmi_event_service_rea
 			 ar->fw_version_build);
 	}
 
+	if ((ar->eeprom_regdom != -1) &&
+	    (ar->eeprom_regdom != ar->ath_common.regulatory.current_rd)) {
+		static int do_once = 1;
+		if (do_once) {
+			ath10k_err(ar, "DANGER! You're overriding EEPROM-defined regulatory domain,"
+				   "\nfrom: 0x%x to 0x%x\n",
+				   ar->ath_common.regulatory.current_rd, ar->eeprom_regdom);
+			ath10k_err(ar, "Your card was not certified to operate in the domain you chose.\n");
+			ath10k_err(ar, "This might result in a violation of your local regulatory rules.\n");
+			ath10k_err(ar, "Do not ever do this unless you really know what you are doing!\n");
+			do_once = 0;
+		}
+		ar->ath_common.regulatory.current_rd = ar->eeprom_regdom | COUNTRY_ERD_FLAG;
+	}
+
 	num_mem_reqs = __le32_to_cpu(arg.num_mem_reqs);
 	if (num_mem_reqs > WMI_MAX_MEM_REQS) {
 		ath10k_warn(ar, "requested memory chunks number (%d) exceeds the limit\n",
@@ -4708,18 +4924,28 @@ static void ath10k_wmi_event_service_rea
 	}
 
 	if (test_bit(WMI_SERVICE_PEER_CACHING, ar->wmi.svc_map)) {
-		if (test_bit(ATH10K_FW_FEATURE_PEER_FLOW_CONTROL,
-			     ar->running_fw->fw_file.fw_features))
-			ar->num_active_peers = TARGET_10_4_QCACHE_ACTIVE_PEERS_PFC +
-					       ar->max_num_vdevs;
-		else
-			ar->num_active_peers = TARGET_10_4_QCACHE_ACTIVE_PEERS +
-					       ar->max_num_vdevs;
 
-		ar->max_num_peers = TARGET_10_4_NUM_QCACHE_PEERS_MAX +
-				    ar->max_num_vdevs;
-		ar->num_tids = ar->num_active_peers * 2;
-		ar->max_num_stations = TARGET_10_4_NUM_QCACHE_PEERS_MAX;
+		/* Don't over-ride user-specified config here, but otherwise,
+		 * adjust in case we are using PEER caching.
+		 */
+		if (!(ar->fwcfg.flags & ATH10K_FWCFG_ACTIVE_PEERS)) {
+			if (test_bit(ATH10K_FW_FEATURE_PEER_FLOW_CONTROL,
+				     ar->running_fw->fw_file.fw_features))
+				ar->num_active_peers = TARGET_10_4_QCACHE_ACTIVE_PEERS_PFC +
+					ar->max_num_vdevs;
+			else
+				ar->num_active_peers = TARGET_10_4_QCACHE_ACTIVE_PEERS +
+					ar->max_num_vdevs;
+		}
+
+		if (!(ar->fwcfg.flags & ATH10K_FWCFG_PEERS))
+			ar->max_num_peers = TARGET_10_4_NUM_QCACHE_PEERS_MAX +
+				ar->max_num_vdevs;
+
+		if (!(ar->fwcfg.flags & ATH10K_FWCFG_NUM_TIDS))
+			ar->num_tids = ar->num_active_peers * 2;
+		if (!(ar->fwcfg.flags & ATH10K_FWCFG_STATIONS))
+			ar->max_num_stations = TARGET_10_4_NUM_QCACHE_PEERS_MAX;
 	}
 
 	/* TODO: Adjust max peer count for cases like WMI_SERVICE_RATECTRL_CACHE
@@ -5443,7 +5669,8 @@ static void ath10k_wmi_10_4_op_rx(struct
 		ath10k_wmi_event_pdev_bss_chan_info(ar, skb);
 		break;
 	case WMI_10_4_PDEV_TPC_CONFIG_EVENTID:
-		ath10k_wmi_event_pdev_tpc_config(ar, skb);
+		// ath10k_wmi_event_pdev_tpc_config(ar, skb);
+		ath10k_wmi_event_csi_mesg(ar, skb);
 		break;
 	default:
 		ath10k_warn(ar, "Unknown eventid: %d\n", id);
@@ -5624,8 +5851,8 @@ static struct sk_buff *ath10k_wmi_op_gen
 	struct wmi_resource_config config = {};
 	u32 len, val;
 
-	config.num_vdevs = __cpu_to_le32(TARGET_NUM_VDEVS);
-	config.num_peers = __cpu_to_le32(TARGET_NUM_PEERS);
+	config.num_vdevs = __cpu_to_le32(ar->max_num_vdevs);
+	config.num_peers = __cpu_to_le32(ar->max_num_peers);
 	config.num_offload_peers = __cpu_to_le32(TARGET_NUM_OFFLOAD_PEERS);
 
 	config.num_offload_reorder_bufs =
@@ -5633,7 +5860,7 @@ static struct sk_buff *ath10k_wmi_op_gen
 
 	config.num_peer_keys = __cpu_to_le32(TARGET_NUM_PEER_KEYS);
 	config.num_tids = __cpu_to_le32(TARGET_NUM_TIDS);
-	config.ast_skid_limit = __cpu_to_le32(TARGET_AST_SKID_LIMIT);
+	config.ast_skid_limit = __cpu_to_le32(ar->skid_limit);
 	config.tx_chain_mask = __cpu_to_le32(TARGET_TX_CHAIN_MASK);
 	config.rx_chain_mask = __cpu_to_le32(TARGET_RX_CHAIN_MASK);
 	config.rx_timeout_pri_vo = __cpu_to_le32(TARGET_RX_TIMEOUT_LO_PRI);
@@ -5644,8 +5871,7 @@ static struct sk_buff *ath10k_wmi_op_gen
 	config.scan_max_pending_reqs =
 		__cpu_to_le32(TARGET_SCAN_MAX_PENDING_REQS);
 
-	config.bmiss_offload_max_vdev =
-		__cpu_to_le32(TARGET_BMISS_OFFLOAD_MAX_VDEV);
+	config.bmiss_offload_max_vdev = __cpu_to_le32(ar->bmiss_offload_max_vdev);
 
 	config.roam_offload_max_vdev =
 		__cpu_to_le32(TARGET_ROAM_OFFLOAD_MAX_VDEV);
@@ -5697,29 +5923,71 @@ static struct sk_buff *ath10k_wmi_10_1_o
 	struct wmi_resource_config_10x config = {};
 	u32 len, val;
 
-	config.num_vdevs = __cpu_to_le32(TARGET_10X_NUM_VDEVS);
-	config.num_peers = __cpu_to_le32(TARGET_10X_NUM_PEERS);
-	config.num_peer_keys = __cpu_to_le32(TARGET_10X_NUM_PEER_KEYS);
-	config.num_tids = __cpu_to_le32(TARGET_10X_NUM_TIDS);
-	config.ast_skid_limit = __cpu_to_le32(TARGET_10X_AST_SKID_LIMIT);
-	config.tx_chain_mask = __cpu_to_le32(TARGET_10X_TX_CHAIN_MASK);
-	config.rx_chain_mask = __cpu_to_le32(TARGET_10X_RX_CHAIN_MASK);
-	config.rx_timeout_pri_vo = __cpu_to_le32(TARGET_10X_RX_TIMEOUT_LO_PRI);
-	config.rx_timeout_pri_vi = __cpu_to_le32(TARGET_10X_RX_TIMEOUT_LO_PRI);
-	config.rx_timeout_pri_be = __cpu_to_le32(TARGET_10X_RX_TIMEOUT_LO_PRI);
-	config.rx_timeout_pri_bk = __cpu_to_le32(TARGET_10X_RX_TIMEOUT_HI_PRI);
 	config.rx_decap_mode = __cpu_to_le32(ar->wmi.rx_decap_mode);
-	config.scan_max_pending_reqs =
-		__cpu_to_le32(TARGET_10X_SCAN_MAX_PENDING_REQS);
+	config.num_vdevs = __cpu_to_le32(ar->max_num_vdevs);
+	config.num_peers = __cpu_to_le32(ar->max_num_peers);
+
+	ath10k_warn(ar, "10.1 wmi init: vdevs: %d  peers: %d  tid: %d\n",
+		    ar->max_num_vdevs, ar->max_num_peers, ar->num_tids);
 
-	config.bmiss_offload_max_vdev =
-		__cpu_to_le32(TARGET_10X_BMISS_OFFLOAD_MAX_VDEV);
+	config.tx_chain_mask = __cpu_to_le32(TARGET_10X_TX_CHAIN_MASK);
 
 	config.roam_offload_max_vdev =
 		__cpu_to_le32(TARGET_10X_ROAM_OFFLOAD_MAX_VDEV);
 
 	config.roam_offload_max_ap_profiles =
 		__cpu_to_le32(TARGET_10X_ROAM_OFFLOAD_MAX_AP_PROFILES);
+	config.num_peer_keys = __cpu_to_le32(TARGET_10X_NUM_PEER_KEYS);
+
+	config.bmiss_offload_max_vdev = __cpu_to_le32(ar->bmiss_offload_max_vdev);
+
+	if (test_bit(ATH10K_FW_FEATURE_WMI_10X_CT,
+		     ar->running_fw->fw_file.fw_features)) {
+		if (test_bit(ATH10K_FW_FEATURE_CT_RXSWCRYPT,
+			     ar->running_fw->fw_file.fw_features) &&
+		    ar->request_nohwcrypt) {
+			/* This will disable rx decryption in hardware, enable raw
+			 * rx mode, and native-wifi tx mode.  Requires 'CT' firmware.
+			 */
+			config.rx_decap_mode = __cpu_to_le32(ATH10K_HW_TXRX_RAW |
+							     ATH10k_USE_SW_RX_CRYPT);
+			ar->use_swcrypt = true;
+			ath10k_info(ar, "using rx swcrypt\n");
+		}
+		else if (ar->request_nohwcrypt) {
+			ath10k_err(ar, "nohwcrypt requested, but firmware does not support this feature.  Disabling swcrypt.\n");
+		}
+		config.rx_decap_mode |= __cpu_to_le32(ATH10k_USE_TXCOMPL_TXRATE);
+		/* Disable WoW in firmware, could make this module option perhaps? */
+		config.rx_decap_mode |= __cpu_to_le32(ATH10k_DISABLE_WOW);
+		config.roam_offload_max_vdev = 0; /* disable roaming */
+		config.roam_offload_max_ap_profiles = 0; /* disable roaming */
+
+		config.num_peer_keys = __cpu_to_le32(TARGET_10X_NUM_PEER_KEYS_CT);
+
+		if (ar->num_ratectrl_objs) {
+			ath10k_info(ar, "using %d firmware rate-ctrl objects\n",
+				    ar->num_ratectrl_objs);
+			config.tx_chain_mask |= __cpu_to_le32(ar->num_ratectrl_objs << 24);
+		}
+	}
+	config.num_msdu_desc = __cpu_to_le32(ar->htt.max_num_pending_tx);
+	config.ast_skid_limit = __cpu_to_le32(ar->skid_limit);
+
+	/* Firmware will crash if this is not even multiple of 8 */
+	if (WARN_ON(ar->htt.max_num_pending_tx & 0x7)) {
+		ath10k_err(ar, "tx-descriptors must be multiple of 8: %d\n",
+			   ar->htt.max_num_pending_tx);
+	}
+
+	config.num_tids = __cpu_to_le32(ar->num_tids);
+	config.rx_chain_mask = __cpu_to_le32(TARGET_10X_RX_CHAIN_MASK);
+	config.rx_timeout_pri_vo = __cpu_to_le32(TARGET_10X_RX_TIMEOUT_LO_PRI);
+	config.rx_timeout_pri_vi = __cpu_to_le32(TARGET_10X_RX_TIMEOUT_LO_PRI);
+	config.rx_timeout_pri_be = __cpu_to_le32(TARGET_10X_RX_TIMEOUT_LO_PRI);
+	config.rx_timeout_pri_bk = __cpu_to_le32(TARGET_10X_RX_TIMEOUT_HI_PRI);
+	config.scan_max_pending_reqs =
+		__cpu_to_le32(TARGET_10X_SCAN_MAX_PENDING_REQS);
 
 	config.num_mcast_groups = __cpu_to_le32(TARGET_10X_NUM_MCAST_GROUPS);
 	config.num_mcast_table_elems =
@@ -5736,7 +6004,6 @@ static struct sk_buff *ath10k_wmi_10_1_o
 
 	config.vow_config = __cpu_to_le32(TARGET_10X_VOW_CONFIG);
 
-	config.num_msdu_desc = __cpu_to_le32(TARGET_10X_NUM_MSDU_DESC);
 	config.max_frag_entries = __cpu_to_le32(TARGET_10X_MAX_FRAG_ENTRIES);
 
 	len = sizeof(*cmd) +
@@ -5762,38 +6029,81 @@ static struct sk_buff *ath10k_wmi_10_2_o
 	struct wmi_resource_config_10x config = {};
 	u32 len, val, features;
 
-	config.num_vdevs = __cpu_to_le32(TARGET_10X_NUM_VDEVS);
+	config.rx_decap_mode = __cpu_to_le32(ar->wmi.rx_decap_mode);
+
+	config.num_vdevs = __cpu_to_le32(ar->max_num_vdevs);
+	config.num_peers = __cpu_to_le32(ar->max_num_peers);
+	config.tx_chain_mask = __cpu_to_le32(TARGET_10X_TX_CHAIN_MASK);
+
+	config.roam_offload_max_vdev =
+		__cpu_to_le32(TARGET_10X_ROAM_OFFLOAD_MAX_VDEV);
+
+	config.roam_offload_max_ap_profiles =
+		__cpu_to_le32(TARGET_10X_ROAM_OFFLOAD_MAX_AP_PROFILES);
 	config.num_peer_keys = __cpu_to_le32(TARGET_10X_NUM_PEER_KEYS);
+	config.bmiss_offload_max_vdev = __cpu_to_le32(ar->bmiss_offload_max_vdev);
 
 	if (ath10k_peer_stats_enabled(ar)) {
 		config.num_peers = __cpu_to_le32(TARGET_10X_TX_STATS_NUM_PEERS);
-		config.num_tids = __cpu_to_le32(TARGET_10X_TX_STATS_NUM_TIDS);
 	} else {
 		config.num_peers = __cpu_to_le32(TARGET_10X_NUM_PEERS);
-		config.num_tids = __cpu_to_le32(TARGET_10X_NUM_TIDS);
 	}
+	config.num_tids = __cpu_to_le32(ar->num_tids);
 
-	config.ast_skid_limit = __cpu_to_le32(TARGET_10X_AST_SKID_LIMIT);
 	config.tx_chain_mask = __cpu_to_le32(TARGET_10X_TX_CHAIN_MASK);
+
+	if (test_bit(ATH10K_FW_FEATURE_WMI_10X_CT,
+		     ar->running_fw->fw_file.fw_features)) {
+		if (test_bit(ATH10K_FW_FEATURE_CT_RXSWCRYPT,
+			     ar->running_fw->fw_file.fw_features) &&
+		    ar->request_nohwcrypt) {
+			/* This will disable rx decryption in hardware, enable raw
+			 * rx mode, and native-wifi tx mode.  Requires 'CT' firmware.
+			 */
+			config.rx_decap_mode = __cpu_to_le32(ATH10K_HW_TXRX_RAW |
+							     ATH10k_USE_SW_RX_CRYPT);
+			ar->use_swcrypt = true;
+			ath10k_info(ar, "using rx swcrypt\n");
+		}
+		else if (ar->request_nohwcrypt) {
+			ath10k_err(ar, "module param nohwcrypt enabled, but firmware does not support this feature.  Disabling swcrypt.\n");
+		}
+
+		if (test_bit(ATH10K_FW_FEATURE_TXRATE_CT,
+			     ar->running_fw->fw_file.fw_features))
+			config.rx_decap_mode |= __cpu_to_le32(ATH10k_USE_TXCOMPL_TXRATE);
+
+		/* Disable WoW in firmware, could make this module option perhaps? */
+		config.rx_decap_mode |= __cpu_to_le32(ATH10k_DISABLE_WOW);
+
+		config.roam_offload_max_vdev = 0; /* disable roaming */
+		config.roam_offload_max_ap_profiles = 0; /* disable roaming */
+		config.num_peer_keys = __cpu_to_le32(TARGET_10X_NUM_PEER_KEYS_CT);
+
+		if (ar->num_ratectrl_objs) {
+			ath10k_info(ar, "using %d firmware rate-ctrl objects\n",
+				    ar->num_ratectrl_objs);
+			config.tx_chain_mask |= __cpu_to_le32(ar->num_ratectrl_objs << 24);
+		}
+	}
+	config.num_msdu_desc = __cpu_to_le32(ar->htt.max_num_pending_tx);
+	config.ast_skid_limit = __cpu_to_le32(ar->skid_limit);
+
+	/* Firmware will crash if this is not even multiple of 8 */
+	if (WARN_ON(ar->htt.max_num_pending_tx & 0x7)) {
+		ath10k_err(ar, "tx-descriptors must be multiple of 8: %d\n",
+			   ar->htt.max_num_pending_tx);
+	}
+
 	config.rx_chain_mask = __cpu_to_le32(TARGET_10X_RX_CHAIN_MASK);
 	config.rx_timeout_pri_vo = __cpu_to_le32(TARGET_10X_RX_TIMEOUT_LO_PRI);
 	config.rx_timeout_pri_vi = __cpu_to_le32(TARGET_10X_RX_TIMEOUT_LO_PRI);
 	config.rx_timeout_pri_be = __cpu_to_le32(TARGET_10X_RX_TIMEOUT_LO_PRI);
 	config.rx_timeout_pri_bk = __cpu_to_le32(TARGET_10X_RX_TIMEOUT_HI_PRI);
-	config.rx_decap_mode = __cpu_to_le32(ar->wmi.rx_decap_mode);
 
 	config.scan_max_pending_reqs =
 		__cpu_to_le32(TARGET_10X_SCAN_MAX_PENDING_REQS);
 
-	config.bmiss_offload_max_vdev =
-		__cpu_to_le32(TARGET_10X_BMISS_OFFLOAD_MAX_VDEV);
-
-	config.roam_offload_max_vdev =
-		__cpu_to_le32(TARGET_10X_ROAM_OFFLOAD_MAX_VDEV);
-
-	config.roam_offload_max_ap_profiles =
-		__cpu_to_le32(TARGET_10X_ROAM_OFFLOAD_MAX_AP_PROFILES);
-
 	config.num_mcast_groups = __cpu_to_le32(TARGET_10X_NUM_MCAST_GROUPS);
 	config.num_mcast_table_elems =
 		__cpu_to_le32(TARGET_10X_NUM_MCAST_TABLE_ELEMS);
@@ -5809,7 +6119,6 @@ static struct sk_buff *ath10k_wmi_10_2_o
 
 	config.vow_config = __cpu_to_le32(TARGET_10X_VOW_CONFIG);
 
-	config.num_msdu_desc = __cpu_to_le32(TARGET_10X_NUM_MSDU_DESC);
 	config.max_frag_entries = __cpu_to_le32(TARGET_10X_MAX_FRAG_ENTRIES);
 
 	len = sizeof(*cmd) +
@@ -5849,32 +6158,92 @@ static struct sk_buff *ath10k_wmi_10_4_o
 	struct wmi_resource_config_10_4 config = {};
 	u32 len;
 
+	config.rx_decap_mode = __cpu_to_le32(ar->wmi.rx_decap_mode);
+
 	config.num_vdevs = __cpu_to_le32(ar->max_num_vdevs);
 	config.num_peers = __cpu_to_le32(ar->max_num_peers);
+	ath10k_warn(ar, "10.4 wmi init: vdevs: %d  peers: %d  tid: %d\n",
+		    ar->max_num_vdevs, ar->max_num_peers, ar->num_tids);
+
+	config.tx_chain_mask  = __cpu_to_le32(ar->hw_params.tx_chain_mask);
+	config.rx_chain_mask  = __cpu_to_le32(ar->hw_params.rx_chain_mask);
+
+	config.roam_offload_max_vdev  =
+			__cpu_to_le32(TARGET_10_4_ROAM_OFFLOAD_MAX_VDEV);
+
+	config.roam_offload_max_ap_profiles =
+			__cpu_to_le32(TARGET_10_4_ROAM_OFFLOAD_MAX_PROFILES);
+	config.num_peer_keys  = __cpu_to_le32(TARGET_10_4_NUM_PEER_KEYS);
+	config.bmiss_offload_max_vdev = __cpu_to_le32(ar->bmiss_offload_max_vdev);
+	config.qwrap_config = __cpu_to_le32(TARGET_10_4_QWRAP_CONFIG);
+
+	if (test_bit(ATH10K_FW_FEATURE_WMI_10X_CT,
+		     ar->running_fw->fw_file.fw_features)) {
+#if 0
+		/* Enabling this kills performance, for whatever reason. */
+		skid_limit = TARGET_10X_AST_SKID_LIMIT_CT;
+#endif
+		if (test_bit(ATH10K_FW_FEATURE_CT_RXSWCRYPT,
+			     ar->running_fw->fw_file.fw_features) &&
+		    ar->request_nohwcrypt) {
+			/* This will disable rx decryption in hardware, enable raw
+			 * rx mode, and native-wifi tx mode.  Requires 'CT' firmware.
+			 */
+			config.rx_decap_mode = __cpu_to_le32(ATH10K_HW_TXRX_RAW |
+							     ATH10k_USE_SW_RX_CRYPT);
+			ar->use_swcrypt = true;
+			ath10k_info(ar, "using rx swcrypt\n");
+		}
+		else if (ar->request_nohwcrypt) {
+			ath10k_err(ar, "nohwcrypt requested, but firmware does not support this feature.  Disabling swcrypt.\n");
+		}
+
+		if (test_bit(ATH10K_FW_FEATURE_TXRATE_CT,
+			     ar->running_fw->fw_file.fw_features)) {
+			config.rx_decap_mode |= __cpu_to_le32(ATH10k_USE_TXCOMPL_TXRATE);
+			/* Must enable alloc_frag_desc_for_data_pkt for txrate support.  This eats up
+			 * 4 extra bytes per msdu descriptor.
+			 */
+			config.qwrap_config = __cpu_to_le32(1 << 16 | TARGET_10_4_QWRAP_CONFIG);
+		}
+		/* Disable WoW in firmware, could make this module option perhaps? */
+		config.rx_decap_mode |= __cpu_to_le32(ATH10k_DISABLE_WOW);
+
+		config.roam_offload_max_vdev = 0; /* disable roaming */
+		config.roam_offload_max_ap_profiles = 0; /* disable roaming */
+		/* 3 per peer is likely enough, but technically, there is room for 4
+		 * The default is 2 per peer, but that is not enough when testing
+		 * lots of station vdevs with encryption since each 'real' peer can
+		 * have 4 keys, and the self-peer has one key.
+		 */
+		config.num_peer_keys = __cpu_to_le32(3);
+
+#if 0
+		if (ar->num_ratectrl_objs) {
+			ath10k_info(ar, "using %d firmware rate-ctrl objects\n",
+				    ar->num_ratectrl_objs);
+			config.tx_chain_mask |= __cpu_to_le32(ar->num_ratectrl_objs << 24);
+		}
+#endif
+	}
+	config.num_msdu_desc = __cpu_to_le32(ar->htt.max_num_pending_tx);
+	ath10k_warn(ar, "msdu-desc: %d  skid: %d\n",
+		    ar->htt.max_num_pending_tx, ar->skid_limit);
+	config.ast_skid_limit = __cpu_to_le32(ar->skid_limit);
+
 	config.num_active_peers = __cpu_to_le32(ar->num_active_peers);
 	config.num_tids = __cpu_to_le32(ar->num_tids);
 
 	config.num_offload_peers = __cpu_to_le32(TARGET_10_4_NUM_OFFLOAD_PEERS);
 	config.num_offload_reorder_buffs =
 			__cpu_to_le32(TARGET_10_4_NUM_OFFLOAD_REORDER_BUFFS);
-	config.num_peer_keys  = __cpu_to_le32(TARGET_10_4_NUM_PEER_KEYS);
-	config.ast_skid_limit = __cpu_to_le32(TARGET_10_4_AST_SKID_LIMIT);
-	config.tx_chain_mask  = __cpu_to_le32(ar->hw_params.tx_chain_mask);
-	config.rx_chain_mask  = __cpu_to_le32(ar->hw_params.rx_chain_mask);
 
 	config.rx_timeout_pri[0] = __cpu_to_le32(TARGET_10_4_RX_TIMEOUT_LO_PRI);
 	config.rx_timeout_pri[1] = __cpu_to_le32(TARGET_10_4_RX_TIMEOUT_LO_PRI);
 	config.rx_timeout_pri[2] = __cpu_to_le32(TARGET_10_4_RX_TIMEOUT_LO_PRI);
 	config.rx_timeout_pri[3] = __cpu_to_le32(TARGET_10_4_RX_TIMEOUT_HI_PRI);
 
-	config.rx_decap_mode	    = __cpu_to_le32(ar->wmi.rx_decap_mode);
 	config.scan_max_pending_req = __cpu_to_le32(TARGET_10_4_SCAN_MAX_REQS);
-	config.bmiss_offload_max_vdev =
-			__cpu_to_le32(TARGET_10_4_BMISS_OFFLOAD_MAX_VDEV);
-	config.roam_offload_max_vdev  =
-			__cpu_to_le32(TARGET_10_4_ROAM_OFFLOAD_MAX_VDEV);
-	config.roam_offload_max_ap_profiles =
-			__cpu_to_le32(TARGET_10_4_ROAM_OFFLOAD_MAX_PROFILES);
 	config.num_mcast_groups = __cpu_to_le32(TARGET_10_4_NUM_MCAST_GROUPS);
 	config.num_mcast_table_elems =
 			__cpu_to_le32(TARGET_10_4_NUM_MCAST_TABLE_ELEMS);
@@ -5891,7 +6260,6 @@ static struct sk_buff *ath10k_wmi_10_4_o
 	config.vow_config = __cpu_to_le32(TARGET_10_4_VOW_CONFIG);
 	config.gtk_offload_max_vdev =
 			__cpu_to_le32(TARGET_10_4_GTK_OFFLOAD_MAX_VDEV);
-	config.num_msdu_desc = __cpu_to_le32(ar->htt.max_num_pending_tx);
 	config.max_frag_entries = __cpu_to_le32(TARGET_10_4_11AC_TX_MAX_FRAGS);
 	config.max_peer_ext_stats =
 			__cpu_to_le32(TARGET_10_4_MAX_PEER_EXT_STATS);
@@ -5907,7 +6275,6 @@ static struct sk_buff *ath10k_wmi_10_4_o
 			__cpu_to_le32(TARGET_10_4_THERMAL_THROTTLING_CONFIG);
 	config.atf_config = __cpu_to_le32(TARGET_10_4_ATF_CONFIG);
 	config.iphdr_pad_config = __cpu_to_le32(TARGET_10_4_IPHDR_PAD_CONFIG);
-	config.qwrap_config = __cpu_to_le32(TARGET_10_4_QWRAP_CONFIG);
 
 	len = sizeof(*cmd) +
 	      (sizeof(struct host_memory_chunk) * ar->wmi.num_mem_chunks);
@@ -6273,7 +6640,7 @@ ath10k_wmi_op_gen_vdev_start(struct ath1
 		memcpy(cmd->ssid.ssid, arg->ssid, arg->ssid_len);
 	}
 
-	ath10k_wmi_put_wmi_channel(&cmd->chan, &arg->channel);
+	ath10k_wmi_put_wmi_channel(ar, &cmd->chan, &arg->channel, arg->vdev_id);
 
 	ath10k_dbg(ar, ATH10K_DBG_WMI,
 		   "wmi vdev %s id 0x%x flags: 0x%0X, freq %d, mode %d, ch_flags: 0x%0X, max_power: %d\n",
@@ -6284,6 +6651,40 @@ ath10k_wmi_op_gen_vdev_start(struct ath1
 	return skb;
 }
 
+#ifdef CONFIG_ATH10K_DEBUGFS
+/* TODO:  Should really enable this all the time, not just when DEBUGFS is enabled. --Ben */
+/* CT firmware only:
+ * (re) start wmi keep-alive timer in firmware.  Once we start
+ * sending these, firmware will assert if it does not receive one
+ * after about 10 seconds.
+ */
+
+struct wmi_request_nop_cmd {
+	u32 nop_id; /* for debugging purposes */
+};
+
+int ath10k_wmi_request_nop(struct ath10k *ar)
+{
+	struct wmi_request_nop_cmd *cmd;
+	struct sk_buff *skb;
+
+	if (! test_bit(ATH10K_FW_FEATURE_NOP_CT,
+		       ar->running_fw->fw_file.fw_features))
+		return 0;
+
+	skb = ath10k_wmi_alloc_skb(ar, sizeof(*cmd));
+	if (!skb)
+		return -ENOMEM;
+
+	cmd = (struct wmi_request_nop_cmd *)skb->data;
+	cmd->nop_id = __cpu_to_le32(ar->debug.nop_id++);
+
+	ath10k_dbg(ar, ATH10K_DBG_WMI, "wmi request nop (id %d)\n",
+		   ar->debug.nop_id - 1);
+	return ath10k_wmi_cmd_send(ar, skb, WMI_NOP);
+}
+#endif
+
 static struct sk_buff *
 ath10k_wmi_op_gen_vdev_stop(struct ath10k *ar, u32 vdev_id)
 {
@@ -6401,8 +6802,9 @@ ath10k_wmi_op_gen_vdev_install_key(struc
 		memcpy(cmd->key_data, arg->key_data, arg->key_len);
 
 	ath10k_dbg(ar, ATH10K_DBG_WMI,
-		   "wmi vdev install key idx %d cipher %d len %d\n",
-		   arg->key_idx, arg->key_cipher, arg->key_len);
+		   "wmi vdev %d install key peer %pM idx %d cipher %d len %d flags 0x%x\n",
+		   arg->vdev_id, arg->macaddr, arg->key_idx, arg->key_cipher, arg->key_len,
+		   arg->key_flags);
 	return skb;
 }
 
@@ -6644,7 +7046,7 @@ ath10k_wmi_op_gen_scan_chan_list(struct
 		ch = &arg->channels[i];
 		ci = &cmd->chan_info[i];
 
-		ath10k_wmi_put_wmi_channel(ci, ch);
+		ath10k_wmi_put_wmi_channel(ar, ci, ch, -1);
 	}
 
 	return skb;
@@ -6655,8 +7057,51 @@ ath10k_wmi_peer_assoc_fill(struct ath10k
 			   const struct wmi_peer_assoc_complete_arg *arg)
 {
 	struct wmi_common_peer_assoc_complete_cmd *cmd = buf;
+	u32 vid = arg->vdev_id;
+	u32 ext_flags = 0;
+
+	if (test_bit(ATH10K_FW_FEATURE_CT_RATEMASK,
+		     ar->running_fw->fw_file.fw_features)) {
+		/* Add some CT firmware specific stuff */
+		vid |= (1<<31); /* ext field exists */
+		if (arg->has_rate_overrides) {
+			int i;
+			int opver = ar->running_fw->fw_file.wmi_op_version;
+			ext_flags |= PEER_ASSOC_EXT_USE_OVERRIDES;
+			ext_flags |= PEER_ASSOC_EXT_LEN_32;
+
+			ath10k_dbg(ar, ATH10K_DBG_WMI,
+				   "overrides: len %d\n", (int)(sizeof(arg->rate_overrides)));
+			for (i = 0; i<sizeof(arg->rate_overrides); i++) {
+				ath10k_dbg(ar, ATH10K_DBG_WMI, "[%i] 0x%x\n",
+					   i, arg->rate_overrides[i]);
+			}
+			if (opver == ATH10K_FW_WMI_OP_VERSION_10_4) {
+				struct wmi_10_4_peer_assoc_complete_cmd_ct *c = (void*)cmd;
+				memcpy(c->overrides.rate_overrides, arg->rate_overrides,
+				       sizeof(c->overrides.rate_overrides));
+				c->overrides.ext_flags = __cpu_to_le32(ext_flags);
+			}
+			else if ((opver == ATH10K_FW_WMI_OP_VERSION_10_2) ||
+				 (opver == ATH10K_FW_WMI_OP_VERSION_10_2_4)) {
+				struct wmi_10_2_peer_assoc_complete_cmd_ct *c = (void*)cmd;
+				memcpy(c->overrides.rate_overrides, arg->rate_overrides,
+				       sizeof(c->overrides.rate_overrides));
+				c->overrides.ext_flags = __cpu_to_le32(ext_flags);
+			}
+			else if (opver == ATH10K_FW_WMI_OP_VERSION_10_1) {
+				struct wmi_10_1_peer_assoc_complete_cmd_ct *c = (void*)cmd;
+				memcpy(c->overrides.rate_overrides, arg->rate_overrides,
+				       sizeof(c->overrides.rate_overrides));
+				c->overrides.ext_flags = __cpu_to_le32(ext_flags);
+			}
+			else {
+				WARN_ON_ONCE(1);
+			}
+		}
+	}
 
-	cmd->vdev_id            = __cpu_to_le32(arg->vdev_id);
+	cmd->vdev_id            = __cpu_to_le32(vid);
 	cmd->peer_new_assoc     = __cpu_to_le32(arg->peer_reassoc ? 0 : 1);
 	cmd->peer_associd       = __cpu_to_le32(arg->peer_aid);
 	cmd->peer_flags         = __cpu_to_le32(arg->peer_flags);
@@ -6735,7 +7180,12 @@ ath10k_wmi_peer_assoc_fill_10_4(struct a
 	struct wmi_10_4_peer_assoc_complete_cmd *cmd = buf;
 
 	ath10k_wmi_peer_assoc_fill_10_2(ar, buf, arg);
-	cmd->peer_bw_rxnss_override = 0;
+	if (arg->peer_bw_rxnss_override)
+		cmd->peer_bw_rxnss_override =
+			__cpu_to_le32((arg->peer_bw_rxnss_override - 1) |
+				      (1<<PEER_BW_RXNSS_OVERRIDE_OFFSET));
+	else
+		cmd->peer_bw_rxnss_override = 0;
 }
 
 static int
@@ -6780,7 +7230,7 @@ static struct sk_buff *
 ath10k_wmi_10_1_op_gen_peer_assoc(struct ath10k *ar,
 				  const struct wmi_peer_assoc_complete_arg *arg)
 {
-	size_t len = sizeof(struct wmi_10_1_peer_assoc_complete_cmd);
+	size_t len = sizeof(struct wmi_10_1_peer_assoc_complete_cmd_ct);
 	struct sk_buff *skb;
 	int ret;
 
@@ -6795,9 +7245,10 @@ ath10k_wmi_10_1_op_gen_peer_assoc(struct
 	ath10k_wmi_peer_assoc_fill_10_1(ar, skb->data, arg);
 
 	ath10k_dbg(ar, ATH10K_DBG_WMI,
-		   "wmi peer assoc vdev %d addr %pM (%s)\n",
+		   "wmi peer assoc vdev %d addr %pM (%s) flags 0x%x\n",
 		   arg->vdev_id, arg->addr,
-		   arg->peer_reassoc ? "reassociate" : "new");
+		   arg->peer_reassoc ? "reassociate" : "new",
+		   arg->peer_flags);
 	return skb;
 }
 
@@ -6805,7 +7256,7 @@ static struct sk_buff *
 ath10k_wmi_10_2_op_gen_peer_assoc(struct ath10k *ar,
 				  const struct wmi_peer_assoc_complete_arg *arg)
 {
-	size_t len = sizeof(struct wmi_10_2_peer_assoc_complete_cmd);
+	size_t len = sizeof(struct wmi_10_2_peer_assoc_complete_cmd_ct);
 	struct sk_buff *skb;
 	int ret;
 
@@ -6830,7 +7281,7 @@ static struct sk_buff *
 ath10k_wmi_10_4_op_gen_peer_assoc(struct ath10k *ar,
 				  const struct wmi_peer_assoc_complete_arg *arg)
 {
-	size_t len = sizeof(struct wmi_10_4_peer_assoc_complete_cmd);
+	size_t len = sizeof(struct wmi_10_4_peer_assoc_complete_cmd_ct);
 	struct sk_buff *skb;
 	int ret;
 
@@ -7857,6 +8308,33 @@ ath10k_wmi_barrier(struct ath10k *ar)
 	return 0;
 }
 
+int ath10k_wmi_pdev_set_special(struct ath10k *ar, u32 id, u32 val)
+{
+	struct wmi_pdev_set_special_cmd *cmd;
+	struct sk_buff *skb;
+
+	if (!test_bit(ATH10K_FW_FEATURE_SET_SPECIAL_CT,
+		      ar->running_fw->fw_file.fw_features)) {
+		ath10k_warn(ar, "Only CT firmware supports this method of setting thresh62_ext.\n");
+		return -ENOTSUPP;
+	}
+
+	skb = ath10k_wmi_alloc_skb(ar, sizeof(*cmd));
+	if (!skb)
+		return -ENOMEM;
+
+	cmd = (struct wmi_pdev_set_special_cmd *)skb->data;
+	memset(cmd, 0, sizeof(*cmd));
+
+	cmd->id = __cpu_to_le32(id);
+	cmd->val = __cpu_to_le32(val);
+
+	ath10k_dbg(ar, ATH10K_DBG_WMI,
+		   "wmi pdev set special id:%d val: %d\n",
+		   id, val);
+	return ath10k_wmi_cmd_send(ar, skb, WMI_PDEV_SET_SPECIAL_CMDID);
+}
+
 static const struct wmi_ops wmi_ops = {
 	.rx = ath10k_wmi_op_rx,
 	.map_svc = wmi_main_svc_map,
@@ -8140,6 +8618,7 @@ static const struct wmi_ops wmi_10_4_ops
 	.rx = ath10k_wmi_10_4_op_rx,
 	.map_svc = wmi_10_4_svc_map,
 
+	.gen_peer_assoc = ath10k_wmi_10_4_op_gen_peer_assoc,
 	.pull_fw_stats = ath10k_wmi_10_4_op_pull_fw_stats,
 	.pull_scan = ath10k_wmi_op_pull_scan_ev,
 	.pull_mgmt_rx = ath10k_wmi_10_4_op_pull_mgmt_rx_ev,
@@ -8175,7 +8654,6 @@ static const struct wmi_ops wmi_10_4_ops
 	.gen_peer_delete = ath10k_wmi_op_gen_peer_delete,
 	.gen_peer_flush = ath10k_wmi_op_gen_peer_flush,
 	.gen_peer_set_param = ath10k_wmi_op_gen_peer_set_param,
-	.gen_peer_assoc = ath10k_wmi_10_4_op_gen_peer_assoc,
 	.gen_set_psmode = ath10k_wmi_op_gen_set_psmode,
 	.gen_set_sta_ps = ath10k_wmi_op_gen_set_sta_ps,
 	.gen_set_ap_ps = ath10k_wmi_op_gen_set_ap_ps,
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/net/wireless/ath/ath10k/wmi.h linux-4.10.x/drivers/net/wireless/ath/ath10k/wmi.h
--- linux-4.10.x.ori/drivers/net/wireless/ath/ath10k/wmi.h	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/net/wireless/ath/ath10k/wmi.h	2017-05-12 08:00:57.801800000 +0200
@@ -1266,6 +1266,55 @@ enum wmi_10x_cmd_id {
 	WMI_10X_GPIO_CONFIG_CMDID,
 	WMI_10X_GPIO_OUTPUT_CMDID,
 
+	/* CT Firmware only, trying to add new WMI features w/out breaking backwards compat. */
+	/* add new CMDIDs here (out-of-order backport from 10.2) */
+	/**update a wds  (4 address ) entry. */
+	WMI_10X_PEER_UPDATE_WDS_ENTRY_CMDID,
+	/** request to start/stop keep-alive frame */
+	WMI_10X_RTT_KEEPALIVE_CMDID,
+	WMI_10X_VDEV_RATEMASK_CMDID,
+
+	/** Enable/Disable Smart Antenna */
+	WMI_10X_PDEV_SMART_ANT_ENABLE_CMDID,
+	/** Set Smart Antenna RX antenna*/
+	WMI_10X_PDEV_SMART_ANT_SET_RX_ANTENNA_CMDID,
+	/** Set Smart Antenna TX antenna*/
+	WMI_10X_PEER_SMART_ANT_SET_TX_ANTENNA_CMDID,
+	/** Set Smart Antenna TX train info */
+	WMI_10X_PEER_SMART_ANT_SET_TRAIN_INFO_CMDID,
+	/** Set SA node config options */
+	WMI_10X_PEER_SMART_ANT_SET_NODE_CONFIG_OPS_CMDID,
+	/* For fw recovery test command */
+	WMI_10X_FORCE_FW_HANG_CMDID,
+
+	/** Override the antenna switch table */
+	WMI_10X_PDEV_SET_ANTENNA_SWITCH_TABLE_CMDID,
+	/** Override the CTL table */
+	WMI_10X_PDEV_SET_CTL_TABLE_CMDID,
+	/** Override the array gain table */
+	WMI_10X_PDEV_SET_MIMOGAIN_TABLE_CMDID,
+	/** Set/Get the rate power table in OTP */
+	WMI_10X_PDEV_RATEPWR_TABLE_CMDID,
+	/** En/disable the rate power and chain mask table in FW*/
+	WMI_10X_PDEV_RATEPWR_CHAINMSK_TABLE_CMDID,
+
+	WMI_10X_PDEV_GET_INFO,
+	WMI_10X_VDEV_GET_INFO,
+	/** ATF VDEV REQUEST commands. */
+	WMI_10X_VDEV_ATF_REQUEST_CMDID,
+	/** ATF PEER REQUEST commands. */
+	WMI_10X_PEER_ATF_REQUEST_CMDID,
+
+	/** Get Thermal management params **/
+	WMI_10X_PDEV_GET_TEMPERATURE_CMDID,
+	WMI_10X_MU_CAL_START_CMDID,
+	WMI_10X_SET_LTEU_CONFIG_CMDID,
+	WMI_10X_SET_CCA_PARAMS_CMDID,
+	WMI_10X_PDEV_BSS_CHAN_INFO_REQUEST,
+
+	WMI_PDEV_SET_SPECIAL_CMDID = WMI_10X_END_CMDID - 101, /* CT only:  special hack (cts/slot/cifs/ack timers, etc) */
+	WMI_NOP = WMI_10X_END_CMDID - 100, /* CT only:  wmi transport keep-alive, basically */
+
 	WMI_10X_PDEV_UTF_CMDID = WMI_10X_END_CMDID - 1,
 };
 
@@ -1709,6 +1758,7 @@ enum wmi_10_4_event_id {
 	WMI_10_4_PDEV_NFCAL_POWER_ALL_CHANNELS_EVENTID,
 	WMI_10_4_PDEV_BSS_CHAN_INFO_EVENTID,
 	WMI_10_4_MU_REPORT_EVENTID,
+	WMI_10_4_CSI_MESG_EVENTID = WMI_10_4_END_EVENTID - 2, /* CT Specific event ID */
 	WMI_10_4_PDEV_UTF_EVENTID = WMI_10_4_END_EVENTID - 1,
 };
 
@@ -1728,8 +1778,10 @@ enum wmi_phy_mode {
 	MODE_11AC_VHT20_2G = 11,
 	MODE_11AC_VHT40_2G = 12,
 	MODE_11AC_VHT80_2G = 13,
-	MODE_UNKNOWN    = 14,
-	MODE_MAX        = 14
+	MODE_11AC_VHT80_80 = 14,
+	MODE_11AC_VHT160 = 15,
+	MODE_UNKNOWN    = 16,
+	MODE_MAX        = 16
 };
 
 static inline const char *ath10k_wmi_phymode_str(enum wmi_phy_mode mode)
@@ -1757,6 +1809,10 @@ static inline const char *ath10k_wmi_phy
 		return "11ac-vht40";
 	case MODE_11AC_VHT80:
 		return "11ac-vht80";
+	case MODE_11AC_VHT160:
+		return "11ac-vht160";
+	case MODE_11AC_VHT80_80:
+		return "11ac-vht80+80";
 	case MODE_11AC_VHT20_2G:
 		return "11ac-vht20-2g";
 	case MODE_11AC_VHT40_2G:
@@ -1811,6 +1867,7 @@ struct wmi_channel {
 struct wmi_channel_arg {
 	u32 freq;
 	u32 band_center_freq1;
+	u32 band_center_freq2;
 	bool passive;
 	bool allow_ibss;
 	bool allow_ht;
@@ -1838,6 +1895,13 @@ enum wmi_channel_change_cause {
 #define WMI_CHAN_FLAG_DFS            (1 << 10)
 #define WMI_CHAN_FLAG_ALLOW_HT       (1 << 11)
 #define WMI_CHAN_FLAG_ALLOW_VHT      (1 << 12)
+#define WMI_CHAN_FLAG_HALF           (1 << 13)
+#define WMI_CHAN_FLAG_QUARTER        (1 << 14)
+#define WMI_CHAN_FLAG_NO_RESERVE_CH  (1 << 31) /* CT firmware only, do not reserve channel.
+						* Takes 200+ms to grab reservation when starting
+						* vdev, and I think it is handled elsewhere by the
+						* stack and/or supplicant anyway. --Ben
+						*/
 
 /* Indicate reason for channel switch */
 #define WMI_CHANNEL_CHANGE_CAUSE_CSA (1 << 13)
@@ -1875,9 +1939,18 @@ enum wmi_channel_change_cause {
 #define WMI_VHT_CAP_MAX_MPDU_LEN_MASK            0x00000003
 #define WMI_VHT_CAP_RX_LDPC                      0x00000010
 #define WMI_VHT_CAP_SGI_80MHZ                    0x00000020
+#define WMI_VHT_CAP_SGI_160MHZ                   0x00000040
 #define WMI_VHT_CAP_TX_STBC                      0x00000080
 #define WMI_VHT_CAP_RX_STBC_MASK                 0x00000300
 #define WMI_VHT_CAP_RX_STBC_MASK_SHIFT           8
+#define WMI_VHT_CAP_SU_BFER                      0x00000800
+#define WMI_VHT_CAP_SU_BFEE                      0x00001000
+#define WMI_VHT_CAP_MAX_CS_ANT_MASK              0x0000E000
+#define WMI_VHT_CAP_MAX_CS_ANT_MASK_SHIFT        13
+#define WMI_VHT_CAP_MAX_SND_DIM_MASK             0x00070000
+#define WMI_VHT_CAP_MAX_SND_DIM_MASK_SHIFT       16
+#define WMI_VHT_CAP_MU_BFER                      0x00080000
+#define WMI_VHT_CAP_MU_BFEE                      0x00100000
 #define WMI_VHT_CAP_MAX_AMPDU_LEN_EXP            0x03800000
 #define WMI_VHT_CAP_MAX_AMPDU_LEN_EXP_SHIFT      23
 #define WMI_VHT_CAP_RX_FIXED_ANT                 0x10000000
@@ -1926,6 +1999,8 @@ enum {
 	REGDMN_MODE_11AC_VHT40PLUS   = 0x40000, /* 5Ghz, VHT40 + channels */
 	REGDMN_MODE_11AC_VHT40MINUS  = 0x80000, /* 5Ghz  VHT40 - channels */
 	REGDMN_MODE_11AC_VHT80       = 0x100000, /* 5Ghz, VHT80 channels */
+	REGDMN_MODE_11AC_VHT160      = 0x200000,     /* 5Ghz, VHT160 channels */
+	REGDMN_MODE_11AC_VHT80_80    = 0x400000,     /* 5Ghz, VHT80+80 channels */
 	REGDMN_MODE_ALL              = 0xffffffff
 };
 
@@ -2120,7 +2195,12 @@ struct wmi_resource_config {
 	 *   tx with a reduced number of chains if no clients are associated.
 	 *   This configuration parameter specifies the nominal chain-mask that
 	 *   should be used when not operating with a reduced set of tx chains.
+	 *
+	 *  NOTE:  Stored as uint8 internally in firmware, so I am going to
+	 *  steal some high bits to allow configuring the number of RAM
+	 *  rate-ctrl objects for CT firmware. --Ben
 	 */
+	/* mask >> 24:  rate-ctrl-objs-in-RAM */
 	__le32 tx_chain_mask;
 
 	/*
@@ -2156,7 +2236,28 @@ struct wmi_resource_config {
 	 *   MAC can decap to RAW (no decap), native wifi or Ethernet types
 	 *   THis setting also determines the default TX behavior, however TX
 	 *   behavior can be modified on a per VAP basis during VAP init
+	 *
+	 *  NOTE:  Stealing some of this field for flags, only usable when
+	 *         running "CT" firmware.
+	 *   first byte: rx_decap_mode
+	 *   second byte:  reserved
+	 */
+	#define ATH10K_RX_DECAP_MODE_MASK 0xff
+	/*  Use software rx crypt.  This disables rx checksumming
+	 *  and may turn off some firmware/hardware optimizations for
+	 *  normal use case.  BUT, it does allow us to run multiple
+	 *  stations connected to the same AP.  This flag causes
+	 *  rx encapsulation to be 'raw', and tx mode to be native-wifi.
+	 *  You should probably not enable this unless you need to
+	 *  connect multiple stations to same AP.
+	 */
+	#define ATH10k_USE_SW_RX_CRYPT    0x10000
+	/* Ask firmware to include tx-rate in completion messages. */
+	#define ATH10k_USE_TXCOMPL_TXRATE 0x20000
+	/* Disable Wake-on-Wireless logic.  Saves some RAM, for those
+	 * that do not need WoW.
 	 */
+	#define ATH10k_DISABLE_WOW        0x40000
 	__le32 rx_decap_mode;
 
 	/* what is the maximum number of scan requests that can be queued */
@@ -2959,6 +3060,14 @@ struct wmi_start_scan_arg {
  * Allow the driver to have influence over that. */
 #define WMI_SCAN_CONTINUE_ON_ERROR 0x80
 
+/* CT Firmware only, v15 and higher */
+/* Don't advertise any HT support in scan req */
+#define WMI_SCAN_DISABLE_HT    0x40000000
+#define WMI_SCAN_DISABLE_HT_4  0x00400000 /* 10.4 stole the bits I was using in 10.1. --Ben */
+/* Don't advertise any VHT support in scan req */
+#define WMI_SCAN_DISABLE_VHT   0x80000000
+#define WMI_SCAN_DISABLE_VHT_4 0x00800000
+
 /* WMI_SCAN_CLASS_MASK must be the same value as IEEE80211_SCAN_CLASS_MASK */
 #define WMI_SCAN_CLASS_MASK 0xFF000000
 
@@ -3025,6 +3134,7 @@ enum wmi_scan_completion_reason {
 	WMI_SCAN_REASON_PREEMPTED,
 	WMI_SCAN_REASON_TIMEDOUT,
 	WMI_SCAN_REASON_INTERNAL_FAILURE,
+	WMI_SCAN_REASON_BUSY = 13, /* A_EBUSY, CT firmware at least. */
 	WMI_SCAN_REASON_MAX,
 };
 
@@ -4129,6 +4239,49 @@ struct wmi_pdev_stats_peer {
 	__le32 dummy;
 } __packed;
 
+
+#define REG_DUMP_NONE         0
+#define MAC_FILTER_ADDR_L32   1
+#define MAC_FILTER_ADDR_U16   2
+#define DCU_SLOT_TIME         3
+#define PHY_BB_MODE_SELECT    4
+#define PCU_BSSID_L32         5
+#define PCU_BSSID_U16         6
+#define PCU_BSSID2_L32        7
+#define PCU_BSSID2_U16        8
+#define PCU_STA_ADDR_U16      9
+#define MAC_DMA_CFG          10
+#define MAC_DMA_TXCFG        11
+#define PCU_STA_ADDR_L32     12
+#define PCU_RXFILTER         13
+#define PHY_BB_GEN_CONTROLS  14
+#define DMA_IMR              15
+#define DMA_TXRX_IMR         16
+#define SW_POWERMODE         17
+#define SW_CHAINMASK         18 /* tx is high 16 bits, rx is low 16 bits */
+#define SW_OPMODE            19
+#define SW_RXFILTER          20
+#define SW_LONG_RETRIES      21 /* DATA packet retries */
+#define SW_SHORT_RETRIES     22 /* RTS packet retries */
+#define ADC_TEMP             23 /* ADC Temperature readings. */
+
+
+#define REG_DUMP_COUNT       23 /* max number of registers to dump at once. */
+
+struct ath10k_reg_dump_pair {
+	__le32 reg_id;
+	__le32 reg_val;
+};
+
+struct ath10k_reg_dump {
+	__le16 count;
+	__le16 unused;
+	struct ath10k_reg_dump_pair regpair[REG_DUMP_COUNT];
+};
+
+/* These values are a bitmap, but 10.1.x (at least) firmware will not properly
+ * handle multiple values OR'd together.
+ */
 enum wmi_stats_id {
 	WMI_STAT_PEER = BIT(0),
 	WMI_STAT_AP = BIT(1),
@@ -4136,6 +4289,7 @@ enum wmi_stats_id {
 	WMI_STAT_VDEV = BIT(3),
 	WMI_STAT_BCNFLT = BIT(4),
 	WMI_STAT_VDEV_RATE = BIT(5),
+	WMI_REQUEST_REGISTER_DUMP = BIT(7), /* 0x80, CT Firmware only, request register dump. */
 };
 
 enum wmi_10_4_stats_id {
@@ -5783,6 +5937,7 @@ enum wmi_peer_chwidth {
 	WMI_PEER_CHWIDTH_20MHZ = 0,
 	WMI_PEER_CHWIDTH_40MHZ = 1,
 	WMI_PEER_CHWIDTH_80MHZ = 2,
+	WMI_PEER_CHWIDTH_160MHZ = 3,
 };
 
 enum wmi_peer_param {
@@ -5792,6 +5947,15 @@ enum wmi_peer_param {
 	WMI_PEER_CHAN_WIDTH = 0x4,
 	WMI_PEER_NSS        = 0x5,
 	WMI_PEER_USE_4ADDR  = 0x6,
+	/** Enable extended peer stats */
+	WMI_PEER_EXT_STATS_ENABLE = 0x7,
+	/*Use FIXED Pwr */
+	WMI_PEER_USE_FIXED_PWR = 0x8,
+	/* Set peer fixed rate */
+	WMI_PEER_PARAM_FIXED_RATE = 0x9,
+	/* Whitelist peer TIDs */
+	WMI_PEER_SET_MU_WHITELIST =0x10,
+
 	WMI_PEER_DUMMY_VAR  = 0xff, /* dummy parameter for STA PS workaround */
 };
 
@@ -5873,6 +6037,7 @@ struct wmi_peer_flags_map {
 	u32 bw80;
 	u32 vht_2g;
 	u32 pmf;
+	u32 bw160;
 };
 
 enum wmi_peer_flags {
@@ -5892,6 +6057,7 @@ enum wmi_peer_flags {
 	WMI_PEER_80MHZ = 0x04000000,
 	WMI_PEER_VHT_2G = 0x08000000,
 	WMI_PEER_PMF = 0x10000000,
+	WMI_PEER_160MHZ = 0x20000000
 };
 
 enum wmi_10x_peer_flags {
@@ -5909,6 +6075,7 @@ enum wmi_10x_peer_flags {
 	WMI_10X_PEER_SPATIAL_MUX = 0x00200000,
 	WMI_10X_PEER_VHT = 0x02000000,
 	WMI_10X_PEER_80MHZ = 0x04000000,
+	WMI_10X_PEER_160MHZ = 0x20000000
 };
 
 enum wmi_10_2_peer_flags {
@@ -5928,6 +6095,7 @@ enum wmi_10_2_peer_flags {
 	WMI_10_2_PEER_80MHZ = 0x04000000,
 	WMI_10_2_PEER_VHT_2G = 0x08000000,
 	WMI_10_2_PEER_PMF = 0x10000000,
+	WMI_10_2_PEER_160MHZ = 0x20000000
 };
 
 /*
@@ -5954,6 +6122,8 @@ enum wmi_10_2_peer_flags {
 
 struct wmi_common_peer_assoc_complete_cmd {
 	struct wmi_mac_addr peer_macaddr;
+#define WMI_ASSOC_FLG_EXT (1<<31) /* Extended info is defined, CT firmware ver 15+ only,
+				   * packed into vdev_id */
 	__le32 vdev_id;
 	__le32 peer_new_assoc; /* 1=assoc, 0=reassoc */
 	__le32 peer_associd; /* 16 LSBs */
@@ -5984,6 +6154,26 @@ struct wmi_10_1_peer_assoc_complete_cmd
 	struct wmi_common_peer_assoc_complete_cmd cmd;
 } __packed;
 
+struct wmi_ct_assoc_overrides {
+	/* CT firmware ver 15+ only */
+#define PEER_ASSOC_EXT_USE_OVERRIDES (1<<0)
+#define PEER_ASSOC_EXT_IGNORE_MCS_4_NSS_MASK (1<<1)
+#define PEER_ASSOC_EXT_LEN_32        (1<<2) /* Has 32-override bytes */
+	__le32 ext_flags;
+
+#define RATE_OVERRIDES_COUNT 32
+	/* Space for 256 rates.  If rate_overrides_set is 1,
+	 * any rate NOT specified in rate_overrides will be
+	 * disabled.
+	 */
+	u8 rate_overrides[RATE_OVERRIDES_COUNT];
+} __packed;
+
+struct wmi_10_1_peer_assoc_complete_cmd_ct {
+	struct wmi_10_1_peer_assoc_complete_cmd cmd;
+	struct wmi_ct_assoc_overrides overrides;
+} __packed;
+
 #define WMI_PEER_ASSOC_INFO0_MAX_MCS_IDX_LSB 0
 #define WMI_PEER_ASSOC_INFO0_MAX_MCS_IDX_MASK 0x0f
 #define WMI_PEER_ASSOC_INFO0_MAX_NSS_LSB 4
@@ -5994,11 +6184,22 @@ struct wmi_10_2_peer_assoc_complete_cmd
 	__le32 info0; /* WMI_PEER_ASSOC_INFO0_ */
 } __packed;
 
+struct wmi_10_2_peer_assoc_complete_cmd_ct {
+	struct wmi_10_2_peer_assoc_complete_cmd cmd;
+	struct wmi_ct_assoc_overrides overrides;
+} __packed;
+
+#define PEER_BW_RXNSS_OVERRIDE_OFFSET  31
 struct wmi_10_4_peer_assoc_complete_cmd {
 	struct wmi_10_2_peer_assoc_complete_cmd cmd;
 	__le32 peer_bw_rxnss_override;
 } __packed;
 
+struct wmi_10_4_peer_assoc_complete_cmd_ct {
+	struct wmi_10_4_peer_assoc_complete_cmd cmd;
+	struct wmi_ct_assoc_overrides overrides;
+} __packed;
+
 struct wmi_peer_assoc_complete_arg {
 	u8 addr[ETH_ALEN];
 	u32 vdev_id;
@@ -6017,6 +6218,11 @@ struct wmi_peer_assoc_complete_arg {
 	u32 peer_vht_caps;
 	enum wmi_phy_mode peer_phymode;
 	struct wmi_vht_rate_set_arg peer_vht_rates;
+	u32 peer_bw_rxnss_override;
+
+	/* CT firmware only (beta-15 and higher ) */
+	bool has_rate_overrides;
+	u8 rate_overrides[RATE_OVERRIDES_COUNT];
 };
 
 struct wmi_peer_add_wds_entry_cmd {
@@ -6270,6 +6476,7 @@ struct wmi_vdev_start_ev_arg {
 
 struct wmi_peer_kick_ev_arg {
 	const u8 *mac_addr;
+	u16 unused_hi; /* top 16 bits of 47-32, used to pass info back to host by CT firmware */
 };
 
 struct wmi_swba_ev_arg {
@@ -6316,6 +6523,12 @@ struct wmi_svc_rdy_ev_arg {
 	const struct wlan_host_mem_req *mem_reqs[WMI_MAX_MEM_REQS];
 };
 
+struct ath10k_fw_dbglog_report {
+	__le32 dropped_count;
+	__le32 messages[];
+} __packed;
+
+
 struct wmi_rdy_ev_arg {
 	__le32 sw_version;
 	__le32 abi_version;
@@ -6349,6 +6562,61 @@ struct wmi_pdev_bss_chan_info_event {
 	__le32 reserved;
 } __packed;
 
+/* CT firmware only, and only builds after June 26, 2015 */
+struct wmi_pdev_set_special_cmd {
+#define SET_SPECIAL_ID_ACK_CTS 0 /* set ack-cts-timeout register */
+#define SET_SPECIAL_ID_SLOT    1 /* set slot-duration register */
+#define SET_SPECIAL_ID_SIFS    2 /* set sifs-duration register */
+#define SET_SPECIAL_ID_THRESH62_EXT 3 /* set PHY_BB_EXT_CHAN_PWR_THR_1_THRESH62_EXT register field...
+				       * increasing this to 42 helps at least
+				       * one customer pass regulatory testing, for instance.  This is
+				       * same register/field as: PHY_BB_EXT_CHAN_PWR_THR_1_THR_CCA_EXT40
+				       * this is an 8-bit value.
+				       */
+#define SET_SPECIAL_ID_NOISE_FLR_THRESH 4 /* Set some CCA related values in the eeprom struct.  Over-rides existing values.
+					   * BE CAREFUL!  This could put your system out of spec.  It can also put it in
+					   * spec when the eeprom values are dodgy.
+                                           * See debug.c, ath10k_read_ct_special for details.
+                                           */
+#define SET_SPECIAL_ID_IBSS_AMSDU_OK    5 /* As far as I can tell, AR988X hardware is incapable of properly doing
+					   * IBSS  AMSDU frames.  It zeros out the BSSID, which causes the receiving
+					   * stack (Linux, at least) to drop the frame because of bssid-mismatch.
+					   * But, maybe someone has a received that can handle this one way or another
+					   * and wants the additional speed given by AMSDU.  So, use this setting to
+					   * allow AMSDU with IBSS:  val of 1 enables, val of 0 disables.
+					   */
+#define SET_SPECIAL_ID_MAX_TXPOWER      6 /* Set the maximum allowed tx-power.  This over-rules any other
+                                           * power settings.
+                                           */
+#define SET_SPECIAL_ID_RC_MAX_PER_THR   7 /* Set the 'g_rc_rate_max_per_thr' value.  Default is 50.  Higher may make
+                                           * the rate-ctrl logic work better in crouded RF environments.  Tune with
+                                           * care.  I'm not sure than anything above 100 is meaningful.
+                                           */
+#define SET_SPECIAL_ID_STA_TXBW_MASK    8 /* Set the bandwidths that station vdevs can transmit on:
+					   * 0:  all, 0x1: 20Mhz, 0x2 40Mhz, 0x4 80Mhz
+                                           */
+#define SET_SPECIAL_ID_PDEV_XRETRY_TH   9 /* Set the threshold for resetting phy due to failed retries, U16 */
+#define SET_SPECIAL_ID_RIFS_ENABLE    0xA /* Enable(1)/disable(0) RIFS.  Disabled by default. */
+#define SET_SPECIAL_ID_WMI_WD         0xB /* Set the watchdog trigger count, 0 means disable */
+#define SET_SPECIAL_ID_PSHACK         0xC /* flag 0x1:  ignore PS sleep message from STA
+                                           * flag 0x2:  mark mcast as 'data-is-buffered' regardless.
+                                           */
+#define SET_SPECIAL_ID_CSI            0xD /* 0 == disable, else enable reporting CSI data.  10.4 FW only at this time. */
+
+#define CT_CCA_TYPE_MIN0 0
+#define CT_CCA_TYPE_MIN1 1
+#define CT_CCA_TYPE_MIN2 2
+#define CT_CCA_TYPE_NOISE_FLOOR 3
+#define CT_CCA_TYPE_EN_MINCCAPWR 4
+#define CT_CCA_TYPE_MAX 4 /* change as more types are added */
+
+    __le32 id;
+    __le32 val;
+    __le32 extra1;
+    __le32 extra2;
+};
+int ath10k_wmi_pdev_set_special(struct ath10k *ar, u32 id, u32 val);
+
 /* WOW structures */
 enum wmi_wow_wakeup_event {
 	WOW_BMISS_EVENT = 0,
@@ -6599,8 +6867,10 @@ void ath10k_wmi_put_start_scan_common(st
 				      const struct wmi_start_scan_arg *arg);
 void ath10k_wmi_set_wmm_param(struct wmi_wmm_params *params,
 			      const struct wmi_wmm_params_arg *arg);
-void ath10k_wmi_put_wmi_channel(struct wmi_channel *ch,
-				const struct wmi_channel_arg *arg);
+void ath10k_wmi_put_wmi_channel(struct ath10k *ar,
+				struct wmi_channel *ch,
+				const struct wmi_channel_arg *arg,
+				u32 vdev_id);
 int ath10k_wmi_start_scan_verify(const struct wmi_start_scan_arg *arg);
 
 int ath10k_wmi_event_scan(struct ath10k *ar, struct sk_buff *skb);
@@ -6608,6 +6878,7 @@ int ath10k_wmi_event_mgmt_rx(struct ath1
 void ath10k_wmi_event_chan_info(struct ath10k *ar, struct sk_buff *skb);
 void ath10k_wmi_event_echo(struct ath10k *ar, struct sk_buff *skb);
 int ath10k_wmi_event_debug_mesg(struct ath10k *ar, struct sk_buff *skb);
+int ath10k_wmi_event_csi_mesg(struct ath10k *ar, struct sk_buff *skb);
 void ath10k_wmi_event_update_stats(struct ath10k *ar, struct sk_buff *skb);
 void ath10k_wmi_event_vdev_start_resp(struct ath10k *ar, struct sk_buff *skb);
 void ath10k_wmi_event_vdev_stopped(struct ath10k *ar, struct sk_buff *skb);
@@ -6663,4 +6934,12 @@ int ath10k_wmi_op_get_vdev_subtype(struc
 				   enum wmi_vdev_subtype subtype);
 int ath10k_wmi_barrier(struct ath10k *ar);
 
+#ifdef CONFIG_ATH10K_DEBUGFS
+/* TODO:  Should really enable this all the time, not just when DEBUGFS is enabled. --Ben */
+/* CT Firmware only */
+int ath10k_wmi_request_nop(struct ath10k *ar);
+#else
+#warning Please enable ATH10K-DEBUGFS kernel option for optimal support for CT firmware.
+#endif
+
 #endif /* _WMI_H_ */
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/net/wireless/ath/ath10k/wmi-tlv.c linux-4.10.x/drivers/net/wireless/ath/ath10k/wmi-tlv.c
--- linux-4.10.x.ori/drivers/net/wireless/ath/ath10k/wmi-tlv.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/net/wireless/ath/ath10k/wmi-tlv.c	2017-05-12 08:00:57.801800000 +0200
@@ -1694,7 +1694,7 @@ ath10k_wmi_tlv_op_gen_vdev_start(struct
 	tlv->tag = __cpu_to_le16(WMI_TLV_TAG_STRUCT_CHANNEL);
 	tlv->len = __cpu_to_le16(sizeof(*ch));
 	ch = (void *)tlv->value;
-	ath10k_wmi_put_wmi_channel(ch, &arg->channel);
+	ath10k_wmi_put_wmi_channel(ar, ch, &arg->channel, arg->vdev_id);
 
 	ptr += sizeof(*tlv);
 	ptr += sizeof(*ch);
@@ -2330,7 +2330,7 @@ ath10k_wmi_tlv_op_gen_scan_chan_list(str
 		tlv->len = __cpu_to_le16(sizeof(*ci));
 		ci = (void *)tlv->value;
 
-		ath10k_wmi_put_wmi_channel(ci, ch);
+		ath10k_wmi_put_wmi_channel(ar, ci, ch, 0xFFFFFFFF);
 
 		chans += sizeof(*tlv);
 		chans += sizeof(*ci);
@@ -2864,7 +2864,7 @@ ath10k_wmi_tlv_op_gen_tdls_peer_update(s
 		tlv->tag = __cpu_to_le16(WMI_TLV_TAG_STRUCT_CHANNEL);
 		tlv->len = __cpu_to_le16(sizeof(*chan));
 		chan = (void *)tlv->value;
-		ath10k_wmi_put_wmi_channel(chan, &chan_arg[i]);
+		ath10k_wmi_put_wmi_channel(ar, chan, &chan_arg[i], arg->vdev_id);
 
 		ptr += sizeof(*tlv);
 		ptr += sizeof(*chan);
@@ -3631,6 +3631,7 @@ static const struct wmi_peer_flags_map w
 	.vht = WMI_TLV_PEER_VHT,
 	.bw80 = WMI_TLV_PEER_80MHZ,
 	.pmf = WMI_TLV_PEER_PMF,
+	.bw160 = WMI_TLV_PEER_160MHZ,
 };
 
 /************/
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/net/wireless/ath/ath10k/wmi-tlv.h linux-4.10.x/drivers/net/wireless/ath/ath10k/wmi-tlv.h
--- linux-4.10.x.ori/drivers/net/wireless/ath/ath10k/wmi-tlv.h	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/net/wireless/ath/ath10k/wmi-tlv.h	2017-05-12 08:00:57.801800000 +0200
@@ -543,6 +543,7 @@ enum wmi_tlv_peer_flags {
 	WMI_TLV_PEER_VHT = 0x02000000,
 	WMI_TLV_PEER_80MHZ = 0x04000000,
 	WMI_TLV_PEER_PMF = 0x08000000,
+        WMI_TLV_PEER_160MHZ = 0x20000000,
 };
 
 enum wmi_tlv_tag {
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/net/wireless/intel/iwlwifi/iwl-6000.c linux-4.10.x/drivers/net/wireless/intel/iwlwifi/iwl-6000.c
--- linux-4.10.x.ori/drivers/net/wireless/intel/iwlwifi/iwl-6000.c	2017-04-21 13:47:09.278670000 +0200
+++ linux-4.10.x/drivers/net/wireless/intel/iwlwifi/iwl-6000.c	2017-04-20 13:49:21.051877000 +0200
@@ -368,7 +368,7 @@ const struct iwl_cfg iwl6000_3agn_cfg =
 	.led_mode = IWL_LED_BLINK,
 };
 
-MODULE_FIRMWARE(IWL6000_MODULE_FIRMWARE(IWL6000_UCODE_API_MAX));
+MODULE_FIRMWARE(IWL6000_MODULE_FIRMWARE(IWL6000_UCODE_API_MIN));
 MODULE_FIRMWARE(IWL6050_MODULE_FIRMWARE(IWL6050_UCODE_API_MAX));
 MODULE_FIRMWARE(IWL6005_MODULE_FIRMWARE(IWL6000G2_UCODE_API_MAX));
 MODULE_FIRMWARE(IWL6030_MODULE_FIRMWARE(IWL6000G2_UCODE_API_MAX));
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/net/wireless/intel/iwlwifi/iwl-7000.c linux-4.10.x/drivers/net/wireless/intel/iwlwifi/iwl-7000.c
--- linux-4.10.x.ori/drivers/net/wireless/intel/iwlwifi/iwl-7000.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/net/wireless/intel/iwlwifi/iwl-7000.c	2017-04-20 14:36:12.062836000 +0200
@@ -73,7 +73,9 @@
 /* Highest firmware API version supported */
 #define IWL7260_UCODE_API_MAX	17
 #define IWL7265_UCODE_API_MAX	17
+#define IWL7265D_UCODE_API_USE	22
 #define IWL7265D_UCODE_API_MAX	26
+#define IWL3168_UCODE_API_USE	22
 #define IWL3168_UCODE_API_MAX	26
 
 /* Lowest firmware API version supported */
@@ -379,6 +381,6 @@ const struct iwl_cfg iwl7265d_n_cfg = {
 
 MODULE_FIRMWARE(IWL7260_MODULE_FIRMWARE(IWL7260_UCODE_API_MAX));
 MODULE_FIRMWARE(IWL3160_MODULE_FIRMWARE(IWL7260_UCODE_API_MAX));
-MODULE_FIRMWARE(IWL3168_MODULE_FIRMWARE(IWL3168_UCODE_API_MAX));
+MODULE_FIRMWARE(IWL3168_MODULE_FIRMWARE(IWL3168_UCODE_API_USE));
 MODULE_FIRMWARE(IWL7265_MODULE_FIRMWARE(IWL7265_UCODE_API_MAX));
-MODULE_FIRMWARE(IWL7265D_MODULE_FIRMWARE(IWL7265D_UCODE_API_MAX));
+MODULE_FIRMWARE(IWL7265D_MODULE_FIRMWARE(IWL7265D_UCODE_API_USE));
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/net/wireless/intel/iwlwifi/iwl-8000.c linux-4.10.x/drivers/net/wireless/intel/iwlwifi/iwl-8000.c
--- linux-4.10.x.ori/drivers/net/wireless/intel/iwlwifi/iwl-8000.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/net/wireless/intel/iwlwifi/iwl-8000.c	2017-08-31 11:35:19.213639000 +0200
@@ -70,7 +70,9 @@
 #include "iwl-agn-hw.h"
 
 /* Highest firmware API version supported */
+#define IWL8000_UCODE_API_USE	21
 #define IWL8000_UCODE_API_MAX	26
+#define IWL8265_UCODE_API_USE	22
 #define IWL8265_UCODE_API_MAX	26
 
 /* Lowest firmware API version supported */
@@ -276,5 +278,5 @@ const struct iwl_cfg iwl4165_2ac_sdio_cf
 	.max_vht_ampdu_exponent = MAX_VHT_AMPDU_EXPONENT_8260_SDIO,
 };
 
-MODULE_FIRMWARE(IWL8000_MODULE_FIRMWARE(IWL8000_UCODE_API_MAX));
-MODULE_FIRMWARE(IWL8265_MODULE_FIRMWARE(IWL8265_UCODE_API_MAX));
+MODULE_FIRMWARE(IWL8000_MODULE_FIRMWARE(IWL8000_UCODE_API_USE));
+MODULE_FIRMWARE(IWL8265_MODULE_FIRMWARE(IWL8265_UCODE_API_USE));
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/net/wireless/marvell/mwifiex/11n_aggr.c linux-4.10.x/drivers/net/wireless/marvell/mwifiex/11n_aggr.c
--- linux-4.10.x.ori/drivers/net/wireless/marvell/mwifiex/11n_aggr.c	2017-06-12 15:36:29.913019000 +0200
+++ linux-4.10.x/drivers/net/wireless/marvell/mwifiex/11n_aggr.c	2017-06-12 15:36:29.913019000 +0200
@@ -200,8 +200,14 @@ mwifiex_11n_aggregate_pkt(struct mwifiex
 
 	do {
 		/* Check if AMSDU can accommodate this MSDU */
+		/* gottwald@igel.com try to improve stability of driver
+		 * https://www.reddit.com/r/SurfaceLinux/comments/5sw38n/surfac_book_4_keyboard_ubuntu_1610/dditqwb/ */
+#if 1
+		if (skb_tailroom(skb_aggr) < (skb_src->len + LLC_SNAP_LEN))
+#else
 		if ((skb_aggr->len + skb_src->len + LLC_SNAP_LEN) >
 		    adapter->tx_buf_size)
+#endif
 			break;
 
 		skb_src = skb_dequeue(&pra_list->skb_head);
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/net/wireless/marvell/mwifiex/cfg80211.c linux-4.10.x/drivers/net/wireless/marvell/mwifiex/cfg80211.c
--- linux-4.10.x.ori/drivers/net/wireless/marvell/mwifiex/cfg80211.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/net/wireless/marvell/mwifiex/cfg80211.c	2017-04-24 15:37:43.477350000 +0200
@@ -416,7 +416,10 @@ mwifiex_cfg80211_set_power_mgmt(struct w
 		mwifiex_dbg(priv->adapter, INFO,
 			    "info: ignore timeout value for IEEE Power Save\n");
 
-	ps_mode = enabled;
+	/* gottwald@igel.com disable ps_mode due to stability problems see also
+	 * https://bugzilla.kernel.org/show_bug.cgi?id=109681 */
+
+	ps_mode = 0;
 
 	return mwifiex_drv_set_power(priv, &ps_mode);
 }
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/net/wireless/marvell/mwifiex/pcie.c linux-4.10.x/drivers/net/wireless/marvell/mwifiex/pcie.c
--- linux-4.10.x.ori/drivers/net/wireless/marvell/mwifiex/pcie.c	2017-04-21 13:47:09.278670000 +0200
+++ linux-4.10.x/drivers/net/wireless/marvell/mwifiex/pcie.c	2017-04-24 15:37:43.477350000 +0200
@@ -1692,6 +1692,14 @@ static int mwifiex_pcie_process_cmd_comp
 
 	pkt_len = *((__le16 *)skb->data);
 	rx_len = le16_to_cpu(pkt_len);
+	/* gottwald@igel.com improve stability of driver see also
+	 * https://bugzilla.kernel.org/show_bug.cgi?id=109681 */
+	if(rx_len == 0) {
+		mwifiex_map_pci_memory(adapter, skb, MWIFIEX_UPLD_SIZE,
+			PCI_DMA_FROMDEVICE);
+		return 0;
+	}
+
 	skb_put(skb, MWIFIEX_UPLD_SIZE - skb->len);
 	skb_trim(skb, rx_len);
 	skb_pull(skb, INTF_HEADER_LEN);
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/net/wireless/marvell/mwifiex/sta_cmd.c linux-4.10.x/drivers/net/wireless/marvell/mwifiex/sta_cmd.c
--- linux-4.10.x.ori/drivers/net/wireless/marvell/mwifiex/sta_cmd.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/net/wireless/marvell/mwifiex/sta_cmd.c	2017-04-24 15:37:43.477350000 +0200
@@ -2232,7 +2232,13 @@ int mwifiex_sta_init_cmd(struct mwifiex_
 	struct mwifiex_adapter *adapter = priv->adapter;
 	int ret;
 	struct mwifiex_ds_11n_amsdu_aggr_ctrl amsdu_aggr_ctrl;
+	/* gottwald@igel.com improve stability of driver see also
+	 * https://bugzilla.kernel.org/show_bug.cgi?id=109681 */
+#if 0
 	struct mwifiex_ds_auto_ds auto_ds;
+#else
+	struct mwifiex_ds_auto_ds;
+#endif
 	enum state_11d_t state_11d;
 	struct mwifiex_ds_11n_tx_cfg tx_cfg;
 	u8 sdio_sp_rx_aggr_enable;
@@ -2303,6 +2309,10 @@ int mwifiex_sta_init_cmd(struct mwifiex_
 		if (ret)
 			return -1;
 
+		/* gottwald@igel.com improve stability of driver see also
+		 * https://bugzilla.kernel.org/show_bug.cgi?id=109681 */
+#if 0
+
 		if (priv->bss_type != MWIFIEX_BSS_TYPE_UAP) {
 			/* Enable IEEE PS by default */
 			priv->adapter->ps_mode = MWIFIEX_802_11_POWER_MODE_PSP;
@@ -2313,6 +2323,7 @@ int mwifiex_sta_init_cmd(struct mwifiex_
 			if (ret)
 				return -1;
 		}
+#endif
 
 		if (drcs) {
 			adapter->drcs_enabled = true;
@@ -2359,6 +2370,9 @@ int mwifiex_sta_init_cmd(struct mwifiex_
 	if (ret)
 		return -1;
 
+		/* gottwald@igel.com improve stability of driver see also
+		 * https://bugzilla.kernel.org/show_bug.cgi?id=109681 */
+#if 0
 	if (!disable_auto_ds &&
 	    first_sta && priv->adapter->iface_type != MWIFIEX_USB &&
 	    priv->bss_type != MWIFIEX_BSS_TYPE_UAP) {
@@ -2371,6 +2385,7 @@ int mwifiex_sta_init_cmd(struct mwifiex_
 		if (ret)
 			return -1;
 	}
+#endif
 
 	if (priv->bss_type != MWIFIEX_BSS_TYPE_UAP) {
 		/* Send cmd to FW to enable/disable 11D function */
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/net/wireless/ralink/rt2x00/rt2800lib.c linux-4.10.x/drivers/net/wireless/ralink/rt2x00/rt2800lib.c
--- linux-4.10.x.ori/drivers/net/wireless/ralink/rt2x00/rt2800lib.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/net/wireless/ralink/rt2x00/rt2800lib.c	2017-04-10 11:27:25.836919000 +0200
@@ -4114,8 +4114,9 @@ static void rt2800_config_txpower_rt28xx
 	 * maximum tx power. For other devices we take user power_level into
 	 * consideration on rt2800_compensate_txpower().
 	 */
+	/* hamburg@igel.com fix for control tx power */
 	delta += rt2800_get_txpower_reg_delta(rt2x00dev, power_level,
-					      chan->max_power);
+					      chan->max_reg_power);
 
 	/*
 	 * BBP_R1 controls TX power for all rates, it allow to set the following
@@ -4131,6 +4132,10 @@ static void rt2800_config_txpower_rt28xx
 	} else if (delta <= -6) {
 		power_ctrl = 1;
 		delta += 6;
+	/* hamburg@igel.com fix for control tx power */
+	} else if (delta > 0) {
+		power_ctrl = 3;
+		delta -= 6;
 	} else {
 		power_ctrl = 0;
 	}
@@ -4701,7 +4706,12 @@ static int rt2800_init_registers(struct
 	rt2800_register_write(rt2x00dev, TX_TIMEOUT_CFG, reg);
 
 	rt2800_register_read(rt2x00dev, MAX_LEN_CFG, &reg);
-	rt2x00_set_field32(&reg, MAX_LEN_CFG_MAX_MPDU, AGGREGATION_SIZE);
+	/* hamburg@igel.com fix for frame aggregation with one antenna */
+	if (rt2x00dev->default_ant.tx_chain_num < 2) {
+		rt2x00_set_field32(&reg, MAX_LEN_CFG_MAX_MPDU, DATA_FRAME_SIZE);
+	} else {
+		rt2x00_set_field32(&reg, MAX_LEN_CFG_MAX_MPDU, AGGREGATION_SIZE);
+	}
 	if (rt2x00_rt_rev_gte(rt2x00dev, RT2872, REV_RT2872E) ||
 	    rt2x00_rt(rt2x00dev, RT2883) ||
 	    rt2x00_rt_rev_lt(rt2x00dev, RT3070, REV_RT3070E))
@@ -7045,6 +7055,7 @@ static int rt2800_init_eeprom(struct rt2
 	u16 value;
 	u16 eeprom;
 	u16 rf;
+	int n;
 
 	/*
 	 * Read EEPROM word for configuration.
@@ -7097,10 +7108,17 @@ static int rt2800_init_eeprom(struct rt2
 	/*
 	 * Identify default antenna configuration.
 	 */
-	rt2x00dev->default_ant.tx_chain_num =
-	    rt2x00_get_field16(eeprom, EEPROM_NIC_CONF0_TXPATH);
-	rt2x00dev->default_ant.rx_chain_num =
-	    rt2x00_get_field16(eeprom, EEPROM_NIC_CONF0_RXPATH);
+	/* hamburg@igel.com adapted for using with one antenna */
+	if ((n = rt2800_get_chain_number(rt2x00dev)) > 0) {
+		/* set chain number from the module parameter */
+		rt2x00dev->default_ant.tx_chain_num = n;
+		rt2x00dev->default_ant.rx_chain_num = n;
+	} else {
+		rt2x00dev->default_ant.tx_chain_num =
+		    rt2x00_get_field16(eeprom, EEPROM_NIC_CONF0_TXPATH);
+		rt2x00dev->default_ant.rx_chain_num =
+		    rt2x00_get_field16(eeprom, EEPROM_NIC_CONF0_RXPATH);
+	}
 
 	rt2800_eeprom_read(rt2x00dev, EEPROM_NIC_CONF1, &eeprom);
 
@@ -7473,11 +7491,14 @@ static int rt2800_probe_hw_mode(struct r
 	 * Initialize all hw fields.
 	 */
 	ieee80211_hw_set(rt2x00dev->hw, REPORTS_TX_ACK_STATUS);
-	ieee80211_hw_set(rt2x00dev->hw, AMPDU_AGGREGATION);
 	ieee80211_hw_set(rt2x00dev->hw, PS_NULLFUNC_STACK);
 	ieee80211_hw_set(rt2x00dev->hw, SIGNAL_DBM);
 	ieee80211_hw_set(rt2x00dev->hw, SUPPORTS_PS);
 
+	/* hamburg@igel.com fix for AMPDU with one antenna */
+	if (rt2x00dev->default_ant.tx_chain_num > 1)
+		ieee80211_hw_set(rt2x00dev->hw, AMPDU_AGGREGATION);
+
 	/*
 	 * Don't set IEEE80211_HW_HOST_BROADCAST_PS_BUFFERING for USB devices
 	 * unless we are capable of sending the buffered frames out after the
@@ -7574,10 +7595,17 @@ static int rt2800_probe_hw_mode(struct r
 	/*
 	 * Initialize HT information.
 	 */
-	if (!rt2x00_rf(rt2x00dev, RF2020))
-		spec->ht.ht_supported = true;
-	else
+	/* hamburg@igel.com adapted for using with one antenna */
+	if (!rt2x00_rf(rt2x00dev, RF2020)) {
+		if (rt2800_ht_disabled(rt2x00dev)) {
+			spec->ht.ht_supported = false;
+			rt2x00_info(rt2x00dev, "HT is disabled.\n");
+		} else {
+			spec->ht.ht_supported = true;
+		}
+	} else {
 		spec->ht.ht_supported = false;
+	}
 
 	spec->ht.cap =
 	    IEEE80211_HT_CAP_SUP_WIDTH_20_40 |
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/net/wireless/ralink/rt2x00/rt2800lib.h linux-4.10.x/drivers/net/wireless/ralink/rt2x00/rt2800lib.h
--- linux-4.10.x.ori/drivers/net/wireless/ralink/rt2x00/rt2800lib.h	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/net/wireless/ralink/rt2x00/rt2800lib.h	2017-04-10 11:27:25.836919000 +0200
@@ -48,6 +48,9 @@ struct rt2800_ops {
 				  const u8 *data, const size_t len);
 	int (*drv_init_registers)(struct rt2x00_dev *rt2x00dev);
 	__le32 *(*drv_get_txwi)(struct queue_entry *entry);
+	/* hamburg@igel.com adapted for using with one antenna */
+	bool (*ht_disabled)(struct rt2x00_dev *rt2x00dev);
+	int (*get_chain_number)(struct rt2x00_dev *rt2x00dev);
 };
 
 static inline void rt2800_register_read(struct rt2x00_dev *rt2x00dev,
@@ -129,6 +132,28 @@ static inline bool rt2800_hwcrypt_disabl
 	return rt2800ops->hwcrypt_disabled(rt2x00dev);
 }
 
+/* hamburg@igel.com adapted for using with one antenna */
+
+static inline bool rt2800_ht_disabled(struct rt2x00_dev *rt2x00dev)
+{
+	const struct rt2800_ops *rt2800ops = rt2x00dev->ops->drv;
+	if (NULL == rt2800ops->ht_disabled) {
+		return false;
+	}	
+	return rt2800ops->ht_disabled(rt2x00dev);
+}	
+
+/* hamburg@igel.com adapted for using with one antenna */
+
+static inline int rt2800_get_chain_number(struct rt2x00_dev *rt2x00dev)
+{
+	const struct rt2800_ops *rt2800ops = rt2x00dev->ops->drv;
+	if (NULL == rt2800ops->get_chain_number) {
+		return -1;
+	}
+	return rt2800ops->get_chain_number(rt2x00dev);
+}
+
 static inline int rt2800_drv_write_firmware(struct rt2x00_dev *rt2x00dev,
 					    const u8 *data, const size_t len)
 {
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/net/wireless/ralink/rt2x00/rt2800usb.c linux-4.10.x/drivers/net/wireless/ralink/rt2x00/rt2800usb.c
--- linux-4.10.x.ori/drivers/net/wireless/ralink/rt2x00/rt2800usb.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/net/wireless/ralink/rt2x00/rt2800usb.c	2017-04-10 11:27:25.836919000 +0200
@@ -51,6 +51,28 @@ static bool rt2800usb_hwcrypt_disabled(s
 	return modparam_nohwcrypt;
 }
 
+/* hamburg@igel.com adapted for using with one antenna */
+
+static bool modparam_noht;
+module_param_named(noht, modparam_noht, bool, S_IRUGO);
+MODULE_PARM_DESC(noht, "Disable HT capabilities.");
+
+static bool rt2800usb_ht_disabled(struct rt2x00_dev *rt2x00dev)
+{
+	return modparam_noht;
+}	
+
+/* hamburg@igel.com adapted for using with one antenna */
+
+static int modparam_chain_num = -1;
+module_param_named(chain_num, modparam_chain_num, int, S_IRUGO);
+MODULE_PARM_DESC(chain_num, "Set RX/TX chain number.");
+
+static int rt2800usb_modparam_chain_num(struct rt2x00_dev *rt2x00dev)
+{
+	return modparam_chain_num;
+}
+
 /*
  * Queue handlers.
  */
@@ -860,6 +882,9 @@ static const struct rt2800_ops rt2800usb
 	.drv_write_firmware	= rt2800usb_write_firmware,
 	.drv_init_registers	= rt2800usb_init_registers,
 	.drv_get_txwi		= rt2800usb_get_txwi,
+	/* hamburg@igel.com adapted for using with one antenna */
+	.ht_disabled		= rt2800usb_ht_disabled,
+	.get_chain_number	= rt2800usb_modparam_chain_num,
 };
 
 static const struct rt2x00lib_ops rt2800usb_rt2x00_ops = {
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/nvme/host/pci.c linux-4.10.x/drivers/nvme/host/pci.c
--- linux-4.10.x.ori/drivers/nvme/host/pci.c	2017-07-26 08:43:46.546116000 +0200
+++ linux-4.10.x/drivers/nvme/host/pci.c	2017-07-26 08:43:46.546116000 +0200
@@ -2297,6 +2297,10 @@ static const struct pci_device_id nvme_i
 		.driver_data = NVME_QUIRK_DELAY_BEFORE_CHK_RDY, },
 	{ PCI_DEVICE_CLASS(PCI_CLASS_STORAGE_EXPRESS, 0xffffff) },
 	{ PCI_DEVICE(PCI_VENDOR_ID_APPLE, 0x2001) },
+	/* gottwald@igel.com Patch from 
+	 * https://gist.github.com/roadrunner2/1289542a748d9a104e7baec6a92f9cd7
+	 * to get nvme running on MacBooks from 2016 */
+	{ PCI_DEVICE(PCI_VENDOR_ID_APPLE, 0x2003) },
 	{ 0, }
 };
 MODULE_DEVICE_TABLE(pci, nvme_id_table);
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/pci/pcie/aer/aerdrv.c linux-4.10.x/drivers/pci/pcie/aer/aerdrv.c
--- linux-4.10.x.ori/drivers/pci/pcie/aer/aerdrv.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/pci/pcie/aer/aerdrv.c	2017-04-10 11:27:25.836919000 +0200
@@ -55,7 +55,12 @@ static struct pcie_port_service_driver a
 	.reset_link	= aer_root_reset,
 };
 
-static int pcie_aer_disable;
+/* gottwald@igel.com disable PCI advanced error reporting because it is spaming
+ * the syslog with unnecessary messages see also
+ * http://marc.info/?l=linux-pci&m=145140470807043
+ * for details */
+
+static int pcie_aer_disable = 1;
 
 void pci_no_aer(void)
 {
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/pci/pcie/aspm.c linux-4.10.x/drivers/pci/pcie/aspm.c
--- linux-4.10.x.ori/drivers/pci/pcie/aspm.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/pci/pcie/aspm.c	2017-04-10 11:27:25.836919000 +0200
@@ -796,6 +796,26 @@ void pci_disable_link_state(struct pci_d
 }
 EXPORT_SYMBOL(pci_disable_link_state);
 
+/* gottwald@igel.com leave clear_aspm as it is, remove cause problems with 
+ * Tuxedo laptop (network with r8168 not working) */
+void pcie_clear_aspm(struct pci_bus *bus)
+{
+	struct pci_dev *child;
+
+	if (aspm_force)
+		return;
+
+	/*
+	 * Clear any ASPM setup that the firmware has carried out on this bus
+	 */
+	list_for_each_entry(child, &bus->devices, bus_list) {
+		__pci_disable_link_state(child, PCIE_LINK_STATE_L0S |
+					 PCIE_LINK_STATE_L1 |
+					 PCIE_LINK_STATE_CLKPM,
+					 false);
+	}
+}
+
 static int pcie_aspm_set_policy(const char *val, struct kernel_param *kp)
 {
 	int i;
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/pci/pci-sysfs.c linux-4.10.x/drivers/pci/pci-sysfs.c
--- linux-4.10.x.ori/drivers/pci/pci-sysfs.c	2017-09-21 16:13:04.121880000 +0200
+++ linux-4.10.x/drivers/pci/pci-sysfs.c	2017-09-21 16:13:04.121880000 +0200
@@ -719,6 +719,10 @@ static ssize_t pci_read_config(struct fi
 	return count;
 }
 
+/* lang@igel.de: we do not want to be able
+   to change the pci config space via sysfs */
+#ifdef ALLOW_PCI_WRITE_CONFIG_SPACE
+
 static ssize_t pci_write_config(struct file *filp, struct kobject *kobj,
 				struct bin_attribute *bin_attr, char *buf,
 				loff_t off, size_t count)
@@ -782,6 +786,7 @@ static ssize_t pci_write_config(struct f
 
 	return count;
 }
+#endif
 
 static ssize_t read_vpd_attr(struct file *filp, struct kobject *kobj,
 			     struct bin_attribute *bin_attr, char *buf,
@@ -1304,7 +1309,11 @@ static struct bin_attribute pci_config_a
 	},
 	.size = PCI_CFG_SPACE_SIZE,
 	.read = pci_read_config,
+	/* lang@igel.de: we do not want to be able
+	   to change the pci config space via sysfs */
+#ifdef ALLOW_PCI_WRITE_CONFIG_SPACE
 	.write = pci_write_config,
+#endif
 };
 
 static struct bin_attribute pcie_config_attr = {
@@ -1314,7 +1323,11 @@ static struct bin_attribute pcie_config_
 	},
 	.size = PCI_CFG_SPACE_EXP_SIZE,
 	.read = pci_read_config,
+	/* lang@igel.de: we do not want to be able
+	   to change the pci config space via sysfs */
+#ifdef ALLOW_PCI_WRITE_CONFIG_SPACE
 	.write = pci_write_config,
+#endif
 };
 
 static ssize_t reset_store(struct device *dev, struct device_attribute *attr,
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/pci/quirks.c linux-4.10.x/drivers/pci/quirks.c
--- linux-4.10.x.ori/drivers/pci/quirks.c	2017-07-26 08:43:46.546116000 +0200
+++ linux-4.10.x/drivers/pci/quirks.c	2017-07-26 08:43:46.546116000 +0200
@@ -2192,6 +2192,31 @@ DECLARE_PCI_FIXUP_FINAL(PCI_VENDOR_ID_AT
 		quirk_blacklist_vpd);
 DECLARE_PCI_FIXUP_FINAL(PCI_VENDOR_ID_QLOGIC, 0x2261, quirk_blacklist_vpd);
 
+/* lang@igel.de: the realtek VPD area should not be accessable via sysfs */
+static void quirk_r8169_disable_vpd(struct pci_dev *dev)
+{
+	/* lang@igel.de: release VPD structure */
+	if ((dev->device == 0x8167) ||
+	    (dev->device == 0x8168) ||
+	    (dev->device == 0x8169)) {
+		if (dev->vpd) {
+			dev_info(&dev->dev,
+				"Removing Realtek r8169 VPD access\n");
+			pci_vpd_release(dev);
+			dev->vpd = NULL;
+		}
+	}
+}
+DECLARE_PCI_FIXUP_FINAL(PCI_VENDOR_ID_REALTEK,
+			0x8167,
+			quirk_r8169_disable_vpd);
+DECLARE_PCI_FIXUP_FINAL(PCI_VENDOR_ID_REALTEK,
+			0x8168,
+			quirk_r8169_disable_vpd);
+DECLARE_PCI_FIXUP_FINAL(PCI_VENDOR_ID_REALTEK,
+			0x8169,
+			quirk_r8169_disable_vpd);
+
 /*
  * For Broadcom 5706, 5708, 5709 rev. A nics, any read beyond the
  * VPD end tag will hang the device.  This problem was initially
@@ -3507,7 +3532,8 @@ static void quirk_apple_wait_for_thunder
 		    || (nhi->device != PCI_DEVICE_ID_INTEL_LIGHT_RIDGE &&
 			nhi->device != PCI_DEVICE_ID_INTEL_CACTUS_RIDGE_4C &&
 			nhi->device != PCI_DEVICE_ID_INTEL_FALCON_RIDGE_2C_NHI &&
-			nhi->device != PCI_DEVICE_ID_INTEL_FALCON_RIDGE_4C_NHI)
+			nhi->device != PCI_DEVICE_ID_INTEL_FALCON_RIDGE_4C_NHI &&
+			nhi->device != PCI_DEVICE_ID_INTEL_ALPINE_RIDGE_C_4C_NHI)
 		    || nhi->class != PCI_CLASS_SYSTEM_OTHER << 8)
 		goto out;
 	dev_info(&dev->dev, "quirk: waiting for thunderbolt to reestablish PCI tunnels...\n");
@@ -3528,6 +3554,9 @@ DECLARE_PCI_FIXUP_RESUME_EARLY(PCI_VENDO
 DECLARE_PCI_FIXUP_RESUME_EARLY(PCI_VENDOR_ID_INTEL,
 			       PCI_DEVICE_ID_INTEL_FALCON_RIDGE_4C_BRIDGE,
 			       quirk_apple_wait_for_thunderbolt);
+DECLARE_PCI_FIXUP_RESUME_EARLY(PCI_VENDOR_ID_INTEL,
+			       PCI_DEVICE_ID_INTEL_ALPINE_RIDGE_C_4C_BRIDGE,
+			       quirk_apple_wait_for_thunderbolt);
 #endif
 
 static void pci_do_fixups(struct pci_dev *dev, struct pci_fixup *f,
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/platform/x86/apple-gmux.c linux-4.10.x/drivers/platform/x86/apple-gmux.c
--- linux-4.10.x.ori/drivers/platform/x86/apple-gmux.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/platform/x86/apple-gmux.c	2017-06-21 11:26:54.470509000 +0200
@@ -586,6 +586,7 @@ static int gmux_resume(struct device *de
 
 static struct pci_dev *gmux_get_io_pdev(void)
 {
+	struct pci_dev *igp = NULL, *dgp = NULL;
 	struct pci_dev *pdev = NULL;
 
 	while ((pdev = pci_get_class(PCI_CLASS_DISPLAY_VGA << 8, pdev))) {
@@ -595,10 +596,18 @@ static struct pci_dev *gmux_get_io_pdev(
 		if (!(cmd & PCI_COMMAND_IO))
 			continue;
 
-		return pdev;
+		if (pdev->bus && pdev->bus->number > 0 && !dgp)
+			dgp = pci_dev_get(pdev);
+		else if (pdev->bus && pdev->bus->number == 0 && !igp)
+			igp = pci_dev_get(pdev);
 	}
 
-	return NULL;
+	if (dgp && !igp)
+		pr_warn("Found only discrete GPU %s, integrated GPU is hidden,"
+				" unable to protect backlight behind VGA IO",
+				pci_name(dgp));
+	pci_dev_put(dgp);
+	return igp;
 }
 
 static int gmux_probe(struct pnp_dev *pnp, const struct pnp_device_id *id)
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/platform/x86/ideapad-laptop.c linux-4.10.x/drivers/platform/x86/ideapad-laptop.c
--- linux-4.10.x.ori/drivers/platform/x86/ideapad-laptop.c	2017-08-31 08:18:50.846242000 +0200
+++ linux-4.10.x/drivers/platform/x86/ideapad-laptop.c	2017-09-20 12:52:35.473048000 +0200
@@ -99,6 +99,10 @@ struct ideapad_private {
 	const char *fnesc_guid;
 };
 
+static bool no_hw_rfkill;
+module_param(no_hw_rfkill, bool, 0444);
+MODULE_PARM_DESC(no_hw_rfkill, "Disable usage of hardware rfkill switch.");
+
 static bool no_bt_rfkill;
 module_param(no_bt_rfkill, bool, 0444);
 MODULE_PARM_DESC(no_bt_rfkill, "No rfkill for bluetooth.");
@@ -872,13 +876,6 @@ static const struct dmi_system_id no_hw_
 		},
 	},
 	{
-		.ident = "Lenovo ideapad Y700-15ACZ",
-		.matches = {
-			DMI_MATCH(DMI_SYS_VENDOR, "LENOVO"),
-			DMI_MATCH(DMI_PRODUCT_VERSION, "Lenovo ideapad Y700-15ACZ"),
-		},
-	},
-	{
 		.ident = "Lenovo V310-14IKB",
 		.matches = {
 			DMI_MATCH(DMI_SYS_VENDOR, "LENOVO"),
@@ -900,6 +897,20 @@ static const struct dmi_system_id no_hw_
 		},
 	},
 	{
+		.ident = "Lenovo V310-15ISK",
+		.matches = {
+			DMI_MATCH(DMI_SYS_VENDOR, "LENOVO"),
+			DMI_MATCH(DMI_PRODUCT_VERSION, "Lenovo V310-15ISK"),
+		},
+	},
+	{
+		.ident = "Lenovo V510-15IKB",
+		.matches = {
+			DMI_MATCH(DMI_SYS_VENDOR, "LENOVO"),
+			DMI_MATCH(DMI_PRODUCT_VERSION, "Lenovo V510-15IKB"),
+		},
+	},
+	{
 		.ident = "Lenovo ideapad 300-15IBR",
 		.matches = {
 			DMI_MATCH(DMI_SYS_VENDOR, "LENOVO"),
@@ -935,6 +946,13 @@ static const struct dmi_system_id no_hw_
 		},
 	},
 	{
+		.ident = "Lenovo ideapad 310-15IKB",
+		.matches = {
+			DMI_MATCH(DMI_SYS_VENDOR, "LENOVO"),
+			DMI_MATCH(DMI_PRODUCT_VERSION, "Lenovo ideapad 310-15IKB"),
+		},
+	},
+	{
 		.ident = "Lenovo ideapad 310-15ISK",
 		.matches = {
 			DMI_MATCH(DMI_SYS_VENDOR, "LENOVO"),
@@ -949,6 +967,13 @@ static const struct dmi_system_id no_hw_
 		},
 	},
 	{
+		.ident = "Lenovo ideapad Y700-15ACZ",
+		.matches = {
+			DMI_MATCH(DMI_SYS_VENDOR, "LENOVO"),
+			DMI_MATCH(DMI_PRODUCT_VERSION, "Lenovo ideapad Y700-15ACZ"),
+		},
+	},
+	{
 		.ident = "Lenovo ideapad Y700-15ISK",
 		.matches = {
 			DMI_MATCH(DMI_SYS_VENDOR, "LENOVO"),
@@ -970,6 +995,20 @@ static const struct dmi_system_id no_hw_
 		},
 	},
 	{
+		.ident = "Lenovo Legion Y520-15IKBN",
+		.matches = {
+			DMI_MATCH(DMI_SYS_VENDOR, "LENOVO"),
+			DMI_MATCH(DMI_PRODUCT_VERSION, "Lenovo Y520-15IKBN"),
+		},
+	},
+	{
+		.ident = "Lenovo Legion Y720-15IKBN",
+		.matches = {
+			DMI_MATCH(DMI_SYS_VENDOR, "LENOVO"),
+			DMI_MATCH(DMI_PRODUCT_VERSION, "Lenovo Y720-15IKBN"),
+		},
+	},
+	{
 		.ident = "Lenovo Yoga 2 11 / 13 / Pro",
 		.matches = {
 			DMI_MATCH(DMI_SYS_VENDOR, "LENOVO"),
@@ -1050,7 +1089,11 @@ static int ideapad_acpi_add(struct platf
 	priv->cfg = cfg;
 	priv->adev = adev;
 	priv->platform_device = pdev;
-	priv->has_hw_rfkill_switch = !dmi_check_system(no_hw_rfkill_list);
+	if (no_hw_rfkill) {
+		priv->has_hw_rfkill_switch = 0;
+	} else {
+		priv->has_hw_rfkill_switch = !dmi_check_system(no_hw_rfkill_list);
+	}
 
 	ret = ideapad_sysfs_init(priv);
 	if (ret)
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/ssb/b43_pci_bridge.c linux-4.10.x/drivers/ssb/b43_pci_bridge.c
--- linux-4.10.x.ori/drivers/ssb/b43_pci_bridge.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/ssb/b43_pci_bridge.c	2017-04-10 11:27:25.836919000 +0200
@@ -21,9 +21,11 @@ static const struct pci_device_id b43_pc
 	{ PCI_DEVICE(PCI_VENDOR_ID_BROADCOM, 0x4301) },
 	{ PCI_DEVICE(PCI_VENDOR_ID_BROADCOM, 0x4306) },
 	{ PCI_DEVICE(PCI_VENDOR_ID_BROADCOM, 0x4307) },
+	/* gobbo@igel.com support of Broadcom bcm943224hms WLAN Adapter in our UDC2 
 	{ PCI_DEVICE(PCI_VENDOR_ID_BROADCOM, 0x4311) },
 	{ PCI_DEVICE(PCI_VENDOR_ID_BROADCOM, 0x4312) },
 	{ PCI_DEVICE(PCI_VENDOR_ID_BROADCOM, 0x4315) },
+	*/
 	{ PCI_DEVICE(PCI_VENDOR_ID_BROADCOM, 0x4318) },
 	{ PCI_DEVICE(PCI_VENDOR_ID_BCM_GVC,  0x4318) },
 	{ PCI_DEVICE(PCI_VENDOR_ID_BROADCOM, 0x4319) },
@@ -33,10 +35,12 @@ static const struct pci_device_id b43_pc
 	{ PCI_DEVICE(PCI_VENDOR_ID_BROADCOM, 43222) },
 	{ PCI_DEVICE(PCI_VENDOR_ID_BROADCOM, 0x4324) },
 	{ PCI_DEVICE(PCI_VENDOR_ID_BROADCOM, 0x4325) },
+	/* gobbo@igel.com support of Broadcom bcm943224hms WLAN Adapter in our UDC2 
 	{ PCI_DEVICE(PCI_VENDOR_ID_BROADCOM, 0x4328) },
 	{ PCI_DEVICE(PCI_VENDOR_ID_BROADCOM, 0x4329) },
 	{ PCI_DEVICE(PCI_VENDOR_ID_BROADCOM, 0x432b) },
 	{ PCI_DEVICE(PCI_VENDOR_ID_BROADCOM, 0x432c) },
+	*/
 	{ PCI_DEVICE(PCI_VENDOR_ID_BROADCOM, 0x4350) },
 	{ PCI_DEVICE(PCI_VENDOR_ID_BROADCOM, 0x4351) },
 	{ 0, },
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/thunderbolt/nhi.c linux-4.10.x/drivers/thunderbolt/nhi.c
--- linux-4.10.x.ori/drivers/thunderbolt/nhi.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/thunderbolt/nhi.c	2017-06-21 11:26:54.470509000 +0200
@@ -660,6 +660,12 @@ static struct pci_device_id nhi_ids[] =
 		.device = PCI_DEVICE_ID_INTEL_FALCON_RIDGE_4C_NHI,
 		.subvendor = PCI_ANY_ID, .subdevice = PCI_ANY_ID,
 	},
+	{
+		.class = PCI_CLASS_SYSTEM_OTHER << 8, .class_mask = ~0,
+		.vendor = PCI_VENDOR_ID_INTEL,
+		.device = PCI_DEVICE_ID_INTEL_ALPINE_RIDGE_C_4C_NHI,
+		.subvendor = PCI_ANY_ID, .subdevice = PCI_ANY_ID,
+	},
 	{ 0,}
 };
 
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/thunderbolt/switch.c linux-4.10.x/drivers/thunderbolt/switch.c
--- linux-4.10.x.ori/drivers/thunderbolt/switch.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/thunderbolt/switch.c	2017-06-21 11:26:54.470509000 +0200
@@ -374,7 +374,8 @@ struct tb_switch *tb_switch_alloc(struct
 	    sw->config.device_id != PCI_DEVICE_ID_INTEL_CACTUS_RIDGE_4C &&
 	    sw->config.device_id != PCI_DEVICE_ID_INTEL_PORT_RIDGE &&
 	    sw->config.device_id != PCI_DEVICE_ID_INTEL_FALCON_RIDGE_2C_BRIDGE &&
-	    sw->config.device_id != PCI_DEVICE_ID_INTEL_FALCON_RIDGE_4C_BRIDGE)
+	    sw->config.device_id != PCI_DEVICE_ID_INTEL_FALCON_RIDGE_4C_BRIDGE &&
+	    sw->config.device_id != PCI_DEVICE_ID_INTEL_ALPINE_RIDGE_C_4C_BRIDGE)
 		tb_sw_warn(sw, "unsupported switch device id %#x\n",
 			   sw->config.device_id);
 
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/tty/serial/8250/8250_dw.c linux-4.10.x/drivers/tty/serial/8250/8250_dw.c
--- linux-4.10.x.ori/drivers/tty/serial/8250/8250_dw.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/tty/serial/8250/8250_dw.c	2017-06-29 13:55:59.065859000 +0200
@@ -320,7 +320,8 @@ static void dw8250_quirks(struct uart_po
 
 		id = acpi_match_device(p->dev->driver->acpi_match_table,
 				       p->dev);
-		if (id && !strcmp(id->id, "APMC0D08")) {
+		if (id && (!strcmp(id->id, "APMC0D08") ||
+			!strcmp(id->id, "80860F0A"))) {
 			p->iotype = UPIO_MEM32;
 			p->regshift = 2;
 			p->serial_in = dw8250_serial_in32;
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/tty/serial/8250/8250_pci.c linux-4.10.x/drivers/tty/serial/8250/8250_pci.c
--- linux-4.10.x.ori/drivers/tty/serial/8250/8250_pci.c	2017-04-21 13:47:09.278670000 +0200
+++ linux-4.10.x/drivers/tty/serial/8250/8250_pci.c	2017-04-21 13:47:09.278670000 +0200
@@ -3746,6 +3746,338 @@ static const struct pci_device_id blackl
 };
 
 /*
+ * lechner@igel.de, 07.08.09
+ * this list is copied from the perle_serial driver
+ * blacklist perle cards here and handle them with perle_serial driver
+ */
+
+/* PCI PNP Vendor and Device IDs */
+#define PCI_VENDOR_ID_PLX					0x10b5
+#define PCI_DEVICE_ID_PLX_9030				0x9030
+
+#define PCI_VENDOR_ID_P_EXAR	   			0x13A8
+#define PCI_DEVICE_ID_EXAR_158     			0x158
+#define PCI_DEVICE_ID_EXAR_154     			0x154
+#define PCI_DEVICE_ID_EXAR_152     			0x152
+
+// duplicate of Vender and Device ID for Exar as sub-vendor and sub-device IDs
+#define PCI_SUBVENDOR_ID_P_EXAR	 	  		0x13A8
+#define PCI_SUBDEVICE_ID_EXAR_158     		0x158
+#define PCI_SUBDEVICE_ID_EXAR_154     		0x154
+#define PCI_SUBDEVICE_ID_EXAR_152     		0x152
+
+#define PCI_VENDOR_ID_PERLE					0x155F
+#define PCI_DEVICE_ID_PERLE_SPEED1LE		0xB001
+#define PCI_DEVICE_ID_PERLE_SPEED2LE		0xB002
+#define PCI_DEVICE_ID_PERLE_SPEED4LE		0xB004
+#define PCI_DEVICE_ID_PERLE_SPEED8LE		0xB008
+
+#define PCI_DEVICE_ID_PERLE_SPEED1LEV2		0xB011
+#define PCI_DEVICE_ID_PERLE_SPEED2LEV2		0xB012
+#define PCI_DEVICE_ID_PERLE_SPEED1LE1P		0xB013
+#define PCI_DEVICE_ID_PERLE_SPEED2LE1P		0xB014
+#define PCI_DEVICE_ID_PERLE_SPEEDLE1P		0xB015
+
+#define PCI_DEVICE_ID_PERLE_SPEED1LEEXP		0xB021
+#define PCI_DEVICE_ID_PERLE_SPEED2LEEXP		0xB022
+#define PCI_DEVICE_ID_PERLE_SPEED1LE1PEXP	0xB026
+#define PCI_DEVICE_ID_PERLE_SPEED2LE1PEXP	0xB024
+#define PCI_DEVICE_ID_PERLE_SPEEDLE1PEXP	0xB025
+
+#define PCI_DEVICE_ID_PERLE_ULTRAPORT1EXP	0x0361
+#define PCI_DEVICE_ID_PERLE_ULTRAPORT2EXP	0x0311
+#define PCI_DEVICE_ID_PERLE_ULTRAPORT4EXP	0x0331
+#define PCI_DEVICE_ID_PERLE_ULTRAPORT8EXP	0x0321
+#define PCI_DEVICE_ID_PERLE_ULTRAPORT8IEXP	0x0351
+
+#define PCI_DEVICE_ID_PERLE_ULTRAPORT1EXPV2		0xB030
+#define PCI_DEVICE_ID_PERLE_ULTRAPORT2EXPV2		0xB031
+#define PCI_DEVICE_ID_PERLE_ULTRAPORT4EXPV2		0xB032
+#define PCI_DEVICE_ID_PERLE_ULTRAPORT8EXPV2		0xB033
+
+// duplicate of Ultraport SI sub-device IDs as Device IDs
+#define PCI_DEVICE_ID_PERLE_ULTRAPORT1SI	0x0261
+#define PCI_DEVICE_ID_PERLE_ULTRAPORT2SI	0x0211
+#define PCI_DEVICE_ID_PERLE_ULTRAPORT4SI	0x0231
+#define PCI_DEVICE_ID_PERLE_ULTRAPORT8SI	0x0221
+#define PCI_DEVICE_ID_PERLE_ULTRAPORT8ISI	0x0251
+
+// Versions of linux kernel at approx. 2.6.22 now have PCI_SUBVENDOR_ID_PERLE
+//	defined. Therefore undefine and redefine here.
+#undef	 PCI_SUBVENDOR_ID_PERLE
+#define PCI_SUBVENDOR_ID_PERLE				0x155F
+#define PCI_SUBDEVICE_ID_PERLE_ULTRAPORT1	0x0061
+#define PCI_SUBDEVICE_ID_PERLE_ULTRAPORT2	0x0011
+#define PCI_SUBDEVICE_ID_PERLE_ULTRAPORT4	0x0031
+#define PCI_SUBDEVICE_ID_PERLE_ULTRAPORT8	0x0021
+#define PCI_SUBDEVICE_ID_PERLE_ULTRAPORT16	0x0041
+#define PCI_SUBDEVICE_ID_PERLE_ULTRAPORT8I	0x0051
+
+#define PCI_SUBDEVICE_ID_PERLE_PCIRAS4		0xF001
+#define PCI_SUBDEVICE_ID_PERLE_PCIRAS8		0xF010
+
+#define PCI_SUBDEVICE_ID_PERLE_ULTRAPORT1SI		0x0261
+#define PCI_SUBDEVICE_ID_PERLE_ULTRAPORT2SI		0x0211
+#define PCI_SUBDEVICE_ID_PERLE_ULTRAPORT4SI		0x0231
+#define PCI_SUBDEVICE_ID_PERLE_ULTRAPORT8SI		0x0221
+#define PCI_SUBDEVICE_ID_PERLE_ULTRAPORT16SI	0x0241
+#define PCI_SUBDEVICE_ID_PERLE_ULTRAPORT8ISI	0x0251
+
+#define PCI_SUBVENDOR_ID_OXSEMI				0x1415
+#define PCI_SUBDEVICE_ID_OXSEMI_16PCI952	0x9521
+#define PCI_SUBDEVICE_ID_OXSEMI_16PCI954	0x9501
+#define PCI_SUBDEVICE_ID_OXSEMI_16PCI95N	0x9511
+#define PCI_SUBDEVICE_ID_OXSEMI_OXMPCIe95x	0x9505
+#define PCI_SUBDEVICE_ID_OXSEMI_OXMPCI952P	0x9513
+
+static const struct pci_device_id perle_blacklist[] = {
+
+	/* Perle PCI-RAS V.92 Multi-Modem cards */
+	{	PCI_VENDOR_ID_PLX, PCI_DEVICE_ID_PLX_9030,
+		PCI_SUBVENDOR_ID_PERLE,
+		PCI_SUBDEVICE_ID_PERLE_PCIRAS4, 0, 0, 
+		0 },
+		
+	{	PCI_VENDOR_ID_PLX, PCI_DEVICE_ID_PLX_9030,
+		PCI_SUBVENDOR_ID_PERLE,
+		PCI_SUBDEVICE_ID_PERLE_PCIRAS8, 0, 0, 
+		0 },
+
+	/* Perle UltraPort cards */
+	{	PCI_VENDOR_ID_PLX, PCI_DEVICE_ID_PLX_9030,
+		PCI_SUBVENDOR_ID_PERLE,
+		PCI_SUBDEVICE_ID_PERLE_ULTRAPORT1, 0, 0, 
+		0 },
+		
+	{	PCI_VENDOR_ID_PLX, PCI_DEVICE_ID_PLX_9030,
+		PCI_SUBVENDOR_ID_PERLE,
+		PCI_SUBDEVICE_ID_PERLE_ULTRAPORT2, 0, 0, 
+		0 },
+		
+	{	PCI_VENDOR_ID_PLX, PCI_DEVICE_ID_PLX_9030,
+		PCI_SUBVENDOR_ID_PERLE,
+		PCI_SUBDEVICE_ID_PERLE_ULTRAPORT4, 0, 0, 
+		0 },
+		
+	{	PCI_VENDOR_ID_PLX, PCI_DEVICE_ID_PLX_9030,
+		PCI_SUBVENDOR_ID_PERLE,
+		PCI_SUBDEVICE_ID_PERLE_ULTRAPORT8, 0, 0, 
+		0 },
+		
+	{	PCI_VENDOR_ID_PLX, PCI_DEVICE_ID_PLX_9030,
+		PCI_SUBVENDOR_ID_PERLE,
+		PCI_SUBDEVICE_ID_PERLE_ULTRAPORT16, 0, 0, 
+		0 },
+		
+	{	PCI_VENDOR_ID_PLX, PCI_DEVICE_ID_PLX_9030,
+		PCI_SUBVENDOR_ID_PERLE,
+		PCI_SUBDEVICE_ID_PERLE_ULTRAPORT8I, 0, 0, 
+		0 },
+
+	/* Perle UltraPort SI cards */
+	{	PCI_VENDOR_ID_P_EXAR, PCI_DEVICE_ID_EXAR_152,
+		PCI_SUBVENDOR_ID_PERLE,
+		PCI_SUBDEVICE_ID_PERLE_ULTRAPORT1SI, 0, 0, 
+		0 },
+
+	{	PCI_VENDOR_ID_P_EXAR, PCI_DEVICE_ID_EXAR_152,
+		PCI_SUBVENDOR_ID_PERLE,
+		PCI_SUBDEVICE_ID_PERLE_ULTRAPORT2SI, 0, 0, 
+		0 },
+
+	{	PCI_VENDOR_ID_P_EXAR, PCI_DEVICE_ID_EXAR_154,
+		PCI_SUBVENDOR_ID_PERLE,
+		PCI_SUBDEVICE_ID_PERLE_ULTRAPORT4SI, 0, 0, 
+		0 },
+
+	{	PCI_VENDOR_ID_P_EXAR, PCI_DEVICE_ID_EXAR_158,
+		PCI_SUBVENDOR_ID_PERLE,
+		PCI_SUBDEVICE_ID_PERLE_ULTRAPORT8SI, 0, 0, 
+		0 },
+
+	{	PCI_VENDOR_ID_PLX, PCI_DEVICE_ID_PLX_9030,
+		PCI_SUBVENDOR_ID_PERLE,
+		PCI_SUBDEVICE_ID_PERLE_ULTRAPORT16SI, 0, 0, 
+		0 },
+
+	{	PCI_VENDOR_ID_P_EXAR, PCI_DEVICE_ID_EXAR_158,
+		PCI_SUBVENDOR_ID_PERLE,
+		PCI_SUBDEVICE_ID_PERLE_ULTRAPORT8ISI, 0, 0, 
+		0 },
+
+	/* Perle UltraPort SI cards - now with Perle as the Vender ID. */
+	//	Do not create a new version for 16SI, it is safe (for now) using PLX.
+
+	{	PCI_VENDOR_ID_PERLE,		PCI_DEVICE_ID_PERLE_ULTRAPORT1SI, 
+		PCI_SUBVENDOR_ID_P_EXAR, 	PCI_SUBDEVICE_ID_EXAR_152,
+		0, 0, 
+		0 },
+
+	{	PCI_VENDOR_ID_PERLE,		PCI_DEVICE_ID_PERLE_ULTRAPORT2SI,
+		PCI_SUBVENDOR_ID_P_EXAR, 	PCI_SUBDEVICE_ID_EXAR_152,
+		0, 0, 
+		0 },
+
+	{	PCI_VENDOR_ID_PERLE,		PCI_DEVICE_ID_PERLE_ULTRAPORT4SI, 
+		PCI_SUBVENDOR_ID_P_EXAR,	PCI_SUBDEVICE_ID_EXAR_154,
+		0, 0, 
+		0 },
+
+	{	PCI_VENDOR_ID_PERLE, 		PCI_DEVICE_ID_PERLE_ULTRAPORT8SI, 
+		PCI_SUBVENDOR_ID_P_EXAR, 	PCI_SUBDEVICE_ID_EXAR_158,
+		0, 0, 
+		0 },
+
+	{	PCI_VENDOR_ID_PERLE,		PCI_DEVICE_ID_PERLE_ULTRAPORT8ISI, 
+		PCI_SUBVENDOR_ID_P_EXAR, 	PCI_SUBDEVICE_ID_EXAR_158,
+		0, 0, 
+		0 },
+
+		/* Perle Speed LE cards */
+	{	PCI_VENDOR_ID_PERLE, PCI_DEVICE_ID_PERLE_SPEED1LE,
+		PCI_SUBVENDOR_ID_OXSEMI,
+		PCI_SUBDEVICE_ID_OXSEMI_16PCI952, 0, 0, 
+		0 },
+
+	{	PCI_VENDOR_ID_PERLE, PCI_DEVICE_ID_PERLE_SPEED2LE,
+		PCI_SUBVENDOR_ID_OXSEMI,
+		PCI_SUBDEVICE_ID_OXSEMI_16PCI952, 0, 0, 
+		0 },
+
+	{	PCI_VENDOR_ID_PERLE, PCI_DEVICE_ID_PERLE_SPEED4LE,
+		PCI_SUBVENDOR_ID_OXSEMI,
+		PCI_SUBDEVICE_ID_OXSEMI_16PCI954, 0, 0, 
+		0 },
+
+	{	PCI_VENDOR_ID_PERLE, PCI_DEVICE_ID_PERLE_SPEED8LE,
+		PCI_SUBVENDOR_ID_OXSEMI,
+		PCI_SUBDEVICE_ID_OXSEMI_16PCI954, 0, 0, 
+		0 },
+
+	{	PCI_VENDOR_ID_PERLE, PCI_DEVICE_ID_PERLE_SPEED8LE,
+		PCI_SUBVENDOR_ID_OXSEMI,
+		PCI_SUBDEVICE_ID_OXSEMI_16PCI95N, 0, 0, 
+		0 },
+
+		
+		// Kludges to solve hardware problems.
+		//
+		// PCI - The Speed1 LE1P will use the 2nd Uart (which is connected to 
+		//		 the 10 pin header) for port 1. This is done to allow both the 
+		//		 serial and parallel ports to fit on 1 back panel.
+		//
+		// Express - The express chip does not allow 2 serial ports when the 
+		//			 parallel port is enabled. Therefore the first Uart was 
+		//           connected to the 10 pin header. This required the 
+		//           Speed1 LE Express to use 2nd Uart (which is 
+		//			 connected to the DB9 ) for port 1
+		//			 This also required that a new back panel for the 2 serial
+		//			 port version of the card to be created which changed the 
+		//           labelling of ports 1 and 2.
+	
+		
+	// Perle Speed LE with Parallel Port cards.
+	{	PCI_VENDOR_ID_PERLE, PCI_DEVICE_ID_PERLE_SPEED1LEV2,
+		PCI_SUBVENDOR_ID_OXSEMI,
+		PCI_SUBDEVICE_ID_OXSEMI_OXMPCIe95x, 0, 0, 
+		0 },
+
+	{	PCI_VENDOR_ID_PERLE, PCI_DEVICE_ID_PERLE_SPEED2LEV2,
+		PCI_SUBVENDOR_ID_OXSEMI,
+		PCI_SUBDEVICE_ID_OXSEMI_OXMPCIe95x, 0, 0, 
+		0 },
+
+	{	PCI_VENDOR_ID_PERLE, PCI_DEVICE_ID_PERLE_SPEED1LE1P,
+		PCI_SUBVENDOR_ID_OXSEMI,
+		PCI_SUBDEVICE_ID_OXSEMI_OXMPCIe95x, 0, 0, 
+		0 },
+
+	{	PCI_VENDOR_ID_PERLE, PCI_DEVICE_ID_PERLE_SPEED2LE1P,
+		PCI_SUBVENDOR_ID_OXSEMI,
+		PCI_SUBDEVICE_ID_OXSEMI_OXMPCIe95x, 0, 0, 
+		0 },
+	
+		// do not include parallel only card (PCI_DEVICE_ID_PERLE_SPEEDLE1P)
+
+	// Perle Speed LE Express with Parallel Port cards.
+	{	PCI_VENDOR_ID_PERLE, PCI_DEVICE_ID_PERLE_SPEED1LEEXP,
+		PCI_SUBVENDOR_ID_OXSEMI,
+		PCI_SUBDEVICE_ID_OXSEMI_OXMPCIe95x, 0, 0, 
+		0 },
+
+	{	PCI_VENDOR_ID_PERLE, PCI_DEVICE_ID_PERLE_SPEED2LEEXP,
+		PCI_SUBVENDOR_ID_OXSEMI,
+		PCI_SUBDEVICE_ID_OXSEMI_OXMPCIe95x, 0, 0, 
+		0 },
+
+	{	PCI_VENDOR_ID_PERLE, PCI_DEVICE_ID_PERLE_SPEED1LE1PEXP,
+		PCI_SUBVENDOR_ID_OXSEMI,
+		PCI_SUBDEVICE_ID_OXSEMI_OXMPCIe95x, 0, 0, 
+		0 },
+
+		// do not include parallel only card (PCI_DEVICE_ID_PERLE_SPEEDLE1PEXP)
+	
+
+		/* Perle UltraPort Express cards */
+	{	PCI_VENDOR_ID_PERLE, PCI_DEVICE_ID_PERLE_ULTRAPORT1EXP,
+		PCI_SUBVENDOR_ID_OXSEMI,
+		PCI_SUBDEVICE_ID_OXSEMI_16PCI952, 0, 0, 
+		0 },
+
+	{	PCI_VENDOR_ID_PERLE, PCI_DEVICE_ID_PERLE_ULTRAPORT2EXP,
+		PCI_SUBVENDOR_ID_OXSEMI,
+		PCI_SUBDEVICE_ID_OXSEMI_16PCI952, 0, 0, 
+		0 },
+
+	{	PCI_VENDOR_ID_PERLE, PCI_DEVICE_ID_PERLE_ULTRAPORT4EXP,
+		PCI_SUBVENDOR_ID_OXSEMI,
+		PCI_SUBDEVICE_ID_OXSEMI_16PCI954, 0, 0, 
+		0 },
+
+	{	PCI_VENDOR_ID_PERLE, PCI_DEVICE_ID_PERLE_ULTRAPORT8EXP,
+		PCI_SUBVENDOR_ID_OXSEMI,
+		PCI_SUBDEVICE_ID_OXSEMI_16PCI954, 0, 0, 
+		0 },
+
+	{	PCI_VENDOR_ID_PERLE, PCI_DEVICE_ID_PERLE_ULTRAPORT8EXP,
+		PCI_SUBVENDOR_ID_OXSEMI,
+		PCI_SUBDEVICE_ID_OXSEMI_16PCI95N, 0, 0, 
+		0 },
+
+	{	PCI_VENDOR_ID_PERLE, PCI_DEVICE_ID_PERLE_ULTRAPORT8IEXP,
+		PCI_SUBVENDOR_ID_OXSEMI,
+		PCI_SUBDEVICE_ID_OXSEMI_16PCI954, 0, 0, 
+		0 },
+
+	{	PCI_VENDOR_ID_PERLE, PCI_DEVICE_ID_PERLE_ULTRAPORT8IEXP,
+		PCI_SUBVENDOR_ID_OXSEMI,
+		PCI_SUBDEVICE_ID_OXSEMI_16PCI95N, 0, 0, 
+		0 },
+		
+	{	PCI_VENDOR_ID_PERLE, PCI_DEVICE_ID_PERLE_ULTRAPORT1EXPV2,
+		PCI_SUBVENDOR_ID_OXSEMI,
+		PCI_SUBDEVICE_ID_OXSEMI_OXMPCIe95x, 0, 0, 
+		0 },
+
+	{	PCI_VENDOR_ID_PERLE, PCI_DEVICE_ID_PERLE_ULTRAPORT2EXPV2,
+		PCI_SUBVENDOR_ID_OXSEMI,
+		PCI_SUBDEVICE_ID_OXSEMI_OXMPCIe95x, 0, 0, 
+		0 },
+
+	{	PCI_VENDOR_ID_PERLE, PCI_DEVICE_ID_PERLE_ULTRAPORT4EXPV2,
+		PCI_SUBVENDOR_ID_OXSEMI,
+		PCI_SUBDEVICE_ID_OXSEMI_OXMPCIe95x, 0, 0, 
+		0 },
+
+	{	PCI_VENDOR_ID_PERLE, PCI_DEVICE_ID_PERLE_ULTRAPORT8EXPV2,
+		PCI_SUBVENDOR_ID_OXSEMI,
+		PCI_SUBDEVICE_ID_OXSEMI_OXMPCIe95x, 0, 0, 
+		0 },
+
+	{	0, }
+};
+
+/*
  * Given a complete unknown PCI device, try to use some heuristics to
  * guess what the configuration might be, based on the pitiful PCI
  * serial specs.  Returns 0 on success, 1 on failure.
@@ -3780,6 +4112,22 @@ serial_pci_guess_board(struct pci_dev *d
 			return -ENODEV;
 	}
 
+	/*
+	 * lechner@igel.de, 07.08.09
+	 * blacklist perle cards handled by perle_serial driver
+	 * Do not access blacklisted devices that are known not to
+	 * feature serial ports.
+	 */
+	for (bldev = perle_blacklist;
+	     bldev < perle_blacklist + ARRAY_SIZE(perle_blacklist);
+	     bldev++) {
+		if (dev->vendor == bldev->vendor &&
+		    dev->device == bldev->device &&
+		    dev->subsystem_vendor == bldev->subvendor &&
+		    dev->subsystem_device == bldev->subdevice)
+			return -ENODEV;
+	}
+
 	num_iomem = num_port = 0;
 	for (i = 0; i < PCI_NUM_BAR_RESOURCES; i++) {
 		if (pci_resource_flags(dev, i) & IORESOURCE_IO) {
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/tty/vt/keyboard.c linux-4.10.x/drivers/tty/vt/keyboard.c
--- linux-4.10.x.ori/drivers/tty/vt/keyboard.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/tty/vt/keyboard.c	2017-04-10 11:27:25.836919000 +0200
@@ -1208,6 +1208,26 @@ DECLARE_TASKLET_DISABLED(keyboard_taskle
 #define HW_RAW(dev) (test_bit(EV_MSC, dev->evbit) && test_bit(MSC_RAW, dev->mscbit) &&\
 			((dev)->id.bustype == BUS_I8042) && ((dev)->id.vendor == 0x0001) && ((dev)->id.product == 0x0001))
 
+/* lechner@igel.com fix x86_keycodes */
+
+#if 1
+static const unsigned short x86_keycodes[256] =
+	{ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15,
+	 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31,
+	 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47,
+	 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63,
+	 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79,
+	 80, 81, 82, 83, 84,118, 86, 87, 88,115,120,119,121,112,123, 92,
+	284,285,309,311,312, 91,327,328,329,331,333,335,336,337,338,339,
+	367,288,302,304,350, 89,334,326,267,126,268,269,125,347,348,349,
+	360,261,262,263,268,376,100,101,321,316,373,286,289,102,351,355,
+	103,104,105,275,287,279,258,106,274,107,294,364,358,363,362,361,
+	 98,108,381,281,290,272,292,305,280, 99,112,257,306,359,113,114,
+	264,117,271,374,379,265,266, 93, 94, 95, 85,259,375,260, 90,116,
+	377,109,111,277,278,282,283,295,296,297,299,300,301,293,303,307,
+	308,310,313,314,315,317,318,319,320,357,322,323,324,325,276,330,
+	332,340,365,342,343,344,345,346,356,270,341,368,369,370,371,372 };
+#else
 static const unsigned short x86_keycodes[256] =
 	{ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15,
 	 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31,
@@ -1224,7 +1244,7 @@ static const unsigned short x86_keycodes
 	377,109,111,277,278,282,283,295,296,297,299,300,301,293,303,307,
 	308,310,313,314,315,317,318,319,320,357,322,323,324,325,276,330,
 	332,340,365,342,343,344,345,346,356,270,341,368,369,370,371,372 };
-
+#endif
 #ifdef CONFIG_SPARC
 static int sparc_l1_a_state;
 extern void sun_do_break(void);
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/usb/class/cdc-wdm.c linux-4.10.x/drivers/usb/class/cdc-wdm.c
--- linux-4.10.x.ori/drivers/usb/class/cdc-wdm.c	2017-06-12 15:36:29.913019000 +0200
+++ linux-4.10.x/drivers/usb/class/cdc-wdm.c	2017-11-17 08:04:02.640195000 +0100
@@ -194,8 +194,10 @@ static void wdm_in_callback(struct urb *
 	/*
 	 * only set a new error if there is no previous error.
 	 * Errors are only cleared during read/open
+	 * Avoid propagating -EPIPE (stall) to userspace since it is
+	 * better handled as an empty read
 	 */
-	if (desc->rerr  == 0)
+	if (desc->rerr == 0 && status != -EPIPE)
 		desc->rerr = status;
 
 	if (length + desc->length > desc->wMaxCommand) {
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/usb/core/devio.c linux-4.10.x/drivers/usb/core/devio.c
--- linux-4.10.x.ori/drivers/usb/core/devio.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/usb/core/devio.c	2017-04-10 11:27:25.836919000 +0200
@@ -2123,6 +2123,7 @@ static int proc_ioctl(struct usb_dev_sta
 	int			retval = 0;
 	struct usb_interface    *intf = NULL;
 	struct usb_driver       *driver = NULL;
+	struct usb_device       *udev = ps->dev;
 
 	if (ps->privileges_dropped)
 		return -EACCES;
@@ -2157,9 +2158,15 @@ static int proc_ioctl(struct usb_dev_sta
 	/* disconnect kernel driver from interface */
 	case USBDEVFS_DISCONNECT:
 		if (intf->dev.driver) {
-			driver = to_usb_driver(intf->dev.driver);
-			dev_dbg(&intf->dev, "disconnect by usbfs\n");
-			usb_driver_release_interface(driver, intf);
+			/* gottwald@igel.com disable disconnect if it was disabled via sysfs */
+			if (udev->disable_disconnect) {
+				printk(KERN_WARNING "Blocked usbdevfs disconnect ioctl for USB device protected by disable_disconnect\n");
+				retval = -ENODEV;
+			} else {
+				driver = to_usb_driver(intf->dev.driver);
+				dev_dbg(&intf->dev, "disconnect by usbfs\n");
+				usb_driver_release_interface(driver, intf);
+			}
 		} else
 			retval = -ENODATA;
 		break;
@@ -2269,6 +2276,7 @@ static int proc_disconnect_claim(struct
 {
 	struct usbdevfs_disconnect_claim dc;
 	struct usb_interface *intf;
+	struct usb_device *udev = ps->dev;
 
 	if (copy_from_user(&dc, arg, sizeof(dc)))
 		return -EFAULT;
@@ -2277,6 +2285,13 @@ static int proc_disconnect_claim(struct
 	if (!intf)
 		return -EINVAL;
 
+	/* gottwald@igel.com disable disconnect if it was disabled via sysfs */
+
+	if (udev->disable_disconnect) {
+		printk(KERN_WARNING "Blocked disconnect claim ioctl for USB device protected by disable_disconnect\n");
+		return -ENODEV;
+	}
+
 	if (intf->dev.driver) {
 		struct usb_driver *driver = to_usb_driver(intf->dev.driver);
 
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/usb/core/driver.c linux-4.10.x/drivers/usb/core/driver.c
--- linux-4.10.x.ori/drivers/usb/core/driver.c	2017-06-12 15:36:29.913019000 +0200
+++ linux-4.10.x/drivers/usb/core/driver.c	2017-06-12 15:36:29.913019000 +0200
@@ -273,6 +273,13 @@ static int usb_unbind_device(struct devi
 	struct usb_device *udev = to_usb_device(dev);
 	struct usb_device_driver *udriver = to_usb_device_driver(dev->driver);
 
+	/* gottwald@igel.com prevent device from being released */
+
+	if (udev->disable_disconnect) {
+		printk(KERN_WARNING "Blocked usb_unbind_device for USB device protected by disable_disconnect\n");
+		return -ENODEV;
+	}
+
 	udriver->disconnect(udev);
 	if (!udriver->supports_autosuspend)
 		usb_autosuspend_device(udev);
@@ -399,10 +406,16 @@ static int usb_unbind_interface(struct d
 	int i, j, error, r;
 	int lpm_disable_error = -ENODEV;
 
-	intf->condition = USB_INTERFACE_UNBINDING;
-
 	/* Autoresume for set_interface call below */
 	udev = interface_to_usbdev(intf);
+	/* gottwald@igel.com prevent device from being released */
+
+	if (udev->disable_disconnect) {
+		printk(KERN_WARNING "Blocked usb_unbind_interface for USB device protected by disable_disconnect\n");
+		return lpm_disable_error;
+	}
+
+	intf->condition = USB_INTERFACE_UNBINDING;
 	error = usb_autoresume_device(udev);
 
 	/* If hub-initiated LPM policy may change, attempt to disable LPM until
@@ -587,6 +600,7 @@ void usb_driver_release_interface(struct
 					struct usb_interface *iface)
 {
 	struct device *dev = &iface->dev;
+	struct usb_device *udev = interface_to_usbdev(iface);
 
 	/* this should never happen, don't release something that's not ours */
 	if (!dev->driver || dev->driver != &driver->drvwrap.driver)
@@ -595,6 +609,14 @@ void usb_driver_release_interface(struct
 	/* don't release from within disconnect() */
 	if (iface->condition != USB_INTERFACE_BOUND)
 		return;
+	
+	/* gottwald@igel.com prevent device from being released */
+
+	if (udev->disable_disconnect) {
+		printk(KERN_WARNING "Blocked usb_driver_release_interface for USB device protected by disable_disconnect\n");
+		return;
+	}
+
 	iface->condition = USB_INTERFACE_UNBINDING;
 
 	/* Release via the driver core only if the interface
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/usb/core/quirks.c linux-4.10.x/drivers/usb/core/quirks.c
--- linux-4.10.x.ori/drivers/usb/core/quirks.c	2017-09-21 16:13:04.121880000 +0200
+++ linux-4.10.x/drivers/usb/core/quirks.c	2017-09-21 16:13:04.121880000 +0200
@@ -147,6 +147,9 @@ static const struct usb_device_id usb_qu
 	/* Alcor Micro Corp. Hub */
 	{ USB_DEVICE(0x058f, 0x9254), .driver_info = USB_QUIRK_RESET_RESUME },
 
+	/* MicroTouch Systems touchscreen */
+	{ USB_DEVICE(0x0596, 0x051e), .driver_info = USB_QUIRK_RESET_RESUME },
+
 	/* appletouch */
 	{ USB_DEVICE(0x05ac, 0x021a), .driver_info = USB_QUIRK_RESET_RESUME },
 
@@ -210,6 +213,10 @@ static const struct usb_device_id usb_qu
 	{ USB_DEVICE(0x1908, 0x1315), .driver_info =
 			USB_QUIRK_HONOR_BNUMINTERFACES },
 
+	/* lang@igel: Kyocera FS-1350DN printer 
+	 * doesn't print anything if quirk is not set */
+	{ USB_DEVICE(0x0482, 0x0392), .driver_info = USB_QUIRK_NO_SET_INTF },
+
 	/* Protocol and OTG Electrical Test Device */
 	{ USB_DEVICE(0x1a0a, 0x0200), .driver_info =
 			USB_QUIRK_LINEAR_UFRAME_INTR_BINTERVAL },
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/usb/core/sysfs.c linux-4.10.x/drivers/usb/core/sysfs.c
--- linux-4.10.x.ori/drivers/usb/core/sysfs.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/usb/core/sysfs.c	2017-04-10 11:27:25.836919000 +0200
@@ -418,6 +418,40 @@ static ssize_t autosuspend_store(struct
 }
 static DEVICE_ATTR_RW(autosuspend);
 
+/* gottwald@igel.com added sysfs entry to disable USB device disconnect */
+
+static ssize_t disable_disconnect_show(struct device *dev,
+				struct device_attribute *attr, char *buf)
+{
+	struct usb_device *udev = to_usb_device(dev);
+	return sprintf(buf, "%d\n", udev->disable_disconnect);
+}
+
+static ssize_t disable_disconnect_store(struct device *dev,
+				 struct device_attribute *attr, const char *buf,
+				 size_t count)
+{
+	int value;
+	struct usb_interface *intf = to_usb_interface(dev);
+	struct usb_device *udev = to_usb_device(dev);
+	struct usb_device *udev2 = interface_to_usbdev(intf);
+
+	if (sscanf(buf, "%d", &value) != 1 || value > 1 ||
+			value < 0)
+		return -EINVAL;
+
+	usb_lock_device(udev);
+	udev->disable_disconnect = value;
+	usb_unlock_device(udev);
+
+	usb_lock_device(udev2);
+	udev2->disable_disconnect = value;
+	usb_unlock_device(udev2);
+
+	return count;
+}
+static DEVICE_ATTR_RW(disable_disconnect);
+
 static const char on_string[] = "on";
 static const char auto_string[] = "auto";
 
@@ -1068,6 +1102,7 @@ static struct attribute *intf_attrs[] =
 	&dev_attr_modalias.attr,
 	&dev_attr_supports_autosuspend.attr,
 	&dev_attr_interface_authorized.attr,
+	&dev_attr_disable_disconnect.attr,
 	NULL,
 };
 static struct attribute_group intf_attr_grp = {
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/usb/core/usb.c linux-4.10.x/drivers/usb/core/usb.c
--- linux-4.10.x.ori/drivers/usb/core/usb.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/usb/core/usb.c	2017-04-10 11:27:25.836919000 +0200
@@ -65,7 +65,9 @@ int usb_disabled(void)
 EXPORT_SYMBOL_GPL(usb_disabled);
 
 #ifdef	CONFIG_PM
-static int usb_autosuspend_delay = 2;		/* Default delay value,
+/* gottwald@igel.com disable USB autosuspend because some devices have 
+ * problems with this (Samsung TC2 for example) */
+static int usb_autosuspend_delay = -1;		/* Default delay value,
 						 * in seconds */
 module_param_named(autosuspend, usb_autosuspend_delay, int, 0644);
 MODULE_PARM_DESC(autosuspend, "default autosuspend delay");
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/usb/host/pci-quirks.c linux-4.10.x/drivers/usb/host/pci-quirks.c
--- linux-4.10.x.ori/drivers/usb/host/pci-quirks.c	2017-08-31 08:18:50.846242000 +0200
+++ linux-4.10.x/drivers/usb/host/pci-quirks.c	2017-07-18 07:44:29.338041000 +0200
@@ -899,6 +899,55 @@ static int handshake(void __iomem *ptr,
 	return -ETIMEDOUT;
 }
 
+/* lang@igel: quirk for TI tusb73x0 xHCI controller, if HC halt failed */
+/* gottwald@igel.de: readded patch from 3.2 kernel */
+#define PCI_DEVICE_ID_TI_TUSB73X0_XHCI	0x8241
+#define PCIE_TUSB73X0_USBCONTROL	0xE0
+#define XHCI_CMD_LHCRSE		(1 << 7)
+static int quirk_ti_tusb73x0_xhci(struct pci_dev *pdev, void __iomem *op_reg_base)
+{
+	u32 ti_usbcontrol_reg = 0, val;
+	int timeout;
+ 
+	if (pdev->class != PCI_CLASS_SERIAL_USB_XHCI ||
+	    pdev->vendor != PCI_VENDOR_ID_TI ||
+	    pdev->device != PCI_DEVICE_ID_TI_TUSB73X0_XHCI)
+		return 1;
+ 
+	dev_warn(&pdev->dev, "Quirk for TI tusb73x0 xHCI controller\n");
+	pci_read_config_dword(pdev, PCIE_TUSB73X0_USBCONTROL,
+			&ti_usbcontrol_reg);
+	/* disable all ports */
+	pci_write_config_dword(pdev, PCIE_TUSB73X0_USBCONTROL,
+			cpu_to_le32(ti_usbcontrol_reg | 0xf00));
+ 
+	/* light host controller reset */
+	val = readl(op_reg_base + XHCI_CMD_OFFSET);
+	val |= XHCI_CMD_LHCRSE;
+	writel(val, op_reg_base + XHCI_CMD_OFFSET);
+	timeout = handshake(op_reg_base + XHCI_CMD_OFFSET, XHCI_CMD_LHCRSE, 0,
+			5000, 125);
+	/* Wait for the host controller to be ready before writing any
+	 * operational or runtime registers.  Wait 5 seconds and no more.
+	 */
+	timeout = handshake(op_reg_base + XHCI_STS_OFFSET, XHCI_STS_CNR, 0,
+			5000, 10);
+ 
+	dev_warn(&pdev->dev, "xHCI HC status=%08x, cmd=%08x\n",
+			readl(op_reg_base + XHCI_STS_OFFSET),
+			readl(op_reg_base + XHCI_CMD_OFFSET));
+ 
+	/* Wait for the HC to halt - poll every 125 usec (one microframe). */
+	timeout = handshake(op_reg_base + XHCI_STS_OFFSET, XHCI_STS_HALT, 1,
+			XHCI_MAX_HALT_USEC, 125);
+ 
+	/* enable ports again */
+	pci_write_config_dword(pdev, PCIE_TUSB73X0_USBCONTROL,
+			cpu_to_le32(ti_usbcontrol_reg));
+ 
+	return timeout;
+}
+
 /*
  * Intel's Panther Point chipset has two host controllers (EHCI and xHCI) that
  * share some number of ports.  These ports can be switched between either
@@ -1110,10 +1159,14 @@ hc_init:
 	timeout = handshake(op_reg_base + XHCI_STS_OFFSET, XHCI_STS_HALT, 1,
 			XHCI_MAX_HALT_USEC, 125);
 	if (timeout) {
-		val = readl(op_reg_base + XHCI_STS_OFFSET);
-		dev_warn(&pdev->dev,
-			 "xHCI HW did not halt within %d usec status = 0x%x\n",
-			 XHCI_MAX_HALT_USEC, val);
+		/* lang@igel: quirk for TI tusb73x0 xHCI controller */
+		/* gottwald@igel.de: readded patch from 3.2 kernel */
+		if (quirk_ti_tusb73x0_xhci(pdev, op_reg_base)) {
+			val = readl(op_reg_base + XHCI_STS_OFFSET);
+			dev_warn(&pdev->dev,
+				 "xHCI HW did not halt within %d usec status = 0x%x\n",
+				 XHCI_MAX_HALT_USEC, val);
+		}
 	}
 
 iounmap:
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/usb/host/xhci.h linux-4.10.x/drivers/usb/host/xhci.h
--- linux-4.10.x.ori/drivers/usb/host/xhci.h	2017-08-31 08:18:50.846242000 +0200
+++ linux-4.10.x/drivers/usb/host/xhci.h	2017-07-18 07:44:29.338041000 +0200
@@ -1654,7 +1654,8 @@ struct xhci_hcd {
 #define XHCI_BROKEN_PORT_PED	(1 << 25)
 #define XHCI_LIMIT_ENDPOINT_INTERVAL_7	(1 << 26)
 #define XHCI_ASMEDIA_MODIFY_FLOWCONTROL	(1 << 28)
-
+/* lang@igel: new quirk for remote wakeup on M330C */
+#define XHCI_SET_PCIWAKEUP	(1 << 29)
 	unsigned int		num_active_eps;
 	unsigned int		limit_active_eps;
 	/* There are two roothubs to keep track of bus suspend info for */
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/usb/host/xhci-pci.c linux-4.10.x/drivers/usb/host/xhci-pci.c
--- linux-4.10.x.ori/drivers/usb/host/xhci-pci.c	2017-08-31 08:18:50.846242000 +0200
+++ linux-4.10.x/drivers/usb/host/xhci-pci.c	2017-07-18 07:44:29.338041000 +0200
@@ -24,6 +24,7 @@
 #include <linux/slab.h>
 #include <linux/module.h>
 #include <linux/acpi.h>
+#include <linux/dmi.h>
 
 #include "xhci.h"
 #include "xhci-trace.h"
@@ -202,12 +203,28 @@ static void xhci_pci_quirks(struct devic
 		xhci->quirks |= XHCI_BROKEN_STREAMS;
 
 	if (pdev->vendor == PCI_VENDOR_ID_ASMEDIA &&
+			pdev->device == 0x1142)
+		xhci->quirks |= XHCI_TRUST_TX_LENGTH;
+
+	if (pdev->vendor == PCI_VENDOR_ID_ASMEDIA &&
 		pdev->device == PCI_DEVICE_ID_ASMEDIA_1042A_XHCI)
 		xhci->quirks |= XHCI_ASMEDIA_MODIFY_FLOWCONTROL;
 
 	if (pdev->vendor == PCI_VENDOR_ID_TI && pdev->device == 0x8241)
 		xhci->quirks |= XHCI_LIMIT_ENDPOINT_INTERVAL_7;
 
+	/* lang@igel: new quirk for remote wakeup on M330C and TC236 */
+	if (pdev->vendor == PCI_VENDOR_ID_ASMEDIA &&
+			pdev->device == 0x1142) {
+		const char *product_name = dmi_get_system_info(DMI_PRODUCT_NAME);
+		if (product_name != NULL) {
+			if (!strcmp(product_name, "M330C") || !strcmp(product_name, "TC236")) {
+				xhci_warn(xhci, "Enable wake up quirk for M330C, TC236 hardware.\n");
+				xhci->quirks |= XHCI_SET_PCIWAKEUP;
+			}
+		}
+	}
+
 	if (xhci->quirks & XHCI_RESET_ON_RESUME)
 		xhci_dbg_trace(xhci, trace_xhci_dbg_quirks,
 				"QUIRK: Resetting on resume");
@@ -414,6 +431,10 @@ static int xhci_pci_suspend(struct usb_h
 	if (xhci->quirks & XHCI_SSIC_PORT_UNUSED)
 		xhci_ssic_port_unused_quirk(hcd, true);
 
+	/* lang@igel: new quirk for remote wakeup on ASMedia ASM1042A (M330, TC236...) */
+	if ((xhci->quirks & XHCI_SET_PCIWAKEUP) && do_wakeup)
+		pci_wake_from_d3(pdev, true);
+
 	ret = xhci_suspend(xhci, do_wakeup);
 	if (ret && (xhci->quirks & XHCI_SSIC_PORT_UNUSED))
 		xhci_ssic_port_unused_quirk(hcd, false);
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/usb/serial/ftdi_sio.c linux-4.10.x/drivers/usb/serial/ftdi_sio.c
--- linux-4.10.x.ori/drivers/usb/serial/ftdi_sio.c	2017-06-12 15:36:29.913019000 +0200
+++ linux-4.10.x/drivers/usb/serial/ftdi_sio.c	2017-06-12 15:36:29.913019000 +0200
@@ -986,6 +986,8 @@ static const struct usb_device_id id_tab
 	{ USB_DEVICE(BRAINBOXES_VID, BRAINBOXES_US_842_4_PID) },
 	/* ekey Devices */
 	{ USB_DEVICE(FTDI_VID, FTDI_EKEY_CONV_USB_PID) },
+	/* freund@igel: */
+	{ USB_DEVICE(KABA_VID, KABA_B_Net_9107_PID) },
 	/* Infineon Devices */
 	{ USB_DEVICE_INTERFACE_NUMBER(INFINEON_VID, INFINEON_TRIBOARD_TC1798_PID, 1) },
 	{ USB_DEVICE_INTERFACE_NUMBER(INFINEON_VID, INFINEON_TRIBOARD_TC2X7_PID, 1) },
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/usb/serial/ftdi_sio_ids.h linux-4.10.x/drivers/usb/serial/ftdi_sio_ids.h
--- linux-4.10.x.ori/drivers/usb/serial/ftdi_sio_ids.h	2017-06-12 15:36:29.913019000 +0200
+++ linux-4.10.x/drivers/usb/serial/ftdi_sio_ids.h	2017-06-12 15:36:29.913019000 +0200
@@ -1431,6 +1431,13 @@
  */
 #define FTDI_CT_COMET_PID	0x8e08
 
+/* freund@igel
+ * KABA B-Net 9107
+ * Legic RFID reader 
+ */
+#define KABA_VID 0x18D9
+#define KABA_B_Net_9107_PID	0x01A0
+
 /*
  * Product: Z3X Box
  * Manufacturer: Smart GSM Team
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/usb/serial/generic.c linux-4.10.x/drivers/usb/serial/generic.c
--- linux-4.10.x.ori/drivers/usb/serial/generic.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/usb/serial/generic.c	2017-04-10 11:27:25.836919000 +0200
@@ -34,7 +34,19 @@ MODULE_PARM_DESC(vendor, "User specified
 module_param(product, ushort, 0);
 MODULE_PARM_DESC(product, "User specified USB idProduct");
 
-static struct usb_device_id generic_device_ids[2]; /* Initially all zeroes. */
+/* lechner@igel.com add some more devices in device table */
+
+static struct usb_device_id generic_device_ids[] = {
+	/* The first entry is a placeholder for the insmod-specified device */
+	{ USB_DEVICE(0x05f9, 0xffff) },
+	{ USB_DEVICE(0x0780, 0x1202) }, /* Sagem Monetel ORGA 900 */
+	{ USB_DEVICE(0x0780, 0x1302) }, /* Sagem Monetel ORGA 6000 */
+	{ USB_DEVICE(0x04e6, 0x1a02) }, /* SCM Microsystems eHealth500 */
+	{ USB_DEVICE(0x152a, 0x8180) }, /* Celectronic CARD STAR /medic2 and /memo3 */
+	{ }                             /* Terminating entry */
+};
+
+MODULE_DEVICE_TABLE (usb, generic_device_ids);
 
 struct usb_serial_driver usb_serial_generic_device = {
 	.driver = {
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/usb/storage/realtek_cr.c linux-4.10.x/drivers/usb/storage/realtek_cr.c
--- linux-4.10.x.ori/drivers/usb/storage/realtek_cr.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/usb/storage/realtek_cr.c	2017-04-10 11:27:25.836919000 +0200
@@ -1013,8 +1013,14 @@ static int init_realtek_cr(struct us_dat
 			goto INIT_FAIL;
 	}
 
-	if (CHECK_FW_VER(chip, 0x5888) || CHECK_FW_VER(chip, 0x5889) ||
-	    CHECK_FW_VER(chip, 0x5901))
+	/* gottwald@igel.com do not set auto delink on Firmware Version 0x5888
+	 *                   because this is known to break udc installation on
+	 *                   a Lenovo ThinkPad X100e if no SD card is present */
+
+/*	if (CHECK_FW_VER(chip, 0x5888) || CHECK_FW_VER(chip, 0x5889) ||
+	    CHECK_FW_VER(chip, 0x5901)) */
+	if (CHECK_FW_VER(chip, 0x5889) ||
+	    CHECK_FW_VER(chip, 0x5901)) 
 		SET_AUTO_DELINK(chip);
 	if (STATUS_LEN(chip) == 16) {
 		if (SUPPORT_AUTO_DELINK(chip))
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/video/console/fbcon.c linux-4.10.x/drivers/video/console/fbcon.c
--- linux-4.10.x.ori/drivers/video/console/fbcon.c	2017-04-21 13:47:09.278670000 +0200
+++ linux-4.10.x/drivers/video/console/fbcon.c	2017-07-26 15:53:02.688280000 +0200
@@ -270,11 +270,35 @@ static int fbcon_get_rotate(struct fb_in
 
 	return (ops) ? ops->rotate : 0;
 }
+static int igel_splash_fix = 1;
+
+/* lang@igel: our bootcode shows a boot splash, the splash
+   should not be destroyed by a frame buffer console */
+static inline int fbcon_fix_igel_splash(struct vc_data *vc)
+{
+	if (vc->vc_num != 0 || fg_console != 0 || ! (*vc->vc_display_fg == vc))
+		return 0;
+	/* remove splash fix after x server was started */
+	if (vc->vc_mode == KD_GRAPHICS) {
+		igel_splash_fix = 0;
+		printk("fbcon: remove igel boot splash fix\n");
+		return 0;
+	}
+	/* show the message only once ! */
+	if (igel_splash_fix == 1) {
+		printk("fbcon: fix igel boot splash\n");
+		igel_splash_fix = 2;
+	}
+	return (!vt_force_oops_output(vc));
+}
 
 static inline int fbcon_is_inactive(struct vc_data *vc, struct fb_info *info)
 {
 	struct fbcon_ops *ops = info->fbcon_par;
 
+	if (igel_splash_fix && fbcon_fix_igel_splash(vc))
+		return 1;
+
 	return (info->state != FBINFO_STATE_RUNNING ||
 		vc->vc_mode != KD_TEXT || ops->graphics) &&
 		!vt_force_oops_output(vc);
diff -Naurp -x debian.hwe linux-4.10.x.ori/drivers/video/console/vgacon.c linux-4.10.x/drivers/video/console/vgacon.c
--- linux-4.10.x.ori/drivers/video/console/vgacon.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/drivers/video/console/vgacon.c	2017-04-10 11:27:25.836919000 +0200
@@ -118,6 +118,16 @@ static int __init text_mode(char *str)
 /* force text mode - used by kernel modesetting */
 __setup("nomodeset", text_mode);
 
+/* lang@igel.de: splash=<modenr> is set by our bootcode if splash is active */
+static int splash_mode = 0;
+
+static int __init setup_splash_mode(char *str)
+{
+	get_option(&str, &splash_mode);
+	return 1;
+}
+__setup("splash=", setup_splash_mode);
+
 static int __init no_scroll(char *str)
 {
 	/*
@@ -338,6 +348,12 @@ static const char *vgacon_startup(void)
 #endif
 	}
 
+	/* lang@igel.de: if splash is active do not configure a VGA console,
+	   because the boot splash is corrupted by a VGA console */
+	if (splash_mode > 0) {
+		goto no_vga;
+	}
+
 	/* boot_params.screen_info initialized? */
 	if ((screen_info.orig_video_mode  == 0) &&
 	    (screen_info.orig_video_lines == 0) &&
diff -Naurp -x debian.hwe linux-4.10.x.ori/fs/squashfs/decompressor.c linux-4.10.x/fs/squashfs/decompressor.c
--- linux-4.10.x.ori/fs/squashfs/decompressor.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/fs/squashfs/decompressor.c	2017-10-30 10:05:19.610447000 +0100
@@ -65,6 +65,12 @@ static const struct squashfs_decompresso
 };
 #endif
 
+#ifndef CONFIG_SQUASHFS_ZSTD
+static const struct squashfs_decompressor squashfs_zstd_comp_ops = {
+	NULL, NULL, NULL, NULL, ZSTD_COMPRESSION, "zstd", 0
+};
+#endif
+
 static const struct squashfs_decompressor squashfs_unknown_comp_ops = {
 	NULL, NULL, NULL, NULL, 0, "unknown", 0
 };
@@ -75,6 +81,7 @@ static const struct squashfs_decompresso
 	&squashfs_lzo_comp_ops,
 	&squashfs_xz_comp_ops,
 	&squashfs_lzma_unsupported_comp_ops,
+	&squashfs_zstd_comp_ops,
 	&squashfs_unknown_comp_ops
 };
 
diff -Naurp -x debian.hwe linux-4.10.x.ori/fs/squashfs/decompressor.h linux-4.10.x/fs/squashfs/decompressor.h
--- linux-4.10.x.ori/fs/squashfs/decompressor.h	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/fs/squashfs/decompressor.h	2017-10-30 10:05:19.610447000 +0100
@@ -58,4 +58,8 @@ extern const struct squashfs_decompresso
 extern const struct squashfs_decompressor squashfs_zlib_comp_ops;
 #endif
 
+#ifdef CONFIG_SQUASHFS_ZSTD
+extern const struct squashfs_decompressor squashfs_zstd_comp_ops;
+#endif
+
 #endif
diff -Naurp -x debian.hwe linux-4.10.x.ori/fs/squashfs/Kconfig linux-4.10.x/fs/squashfs/Kconfig
--- linux-4.10.x.ori/fs/squashfs/Kconfig	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/fs/squashfs/Kconfig	2017-10-30 10:05:19.610447000 +0100
@@ -165,6 +165,20 @@ config SQUASHFS_XZ
 
 	  If unsure, say N.
 
+config SQUASHFS_ZSTD
+	bool "Include support for ZSTD compressed file systems"
+	depends on SQUASHFS
+	select ZSTD_DECOMPRESS
+	help
+	  Saying Y here includes support for reading Squashfs file systems
+	  compressed with ZSTD compression.  ZSTD gives better compression than
+	  the default ZLIB compression, while using less CPU.
+
+	  ZSTD is not the standard compression used in Squashfs and so most
+	  file systems will be readable without selecting this option.
+
+	  If unsure, say N.
+
 config SQUASHFS_4K_DEVBLK_SIZE
 	bool "Use 4K device block size?"
 	depends on SQUASHFS
diff -Naurp -x debian.hwe linux-4.10.x.ori/fs/squashfs/Makefile linux-4.10.x/fs/squashfs/Makefile
--- linux-4.10.x.ori/fs/squashfs/Makefile	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/fs/squashfs/Makefile	2017-10-30 10:05:19.610447000 +0100
@@ -15,3 +15,4 @@ squashfs-$(CONFIG_SQUASHFS_LZ4) += lz4_w
 squashfs-$(CONFIG_SQUASHFS_LZO) += lzo_wrapper.o
 squashfs-$(CONFIG_SQUASHFS_XZ) += xz_wrapper.o
 squashfs-$(CONFIG_SQUASHFS_ZLIB) += zlib_wrapper.o
+squashfs-$(CONFIG_SQUASHFS_ZSTD) += zstd_wrapper.o
diff -Naurp -x debian.hwe linux-4.10.x.ori/fs/squashfs/squashfs_fs.h linux-4.10.x/fs/squashfs/squashfs_fs.h
--- linux-4.10.x.ori/fs/squashfs/squashfs_fs.h	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/fs/squashfs/squashfs_fs.h	2017-10-30 10:05:19.610447000 +0100
@@ -241,6 +241,7 @@ struct meta_index {
 #define LZO_COMPRESSION		3
 #define XZ_COMPRESSION		4
 #define LZ4_COMPRESSION		5
+#define ZSTD_COMPRESSION	6
 
 struct squashfs_super_block {
 	__le32			s_magic;
diff -Naurp -x debian.hwe linux-4.10.x.ori/fs/squashfs/zstd_wrapper.c linux-4.10.x/fs/squashfs/zstd_wrapper.c
--- linux-4.10.x.ori/fs/squashfs/zstd_wrapper.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-4.10.x/fs/squashfs/zstd_wrapper.c	2017-10-30 10:05:19.610447000 +0100
@@ -0,0 +1,151 @@
+/*
+ * Squashfs - a compressed read only filesystem for Linux
+ *
+ * Copyright (c) 2016-present, Facebook, Inc.
+ * All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; either version 2,
+ * or (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * zstd_wrapper.c
+ */
+
+#include <linux/mutex.h>
+#include <linux/buffer_head.h>
+#include <linux/slab.h>
+#include <linux/zstd.h>
+#include <linux/vmalloc.h>
+
+#include "squashfs_fs.h"
+#include "squashfs_fs_sb.h"
+#include "squashfs.h"
+#include "decompressor.h"
+#include "page_actor.h"
+
+struct workspace {
+	void *mem;
+	size_t mem_size;
+	size_t window_size;
+};
+
+static void *zstd_init(struct squashfs_sb_info *msblk, void *buff)
+{
+	struct workspace *wksp = kmalloc(sizeof(*wksp), GFP_KERNEL);
+
+	if (wksp == NULL)
+		goto failed;
+	wksp->window_size = max_t(size_t,
+			msblk->block_size, SQUASHFS_METADATA_SIZE);
+	wksp->mem_size = ZSTD_DStreamWorkspaceBound(wksp->window_size);
+	wksp->mem = vmalloc(wksp->mem_size);
+	if (wksp->mem == NULL)
+		goto failed;
+
+	return wksp;
+
+failed:
+	ERROR("Failed to allocate zstd workspace\n");
+	kfree(wksp);
+	return ERR_PTR(-ENOMEM);
+}
+
+
+static void zstd_free(void *strm)
+{
+	struct workspace *wksp = strm;
+
+	if (wksp)
+		vfree(wksp->mem);
+	kfree(wksp);
+}
+
+
+static int zstd_uncompress(struct squashfs_sb_info *msblk, void *strm,
+	struct buffer_head **bh, int b, int offset, int length,
+	struct squashfs_page_actor *output)
+{
+	struct workspace *wksp = strm;
+	ZSTD_DStream *stream;
+	size_t total_out = 0;
+	size_t zstd_err;
+	int k = 0;
+	ZSTD_inBuffer in_buf = { NULL, 0, 0 };
+	ZSTD_outBuffer out_buf = { NULL, 0, 0 };
+
+	stream = ZSTD_initDStream(wksp->window_size, wksp->mem, wksp->mem_size);
+
+	if (!stream) {
+		ERROR("Failed to initialize zstd decompressor\n");
+		goto out;
+	}
+
+	out_buf.size = PAGE_SIZE;
+	out_buf.dst = squashfs_first_page(output);
+
+	do {
+		if (in_buf.pos == in_buf.size && k < b) {
+			int avail = min(length, msblk->devblksize - offset);
+
+			length -= avail;
+			in_buf.src = bh[k]->b_data + offset;
+			in_buf.size = avail;
+			in_buf.pos = 0;
+			offset = 0;
+		}
+
+		if (out_buf.pos == out_buf.size) {
+			out_buf.dst = squashfs_next_page(output);
+			if (out_buf.dst == NULL) {
+				/* Shouldn't run out of pages
+				 * before stream is done.
+				 */
+				squashfs_finish_page(output);
+				goto out;
+			}
+			out_buf.pos = 0;
+			out_buf.size = PAGE_SIZE;
+		}
+
+		total_out -= out_buf.pos;
+		zstd_err = ZSTD_decompressStream(stream, &out_buf, &in_buf);
+		total_out += out_buf.pos; /* add the additional data produced */
+
+		if (in_buf.pos == in_buf.size && k < b)
+			put_bh(bh[k++]);
+	} while (zstd_err != 0 && !ZSTD_isError(zstd_err));
+
+	squashfs_finish_page(output);
+
+	if (ZSTD_isError(zstd_err)) {
+		ERROR("zstd decompression error: %d\n",
+				(int)ZSTD_getErrorCode(zstd_err));
+		goto out;
+	}
+
+	if (k < b)
+		goto out;
+
+	return (int)total_out;
+
+out:
+	for (; k < b; k++)
+		put_bh(bh[k]);
+
+	return -EIO;
+}
+
+const struct squashfs_decompressor squashfs_zstd_comp_ops = {
+	.init = zstd_init,
+	.free = zstd_free,
+	.decompress = zstd_uncompress,
+	.id = ZSTD_COMPRESSION,
+	.name = "zstd",
+	.supported = 1
+};
diff -Naurp -x debian.hwe linux-4.10.x.ori/include/drm/drm_connector.h linux-4.10.x/include/drm/drm_connector.h
--- linux-4.10.x.ori/include/drm/drm_connector.h	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/include/drm/drm_connector.h	2017-04-10 11:27:25.836919000 +0200
@@ -533,6 +533,13 @@ struct drm_connector_funcs {
 	 */
 	void (*atomic_print_state)(struct drm_printer *p,
 				   const struct drm_connector_state *state);
+
+	/* schneider@igel.com SDVO register save function */
+	/* Save CRTC state */
+	void (*save)(struct drm_connector *connector); /* suspend? */
+	/* schneider@igel.com SDVO register restore function */
+	/* Restore CRTC state */
+	void (*restore)(struct drm_connector *connector); /* resume? */
 };
 
 /* mode specified on the command line */
diff -Naurp -x debian.hwe linux-4.10.x.ori/include/drm/intel_lpe_audio.h linux-4.10.x/include/drm/intel_lpe_audio.h
--- linux-4.10.x.ori/include/drm/intel_lpe_audio.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-4.10.x/include/drm/intel_lpe_audio.h	2017-04-21 17:01:32.706015000 +0200
@@ -0,0 +1,46 @@
+/*
+ * Copyright © 2016 Intel Corporation
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the next
+ * paragraph) shall be included in all copies or substantial portions of the
+ * Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+ * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
+ * IN THE SOFTWARE.
+ */
+
+#ifndef _INTEL_LPE_AUDIO_H_
+#define _INTEL_LPE_AUDIO_H_
+
+#include <linux/types.h>
+#include <linux/spinlock_types.h>
+
+#define HDMI_MAX_ELD_BYTES	128
+
+struct intel_hdmi_lpe_audio_eld {
+	int port_id;
+	unsigned char eld_data[HDMI_MAX_ELD_BYTES];
+};
+
+struct intel_hdmi_lpe_audio_pdata {
+	bool notify_pending;
+	int tmds_clock_speed;
+	bool hdmi_connected;
+	struct intel_hdmi_lpe_audio_eld eld;
+	void (*notify_audio_lpe)(void *audio_ptr);
+	spinlock_t lpe_audio_slock;
+};
+
+#endif /* _I915_LPE_AUDIO_H_ */
diff -Naurp -x debian.hwe linux-4.10.x.ori/include/drm/ttm/ttm_bo_driver.h linux-4.10.x/include/drm/ttm/ttm_bo_driver.h
--- linux-4.10.x.ori/include/drm/ttm/ttm_bo_driver.h	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/include/drm/ttm/ttm_bo_driver.h	2017-07-12 14:58:46.400789000 +0200
@@ -431,9 +431,15 @@ struct ttm_bo_driver {
 	int (*verify_access)(struct ttm_buffer_object *bo,
 			     struct file *filp);
 
-	/* hook to notify driver about a driver move so it
-	 * can do tiling things */
+	/**
+	 * Hook to notify driver about a driver move so it
+	 * can do tiling things and book-keeping.
+	 *
+	 * @evict: whether this move is evicting the buffer from the graphics
+	 * address space
+	 */
 	void (*move_notify)(struct ttm_buffer_object *bo,
+			    bool evict,
 			    struct ttm_mem_reg *new_mem);
 	/* notify the driver we are taking a fault on this BO
 	 * and have reserved it */
diff -Naurp -x debian.hwe linux-4.10.x.ori/include/linux/pci-aspm.h linux-4.10.x/include/linux/pci-aspm.h
--- linux-4.10.x.ori/include/linux/pci-aspm.h	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/include/linux/pci-aspm.h	2017-04-10 11:27:25.836919000 +0200
@@ -29,6 +29,9 @@ void pcie_aspm_pm_state_change(struct pc
 void pcie_aspm_powersave_config_link(struct pci_dev *pdev);
 void pci_disable_link_state(struct pci_dev *pdev, int state);
 void pci_disable_link_state_locked(struct pci_dev *pdev, int state);
+/* gottwald@igel.com leave clear_aspm as it is, remove cause problems with 
+ * Tuxedo laptop (network with r8168 not working) */
+void pcie_clear_aspm(struct pci_bus *bus);
 void pcie_no_aspm(void);
 #else
 static inline void pcie_aspm_init_link_state(struct pci_dev *pdev)
@@ -46,6 +49,9 @@ static inline void pcie_aspm_powersave_c
 static inline void pci_disable_link_state(struct pci_dev *pdev, int state)
 {
 }
+static inline void pcie_clear_aspm(struct pci_bus *bus)
+{
+}
 static inline void pcie_no_aspm(void)
 {
 }
diff -Naurp -x debian.hwe linux-4.10.x.ori/include/linux/pci_ids.h linux-4.10.x/include/linux/pci_ids.h
--- linux-4.10.x.ori/include/linux/pci_ids.h	2017-05-03 11:18:05.164927000 +0200
+++ linux-4.10.x/include/linux/pci_ids.h	2017-06-21 11:26:54.470509000 +0200
@@ -2644,6 +2644,8 @@
 #define PCI_DEVICE_ID_INTEL_ALPINE_RIDGE_2C_BRIDGE  0x1576
 #define PCI_DEVICE_ID_INTEL_ALPINE_RIDGE_4C_NHI     0x1577
 #define PCI_DEVICE_ID_INTEL_ALPINE_RIDGE_4C_BRIDGE  0x1578
+#define PCI_DEVICE_ID_INTEL_ALPINE_RIDGE_C_4C_NHI   0x15d2
+#define PCI_DEVICE_ID_INTEL_ALPINE_RIDGE_C_4C_BRIDGE 0x15d3
 #define PCI_DEVICE_ID_INTEL_80960_RP	0x1960
 #define PCI_DEVICE_ID_INTEL_82840_HB	0x1a21
 #define PCI_DEVICE_ID_INTEL_82845_HB	0x1a30
diff -Naurp -x debian.hwe linux-4.10.x.ori/include/linux/usb.h linux-4.10.x/include/linux/usb.h
--- linux-4.10.x.ori/include/linux/usb.h	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/include/linux/usb.h	2017-04-10 11:27:25.836919000 +0200
@@ -617,6 +617,8 @@ struct usb_device {
 	struct usb3_lpm_parameters u1_params;
 	struct usb3_lpm_parameters u2_params;
 	unsigned lpm_disable_count;
+	/* IGEL to prevent driver disconnect */
+	unsigned disable_disconnect:1;
 };
 #define	to_usb_device(d) container_of(d, struct usb_device, dev)
 
diff -Naurp -x debian.hwe linux-4.10.x.ori/include/linux/xxhash.h linux-4.10.x/include/linux/xxhash.h
--- linux-4.10.x.ori/include/linux/xxhash.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-4.10.x/include/linux/xxhash.h	2017-10-30 10:05:19.610447000 +0100
@@ -0,0 +1,236 @@
+/*
+ * xxHash - Extremely Fast Hash algorithm
+ * Copyright (C) 2012-2016, Yann Collet.
+ *
+ * BSD 2-Clause License (http://www.opensource.org/licenses/bsd-license.php)
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ *   * Redistributions in binary form must reproduce the above
+ *     copyright notice, this list of conditions and the following disclaimer
+ *     in the documentation and/or other materials provided with the
+ *     distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ * This program is free software; you can redistribute it and/or modify it under
+ * the terms of the GNU General Public License version 2 as published by the
+ * Free Software Foundation. This program is dual-licensed; you may select
+ * either version 2 of the GNU General Public License ("GPL") or BSD license
+ * ("BSD").
+ *
+ * You can contact the author at:
+ * - xxHash homepage: http://cyan4973.github.io/xxHash/
+ * - xxHash source repository: https://github.com/Cyan4973/xxHash
+ */
+
+/*
+ * Notice extracted from xxHash homepage:
+ *
+ * xxHash is an extremely fast Hash algorithm, running at RAM speed limits.
+ * It also successfully passes all tests from the SMHasher suite.
+ *
+ * Comparison (single thread, Windows Seven 32 bits, using SMHasher on a Core 2
+ * Duo @3GHz)
+ *
+ * Name            Speed       Q.Score   Author
+ * xxHash          5.4 GB/s     10
+ * CrapWow         3.2 GB/s      2       Andrew
+ * MumurHash 3a    2.7 GB/s     10       Austin Appleby
+ * SpookyHash      2.0 GB/s     10       Bob Jenkins
+ * SBox            1.4 GB/s      9       Bret Mulvey
+ * Lookup3         1.2 GB/s      9       Bob Jenkins
+ * SuperFastHash   1.2 GB/s      1       Paul Hsieh
+ * CityHash64      1.05 GB/s    10       Pike & Alakuijala
+ * FNV             0.55 GB/s     5       Fowler, Noll, Vo
+ * CRC32           0.43 GB/s     9
+ * MD5-32          0.33 GB/s    10       Ronald L. Rivest
+ * SHA1-32         0.28 GB/s    10
+ *
+ * Q.Score is a measure of quality of the hash function.
+ * It depends on successfully passing SMHasher test set.
+ * 10 is a perfect score.
+ *
+ * A 64-bits version, named xxh64 offers much better speed,
+ * but for 64-bits applications only.
+ * Name     Speed on 64 bits    Speed on 32 bits
+ * xxh64       13.8 GB/s            1.9 GB/s
+ * xxh32        6.8 GB/s            6.0 GB/s
+ */
+
+#ifndef XXHASH_H
+#define XXHASH_H
+
+#include <linux/types.h>
+
+/*-****************************
+ * Simple Hash Functions
+ *****************************/
+
+/**
+ * xxh32() - calculate the 32-bit hash of the input with a given seed.
+ *
+ * @input:  The data to hash.
+ * @length: The length of the data to hash.
+ * @seed:   The seed can be used to alter the result predictably.
+ *
+ * Speed on Core 2 Duo @ 3 GHz (single thread, SMHasher benchmark) : 5.4 GB/s
+ *
+ * Return:  The 32-bit hash of the data.
+ */
+uint32_t xxh32(const void *input, size_t length, uint32_t seed);
+
+/**
+ * xxh64() - calculate the 64-bit hash of the input with a given seed.
+ *
+ * @input:  The data to hash.
+ * @length: The length of the data to hash.
+ * @seed:   The seed can be used to alter the result predictably.
+ *
+ * This function runs 2x faster on 64-bit systems, but slower on 32-bit systems.
+ *
+ * Return:  The 64-bit hash of the data.
+ */
+uint64_t xxh64(const void *input, size_t length, uint64_t seed);
+
+/*-****************************
+ * Streaming Hash Functions
+ *****************************/
+
+/*
+ * These definitions are only meant to allow allocation of XXH state
+ * statically, on stack, or in a struct for example.
+ * Do not use members directly.
+ */
+
+/**
+ * struct xxh32_state - private xxh32 state, do not use members directly
+ */
+struct xxh32_state {
+	uint32_t total_len_32;
+	uint32_t large_len;
+	uint32_t v1;
+	uint32_t v2;
+	uint32_t v3;
+	uint32_t v4;
+	uint32_t mem32[4];
+	uint32_t memsize;
+};
+
+/**
+ * struct xxh32_state - private xxh64 state, do not use members directly
+ */
+struct xxh64_state {
+	uint64_t total_len;
+	uint64_t v1;
+	uint64_t v2;
+	uint64_t v3;
+	uint64_t v4;
+	uint64_t mem64[4];
+	uint32_t memsize;
+};
+
+/**
+ * xxh32_reset() - reset the xxh32 state to start a new hashing operation
+ *
+ * @state: The xxh32 state to reset.
+ * @seed:  Initialize the hash state with this seed.
+ *
+ * Call this function on any xxh32_state to prepare for a new hashing operation.
+ */
+void xxh32_reset(struct xxh32_state *state, uint32_t seed);
+
+/**
+ * xxh32_update() - hash the data given and update the xxh32 state
+ *
+ * @state:  The xxh32 state to update.
+ * @input:  The data to hash.
+ * @length: The length of the data to hash.
+ *
+ * After calling xxh32_reset() call xxh32_update() as many times as necessary.
+ *
+ * Return:  Zero on success, otherwise an error code.
+ */
+int xxh32_update(struct xxh32_state *state, const void *input, size_t length);
+
+/**
+ * xxh32_digest() - produce the current xxh32 hash
+ *
+ * @state: Produce the current xxh32 hash of this state.
+ *
+ * A hash value can be produced at any time. It is still possible to continue
+ * inserting input into the hash state after a call to xxh32_digest(), and
+ * generate new hashes later on, by calling xxh32_digest() again.
+ *
+ * Return: The xxh32 hash stored in the state.
+ */
+uint32_t xxh32_digest(const struct xxh32_state *state);
+
+/**
+ * xxh64_reset() - reset the xxh64 state to start a new hashing operation
+ *
+ * @state: The xxh64 state to reset.
+ * @seed:  Initialize the hash state with this seed.
+ */
+void xxh64_reset(struct xxh64_state *state, uint64_t seed);
+
+/**
+ * xxh64_update() - hash the data given and update the xxh64 state
+ * @state:  The xxh64 state to update.
+ * @input:  The data to hash.
+ * @length: The length of the data to hash.
+ *
+ * After calling xxh64_reset() call xxh64_update() as many times as necessary.
+ *
+ * Return:  Zero on success, otherwise an error code.
+ */
+int xxh64_update(struct xxh64_state *state, const void *input, size_t length);
+
+/**
+ * xxh64_digest() - produce the current xxh64 hash
+ *
+ * @state: Produce the current xxh64 hash of this state.
+ *
+ * A hash value can be produced at any time. It is still possible to continue
+ * inserting input into the hash state after a call to xxh64_digest(), and
+ * generate new hashes later on, by calling xxh64_digest() again.
+ *
+ * Return: The xxh64 hash stored in the state.
+ */
+uint64_t xxh64_digest(const struct xxh64_state *state);
+
+/*-**************************
+ * Utils
+ ***************************/
+
+/**
+ * xxh32_copy_state() - copy the source state into the destination state
+ *
+ * @src: The source xxh32 state.
+ * @dst: The destination xxh32 state.
+ */
+void xxh32_copy_state(struct xxh32_state *dst, const struct xxh32_state *src);
+
+/**
+ * xxh64_copy_state() - copy the source state into the destination state
+ *
+ * @src: The source xxh64 state.
+ * @dst: The destination xxh64 state.
+ */
+void xxh64_copy_state(struct xxh64_state *dst, const struct xxh64_state *src);
+
+#endif /* XXHASH_H */
diff -Naurp -x debian.hwe linux-4.10.x.ori/include/linux/zstd.h linux-4.10.x/include/linux/zstd.h
--- linux-4.10.x.ori/include/linux/zstd.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-4.10.x/include/linux/zstd.h	2017-10-30 10:05:19.610447000 +0100
@@ -0,0 +1,1155 @@
+/*
+ * Copyright (c) 2016-present, Yann Collet, Facebook, Inc.
+ * All rights reserved.
+ *
+ * This source code is licensed under the BSD-style license found in the
+ * LICENSE file in the root directory of https://github.com/facebook/zstd.
+ *
+ * This program is free software; you can redistribute it and/or modify it under
+ * the terms of the GNU General Public License version 2 as published by the
+ * Free Software Foundation. This program is dual-licensed; you may select
+ * either version 2 of the GNU General Public License ("GPL") or BSD license
+ * ("BSD").
+ */
+
+#ifndef ZSTD_H
+#define ZSTD_H
+
+/* ======   Dependency   ======*/
+#include <linux/types.h>   /* size_t */
+
+
+/*-*****************************************************************************
+ * Introduction
+ *
+ * zstd, short for Zstandard, is a fast lossless compression algorithm,
+ * targeting real-time compression scenarios at zlib-level and better
+ * compression ratios. The zstd compression library provides in-memory
+ * compression and decompression functions. The library supports compression
+ * levels from 1 up to ZSTD_maxCLevel() which is 22. Levels >= 20, labeled
+ * ultra, should be used with caution, as they require more memory.
+ * Compression can be done in:
+ *  - a single step, reusing a context (described as Explicit memory management)
+ *  - unbounded multiple steps (described as Streaming compression)
+ * The compression ratio achievable on small data can be highly improved using
+ * compression with a dictionary in:
+ *  - a single step (described as Simple dictionary API)
+ *  - a single step, reusing a dictionary (described as Fast dictionary API)
+ ******************************************************************************/
+
+/*======  Helper functions  ======*/
+
+/**
+ * enum ZSTD_ErrorCode - zstd error codes
+ *
+ * Functions that return size_t can be checked for errors using ZSTD_isError()
+ * and the ZSTD_ErrorCode can be extracted using ZSTD_getErrorCode().
+ */
+typedef enum {
+	ZSTD_error_no_error,
+	ZSTD_error_GENERIC,
+	ZSTD_error_prefix_unknown,
+	ZSTD_error_version_unsupported,
+	ZSTD_error_parameter_unknown,
+	ZSTD_error_frameParameter_unsupported,
+	ZSTD_error_frameParameter_unsupportedBy32bits,
+	ZSTD_error_frameParameter_windowTooLarge,
+	ZSTD_error_compressionParameter_unsupported,
+	ZSTD_error_init_missing,
+	ZSTD_error_memory_allocation,
+	ZSTD_error_stage_wrong,
+	ZSTD_error_dstSize_tooSmall,
+	ZSTD_error_srcSize_wrong,
+	ZSTD_error_corruption_detected,
+	ZSTD_error_checksum_wrong,
+	ZSTD_error_tableLog_tooLarge,
+	ZSTD_error_maxSymbolValue_tooLarge,
+	ZSTD_error_maxSymbolValue_tooSmall,
+	ZSTD_error_dictionary_corrupted,
+	ZSTD_error_dictionary_wrong,
+	ZSTD_error_dictionaryCreation_failed,
+	ZSTD_error_maxCode
+} ZSTD_ErrorCode;
+
+/**
+ * ZSTD_maxCLevel() - maximum compression level available
+ *
+ * Return: Maximum compression level available.
+ */
+int ZSTD_maxCLevel(void);
+/**
+ * ZSTD_compressBound() - maximum compressed size in worst case scenario
+ * @srcSize: The size of the data to compress.
+ *
+ * Return:   The maximum compressed size in the worst case scenario.
+ */
+size_t ZSTD_compressBound(size_t srcSize);
+/**
+ * ZSTD_isError() - tells if a size_t function result is an error code
+ * @code:  The function result to check for error.
+ *
+ * Return: Non-zero iff the code is an error.
+ */
+static __attribute__((unused)) unsigned int ZSTD_isError(size_t code)
+{
+	return code > (size_t)-ZSTD_error_maxCode;
+}
+/**
+ * ZSTD_getErrorCode() - translates an error function result to a ZSTD_ErrorCode
+ * @functionResult: The result of a function for which ZSTD_isError() is true.
+ *
+ * Return:          The ZSTD_ErrorCode corresponding to the functionResult or 0
+ *                  if the functionResult isn't an error.
+ */
+static __attribute__((unused)) ZSTD_ErrorCode ZSTD_getErrorCode(
+	size_t functionResult)
+{
+	if (!ZSTD_isError(functionResult))
+		return (ZSTD_ErrorCode)0;
+	return (ZSTD_ErrorCode)(0 - functionResult);
+}
+
+/**
+ * enum ZSTD_strategy - zstd compression search strategy
+ *
+ * From faster to stronger.
+ */
+typedef enum {
+	ZSTD_fast,
+	ZSTD_dfast,
+	ZSTD_greedy,
+	ZSTD_lazy,
+	ZSTD_lazy2,
+	ZSTD_btlazy2,
+	ZSTD_btopt,
+	ZSTD_btopt2
+} ZSTD_strategy;
+
+/**
+ * struct ZSTD_compressionParameters - zstd compression parameters
+ * @windowLog:    Log of the largest match distance. Larger means more
+ *                compression, and more memory needed during decompression.
+ * @chainLog:     Fully searched segment. Larger means more compression, slower,
+ *                and more memory (useless for fast).
+ * @hashLog:      Dispatch table. Larger means more compression,
+ *                slower, and more memory.
+ * @searchLog:    Number of searches. Larger means more compression and slower.
+ * @searchLength: Match length searched. Larger means faster decompression,
+ *                sometimes less compression.
+ * @targetLength: Acceptable match size for optimal parser (only). Larger means
+ *                more compression, and slower.
+ * @strategy:     The zstd compression strategy.
+ */
+typedef struct {
+	unsigned int windowLog;
+	unsigned int chainLog;
+	unsigned int hashLog;
+	unsigned int searchLog;
+	unsigned int searchLength;
+	unsigned int targetLength;
+	ZSTD_strategy strategy;
+} ZSTD_compressionParameters;
+
+/**
+ * struct ZSTD_frameParameters - zstd frame parameters
+ * @contentSizeFlag: Controls whether content size will be present in the frame
+ *                   header (when known).
+ * @checksumFlag:    Controls whether a 32-bit checksum is generated at the end
+ *                   of the frame for error detection.
+ * @noDictIDFlag:    Controls whether dictID will be saved into the frame header
+ *                   when using dictionary compression.
+ *
+ * The default value is all fields set to 0.
+ */
+typedef struct {
+	unsigned int contentSizeFlag;
+	unsigned int checksumFlag;
+	unsigned int noDictIDFlag;
+} ZSTD_frameParameters;
+
+/**
+ * struct ZSTD_parameters - zstd parameters
+ * @cParams: The compression parameters.
+ * @fParams: The frame parameters.
+ */
+typedef struct {
+	ZSTD_compressionParameters cParams;
+	ZSTD_frameParameters fParams;
+} ZSTD_parameters;
+
+/**
+ * ZSTD_getCParams() - returns ZSTD_compressionParameters for selected level
+ * @compressionLevel: The compression level from 1 to ZSTD_maxCLevel().
+ * @estimatedSrcSize: The estimated source size to compress or 0 if unknown.
+ * @dictSize:         The dictionary size or 0 if a dictionary isn't being used.
+ *
+ * Return:            The selected ZSTD_compressionParameters.
+ */
+ZSTD_compressionParameters ZSTD_getCParams(int compressionLevel,
+	unsigned long long estimatedSrcSize, size_t dictSize);
+
+/**
+ * ZSTD_getParams() - returns ZSTD_parameters for selected level
+ * @compressionLevel: The compression level from 1 to ZSTD_maxCLevel().
+ * @estimatedSrcSize: The estimated source size to compress or 0 if unknown.
+ * @dictSize:         The dictionary size or 0 if a dictionary isn't being used.
+ *
+ * The same as ZSTD_getCParams() except also selects the default frame
+ * parameters (all zero).
+ *
+ * Return:            The selected ZSTD_parameters.
+ */
+ZSTD_parameters ZSTD_getParams(int compressionLevel,
+	unsigned long long estimatedSrcSize, size_t dictSize);
+
+/*-*************************************
+ * Explicit memory management
+ **************************************/
+
+/**
+ * ZSTD_CCtxWorkspaceBound() - amount of memory needed to initialize a ZSTD_CCtx
+ * @cParams: The compression parameters to be used for compression.
+ *
+ * If multiple compression parameters might be used, the caller must call
+ * ZSTD_CCtxWorkspaceBound() for each set of parameters and use the maximum
+ * size.
+ *
+ * Return:   A lower bound on the size of the workspace that is passed to
+ *           ZSTD_initCCtx().
+ */
+size_t ZSTD_CCtxWorkspaceBound(ZSTD_compressionParameters cParams);
+
+/**
+ * struct ZSTD_CCtx - the zstd compression context
+ *
+ * When compressing many times it is recommended to allocate a context just once
+ * and reuse it for each successive compression operation.
+ */
+typedef struct ZSTD_CCtx_s ZSTD_CCtx;
+/**
+ * ZSTD_initCCtx() - initialize a zstd compression context
+ * @workspace:     The workspace to emplace the context into. It must outlive
+ *                 the returned context.
+ * @workspaceSize: The size of workspace. Use ZSTD_CCtxWorkspaceBound() to
+ *                 determine how large the workspace must be.
+ *
+ * Return:         A compression context emplaced into workspace.
+ */
+ZSTD_CCtx *ZSTD_initCCtx(void *workspace, size_t workspaceSize);
+
+/**
+ * ZSTD_compressCCtx() - compress src into dst
+ * @ctx:         The context. Must have been initialized with a workspace at
+ *               least as large as ZSTD_CCtxWorkspaceBound(params.cParams).
+ * @dst:         The buffer to compress src into.
+ * @dstCapacity: The size of the destination buffer. May be any size, but
+ *               ZSTD_compressBound(srcSize) is guaranteed to be large enough.
+ * @src:         The data to compress.
+ * @srcSize:     The size of the data to compress.
+ * @params:      The parameters to use for compression. See ZSTD_getParams().
+ *
+ * Return:       The compressed size or an error, which can be checked using
+ *               ZSTD_isError().
+ */
+size_t ZSTD_compressCCtx(ZSTD_CCtx *ctx, void *dst, size_t dstCapacity,
+	const void *src, size_t srcSize, ZSTD_parameters params);
+
+/**
+ * ZSTD_DCtxWorkspaceBound() - amount of memory needed to initialize a ZSTD_DCtx
+ *
+ * Return: A lower bound on the size of the workspace that is passed to
+ *         ZSTD_initDCtx().
+ */
+size_t ZSTD_DCtxWorkspaceBound(void);
+
+/**
+ * struct ZSTD_DCtx - the zstd decompression context
+ *
+ * When decompressing many times it is recommended to allocate a context just
+ * once and reuse it for each successive decompression operation.
+ */
+typedef struct ZSTD_DCtx_s ZSTD_DCtx;
+/**
+ * ZSTD_initDCtx() - initialize a zstd decompression context
+ * @workspace:     The workspace to emplace the context into. It must outlive
+ *                 the returned context.
+ * @workspaceSize: The size of workspace. Use ZSTD_DCtxWorkspaceBound() to
+ *                 determine how large the workspace must be.
+ *
+ * Return:         A decompression context emplaced into workspace.
+ */
+ZSTD_DCtx *ZSTD_initDCtx(void *workspace, size_t workspaceSize);
+
+/**
+ * ZSTD_decompressDCtx() - decompress zstd compressed src into dst
+ * @ctx:         The decompression context.
+ * @dst:         The buffer to decompress src into.
+ * @dstCapacity: The size of the destination buffer. Must be at least as large
+ *               as the decompressed size. If the caller cannot upper bound the
+ *               decompressed size, then it's better to use the streaming API.
+ * @src:         The zstd compressed data to decompress. Multiple concatenated
+ *               frames and skippable frames are allowed.
+ * @srcSize:     The exact size of the data to decompress.
+ *
+ * Return:       The decompressed size or an error, which can be checked using
+ *               ZSTD_isError().
+ */
+size_t ZSTD_decompressDCtx(ZSTD_DCtx *ctx, void *dst, size_t dstCapacity,
+	const void *src, size_t srcSize);
+
+/*-************************
+ * Simple dictionary API
+ **************************/
+
+/**
+ * ZSTD_compress_usingDict() - compress src into dst using a dictionary
+ * @ctx:         The context. Must have been initialized with a workspace at
+ *               least as large as ZSTD_CCtxWorkspaceBound(params.cParams).
+ * @dst:         The buffer to compress src into.
+ * @dstCapacity: The size of the destination buffer. May be any size, but
+ *               ZSTD_compressBound(srcSize) is guaranteed to be large enough.
+ * @src:         The data to compress.
+ * @srcSize:     The size of the data to compress.
+ * @dict:        The dictionary to use for compression.
+ * @dictSize:    The size of the dictionary.
+ * @params:      The parameters to use for compression. See ZSTD_getParams().
+ *
+ * Compression using a predefined dictionary. The same dictionary must be used
+ * during decompression.
+ *
+ * Return:       The compressed size or an error, which can be checked using
+ *               ZSTD_isError().
+ */
+size_t ZSTD_compress_usingDict(ZSTD_CCtx *ctx, void *dst, size_t dstCapacity,
+	const void *src, size_t srcSize, const void *dict, size_t dictSize,
+	ZSTD_parameters params);
+
+/**
+ * ZSTD_decompress_usingDict() - decompress src into dst using a dictionary
+ * @ctx:         The decompression context.
+ * @dst:         The buffer to decompress src into.
+ * @dstCapacity: The size of the destination buffer. Must be at least as large
+ *               as the decompressed size. If the caller cannot upper bound the
+ *               decompressed size, then it's better to use the streaming API.
+ * @src:         The zstd compressed data to decompress. Multiple concatenated
+ *               frames and skippable frames are allowed.
+ * @srcSize:     The exact size of the data to decompress.
+ * @dict:        The dictionary to use for decompression. The same dictionary
+ *               must've been used to compress the data.
+ * @dictSize:    The size of the dictionary.
+ *
+ * Return:       The decompressed size or an error, which can be checked using
+ *               ZSTD_isError().
+ */
+size_t ZSTD_decompress_usingDict(ZSTD_DCtx *ctx, void *dst, size_t dstCapacity,
+	const void *src, size_t srcSize, const void *dict, size_t dictSize);
+
+/*-**************************
+ * Fast dictionary API
+ ***************************/
+
+/**
+ * ZSTD_CDictWorkspaceBound() - memory needed to initialize a ZSTD_CDict
+ * @cParams: The compression parameters to be used for compression.
+ *
+ * Return:   A lower bound on the size of the workspace that is passed to
+ *           ZSTD_initCDict().
+ */
+size_t ZSTD_CDictWorkspaceBound(ZSTD_compressionParameters cParams);
+
+/**
+ * struct ZSTD_CDict - a digested dictionary to be used for compression
+ */
+typedef struct ZSTD_CDict_s ZSTD_CDict;
+
+/**
+ * ZSTD_initCDict() - initialize a digested dictionary for compression
+ * @dictBuffer:    The dictionary to digest. The buffer is referenced by the
+ *                 ZSTD_CDict so it must outlive the returned ZSTD_CDict.
+ * @dictSize:      The size of the dictionary.
+ * @params:        The parameters to use for compression. See ZSTD_getParams().
+ * @workspace:     The workspace. It must outlive the returned ZSTD_CDict.
+ * @workspaceSize: The workspace size. Must be at least
+ *                 ZSTD_CDictWorkspaceBound(params.cParams).
+ *
+ * When compressing multiple messages / blocks with the same dictionary it is
+ * recommended to load it just once. The ZSTD_CDict merely references the
+ * dictBuffer, so it must outlive the returned ZSTD_CDict.
+ *
+ * Return:         The digested dictionary emplaced into workspace.
+ */
+ZSTD_CDict *ZSTD_initCDict(const void *dictBuffer, size_t dictSize,
+	ZSTD_parameters params, void *workspace, size_t workspaceSize);
+
+/**
+ * ZSTD_compress_usingCDict() - compress src into dst using a ZSTD_CDict
+ * @ctx:         The context. Must have been initialized with a workspace at
+ *               least as large as ZSTD_CCtxWorkspaceBound(cParams) where
+ *               cParams are the compression parameters used to initialize the
+ *               cdict.
+ * @dst:         The buffer to compress src into.
+ * @dstCapacity: The size of the destination buffer. May be any size, but
+ *               ZSTD_compressBound(srcSize) is guaranteed to be large enough.
+ * @src:         The data to compress.
+ * @srcSize:     The size of the data to compress.
+ * @cdict:       The digested dictionary to use for compression.
+ * @params:      The parameters to use for compression. See ZSTD_getParams().
+ *
+ * Compression using a digested dictionary. The same dictionary must be used
+ * during decompression.
+ *
+ * Return:       The compressed size or an error, which can be checked using
+ *               ZSTD_isError().
+ */
+size_t ZSTD_compress_usingCDict(ZSTD_CCtx *cctx, void *dst, size_t dstCapacity,
+	const void *src, size_t srcSize, const ZSTD_CDict *cdict);
+
+
+/**
+ * ZSTD_DDictWorkspaceBound() - memory needed to initialize a ZSTD_DDict
+ *
+ * Return:  A lower bound on the size of the workspace that is passed to
+ *          ZSTD_initDDict().
+ */
+size_t ZSTD_DDictWorkspaceBound(void);
+
+/**
+ * struct ZSTD_DDict - a digested dictionary to be used for decompression
+ */
+typedef struct ZSTD_DDict_s ZSTD_DDict;
+
+/**
+ * ZSTD_initDDict() - initialize a digested dictionary for decompression
+ * @dictBuffer:    The dictionary to digest. The buffer is referenced by the
+ *                 ZSTD_DDict so it must outlive the returned ZSTD_DDict.
+ * @dictSize:      The size of the dictionary.
+ * @workspace:     The workspace. It must outlive the returned ZSTD_DDict.
+ * @workspaceSize: The workspace size. Must be at least
+ *                 ZSTD_DDictWorkspaceBound().
+ *
+ * When decompressing multiple messages / blocks with the same dictionary it is
+ * recommended to load it just once. The ZSTD_DDict merely references the
+ * dictBuffer, so it must outlive the returned ZSTD_DDict.
+ *
+ * Return:         The digested dictionary emplaced into workspace.
+ */
+ZSTD_DDict *ZSTD_initDDict(const void *dictBuffer, size_t dictSize,
+	void *workspace, size_t workspaceSize);
+
+/**
+ * ZSTD_decompress_usingDDict() - decompress src into dst using a ZSTD_DDict
+ * @ctx:         The decompression context.
+ * @dst:         The buffer to decompress src into.
+ * @dstCapacity: The size of the destination buffer. Must be at least as large
+ *               as the decompressed size. If the caller cannot upper bound the
+ *               decompressed size, then it's better to use the streaming API.
+ * @src:         The zstd compressed data to decompress. Multiple concatenated
+ *               frames and skippable frames are allowed.
+ * @srcSize:     The exact size of the data to decompress.
+ * @ddict:       The digested dictionary to use for decompression. The same
+ *               dictionary must've been used to compress the data.
+ *
+ * Return:       The decompressed size or an error, which can be checked using
+ *               ZSTD_isError().
+ */
+size_t ZSTD_decompress_usingDDict(ZSTD_DCtx *dctx, void *dst,
+	size_t dstCapacity, const void *src, size_t srcSize,
+	const ZSTD_DDict *ddict);
+
+
+/*-**************************
+ * Streaming
+ ***************************/
+
+/**
+ * struct ZSTD_inBuffer - input buffer for streaming
+ * @src:  Start of the input buffer.
+ * @size: Size of the input buffer.
+ * @pos:  Position where reading stopped. Will be updated.
+ *        Necessarily 0 <= pos <= size.
+ */
+typedef struct ZSTD_inBuffer_s {
+	const void *src;
+	size_t size;
+	size_t pos;
+} ZSTD_inBuffer;
+
+/**
+ * struct ZSTD_outBuffer - output buffer for streaming
+ * @dst:  Start of the output buffer.
+ * @size: Size of the output buffer.
+ * @pos:  Position where writing stopped. Will be updated.
+ *        Necessarily 0 <= pos <= size.
+ */
+typedef struct ZSTD_outBuffer_s {
+	void *dst;
+	size_t size;
+	size_t pos;
+} ZSTD_outBuffer;
+
+
+
+/*-*****************************************************************************
+ * Streaming compression - HowTo
+ *
+ * A ZSTD_CStream object is required to track streaming operation.
+ * Use ZSTD_initCStream() to initialize a ZSTD_CStream object.
+ * ZSTD_CStream objects can be reused multiple times on consecutive compression
+ * operations. It is recommended to re-use ZSTD_CStream in situations where many
+ * streaming operations will be achieved consecutively. Use one separate
+ * ZSTD_CStream per thread for parallel execution.
+ *
+ * Use ZSTD_compressStream() repetitively to consume input stream.
+ * The function will automatically update both `pos` fields.
+ * Note that it may not consume the entire input, in which case `pos < size`,
+ * and it's up to the caller to present again remaining data.
+ * It returns a hint for the preferred number of bytes to use as an input for
+ * the next function call.
+ *
+ * At any moment, it's possible to flush whatever data remains within internal
+ * buffer, using ZSTD_flushStream(). `output->pos` will be updated. There might
+ * still be some content left within the internal buffer if `output->size` is
+ * too small. It returns the number of bytes left in the internal buffer and
+ * must be called until it returns 0.
+ *
+ * ZSTD_endStream() instructs to finish a frame. It will perform a flush and
+ * write frame epilogue. The epilogue is required for decoders to consider a
+ * frame completed. Similar to ZSTD_flushStream(), it may not be able to flush
+ * the full content if `output->size` is too small. In which case, call again
+ * ZSTD_endStream() to complete the flush. It returns the number of bytes left
+ * in the internal buffer and must be called until it returns 0.
+ ******************************************************************************/
+
+/**
+ * ZSTD_CStreamWorkspaceBound() - memory needed to initialize a ZSTD_CStream
+ * @cParams: The compression parameters to be used for compression.
+ *
+ * Return:   A lower bound on the size of the workspace that is passed to
+ *           ZSTD_initCStream() and ZSTD_initCStream_usingCDict().
+ */
+size_t ZSTD_CStreamWorkspaceBound(ZSTD_compressionParameters cParams);
+
+/**
+ * struct ZSTD_CStream - the zstd streaming compression context
+ */
+typedef struct ZSTD_CStream_s ZSTD_CStream;
+
+/*===== ZSTD_CStream management functions =====*/
+/**
+ * ZSTD_initCStream() - initialize a zstd streaming compression context
+ * @params:         The zstd compression parameters.
+ * @pledgedSrcSize: If params.fParams.contentSizeFlag == 1 then the caller must
+ *                  pass the source size (zero means empty source). Otherwise,
+ *                  the caller may optionally pass the source size, or zero if
+ *                  unknown.
+ * @workspace:      The workspace to emplace the context into. It must outlive
+ *                  the returned context.
+ * @workspaceSize:  The size of workspace.
+ *                  Use ZSTD_CStreamWorkspaceBound(params.cParams) to determine
+ *                  how large the workspace must be.
+ *
+ * Return:          The zstd streaming compression context.
+ */
+ZSTD_CStream *ZSTD_initCStream(ZSTD_parameters params,
+	unsigned long long pledgedSrcSize, void *workspace,
+	size_t workspaceSize);
+
+/**
+ * ZSTD_initCStream_usingCDict() - initialize a streaming compression context
+ * @cdict:          The digested dictionary to use for compression.
+ * @pledgedSrcSize: Optionally the source size, or zero if unknown.
+ * @workspace:      The workspace to emplace the context into. It must outlive
+ *                  the returned context.
+ * @workspaceSize:  The size of workspace. Call ZSTD_CStreamWorkspaceBound()
+ *                  with the cParams used to initialize the cdict to determine
+ *                  how large the workspace must be.
+ *
+ * Return:          The zstd streaming compression context.
+ */
+ZSTD_CStream *ZSTD_initCStream_usingCDict(const ZSTD_CDict *cdict,
+	unsigned long long pledgedSrcSize, void *workspace,
+	size_t workspaceSize);
+
+/*===== Streaming compression functions =====*/
+/**
+ * ZSTD_resetCStream() - reset the context using parameters from creation
+ * @zcs:            The zstd streaming compression context to reset.
+ * @pledgedSrcSize: Optionally the source size, or zero if unknown.
+ *
+ * Resets the context using the parameters from creation. Skips dictionary
+ * loading, since it can be reused. If `pledgedSrcSize` is non-zero the frame
+ * content size is always written into the frame header.
+ *
+ * Return:          Zero or an error, which can be checked using ZSTD_isError().
+ */
+size_t ZSTD_resetCStream(ZSTD_CStream *zcs, unsigned long long pledgedSrcSize);
+/**
+ * ZSTD_compressStream() - streaming compress some of input into output
+ * @zcs:    The zstd streaming compression context.
+ * @output: Destination buffer. `output->pos` is updated to indicate how much
+ *          compressed data was written.
+ * @input:  Source buffer. `input->pos` is updated to indicate how much data was
+ *          read. Note that it may not consume the entire input, in which case
+ *          `input->pos < input->size`, and it's up to the caller to present
+ *          remaining data again.
+ *
+ * The `input` and `output` buffers may be any size. Guaranteed to make some
+ * forward progress if `input` and `output` are not empty.
+ *
+ * Return:  A hint for the number of bytes to use as the input for the next
+ *          function call or an error, which can be checked using
+ *          ZSTD_isError().
+ */
+size_t ZSTD_compressStream(ZSTD_CStream *zcs, ZSTD_outBuffer *output,
+	ZSTD_inBuffer *input);
+/**
+ * ZSTD_flushStream() - flush internal buffers into output
+ * @zcs:    The zstd streaming compression context.
+ * @output: Destination buffer. `output->pos` is updated to indicate how much
+ *          compressed data was written.
+ *
+ * ZSTD_flushStream() must be called until it returns 0, meaning all the data
+ * has been flushed. Since ZSTD_flushStream() causes a block to be ended,
+ * calling it too often will degrade the compression ratio.
+ *
+ * Return:  The number of bytes still present within internal buffers or an
+ *          error, which can be checked using ZSTD_isError().
+ */
+size_t ZSTD_flushStream(ZSTD_CStream *zcs, ZSTD_outBuffer *output);
+/**
+ * ZSTD_endStream() - flush internal buffers into output and end the frame
+ * @zcs:    The zstd streaming compression context.
+ * @output: Destination buffer. `output->pos` is updated to indicate how much
+ *          compressed data was written.
+ *
+ * ZSTD_endStream() must be called until it returns 0, meaning all the data has
+ * been flushed and the frame epilogue has been written.
+ *
+ * Return:  The number of bytes still present within internal buffers or an
+ *          error, which can be checked using ZSTD_isError().
+ */
+size_t ZSTD_endStream(ZSTD_CStream *zcs, ZSTD_outBuffer *output);
+
+/**
+ * ZSTD_CStreamInSize() - recommended size for the input buffer
+ *
+ * Return: The recommended size for the input buffer.
+ */
+size_t ZSTD_CStreamInSize(void);
+/**
+ * ZSTD_CStreamOutSize() - recommended size for the output buffer
+ *
+ * When the output buffer is at least this large, it is guaranteed to be large
+ * enough to flush at least one complete compressed block.
+ *
+ * Return: The recommended size for the output buffer.
+ */
+size_t ZSTD_CStreamOutSize(void);
+
+
+
+/*-*****************************************************************************
+ * Streaming decompression - HowTo
+ *
+ * A ZSTD_DStream object is required to track streaming operations.
+ * Use ZSTD_initDStream() to initialize a ZSTD_DStream object.
+ * ZSTD_DStream objects can be re-used multiple times.
+ *
+ * Use ZSTD_decompressStream() repetitively to consume your input.
+ * The function will update both `pos` fields.
+ * If `input->pos < input->size`, some input has not been consumed.
+ * It's up to the caller to present again remaining data.
+ * If `output->pos < output->size`, decoder has flushed everything it could.
+ * Returns 0 iff a frame is completely decoded and fully flushed.
+ * Otherwise it returns a suggested next input size that will never load more
+ * than the current frame.
+ ******************************************************************************/
+
+/**
+ * ZSTD_DStreamWorkspaceBound() - memory needed to initialize a ZSTD_DStream
+ * @maxWindowSize: The maximum window size allowed for compressed frames.
+ *
+ * Return:         A lower bound on the size of the workspace that is passed to
+ *                 ZSTD_initDStream() and ZSTD_initDStream_usingDDict().
+ */
+size_t ZSTD_DStreamWorkspaceBound(size_t maxWindowSize);
+
+/**
+ * struct ZSTD_DStream - the zstd streaming decompression context
+ */
+typedef struct ZSTD_DStream_s ZSTD_DStream;
+/*===== ZSTD_DStream management functions =====*/
+/**
+ * ZSTD_initDStream() - initialize a zstd streaming decompression context
+ * @maxWindowSize: The maximum window size allowed for compressed frames.
+ * @workspace:     The workspace to emplace the context into. It must outlive
+ *                 the returned context.
+ * @workspaceSize: The size of workspace.
+ *                 Use ZSTD_DStreamWorkspaceBound(maxWindowSize) to determine
+ *                 how large the workspace must be.
+ *
+ * Return:         The zstd streaming decompression context.
+ */
+ZSTD_DStream *ZSTD_initDStream(size_t maxWindowSize, void *workspace,
+	size_t workspaceSize);
+/**
+ * ZSTD_initDStream_usingDDict() - initialize streaming decompression context
+ * @maxWindowSize: The maximum window size allowed for compressed frames.
+ * @ddict:         The digested dictionary to use for decompression.
+ * @workspace:     The workspace to emplace the context into. It must outlive
+ *                 the returned context.
+ * @workspaceSize: The size of workspace.
+ *                 Use ZSTD_DStreamWorkspaceBound(maxWindowSize) to determine
+ *                 how large the workspace must be.
+ *
+ * Return:         The zstd streaming decompression context.
+ */
+ZSTD_DStream *ZSTD_initDStream_usingDDict(size_t maxWindowSize,
+	const ZSTD_DDict *ddict, void *workspace, size_t workspaceSize);
+
+/*===== Streaming decompression functions =====*/
+/**
+ * ZSTD_resetDStream() - reset the context using parameters from creation
+ * @zds:   The zstd streaming decompression context to reset.
+ *
+ * Resets the context using the parameters from creation. Skips dictionary
+ * loading, since it can be reused.
+ *
+ * Return: Zero or an error, which can be checked using ZSTD_isError().
+ */
+size_t ZSTD_resetDStream(ZSTD_DStream *zds);
+/**
+ * ZSTD_decompressStream() - streaming decompress some of input into output
+ * @zds:    The zstd streaming decompression context.
+ * @output: Destination buffer. `output.pos` is updated to indicate how much
+ *          decompressed data was written.
+ * @input:  Source buffer. `input.pos` is updated to indicate how much data was
+ *          read. Note that it may not consume the entire input, in which case
+ *          `input.pos < input.size`, and it's up to the caller to present
+ *          remaining data again.
+ *
+ * The `input` and `output` buffers may be any size. Guaranteed to make some
+ * forward progress if `input` and `output` are not empty.
+ * ZSTD_decompressStream() will not consume the last byte of the frame until
+ * the entire frame is flushed.
+ *
+ * Return:  Returns 0 iff a frame is completely decoded and fully flushed.
+ *          Otherwise returns a hint for the number of bytes to use as the input
+ *          for the next function call or an error, which can be checked using
+ *          ZSTD_isError(). The size hint will never load more than the frame.
+ */
+size_t ZSTD_decompressStream(ZSTD_DStream *zds, ZSTD_outBuffer *output,
+	ZSTD_inBuffer *input);
+
+/**
+ * ZSTD_DStreamInSize() - recommended size for the input buffer
+ *
+ * Return: The recommended size for the input buffer.
+ */
+size_t ZSTD_DStreamInSize(void);
+/**
+ * ZSTD_DStreamOutSize() - recommended size for the output buffer
+ *
+ * When the output buffer is at least this large, it is guaranteed to be large
+ * enough to flush at least one complete decompressed block.
+ *
+ * Return: The recommended size for the output buffer.
+ */
+size_t ZSTD_DStreamOutSize(void);
+
+
+/* --- Constants ---*/
+#define ZSTD_MAGICNUMBER            0xFD2FB528   /* >= v0.8.0 */
+#define ZSTD_MAGIC_SKIPPABLE_START  0x184D2A50U
+
+#define ZSTD_CONTENTSIZE_UNKNOWN (0ULL - 1)
+#define ZSTD_CONTENTSIZE_ERROR   (0ULL - 2)
+
+#define ZSTD_WINDOWLOG_MAX_32  27
+#define ZSTD_WINDOWLOG_MAX_64  27
+#define ZSTD_WINDOWLOG_MAX \
+	((unsigned int)(sizeof(size_t) == 4 \
+		? ZSTD_WINDOWLOG_MAX_32 \
+		: ZSTD_WINDOWLOG_MAX_64))
+#define ZSTD_WINDOWLOG_MIN 10
+#define ZSTD_HASHLOG_MAX ZSTD_WINDOWLOG_MAX
+#define ZSTD_HASHLOG_MIN        6
+#define ZSTD_CHAINLOG_MAX     (ZSTD_WINDOWLOG_MAX+1)
+#define ZSTD_CHAINLOG_MIN      ZSTD_HASHLOG_MIN
+#define ZSTD_HASHLOG3_MAX      17
+#define ZSTD_SEARCHLOG_MAX    (ZSTD_WINDOWLOG_MAX-1)
+#define ZSTD_SEARCHLOG_MIN      1
+/* only for ZSTD_fast, other strategies are limited to 6 */
+#define ZSTD_SEARCHLENGTH_MAX   7
+/* only for ZSTD_btopt, other strategies are limited to 4 */
+#define ZSTD_SEARCHLENGTH_MIN   3
+#define ZSTD_TARGETLENGTH_MIN   4
+#define ZSTD_TARGETLENGTH_MAX 999
+
+/* for static allocation */
+#define ZSTD_FRAMEHEADERSIZE_MAX 18
+#define ZSTD_FRAMEHEADERSIZE_MIN  6
+static const size_t ZSTD_frameHeaderSize_prefix = 5;
+static const size_t ZSTD_frameHeaderSize_min = ZSTD_FRAMEHEADERSIZE_MIN;
+static const size_t ZSTD_frameHeaderSize_max = ZSTD_FRAMEHEADERSIZE_MAX;
+/* magic number + skippable frame length */
+static const size_t ZSTD_skippableHeaderSize = 8;
+
+
+/*-*************************************
+ * Compressed size functions
+ **************************************/
+
+/**
+ * ZSTD_findFrameCompressedSize() - returns the size of a compressed frame
+ * @src:     Source buffer. It should point to the start of a zstd encoded frame
+ *           or a skippable frame.
+ * @srcSize: The size of the source buffer. It must be at least as large as the
+ *           size of the frame.
+ *
+ * Return:   The compressed size of the frame pointed to by `src` or an error,
+ *           which can be check with ZSTD_isError().
+ *           Suitable to pass to ZSTD_decompress() or similar functions.
+ */
+size_t ZSTD_findFrameCompressedSize(const void *src, size_t srcSize);
+
+/*-*************************************
+ * Decompressed size functions
+ **************************************/
+/**
+ * ZSTD_getFrameContentSize() - returns the content size in a zstd frame header
+ * @src:     It should point to the start of a zstd encoded frame.
+ * @srcSize: The size of the source buffer. It must be at least as large as the
+ *           frame header. `ZSTD_frameHeaderSize_max` is always large enough.
+ *
+ * Return:   The frame content size stored in the frame header if known.
+ *           `ZSTD_CONTENTSIZE_UNKNOWN` if the content size isn't stored in the
+ *           frame header. `ZSTD_CONTENTSIZE_ERROR` on invalid input.
+ */
+unsigned long long ZSTD_getFrameContentSize(const void *src, size_t srcSize);
+
+/**
+ * ZSTD_findDecompressedSize() - returns decompressed size of a series of frames
+ * @src:     It should point to the start of a series of zstd encoded and/or
+ *           skippable frames.
+ * @srcSize: The exact size of the series of frames.
+ *
+ * If any zstd encoded frame in the series doesn't have the frame content size
+ * set, `ZSTD_CONTENTSIZE_UNKNOWN` is returned. But frame content size is always
+ * set when using ZSTD_compress(). The decompressed size can be very large.
+ * If the source is untrusted, the decompressed size could be wrong or
+ * intentionally modified. Always ensure the result fits within the
+ * application's authorized limits. ZSTD_findDecompressedSize() handles multiple
+ * frames, and so it must traverse the input to read each frame header. This is
+ * efficient as most of the data is skipped, however it does mean that all frame
+ * data must be present and valid.
+ *
+ * Return:   Decompressed size of all the data contained in the frames if known.
+ *           `ZSTD_CONTENTSIZE_UNKNOWN` if the decompressed size is unknown.
+ *           `ZSTD_CONTENTSIZE_ERROR` if an error occurred.
+ */
+unsigned long long ZSTD_findDecompressedSize(const void *src, size_t srcSize);
+
+/*-*************************************
+ * Advanced compression functions
+ **************************************/
+/**
+ * ZSTD_checkCParams() - ensure parameter values remain within authorized range
+ * @cParams: The zstd compression parameters.
+ *
+ * Return:   Zero or an error, which can be checked using ZSTD_isError().
+ */
+size_t ZSTD_checkCParams(ZSTD_compressionParameters cParams);
+
+/**
+ * ZSTD_adjustCParams() - optimize parameters for a given srcSize and dictSize
+ * @srcSize:  Optionally the estimated source size, or zero if unknown.
+ * @dictSize: Optionally the estimated dictionary size, or zero if unknown.
+ *
+ * Return:    The optimized parameters.
+ */
+ZSTD_compressionParameters ZSTD_adjustCParams(
+	ZSTD_compressionParameters cParams, unsigned long long srcSize,
+	size_t dictSize);
+
+/*--- Advanced decompression functions ---*/
+
+/**
+ * ZSTD_isFrame() - returns true iff the buffer starts with a valid frame
+ * @buffer: The source buffer to check.
+ * @size:   The size of the source buffer, must be at least 4 bytes.
+ *
+ * Return: True iff the buffer starts with a zstd or skippable frame identifier.
+ */
+unsigned int ZSTD_isFrame(const void *buffer, size_t size);
+
+/**
+ * ZSTD_getDictID_fromDict() - returns the dictionary id stored in a dictionary
+ * @dict:     The dictionary buffer.
+ * @dictSize: The size of the dictionary buffer.
+ *
+ * Return:    The dictionary id stored within the dictionary or 0 if the
+ *            dictionary is not a zstd dictionary. If it returns 0 the
+ *            dictionary can still be loaded as a content-only dictionary.
+ */
+unsigned int ZSTD_getDictID_fromDict(const void *dict, size_t dictSize);
+
+/**
+ * ZSTD_getDictID_fromDDict() - returns the dictionary id stored in a ZSTD_DDict
+ * @ddict: The ddict to find the id of.
+ *
+ * Return: The dictionary id stored within `ddict` or 0 if the dictionary is not
+ *         a zstd dictionary. If it returns 0 `ddict` will be loaded as a
+ *         content-only dictionary.
+ */
+unsigned int ZSTD_getDictID_fromDDict(const ZSTD_DDict *ddict);
+
+/**
+ * ZSTD_getDictID_fromFrame() - returns the dictionary id stored in a zstd frame
+ * @src:     Source buffer. It must be a zstd encoded frame.
+ * @srcSize: The size of the source buffer. It must be at least as large as the
+ *           frame header. `ZSTD_frameHeaderSize_max` is always large enough.
+ *
+ * Return:   The dictionary id required to decompress the frame stored within
+ *           `src` or 0 if the dictionary id could not be decoded. It can return
+ *           0 if the frame does not require a dictionary, the dictionary id
+ *           wasn't stored in the frame, `src` is not a zstd frame, or `srcSize`
+ *           is too small.
+ */
+unsigned int ZSTD_getDictID_fromFrame(const void *src, size_t srcSize);
+
+/**
+ * struct ZSTD_frameParams - zstd frame parameters stored in the frame header
+ * @frameContentSize: The frame content size, or 0 if not present.
+ * @windowSize:       The window size, or 0 if the frame is a skippable frame.
+ * @dictID:           The dictionary id, or 0 if not present.
+ * @checksumFlag:     Whether a checksum was used.
+ */
+typedef struct {
+	unsigned long long frameContentSize;
+	unsigned int windowSize;
+	unsigned int dictID;
+	unsigned int checksumFlag;
+} ZSTD_frameParams;
+
+/**
+ * ZSTD_getFrameParams() - extracts parameters from a zstd or skippable frame
+ * @fparamsPtr: On success the frame parameters are written here.
+ * @src:        The source buffer. It must point to a zstd or skippable frame.
+ * @srcSize:    The size of the source buffer. `ZSTD_frameHeaderSize_max` is
+ *              always large enough to succeed.
+ *
+ * Return:      0 on success. If more data is required it returns how many bytes
+ *              must be provided to make forward progress. Otherwise it returns
+ *              an error, which can be checked using ZSTD_isError().
+ */
+size_t ZSTD_getFrameParams(ZSTD_frameParams *fparamsPtr, const void *src,
+	size_t srcSize);
+
+/*-*****************************************************************************
+ * Buffer-less and synchronous inner streaming functions
+ *
+ * This is an advanced API, giving full control over buffer management, for
+ * users which need direct control over memory.
+ * But it's also a complex one, with many restrictions (documented below).
+ * Prefer using normal streaming API for an easier experience
+ ******************************************************************************/
+
+/*-*****************************************************************************
+ * Buffer-less streaming compression (synchronous mode)
+ *
+ * A ZSTD_CCtx object is required to track streaming operations.
+ * Use ZSTD_initCCtx() to initialize a context.
+ * ZSTD_CCtx object can be re-used multiple times within successive compression
+ * operations.
+ *
+ * Start by initializing a context.
+ * Use ZSTD_compressBegin(), or ZSTD_compressBegin_usingDict() for dictionary
+ * compression,
+ * or ZSTD_compressBegin_advanced(), for finer parameter control.
+ * It's also possible to duplicate a reference context which has already been
+ * initialized, using ZSTD_copyCCtx()
+ *
+ * Then, consume your input using ZSTD_compressContinue().
+ * There are some important considerations to keep in mind when using this
+ * advanced function :
+ * - ZSTD_compressContinue() has no internal buffer. It uses externally provided
+ *   buffer only.
+ * - Interface is synchronous : input is consumed entirely and produce 1+
+ *   (or more) compressed blocks.
+ * - Caller must ensure there is enough space in `dst` to store compressed data
+ *   under worst case scenario. Worst case evaluation is provided by
+ *   ZSTD_compressBound().
+ *   ZSTD_compressContinue() doesn't guarantee recover after a failed
+ *   compression.
+ * - ZSTD_compressContinue() presumes prior input ***is still accessible and
+ *   unmodified*** (up to maximum distance size, see WindowLog).
+ *   It remembers all previous contiguous blocks, plus one separated memory
+ *   segment (which can itself consists of multiple contiguous blocks)
+ * - ZSTD_compressContinue() detects that prior input has been overwritten when
+ *   `src` buffer overlaps. In which case, it will "discard" the relevant memory
+ *   section from its history.
+ *
+ * Finish a frame with ZSTD_compressEnd(), which will write the last block(s)
+ * and optional checksum. It's possible to use srcSize==0, in which case, it
+ * will write a final empty block to end the frame. Without last block mark,
+ * frames will be considered unfinished (corrupted) by decoders.
+ *
+ * `ZSTD_CCtx` object can be re-used (ZSTD_compressBegin()) to compress some new
+ * frame.
+ ******************************************************************************/
+
+/*=====   Buffer-less streaming compression functions  =====*/
+size_t ZSTD_compressBegin(ZSTD_CCtx *cctx, int compressionLevel);
+size_t ZSTD_compressBegin_usingDict(ZSTD_CCtx *cctx, const void *dict,
+	size_t dictSize, int compressionLevel);
+size_t ZSTD_compressBegin_advanced(ZSTD_CCtx *cctx, const void *dict,
+	size_t dictSize, ZSTD_parameters params,
+	unsigned long long pledgedSrcSize);
+size_t ZSTD_copyCCtx(ZSTD_CCtx *cctx, const ZSTD_CCtx *preparedCCtx,
+	unsigned long long pledgedSrcSize);
+size_t ZSTD_compressBegin_usingCDict(ZSTD_CCtx *cctx, const ZSTD_CDict *cdict,
+	unsigned long long pledgedSrcSize);
+size_t ZSTD_compressContinue(ZSTD_CCtx *cctx, void *dst, size_t dstCapacity,
+	const void *src, size_t srcSize);
+size_t ZSTD_compressEnd(ZSTD_CCtx *cctx, void *dst, size_t dstCapacity,
+	const void *src, size_t srcSize);
+
+
+
+/*-*****************************************************************************
+ * Buffer-less streaming decompression (synchronous mode)
+ *
+ * A ZSTD_DCtx object is required to track streaming operations.
+ * Use ZSTD_initDCtx() to initialize a context.
+ * A ZSTD_DCtx object can be re-used multiple times.
+ *
+ * First typical operation is to retrieve frame parameters, using
+ * ZSTD_getFrameParams(). It fills a ZSTD_frameParams structure which provide
+ * important information to correctly decode the frame, such as the minimum
+ * rolling buffer size to allocate to decompress data (`windowSize`), and the
+ * dictionary ID used.
+ * Note: content size is optional, it may not be present. 0 means unknown.
+ * Note that these values could be wrong, either because of data malformation,
+ * or because an attacker is spoofing deliberate false information. As a
+ * consequence, check that values remain within valid application range,
+ * especially `windowSize`, before allocation. Each application can set its own
+ * limit, depending on local restrictions. For extended interoperability, it is
+ * recommended to support at least 8 MB.
+ * Frame parameters are extracted from the beginning of the compressed frame.
+ * Data fragment must be large enough to ensure successful decoding, typically
+ * `ZSTD_frameHeaderSize_max` bytes.
+ * Result: 0: successful decoding, the `ZSTD_frameParams` structure is filled.
+ *        >0: `srcSize` is too small, provide at least this many bytes.
+ *        errorCode, which can be tested using ZSTD_isError().
+ *
+ * Start decompression, with ZSTD_decompressBegin() or
+ * ZSTD_decompressBegin_usingDict(). Alternatively, you can copy a prepared
+ * context, using ZSTD_copyDCtx().
+ *
+ * Then use ZSTD_nextSrcSizeToDecompress() and ZSTD_decompressContinue()
+ * alternatively.
+ * ZSTD_nextSrcSizeToDecompress() tells how many bytes to provide as 'srcSize'
+ * to ZSTD_decompressContinue().
+ * ZSTD_decompressContinue() requires this _exact_ amount of bytes, or it will
+ * fail.
+ *
+ * The result of ZSTD_decompressContinue() is the number of bytes regenerated
+ * within 'dst' (necessarily <= dstCapacity). It can be zero, which is not an
+ * error; it just means ZSTD_decompressContinue() has decoded some metadata
+ * item. It can also be an error code, which can be tested with ZSTD_isError().
+ *
+ * ZSTD_decompressContinue() needs previous data blocks during decompression, up
+ * to `windowSize`. They should preferably be located contiguously, prior to
+ * current block. Alternatively, a round buffer of sufficient size is also
+ * possible. Sufficient size is determined by frame parameters.
+ * ZSTD_decompressContinue() is very sensitive to contiguity, if 2 blocks don't
+ * follow each other, make sure that either the compressor breaks contiguity at
+ * the same place, or that previous contiguous segment is large enough to
+ * properly handle maximum back-reference.
+ *
+ * A frame is fully decoded when ZSTD_nextSrcSizeToDecompress() returns zero.
+ * Context can then be reset to start a new decompression.
+ *
+ * Note: it's possible to know if next input to present is a header or a block,
+ * using ZSTD_nextInputType(). This information is not required to properly
+ * decode a frame.
+ *
+ * == Special case: skippable frames ==
+ *
+ * Skippable frames allow integration of user-defined data into a flow of
+ * concatenated frames. Skippable frames will be ignored (skipped) by a
+ * decompressor. The format of skippable frames is as follows:
+ * a) Skippable frame ID - 4 Bytes, Little endian format, any value from
+ *    0x184D2A50 to 0x184D2A5F
+ * b) Frame Size - 4 Bytes, Little endian format, unsigned 32-bits
+ * c) Frame Content - any content (User Data) of length equal to Frame Size
+ * For skippable frames ZSTD_decompressContinue() always returns 0.
+ * For skippable frames ZSTD_getFrameParams() returns fparamsPtr->windowLog==0
+ * what means that a frame is skippable.
+ * Note: If fparamsPtr->frameContentSize==0, it is ambiguous: the frame might
+ *       actually be a zstd encoded frame with no content. For purposes of
+ *       decompression, it is valid in both cases to skip the frame using
+ *       ZSTD_findFrameCompressedSize() to find its size in bytes.
+ * It also returns frame size as fparamsPtr->frameContentSize.
+ ******************************************************************************/
+
+/*=====   Buffer-less streaming decompression functions  =====*/
+size_t ZSTD_decompressBegin(ZSTD_DCtx *dctx);
+size_t ZSTD_decompressBegin_usingDict(ZSTD_DCtx *dctx, const void *dict,
+	size_t dictSize);
+void   ZSTD_copyDCtx(ZSTD_DCtx *dctx, const ZSTD_DCtx *preparedDCtx);
+size_t ZSTD_nextSrcSizeToDecompress(ZSTD_DCtx *dctx);
+size_t ZSTD_decompressContinue(ZSTD_DCtx *dctx, void *dst, size_t dstCapacity,
+	const void *src, size_t srcSize);
+typedef enum {
+	ZSTDnit_frameHeader,
+	ZSTDnit_blockHeader,
+	ZSTDnit_block,
+	ZSTDnit_lastBlock,
+	ZSTDnit_checksum,
+	ZSTDnit_skippableFrame
+} ZSTD_nextInputType_e;
+ZSTD_nextInputType_e ZSTD_nextInputType(ZSTD_DCtx *dctx);
+
+/*-*****************************************************************************
+ * Block functions
+ *
+ * Block functions produce and decode raw zstd blocks, without frame metadata.
+ * Frame metadata cost is typically ~18 bytes, which can be non-negligible for
+ * very small blocks (< 100 bytes). User will have to take in charge required
+ * information to regenerate data, such as compressed and content sizes.
+ *
+ * A few rules to respect:
+ * - Compressing and decompressing require a context structure
+ *   + Use ZSTD_initCCtx() and ZSTD_initDCtx()
+ * - It is necessary to init context before starting
+ *   + compression : ZSTD_compressBegin()
+ *   + decompression : ZSTD_decompressBegin()
+ *   + variants _usingDict() are also allowed
+ *   + copyCCtx() and copyDCtx() work too
+ * - Block size is limited, it must be <= ZSTD_getBlockSizeMax()
+ *   + If you need to compress more, cut data into multiple blocks
+ *   + Consider using the regular ZSTD_compress() instead, as frame metadata
+ *     costs become negligible when source size is large.
+ * - When a block is considered not compressible enough, ZSTD_compressBlock()
+ *   result will be zero. In which case, nothing is produced into `dst`.
+ *   + User must test for such outcome and deal directly with uncompressed data
+ *   + ZSTD_decompressBlock() doesn't accept uncompressed data as input!!!
+ *   + In case of multiple successive blocks, decoder must be informed of
+ *     uncompressed block existence to follow proper history. Use
+ *     ZSTD_insertBlock() in such a case.
+ ******************************************************************************/
+
+/* Define for static allocation */
+#define ZSTD_BLOCKSIZE_ABSOLUTEMAX (128 * 1024)
+/*=====   Raw zstd block functions  =====*/
+size_t ZSTD_getBlockSizeMax(ZSTD_CCtx *cctx);
+size_t ZSTD_compressBlock(ZSTD_CCtx *cctx, void *dst, size_t dstCapacity,
+	const void *src, size_t srcSize);
+size_t ZSTD_decompressBlock(ZSTD_DCtx *dctx, void *dst, size_t dstCapacity,
+	const void *src, size_t srcSize);
+size_t ZSTD_insertBlock(ZSTD_DCtx *dctx, const void *blockStart,
+	size_t blockSize);
+
+#endif  /* ZSTD_H */
diff -Naurp -x debian.hwe linux-4.10.x.ori/include/sound/jack.h linux-4.10.x/include/sound/jack.h
--- linux-4.10.x.ori/include/sound/jack.h	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/include/sound/jack.h	2017-04-10 11:27:25.836919000 +0200
@@ -86,6 +86,14 @@ struct snd_jack {
 	void (*private_free)(struct snd_jack *);
 };
 
+/* gottwald@igel.com moved here from sound/core/jack.c */
+
+struct snd_jack_kctl {
+	struct snd_kcontrol *kctl;
+	struct list_head list;  /* list of controls belong to the same jack */
+	unsigned int mask_bits; /* only masked status bits are reported via kctl */
+};
+
 #ifdef CONFIG_SND_JACK
 
 int snd_jack_new(struct snd_card *card, const char *id, int type,
diff -Naurp -x debian.hwe linux-4.10.x.ori/include/uapi/linux/major.h linux-4.10.x/include/uapi/linux/major.h
--- linux-4.10.x.ori/include/uapi/linux/major.h	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/include/uapi/linux/major.h	2017-04-10 11:27:25.836919000 +0200
@@ -76,6 +76,9 @@
 #define IDE4_MAJOR		56
 #define IDE5_MAJOR		57
 
+#define IGEL_FLASH_MAJOR	61   /* /dev/igf... */
+#define IGEL_V5_FLASH_MAJOR	62   /* /dev/igl... */
+#define IGEL_V10_FLASH_MAJOR	63   /* /dev/igb... */
 #define SCSI_DISK1_MAJOR	65
 #define SCSI_DISK2_MAJOR	66
 #define SCSI_DISK3_MAJOR	67
diff -Naurp -x debian.hwe linux-4.10.x.ori/kernel/printk/printk.c linux-4.10.x/kernel/printk/printk.c
--- linux-4.10.x.ori/kernel/printk/printk.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/kernel/printk/printk.c	2017-04-10 11:27:25.836919000 +0200
@@ -1967,6 +1967,15 @@ static int __init console_setup(char *st
 	char *s, *options, *brl_options = NULL;
 	int idx;
 
+	/* lang@igel:
+	 * the IGEL boot code sets an cmdline option
+	 * "console=,1": set minimum console loglevel
+	 */
+	if (str && (!strcmp(str, ",1"))) {
+		console_loglevel=CONSOLE_LOGLEVEL_MIN;
+		return 1;
+	}
+
 	if (_braille_console_setup(&str, &brl_options))
 		return 1;
 
diff -Naurp -x debian.hwe linux-4.10.x.ori/lib/Kconfig linux-4.10.x/lib/Kconfig
--- linux-4.10.x.ori/lib/Kconfig	2017-05-24 07:18:02.975911000 +0200
+++ linux-4.10.x/lib/Kconfig	2017-10-30 10:05:19.610447000 +0100
@@ -199,6 +199,9 @@ config CRC8
 	  when they need to do cyclic redundancy check according CRC8
 	  algorithm. Module will be called crc8.
 
+config XXHASH
+	tristate
+
 config AUDIT_GENERIC
 	bool
 	depends on AUDIT && !AUDIT_ARCH
@@ -253,6 +256,14 @@ config LZ4HC_COMPRESS
 config LZ4_DECOMPRESS
 	tristate
 
+config ZSTD_COMPRESS
+	select XXHASH
+	tristate
+
+config ZSTD_DECOMPRESS
+	select XXHASH
+	tristate
+
 source "lib/xz/Kconfig"
 
 #
diff -Naurp -x debian.hwe linux-4.10.x.ori/lib/Makefile linux-4.10.x/lib/Makefile
--- linux-4.10.x.ori/lib/Makefile	2017-05-24 07:18:02.975911000 +0200
+++ linux-4.10.x/lib/Makefile	2017-10-30 10:05:19.610447000 +0100
@@ -95,6 +95,7 @@ obj-$(CONFIG_CRC32)	+= crc32.o
 obj-$(CONFIG_CRC7)	+= crc7.o
 obj-$(CONFIG_LIBCRC32C)	+= libcrc32c.o
 obj-$(CONFIG_CRC8)	+= crc8.o
+obj-$(CONFIG_XXHASH)	+= xxhash.o
 obj-$(CONFIG_GENERIC_ALLOCATOR) += genalloc.o
 
 obj-$(CONFIG_842_COMPRESS) += 842/
@@ -108,6 +109,8 @@ obj-$(CONFIG_LZO_DECOMPRESS) += lzo/
 obj-$(CONFIG_LZ4_COMPRESS) += lz4/
 obj-$(CONFIG_LZ4HC_COMPRESS) += lz4/
 obj-$(CONFIG_LZ4_DECOMPRESS) += lz4/
+obj-$(CONFIG_ZSTD_COMPRESS) += zstd/
+obj-$(CONFIG_ZSTD_DECOMPRESS) += zstd/
 obj-$(CONFIG_XZ_DEC) += xz/
 obj-$(CONFIG_RAID6_PQ) += raid6/
 
diff -Naurp -x debian.hwe linux-4.10.x.ori/lib/xxhash.c linux-4.10.x/lib/xxhash.c
--- linux-4.10.x.ori/lib/xxhash.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-4.10.x/lib/xxhash.c	2017-10-30 10:05:19.610447000 +0100
@@ -0,0 +1,500 @@
+/*
+ * xxHash - Extremely Fast Hash algorithm
+ * Copyright (C) 2012-2016, Yann Collet.
+ *
+ * BSD 2-Clause License (http://www.opensource.org/licenses/bsd-license.php)
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ *   * Redistributions in binary form must reproduce the above
+ *     copyright notice, this list of conditions and the following disclaimer
+ *     in the documentation and/or other materials provided with the
+ *     distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ * This program is free software; you can redistribute it and/or modify it under
+ * the terms of the GNU General Public License version 2 as published by the
+ * Free Software Foundation. This program is dual-licensed; you may select
+ * either version 2 of the GNU General Public License ("GPL") or BSD license
+ * ("BSD").
+ *
+ * You can contact the author at:
+ * - xxHash homepage: http://cyan4973.github.io/xxHash/
+ * - xxHash source repository: https://github.com/Cyan4973/xxHash
+ */
+
+#include <asm/unaligned.h>
+#include <linux/errno.h>
+#include <linux/compiler.h>
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/string.h>
+#include <linux/xxhash.h>
+
+/*-*************************************
+ * Macros
+ **************************************/
+#define xxh_rotl32(x, r) ((x << r) | (x >> (32 - r)))
+#define xxh_rotl64(x, r) ((x << r) | (x >> (64 - r)))
+
+#ifdef __LITTLE_ENDIAN
+# define XXH_CPU_LITTLE_ENDIAN 1
+#else
+# define XXH_CPU_LITTLE_ENDIAN 0
+#endif
+
+/*-*************************************
+ * Constants
+ **************************************/
+static const uint32_t PRIME32_1 = 2654435761U;
+static const uint32_t PRIME32_2 = 2246822519U;
+static const uint32_t PRIME32_3 = 3266489917U;
+static const uint32_t PRIME32_4 =  668265263U;
+static const uint32_t PRIME32_5 =  374761393U;
+
+static const uint64_t PRIME64_1 = 11400714785074694791ULL;
+static const uint64_t PRIME64_2 = 14029467366897019727ULL;
+static const uint64_t PRIME64_3 =  1609587929392839161ULL;
+static const uint64_t PRIME64_4 =  9650029242287828579ULL;
+static const uint64_t PRIME64_5 =  2870177450012600261ULL;
+
+/*-**************************
+ *  Utils
+ ***************************/
+void xxh32_copy_state(struct xxh32_state *dst, const struct xxh32_state *src)
+{
+	memcpy(dst, src, sizeof(*dst));
+}
+EXPORT_SYMBOL(xxh32_copy_state);
+
+void xxh64_copy_state(struct xxh64_state *dst, const struct xxh64_state *src)
+{
+	memcpy(dst, src, sizeof(*dst));
+}
+EXPORT_SYMBOL(xxh64_copy_state);
+
+/*-***************************
+ * Simple Hash Functions
+ ****************************/
+static uint32_t xxh32_round(uint32_t seed, const uint32_t input)
+{
+	seed += input * PRIME32_2;
+	seed = xxh_rotl32(seed, 13);
+	seed *= PRIME32_1;
+	return seed;
+}
+
+uint32_t xxh32(const void *input, const size_t len, const uint32_t seed)
+{
+	const uint8_t *p = (const uint8_t *)input;
+	const uint8_t *b_end = p + len;
+	uint32_t h32;
+
+	if (len >= 16) {
+		const uint8_t *const limit = b_end - 16;
+		uint32_t v1 = seed + PRIME32_1 + PRIME32_2;
+		uint32_t v2 = seed + PRIME32_2;
+		uint32_t v3 = seed + 0;
+		uint32_t v4 = seed - PRIME32_1;
+
+		do {
+			v1 = xxh32_round(v1, get_unaligned_le32(p));
+			p += 4;
+			v2 = xxh32_round(v2, get_unaligned_le32(p));
+			p += 4;
+			v3 = xxh32_round(v3, get_unaligned_le32(p));
+			p += 4;
+			v4 = xxh32_round(v4, get_unaligned_le32(p));
+			p += 4;
+		} while (p <= limit);
+
+		h32 = xxh_rotl32(v1, 1) + xxh_rotl32(v2, 7) +
+			xxh_rotl32(v3, 12) + xxh_rotl32(v4, 18);
+	} else {
+		h32 = seed + PRIME32_5;
+	}
+
+	h32 += (uint32_t)len;
+
+	while (p + 4 <= b_end) {
+		h32 += get_unaligned_le32(p) * PRIME32_3;
+		h32 = xxh_rotl32(h32, 17) * PRIME32_4;
+		p += 4;
+	}
+
+	while (p < b_end) {
+		h32 += (*p) * PRIME32_5;
+		h32 = xxh_rotl32(h32, 11) * PRIME32_1;
+		p++;
+	}
+
+	h32 ^= h32 >> 15;
+	h32 *= PRIME32_2;
+	h32 ^= h32 >> 13;
+	h32 *= PRIME32_3;
+	h32 ^= h32 >> 16;
+
+	return h32;
+}
+EXPORT_SYMBOL(xxh32);
+
+static uint64_t xxh64_round(uint64_t acc, const uint64_t input)
+{
+	acc += input * PRIME64_2;
+	acc = xxh_rotl64(acc, 31);
+	acc *= PRIME64_1;
+	return acc;
+}
+
+static uint64_t xxh64_merge_round(uint64_t acc, uint64_t val)
+{
+	val = xxh64_round(0, val);
+	acc ^= val;
+	acc = acc * PRIME64_1 + PRIME64_4;
+	return acc;
+}
+
+uint64_t xxh64(const void *input, const size_t len, const uint64_t seed)
+{
+	const uint8_t *p = (const uint8_t *)input;
+	const uint8_t *const b_end = p + len;
+	uint64_t h64;
+
+	if (len >= 32) {
+		const uint8_t *const limit = b_end - 32;
+		uint64_t v1 = seed + PRIME64_1 + PRIME64_2;
+		uint64_t v2 = seed + PRIME64_2;
+		uint64_t v3 = seed + 0;
+		uint64_t v4 = seed - PRIME64_1;
+
+		do {
+			v1 = xxh64_round(v1, get_unaligned_le64(p));
+			p += 8;
+			v2 = xxh64_round(v2, get_unaligned_le64(p));
+			p += 8;
+			v3 = xxh64_round(v3, get_unaligned_le64(p));
+			p += 8;
+			v4 = xxh64_round(v4, get_unaligned_le64(p));
+			p += 8;
+		} while (p <= limit);
+
+		h64 = xxh_rotl64(v1, 1) + xxh_rotl64(v2, 7) +
+			xxh_rotl64(v3, 12) + xxh_rotl64(v4, 18);
+		h64 = xxh64_merge_round(h64, v1);
+		h64 = xxh64_merge_round(h64, v2);
+		h64 = xxh64_merge_round(h64, v3);
+		h64 = xxh64_merge_round(h64, v4);
+
+	} else {
+		h64  = seed + PRIME64_5;
+	}
+
+	h64 += (uint64_t)len;
+
+	while (p + 8 <= b_end) {
+		const uint64_t k1 = xxh64_round(0, get_unaligned_le64(p));
+
+		h64 ^= k1;
+		h64 = xxh_rotl64(h64, 27) * PRIME64_1 + PRIME64_4;
+		p += 8;
+	}
+
+	if (p + 4 <= b_end) {
+		h64 ^= (uint64_t)(get_unaligned_le32(p)) * PRIME64_1;
+		h64 = xxh_rotl64(h64, 23) * PRIME64_2 + PRIME64_3;
+		p += 4;
+	}
+
+	while (p < b_end) {
+		h64 ^= (*p) * PRIME64_5;
+		h64 = xxh_rotl64(h64, 11) * PRIME64_1;
+		p++;
+	}
+
+	h64 ^= h64 >> 33;
+	h64 *= PRIME64_2;
+	h64 ^= h64 >> 29;
+	h64 *= PRIME64_3;
+	h64 ^= h64 >> 32;
+
+	return h64;
+}
+EXPORT_SYMBOL(xxh64);
+
+/*-**************************************************
+ * Advanced Hash Functions
+ ***************************************************/
+void xxh32_reset(struct xxh32_state *statePtr, const uint32_t seed)
+{
+	/* use a local state for memcpy() to avoid strict-aliasing warnings */
+	struct xxh32_state state;
+
+	memset(&state, 0, sizeof(state));
+	state.v1 = seed + PRIME32_1 + PRIME32_2;
+	state.v2 = seed + PRIME32_2;
+	state.v3 = seed + 0;
+	state.v4 = seed - PRIME32_1;
+	memcpy(statePtr, &state, sizeof(state));
+}
+EXPORT_SYMBOL(xxh32_reset);
+
+void xxh64_reset(struct xxh64_state *statePtr, const uint64_t seed)
+{
+	/* use a local state for memcpy() to avoid strict-aliasing warnings */
+	struct xxh64_state state;
+
+	memset(&state, 0, sizeof(state));
+	state.v1 = seed + PRIME64_1 + PRIME64_2;
+	state.v2 = seed + PRIME64_2;
+	state.v3 = seed + 0;
+	state.v4 = seed - PRIME64_1;
+	memcpy(statePtr, &state, sizeof(state));
+}
+EXPORT_SYMBOL(xxh64_reset);
+
+int xxh32_update(struct xxh32_state *state, const void *input, const size_t len)
+{
+	const uint8_t *p = (const uint8_t *)input;
+	const uint8_t *const b_end = p + len;
+
+	if (input == NULL)
+		return -EINVAL;
+
+	state->total_len_32 += (uint32_t)len;
+	state->large_len |= (len >= 16) | (state->total_len_32 >= 16);
+
+	if (state->memsize + len < 16) { /* fill in tmp buffer */
+		memcpy((uint8_t *)(state->mem32) + state->memsize, input, len);
+		state->memsize += (uint32_t)len;
+		return 0;
+	}
+
+	if (state->memsize) { /* some data left from previous update */
+		const uint32_t *p32 = state->mem32;
+
+		memcpy((uint8_t *)(state->mem32) + state->memsize, input,
+			16 - state->memsize);
+
+		state->v1 = xxh32_round(state->v1, get_unaligned_le32(p32));
+		p32++;
+		state->v2 = xxh32_round(state->v2, get_unaligned_le32(p32));
+		p32++;
+		state->v3 = xxh32_round(state->v3, get_unaligned_le32(p32));
+		p32++;
+		state->v4 = xxh32_round(state->v4, get_unaligned_le32(p32));
+		p32++;
+
+		p += 16-state->memsize;
+		state->memsize = 0;
+	}
+
+	if (p <= b_end - 16) {
+		const uint8_t *const limit = b_end - 16;
+		uint32_t v1 = state->v1;
+		uint32_t v2 = state->v2;
+		uint32_t v3 = state->v3;
+		uint32_t v4 = state->v4;
+
+		do {
+			v1 = xxh32_round(v1, get_unaligned_le32(p));
+			p += 4;
+			v2 = xxh32_round(v2, get_unaligned_le32(p));
+			p += 4;
+			v3 = xxh32_round(v3, get_unaligned_le32(p));
+			p += 4;
+			v4 = xxh32_round(v4, get_unaligned_le32(p));
+			p += 4;
+		} while (p <= limit);
+
+		state->v1 = v1;
+		state->v2 = v2;
+		state->v3 = v3;
+		state->v4 = v4;
+	}
+
+	if (p < b_end) {
+		memcpy(state->mem32, p, (size_t)(b_end-p));
+		state->memsize = (uint32_t)(b_end-p);
+	}
+
+	return 0;
+}
+EXPORT_SYMBOL(xxh32_update);
+
+uint32_t xxh32_digest(const struct xxh32_state *state)
+{
+	const uint8_t *p = (const uint8_t *)state->mem32;
+	const uint8_t *const b_end = (const uint8_t *)(state->mem32) +
+		state->memsize;
+	uint32_t h32;
+
+	if (state->large_len) {
+		h32 = xxh_rotl32(state->v1, 1) + xxh_rotl32(state->v2, 7) +
+			xxh_rotl32(state->v3, 12) + xxh_rotl32(state->v4, 18);
+	} else {
+		h32 = state->v3 /* == seed */ + PRIME32_5;
+	}
+
+	h32 += state->total_len_32;
+
+	while (p + 4 <= b_end) {
+		h32 += get_unaligned_le32(p) * PRIME32_3;
+		h32 = xxh_rotl32(h32, 17) * PRIME32_4;
+		p += 4;
+	}
+
+	while (p < b_end) {
+		h32 += (*p) * PRIME32_5;
+		h32 = xxh_rotl32(h32, 11) * PRIME32_1;
+		p++;
+	}
+
+	h32 ^= h32 >> 15;
+	h32 *= PRIME32_2;
+	h32 ^= h32 >> 13;
+	h32 *= PRIME32_3;
+	h32 ^= h32 >> 16;
+
+	return h32;
+}
+EXPORT_SYMBOL(xxh32_digest);
+
+int xxh64_update(struct xxh64_state *state, const void *input, const size_t len)
+{
+	const uint8_t *p = (const uint8_t *)input;
+	const uint8_t *const b_end = p + len;
+
+	if (input == NULL)
+		return -EINVAL;
+
+	state->total_len += len;
+
+	if (state->memsize + len < 32) { /* fill in tmp buffer */
+		memcpy(((uint8_t *)state->mem64) + state->memsize, input, len);
+		state->memsize += (uint32_t)len;
+		return 0;
+	}
+
+	if (state->memsize) { /* tmp buffer is full */
+		uint64_t *p64 = state->mem64;
+
+		memcpy(((uint8_t *)p64) + state->memsize, input,
+			32 - state->memsize);
+
+		state->v1 = xxh64_round(state->v1, get_unaligned_le64(p64));
+		p64++;
+		state->v2 = xxh64_round(state->v2, get_unaligned_le64(p64));
+		p64++;
+		state->v3 = xxh64_round(state->v3, get_unaligned_le64(p64));
+		p64++;
+		state->v4 = xxh64_round(state->v4, get_unaligned_le64(p64));
+
+		p += 32 - state->memsize;
+		state->memsize = 0;
+	}
+
+	if (p + 32 <= b_end) {
+		const uint8_t *const limit = b_end - 32;
+		uint64_t v1 = state->v1;
+		uint64_t v2 = state->v2;
+		uint64_t v3 = state->v3;
+		uint64_t v4 = state->v4;
+
+		do {
+			v1 = xxh64_round(v1, get_unaligned_le64(p));
+			p += 8;
+			v2 = xxh64_round(v2, get_unaligned_le64(p));
+			p += 8;
+			v3 = xxh64_round(v3, get_unaligned_le64(p));
+			p += 8;
+			v4 = xxh64_round(v4, get_unaligned_le64(p));
+			p += 8;
+		} while (p <= limit);
+
+		state->v1 = v1;
+		state->v2 = v2;
+		state->v3 = v3;
+		state->v4 = v4;
+	}
+
+	if (p < b_end) {
+		memcpy(state->mem64, p, (size_t)(b_end-p));
+		state->memsize = (uint32_t)(b_end - p);
+	}
+
+	return 0;
+}
+EXPORT_SYMBOL(xxh64_update);
+
+uint64_t xxh64_digest(const struct xxh64_state *state)
+{
+	const uint8_t *p = (const uint8_t *)state->mem64;
+	const uint8_t *const b_end = (const uint8_t *)state->mem64 +
+		state->memsize;
+	uint64_t h64;
+
+	if (state->total_len >= 32) {
+		const uint64_t v1 = state->v1;
+		const uint64_t v2 = state->v2;
+		const uint64_t v3 = state->v3;
+		const uint64_t v4 = state->v4;
+
+		h64 = xxh_rotl64(v1, 1) + xxh_rotl64(v2, 7) +
+			xxh_rotl64(v3, 12) + xxh_rotl64(v4, 18);
+		h64 = xxh64_merge_round(h64, v1);
+		h64 = xxh64_merge_round(h64, v2);
+		h64 = xxh64_merge_round(h64, v3);
+		h64 = xxh64_merge_round(h64, v4);
+	} else {
+		h64  = state->v3 + PRIME64_5;
+	}
+
+	h64 += (uint64_t)state->total_len;
+
+	while (p + 8 <= b_end) {
+		const uint64_t k1 = xxh64_round(0, get_unaligned_le64(p));
+
+		h64 ^= k1;
+		h64 = xxh_rotl64(h64, 27) * PRIME64_1 + PRIME64_4;
+		p += 8;
+	}
+
+	if (p + 4 <= b_end) {
+		h64 ^= (uint64_t)(get_unaligned_le32(p)) * PRIME64_1;
+		h64 = xxh_rotl64(h64, 23) * PRIME64_2 + PRIME64_3;
+		p += 4;
+	}
+
+	while (p < b_end) {
+		h64 ^= (*p) * PRIME64_5;
+		h64 = xxh_rotl64(h64, 11) * PRIME64_1;
+		p++;
+	}
+
+	h64 ^= h64 >> 33;
+	h64 *= PRIME64_2;
+	h64 ^= h64 >> 29;
+	h64 *= PRIME64_3;
+	h64 ^= h64 >> 32;
+
+	return h64;
+}
+EXPORT_SYMBOL(xxh64_digest);
+
+MODULE_LICENSE("Dual BSD/GPL");
+MODULE_DESCRIPTION("xxHash");
diff -Naurp -x debian.hwe linux-4.10.x.ori/lib/zstd/bitstream.h linux-4.10.x/lib/zstd/bitstream.h
--- linux-4.10.x.ori/lib/zstd/bitstream.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-4.10.x/lib/zstd/bitstream.h	2017-10-30 10:05:19.610447000 +0100
@@ -0,0 +1,374 @@
+/*
+ * bitstream
+ * Part of FSE library
+ * header file (to include)
+ * Copyright (C) 2013-2016, Yann Collet.
+ *
+ * BSD 2-Clause License (http://www.opensource.org/licenses/bsd-license.php)
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ * notice, this list of conditions and the following disclaimer.
+ *   * Redistributions in binary form must reproduce the above
+ * copyright notice, this list of conditions and the following disclaimer
+ * in the documentation and/or other materials provided with the
+ * distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ * This program is free software; you can redistribute it and/or modify it under
+ * the terms of the GNU General Public License version 2 as published by the
+ * Free Software Foundation. This program is dual-licensed; you may select
+ * either version 2 of the GNU General Public License ("GPL") or BSD license
+ * ("BSD").
+ *
+ * You can contact the author at :
+ * - Source repository : https://github.com/Cyan4973/FiniteStateEntropy
+ */
+#ifndef BITSTREAM_H_MODULE
+#define BITSTREAM_H_MODULE
+
+/*
+*  This API consists of small unitary functions, which must be inlined for best performance.
+*  Since link-time-optimization is not available for all compilers,
+*  these functions are defined into a .h to be included.
+*/
+
+/*-****************************************
+*  Dependencies
+******************************************/
+#include "error_private.h" /* error codes and messages */
+#include "mem.h"	   /* unaligned access routines */
+
+/*=========================================
+*  Target specific
+=========================================*/
+#define STREAM_ACCUMULATOR_MIN_32 25
+#define STREAM_ACCUMULATOR_MIN_64 57
+#define STREAM_ACCUMULATOR_MIN ((U32)(ZSTD_32bits() ? STREAM_ACCUMULATOR_MIN_32 : STREAM_ACCUMULATOR_MIN_64))
+
+/*-******************************************
+*  bitStream encoding API (write forward)
+********************************************/
+/* bitStream can mix input from multiple sources.
+*  A critical property of these streams is that they encode and decode in **reverse** direction.
+*  So the first bit sequence you add will be the last to be read, like a LIFO stack.
+*/
+typedef struct {
+	size_t bitContainer;
+	int bitPos;
+	char *startPtr;
+	char *ptr;
+	char *endPtr;
+} BIT_CStream_t;
+
+ZSTD_STATIC size_t BIT_initCStream(BIT_CStream_t *bitC, void *dstBuffer, size_t dstCapacity);
+ZSTD_STATIC void BIT_addBits(BIT_CStream_t *bitC, size_t value, unsigned nbBits);
+ZSTD_STATIC void BIT_flushBits(BIT_CStream_t *bitC);
+ZSTD_STATIC size_t BIT_closeCStream(BIT_CStream_t *bitC);
+
+/* Start with initCStream, providing the size of buffer to write into.
+*  bitStream will never write outside of this buffer.
+*  `dstCapacity` must be >= sizeof(bitD->bitContainer), otherwise @return will be an error code.
+*
+*  bits are first added to a local register.
+*  Local register is size_t, hence 64-bits on 64-bits systems, or 32-bits on 32-bits systems.
+*  Writing data into memory is an explicit operation, performed by the flushBits function.
+*  Hence keep track how many bits are potentially stored into local register to avoid register overflow.
+*  After a flushBits, a maximum of 7 bits might still be stored into local register.
+*
+*  Avoid storing elements of more than 24 bits if you want compatibility with 32-bits bitstream readers.
+*
+*  Last operation is to close the bitStream.
+*  The function returns the final size of CStream in bytes.
+*  If data couldn't fit into `dstBuffer`, it will return a 0 ( == not storable)
+*/
+
+/*-********************************************
+*  bitStream decoding API (read backward)
+**********************************************/
+typedef struct {
+	size_t bitContainer;
+	unsigned bitsConsumed;
+	const char *ptr;
+	const char *start;
+} BIT_DStream_t;
+
+typedef enum {
+	BIT_DStream_unfinished = 0,
+	BIT_DStream_endOfBuffer = 1,
+	BIT_DStream_completed = 2,
+	BIT_DStream_overflow = 3
+} BIT_DStream_status; /* result of BIT_reloadDStream() */
+/* 1,2,4,8 would be better for bitmap combinations, but slows down performance a bit ... :( */
+
+ZSTD_STATIC size_t BIT_initDStream(BIT_DStream_t *bitD, const void *srcBuffer, size_t srcSize);
+ZSTD_STATIC size_t BIT_readBits(BIT_DStream_t *bitD, unsigned nbBits);
+ZSTD_STATIC BIT_DStream_status BIT_reloadDStream(BIT_DStream_t *bitD);
+ZSTD_STATIC unsigned BIT_endOfDStream(const BIT_DStream_t *bitD);
+
+/* Start by invoking BIT_initDStream().
+*  A chunk of the bitStream is then stored into a local register.
+*  Local register size is 64-bits on 64-bits systems, 32-bits on 32-bits systems (size_t).
+*  You can then retrieve bitFields stored into the local register, **in reverse order**.
+*  Local register is explicitly reloaded from memory by the BIT_reloadDStream() method.
+*  A reload guarantee a minimum of ((8*sizeof(bitD->bitContainer))-7) bits when its result is BIT_DStream_unfinished.
+*  Otherwise, it can be less than that, so proceed accordingly.
+*  Checking if DStream has reached its end can be performed with BIT_endOfDStream().
+*/
+
+/*-****************************************
+*  unsafe API
+******************************************/
+ZSTD_STATIC void BIT_addBitsFast(BIT_CStream_t *bitC, size_t value, unsigned nbBits);
+/* faster, but works only if value is "clean", meaning all high bits above nbBits are 0 */
+
+ZSTD_STATIC void BIT_flushBitsFast(BIT_CStream_t *bitC);
+/* unsafe version; does not check buffer overflow */
+
+ZSTD_STATIC size_t BIT_readBitsFast(BIT_DStream_t *bitD, unsigned nbBits);
+/* faster, but works only if nbBits >= 1 */
+
+/*-**************************************************************
+*  Internal functions
+****************************************************************/
+ZSTD_STATIC unsigned BIT_highbit32(register U32 val) { return 31 - __builtin_clz(val); }
+
+/*=====    Local Constants   =====*/
+static const unsigned BIT_mask[] = {0,       1,       3,       7,	0xF,      0x1F,     0x3F,     0x7F,      0xFF,
+				    0x1FF,   0x3FF,   0x7FF,   0xFFF,    0x1FFF,   0x3FFF,   0x7FFF,   0xFFFF,    0x1FFFF,
+				    0x3FFFF, 0x7FFFF, 0xFFFFF, 0x1FFFFF, 0x3FFFFF, 0x7FFFFF, 0xFFFFFF, 0x1FFFFFF, 0x3FFFFFF}; /* up to 26 bits */
+
+/*-**************************************************************
+*  bitStream encoding
+****************************************************************/
+/*! BIT_initCStream() :
+ *  `dstCapacity` must be > sizeof(void*)
+ *  @return : 0 if success,
+			  otherwise an error code (can be tested using ERR_isError() ) */
+ZSTD_STATIC size_t BIT_initCStream(BIT_CStream_t *bitC, void *startPtr, size_t dstCapacity)
+{
+	bitC->bitContainer = 0;
+	bitC->bitPos = 0;
+	bitC->startPtr = (char *)startPtr;
+	bitC->ptr = bitC->startPtr;
+	bitC->endPtr = bitC->startPtr + dstCapacity - sizeof(bitC->ptr);
+	if (dstCapacity <= sizeof(bitC->ptr))
+		return ERROR(dstSize_tooSmall);
+	return 0;
+}
+
+/*! BIT_addBits() :
+	can add up to 26 bits into `bitC`.
+	Does not check for register overflow ! */
+ZSTD_STATIC void BIT_addBits(BIT_CStream_t *bitC, size_t value, unsigned nbBits)
+{
+	bitC->bitContainer |= (value & BIT_mask[nbBits]) << bitC->bitPos;
+	bitC->bitPos += nbBits;
+}
+
+/*! BIT_addBitsFast() :
+ *  works only if `value` is _clean_, meaning all high bits above nbBits are 0 */
+ZSTD_STATIC void BIT_addBitsFast(BIT_CStream_t *bitC, size_t value, unsigned nbBits)
+{
+	bitC->bitContainer |= value << bitC->bitPos;
+	bitC->bitPos += nbBits;
+}
+
+/*! BIT_flushBitsFast() :
+ *  unsafe version; does not check buffer overflow */
+ZSTD_STATIC void BIT_flushBitsFast(BIT_CStream_t *bitC)
+{
+	size_t const nbBytes = bitC->bitPos >> 3;
+	ZSTD_writeLEST(bitC->ptr, bitC->bitContainer);
+	bitC->ptr += nbBytes;
+	bitC->bitPos &= 7;
+	bitC->bitContainer >>= nbBytes * 8; /* if bitPos >= sizeof(bitContainer)*8 --> undefined behavior */
+}
+
+/*! BIT_flushBits() :
+ *  safe version; check for buffer overflow, and prevents it.
+ *  note : does not signal buffer overflow. This will be revealed later on using BIT_closeCStream() */
+ZSTD_STATIC void BIT_flushBits(BIT_CStream_t *bitC)
+{
+	size_t const nbBytes = bitC->bitPos >> 3;
+	ZSTD_writeLEST(bitC->ptr, bitC->bitContainer);
+	bitC->ptr += nbBytes;
+	if (bitC->ptr > bitC->endPtr)
+		bitC->ptr = bitC->endPtr;
+	bitC->bitPos &= 7;
+	bitC->bitContainer >>= nbBytes * 8; /* if bitPos >= sizeof(bitContainer)*8 --> undefined behavior */
+}
+
+/*! BIT_closeCStream() :
+ *  @return : size of CStream, in bytes,
+			  or 0 if it could not fit into dstBuffer */
+ZSTD_STATIC size_t BIT_closeCStream(BIT_CStream_t *bitC)
+{
+	BIT_addBitsFast(bitC, 1, 1); /* endMark */
+	BIT_flushBits(bitC);
+
+	if (bitC->ptr >= bitC->endPtr)
+		return 0; /* doesn't fit within authorized budget : cancel */
+
+	return (bitC->ptr - bitC->startPtr) + (bitC->bitPos > 0);
+}
+
+/*-********************************************************
+* bitStream decoding
+**********************************************************/
+/*! BIT_initDStream() :
+*   Initialize a BIT_DStream_t.
+*   `bitD` : a pointer to an already allocated BIT_DStream_t structure.
+*   `srcSize` must be the *exact* size of the bitStream, in bytes.
+*   @return : size of stream (== srcSize) or an errorCode if a problem is detected
+*/
+ZSTD_STATIC size_t BIT_initDStream(BIT_DStream_t *bitD, const void *srcBuffer, size_t srcSize)
+{
+	if (srcSize < 1) {
+		memset(bitD, 0, sizeof(*bitD));
+		return ERROR(srcSize_wrong);
+	}
+
+	if (srcSize >= sizeof(bitD->bitContainer)) { /* normal case */
+		bitD->start = (const char *)srcBuffer;
+		bitD->ptr = (const char *)srcBuffer + srcSize - sizeof(bitD->bitContainer);
+		bitD->bitContainer = ZSTD_readLEST(bitD->ptr);
+		{
+			BYTE const lastByte = ((const BYTE *)srcBuffer)[srcSize - 1];
+			bitD->bitsConsumed = lastByte ? 8 - BIT_highbit32(lastByte) : 0; /* ensures bitsConsumed is always set */
+			if (lastByte == 0)
+				return ERROR(GENERIC); /* endMark not present */
+		}
+	} else {
+		bitD->start = (const char *)srcBuffer;
+		bitD->ptr = bitD->start;
+		bitD->bitContainer = *(const BYTE *)(bitD->start);
+		switch (srcSize) {
+		case 7: bitD->bitContainer += (size_t)(((const BYTE *)(srcBuffer))[6]) << (sizeof(bitD->bitContainer) * 8 - 16);
+		case 6: bitD->bitContainer += (size_t)(((const BYTE *)(srcBuffer))[5]) << (sizeof(bitD->bitContainer) * 8 - 24);
+		case 5: bitD->bitContainer += (size_t)(((const BYTE *)(srcBuffer))[4]) << (sizeof(bitD->bitContainer) * 8 - 32);
+		case 4: bitD->bitContainer += (size_t)(((const BYTE *)(srcBuffer))[3]) << 24;
+		case 3: bitD->bitContainer += (size_t)(((const BYTE *)(srcBuffer))[2]) << 16;
+		case 2: bitD->bitContainer += (size_t)(((const BYTE *)(srcBuffer))[1]) << 8;
+		default:;
+		}
+		{
+			BYTE const lastByte = ((const BYTE *)srcBuffer)[srcSize - 1];
+			bitD->bitsConsumed = lastByte ? 8 - BIT_highbit32(lastByte) : 0;
+			if (lastByte == 0)
+				return ERROR(GENERIC); /* endMark not present */
+		}
+		bitD->bitsConsumed += (U32)(sizeof(bitD->bitContainer) - srcSize) * 8;
+	}
+
+	return srcSize;
+}
+
+ZSTD_STATIC size_t BIT_getUpperBits(size_t bitContainer, U32 const start) { return bitContainer >> start; }
+
+ZSTD_STATIC size_t BIT_getMiddleBits(size_t bitContainer, U32 const start, U32 const nbBits) { return (bitContainer >> start) & BIT_mask[nbBits]; }
+
+ZSTD_STATIC size_t BIT_getLowerBits(size_t bitContainer, U32 const nbBits) { return bitContainer & BIT_mask[nbBits]; }
+
+/*! BIT_lookBits() :
+ *  Provides next n bits from local register.
+ *  local register is not modified.
+ *  On 32-bits, maxNbBits==24.
+ *  On 64-bits, maxNbBits==56.
+ *  @return : value extracted
+ */
+ZSTD_STATIC size_t BIT_lookBits(const BIT_DStream_t *bitD, U32 nbBits)
+{
+	U32 const bitMask = sizeof(bitD->bitContainer) * 8 - 1;
+	return ((bitD->bitContainer << (bitD->bitsConsumed & bitMask)) >> 1) >> ((bitMask - nbBits) & bitMask);
+}
+
+/*! BIT_lookBitsFast() :
+*   unsafe version; only works only if nbBits >= 1 */
+ZSTD_STATIC size_t BIT_lookBitsFast(const BIT_DStream_t *bitD, U32 nbBits)
+{
+	U32 const bitMask = sizeof(bitD->bitContainer) * 8 - 1;
+	return (bitD->bitContainer << (bitD->bitsConsumed & bitMask)) >> (((bitMask + 1) - nbBits) & bitMask);
+}
+
+ZSTD_STATIC void BIT_skipBits(BIT_DStream_t *bitD, U32 nbBits) { bitD->bitsConsumed += nbBits; }
+
+/*! BIT_readBits() :
+ *  Read (consume) next n bits from local register and update.
+ *  Pay attention to not read more than nbBits contained into local register.
+ *  @return : extracted value.
+ */
+ZSTD_STATIC size_t BIT_readBits(BIT_DStream_t *bitD, U32 nbBits)
+{
+	size_t const value = BIT_lookBits(bitD, nbBits);
+	BIT_skipBits(bitD, nbBits);
+	return value;
+}
+
+/*! BIT_readBitsFast() :
+*   unsafe version; only works only if nbBits >= 1 */
+ZSTD_STATIC size_t BIT_readBitsFast(BIT_DStream_t *bitD, U32 nbBits)
+{
+	size_t const value = BIT_lookBitsFast(bitD, nbBits);
+	BIT_skipBits(bitD, nbBits);
+	return value;
+}
+
+/*! BIT_reloadDStream() :
+*   Refill `bitD` from buffer previously set in BIT_initDStream() .
+*   This function is safe, it guarantees it will not read beyond src buffer.
+*   @return : status of `BIT_DStream_t` internal register.
+			  if status == BIT_DStream_unfinished, internal register is filled with >= (sizeof(bitD->bitContainer)*8 - 7) bits */
+ZSTD_STATIC BIT_DStream_status BIT_reloadDStream(BIT_DStream_t *bitD)
+{
+	if (bitD->bitsConsumed > (sizeof(bitD->bitContainer) * 8)) /* should not happen => corruption detected */
+		return BIT_DStream_overflow;
+
+	if (bitD->ptr >= bitD->start + sizeof(bitD->bitContainer)) {
+		bitD->ptr -= bitD->bitsConsumed >> 3;
+		bitD->bitsConsumed &= 7;
+		bitD->bitContainer = ZSTD_readLEST(bitD->ptr);
+		return BIT_DStream_unfinished;
+	}
+	if (bitD->ptr == bitD->start) {
+		if (bitD->bitsConsumed < sizeof(bitD->bitContainer) * 8)
+			return BIT_DStream_endOfBuffer;
+		return BIT_DStream_completed;
+	}
+	{
+		U32 nbBytes = bitD->bitsConsumed >> 3;
+		BIT_DStream_status result = BIT_DStream_unfinished;
+		if (bitD->ptr - nbBytes < bitD->start) {
+			nbBytes = (U32)(bitD->ptr - bitD->start); /* ptr > start */
+			result = BIT_DStream_endOfBuffer;
+		}
+		bitD->ptr -= nbBytes;
+		bitD->bitsConsumed -= nbBytes * 8;
+		bitD->bitContainer = ZSTD_readLEST(bitD->ptr); /* reminder : srcSize > sizeof(bitD) */
+		return result;
+	}
+}
+
+/*! BIT_endOfDStream() :
+*   @return Tells if DStream has exactly reached its end (all bits consumed).
+*/
+ZSTD_STATIC unsigned BIT_endOfDStream(const BIT_DStream_t *DStream)
+{
+	return ((DStream->ptr == DStream->start) && (DStream->bitsConsumed == sizeof(DStream->bitContainer) * 8));
+}
+
+#endif /* BITSTREAM_H_MODULE */
diff -Naurp -x debian.hwe linux-4.10.x.ori/lib/zstd/compress.c linux-4.10.x/lib/zstd/compress.c
--- linux-4.10.x.ori/lib/zstd/compress.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-4.10.x/lib/zstd/compress.c	2017-10-30 10:05:19.610447000 +0100
@@ -0,0 +1,3482 @@
+/**
+ * Copyright (c) 2016-present, Yann Collet, Facebook, Inc.
+ * All rights reserved.
+ *
+ * This source code is licensed under the BSD-style license found in the
+ * LICENSE file in the root directory of https://github.com/facebook/zstd.
+ *
+ * This program is free software; you can redistribute it and/or modify it under
+ * the terms of the GNU General Public License version 2 as published by the
+ * Free Software Foundation. This program is dual-licensed; you may select
+ * either version 2 of the GNU General Public License ("GPL") or BSD license
+ * ("BSD").
+ */
+
+/*-*************************************
+*  Dependencies
+***************************************/
+#include "fse.h"
+#include "huf.h"
+#include "mem.h"
+#include "zstd_internal.h" /* includes zstd.h */
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/string.h> /* memset */
+
+/*-*************************************
+*  Constants
+***************************************/
+static const U32 g_searchStrength = 8; /* control skip over incompressible data */
+#define HASH_READ_SIZE 8
+typedef enum { ZSTDcs_created = 0, ZSTDcs_init, ZSTDcs_ongoing, ZSTDcs_ending } ZSTD_compressionStage_e;
+
+/*-*************************************
+*  Helper functions
+***************************************/
+size_t ZSTD_compressBound(size_t srcSize) { return FSE_compressBound(srcSize) + 12; }
+
+/*-*************************************
+*  Sequence storage
+***************************************/
+static void ZSTD_resetSeqStore(seqStore_t *ssPtr)
+{
+	ssPtr->lit = ssPtr->litStart;
+	ssPtr->sequences = ssPtr->sequencesStart;
+	ssPtr->longLengthID = 0;
+}
+
+/*-*************************************
+*  Context memory management
+***************************************/
+struct ZSTD_CCtx_s {
+	const BYTE *nextSrc;  /* next block here to continue on curr prefix */
+	const BYTE *base;     /* All regular indexes relative to this position */
+	const BYTE *dictBase; /* extDict indexes relative to this position */
+	U32 dictLimit;	/* below that point, need extDict */
+	U32 lowLimit;	 /* below that point, no more data */
+	U32 nextToUpdate;     /* index from which to continue dictionary update */
+	U32 nextToUpdate3;    /* index from which to continue dictionary update */
+	U32 hashLog3;	 /* dispatch table : larger == faster, more memory */
+	U32 loadedDictEnd;    /* index of end of dictionary */
+	U32 forceWindow;      /* force back-references to respect limit of 1<<wLog, even for dictionary */
+	U32 forceRawDict;     /* Force loading dictionary in "content-only" mode (no header analysis) */
+	ZSTD_compressionStage_e stage;
+	U32 rep[ZSTD_REP_NUM];
+	U32 repToConfirm[ZSTD_REP_NUM];
+	U32 dictID;
+	ZSTD_parameters params;
+	void *workSpace;
+	size_t workSpaceSize;
+	size_t blockSize;
+	U64 frameContentSize;
+	struct xxh64_state xxhState;
+	ZSTD_customMem customMem;
+
+	seqStore_t seqStore; /* sequences storage ptrs */
+	U32 *hashTable;
+	U32 *hashTable3;
+	U32 *chainTable;
+	HUF_CElt *hufTable;
+	U32 flagStaticTables;
+	HUF_repeat flagStaticHufTable;
+	FSE_CTable offcodeCTable[FSE_CTABLE_SIZE_U32(OffFSELog, MaxOff)];
+	FSE_CTable matchlengthCTable[FSE_CTABLE_SIZE_U32(MLFSELog, MaxML)];
+	FSE_CTable litlengthCTable[FSE_CTABLE_SIZE_U32(LLFSELog, MaxLL)];
+	unsigned tmpCounters[HUF_COMPRESS_WORKSPACE_SIZE_U32];
+};
+
+size_t ZSTD_CCtxWorkspaceBound(ZSTD_compressionParameters cParams)
+{
+	size_t const blockSize = MIN(ZSTD_BLOCKSIZE_ABSOLUTEMAX, (size_t)1 << cParams.windowLog);
+	U32 const divider = (cParams.searchLength == 3) ? 3 : 4;
+	size_t const maxNbSeq = blockSize / divider;
+	size_t const tokenSpace = blockSize + 11 * maxNbSeq;
+	size_t const chainSize = (cParams.strategy == ZSTD_fast) ? 0 : (1 << cParams.chainLog);
+	size_t const hSize = ((size_t)1) << cParams.hashLog;
+	U32 const hashLog3 = (cParams.searchLength > 3) ? 0 : MIN(ZSTD_HASHLOG3_MAX, cParams.windowLog);
+	size_t const h3Size = ((size_t)1) << hashLog3;
+	size_t const tableSpace = (chainSize + hSize + h3Size) * sizeof(U32);
+	size_t const optSpace =
+	    ((MaxML + 1) + (MaxLL + 1) + (MaxOff + 1) + (1 << Litbits)) * sizeof(U32) + (ZSTD_OPT_NUM + 1) * (sizeof(ZSTD_match_t) + sizeof(ZSTD_optimal_t));
+	size_t const workspaceSize = tableSpace + (256 * sizeof(U32)) /* huffTable */ + tokenSpace +
+				     (((cParams.strategy == ZSTD_btopt) || (cParams.strategy == ZSTD_btopt2)) ? optSpace : 0);
+
+	return ZSTD_ALIGN(sizeof(ZSTD_stack)) + ZSTD_ALIGN(sizeof(ZSTD_CCtx)) + ZSTD_ALIGN(workspaceSize);
+}
+
+static ZSTD_CCtx *ZSTD_createCCtx_advanced(ZSTD_customMem customMem)
+{
+	ZSTD_CCtx *cctx;
+	if (!customMem.customAlloc || !customMem.customFree)
+		return NULL;
+	cctx = (ZSTD_CCtx *)ZSTD_malloc(sizeof(ZSTD_CCtx), customMem);
+	if (!cctx)
+		return NULL;
+	memset(cctx, 0, sizeof(ZSTD_CCtx));
+	cctx->customMem = customMem;
+	return cctx;
+}
+
+ZSTD_CCtx *ZSTD_initCCtx(void *workspace, size_t workspaceSize)
+{
+	ZSTD_customMem const stackMem = ZSTD_initStack(workspace, workspaceSize);
+	ZSTD_CCtx *cctx = ZSTD_createCCtx_advanced(stackMem);
+	if (cctx) {
+		cctx->workSpace = ZSTD_stackAllocAll(cctx->customMem.opaque, &cctx->workSpaceSize);
+	}
+	return cctx;
+}
+
+size_t ZSTD_freeCCtx(ZSTD_CCtx *cctx)
+{
+	if (cctx == NULL)
+		return 0; /* support free on NULL */
+	ZSTD_free(cctx->workSpace, cctx->customMem);
+	ZSTD_free(cctx, cctx->customMem);
+	return 0; /* reserved as a potential error code in the future */
+}
+
+const seqStore_t *ZSTD_getSeqStore(const ZSTD_CCtx *ctx) /* hidden interface */ { return &(ctx->seqStore); }
+
+static ZSTD_parameters ZSTD_getParamsFromCCtx(const ZSTD_CCtx *cctx) { return cctx->params; }
+
+/** ZSTD_checkParams() :
+	ensure param values remain within authorized range.
+	@return : 0, or an error code if one value is beyond authorized range */
+size_t ZSTD_checkCParams(ZSTD_compressionParameters cParams)
+{
+#define CLAMPCHECK(val, min, max)                                       \
+	{                                                               \
+		if ((val < min) | (val > max))                          \
+			return ERROR(compressionParameter_unsupported); \
+	}
+	CLAMPCHECK(cParams.windowLog, ZSTD_WINDOWLOG_MIN, ZSTD_WINDOWLOG_MAX);
+	CLAMPCHECK(cParams.chainLog, ZSTD_CHAINLOG_MIN, ZSTD_CHAINLOG_MAX);
+	CLAMPCHECK(cParams.hashLog, ZSTD_HASHLOG_MIN, ZSTD_HASHLOG_MAX);
+	CLAMPCHECK(cParams.searchLog, ZSTD_SEARCHLOG_MIN, ZSTD_SEARCHLOG_MAX);
+	CLAMPCHECK(cParams.searchLength, ZSTD_SEARCHLENGTH_MIN, ZSTD_SEARCHLENGTH_MAX);
+	CLAMPCHECK(cParams.targetLength, ZSTD_TARGETLENGTH_MIN, ZSTD_TARGETLENGTH_MAX);
+	if ((U32)(cParams.strategy) > (U32)ZSTD_btopt2)
+		return ERROR(compressionParameter_unsupported);
+	return 0;
+}
+
+/** ZSTD_cycleLog() :
+ *  condition for correct operation : hashLog > 1 */
+static U32 ZSTD_cycleLog(U32 hashLog, ZSTD_strategy strat)
+{
+	U32 const btScale = ((U32)strat >= (U32)ZSTD_btlazy2);
+	return hashLog - btScale;
+}
+
+/** ZSTD_adjustCParams() :
+	optimize `cPar` for a given input (`srcSize` and `dictSize`).
+	mostly downsizing to reduce memory consumption and initialization.
+	Both `srcSize` and `dictSize` are optional (use 0 if unknown),
+	but if both are 0, no optimization can be done.
+	Note : cPar is considered validated at this stage. Use ZSTD_checkParams() to ensure that. */
+ZSTD_compressionParameters ZSTD_adjustCParams(ZSTD_compressionParameters cPar, unsigned long long srcSize, size_t dictSize)
+{
+	if (srcSize + dictSize == 0)
+		return cPar; /* no size information available : no adjustment */
+
+	/* resize params, to use less memory when necessary */
+	{
+		U32 const minSrcSize = (srcSize == 0) ? 500 : 0;
+		U64 const rSize = srcSize + dictSize + minSrcSize;
+		if (rSize < ((U64)1 << ZSTD_WINDOWLOG_MAX)) {
+			U32 const srcLog = MAX(ZSTD_HASHLOG_MIN, ZSTD_highbit32((U32)(rSize)-1) + 1);
+			if (cPar.windowLog > srcLog)
+				cPar.windowLog = srcLog;
+		}
+	}
+	if (cPar.hashLog > cPar.windowLog)
+		cPar.hashLog = cPar.windowLog;
+	{
+		U32 const cycleLog = ZSTD_cycleLog(cPar.chainLog, cPar.strategy);
+		if (cycleLog > cPar.windowLog)
+			cPar.chainLog -= (cycleLog - cPar.windowLog);
+	}
+
+	if (cPar.windowLog < ZSTD_WINDOWLOG_ABSOLUTEMIN)
+		cPar.windowLog = ZSTD_WINDOWLOG_ABSOLUTEMIN; /* required for frame header */
+
+	return cPar;
+}
+
+static U32 ZSTD_equivalentParams(ZSTD_parameters param1, ZSTD_parameters param2)
+{
+	return (param1.cParams.hashLog == param2.cParams.hashLog) & (param1.cParams.chainLog == param2.cParams.chainLog) &
+	       (param1.cParams.strategy == param2.cParams.strategy) & ((param1.cParams.searchLength == 3) == (param2.cParams.searchLength == 3));
+}
+
+/*! ZSTD_continueCCtx() :
+	reuse CCtx without reset (note : requires no dictionary) */
+static size_t ZSTD_continueCCtx(ZSTD_CCtx *cctx, ZSTD_parameters params, U64 frameContentSize)
+{
+	U32 const end = (U32)(cctx->nextSrc - cctx->base);
+	cctx->params = params;
+	cctx->frameContentSize = frameContentSize;
+	cctx->lowLimit = end;
+	cctx->dictLimit = end;
+	cctx->nextToUpdate = end + 1;
+	cctx->stage = ZSTDcs_init;
+	cctx->dictID = 0;
+	cctx->loadedDictEnd = 0;
+	{
+		int i;
+		for (i = 0; i < ZSTD_REP_NUM; i++)
+			cctx->rep[i] = repStartValue[i];
+	}
+	cctx->seqStore.litLengthSum = 0; /* force reset of btopt stats */
+	xxh64_reset(&cctx->xxhState, 0);
+	return 0;
+}
+
+typedef enum { ZSTDcrp_continue, ZSTDcrp_noMemset, ZSTDcrp_fullReset } ZSTD_compResetPolicy_e;
+
+/*! ZSTD_resetCCtx_advanced() :
+	note : `params` must be validated */
+static size_t ZSTD_resetCCtx_advanced(ZSTD_CCtx *zc, ZSTD_parameters params, U64 frameContentSize, ZSTD_compResetPolicy_e const crp)
+{
+	if (crp == ZSTDcrp_continue)
+		if (ZSTD_equivalentParams(params, zc->params)) {
+			zc->flagStaticTables = 0;
+			zc->flagStaticHufTable = HUF_repeat_none;
+			return ZSTD_continueCCtx(zc, params, frameContentSize);
+		}
+
+	{
+		size_t const blockSize = MIN(ZSTD_BLOCKSIZE_ABSOLUTEMAX, (size_t)1 << params.cParams.windowLog);
+		U32 const divider = (params.cParams.searchLength == 3) ? 3 : 4;
+		size_t const maxNbSeq = blockSize / divider;
+		size_t const tokenSpace = blockSize + 11 * maxNbSeq;
+		size_t const chainSize = (params.cParams.strategy == ZSTD_fast) ? 0 : (1 << params.cParams.chainLog);
+		size_t const hSize = ((size_t)1) << params.cParams.hashLog;
+		U32 const hashLog3 = (params.cParams.searchLength > 3) ? 0 : MIN(ZSTD_HASHLOG3_MAX, params.cParams.windowLog);
+		size_t const h3Size = ((size_t)1) << hashLog3;
+		size_t const tableSpace = (chainSize + hSize + h3Size) * sizeof(U32);
+		void *ptr;
+
+		/* Check if workSpace is large enough, alloc a new one if needed */
+		{
+			size_t const optSpace = ((MaxML + 1) + (MaxLL + 1) + (MaxOff + 1) + (1 << Litbits)) * sizeof(U32) +
+						(ZSTD_OPT_NUM + 1) * (sizeof(ZSTD_match_t) + sizeof(ZSTD_optimal_t));
+			size_t const neededSpace = tableSpace + (256 * sizeof(U32)) /* huffTable */ + tokenSpace +
+						   (((params.cParams.strategy == ZSTD_btopt) || (params.cParams.strategy == ZSTD_btopt2)) ? optSpace : 0);
+			if (zc->workSpaceSize < neededSpace) {
+				ZSTD_free(zc->workSpace, zc->customMem);
+				zc->workSpace = ZSTD_malloc(neededSpace, zc->customMem);
+				if (zc->workSpace == NULL)
+					return ERROR(memory_allocation);
+				zc->workSpaceSize = neededSpace;
+			}
+		}
+
+		if (crp != ZSTDcrp_noMemset)
+			memset(zc->workSpace, 0, tableSpace); /* reset tables only */
+		xxh64_reset(&zc->xxhState, 0);
+		zc->hashLog3 = hashLog3;
+		zc->hashTable = (U32 *)(zc->workSpace);
+		zc->chainTable = zc->hashTable + hSize;
+		zc->hashTable3 = zc->chainTable + chainSize;
+		ptr = zc->hashTable3 + h3Size;
+		zc->hufTable = (HUF_CElt *)ptr;
+		zc->flagStaticTables = 0;
+		zc->flagStaticHufTable = HUF_repeat_none;
+		ptr = ((U32 *)ptr) + 256; /* note : HUF_CElt* is incomplete type, size is simulated using U32 */
+
+		zc->nextToUpdate = 1;
+		zc->nextSrc = NULL;
+		zc->base = NULL;
+		zc->dictBase = NULL;
+		zc->dictLimit = 0;
+		zc->lowLimit = 0;
+		zc->params = params;
+		zc->blockSize = blockSize;
+		zc->frameContentSize = frameContentSize;
+		{
+			int i;
+			for (i = 0; i < ZSTD_REP_NUM; i++)
+				zc->rep[i] = repStartValue[i];
+		}
+
+		if ((params.cParams.strategy == ZSTD_btopt) || (params.cParams.strategy == ZSTD_btopt2)) {
+			zc->seqStore.litFreq = (U32 *)ptr;
+			zc->seqStore.litLengthFreq = zc->seqStore.litFreq + (1 << Litbits);
+			zc->seqStore.matchLengthFreq = zc->seqStore.litLengthFreq + (MaxLL + 1);
+			zc->seqStore.offCodeFreq = zc->seqStore.matchLengthFreq + (MaxML + 1);
+			ptr = zc->seqStore.offCodeFreq + (MaxOff + 1);
+			zc->seqStore.matchTable = (ZSTD_match_t *)ptr;
+			ptr = zc->seqStore.matchTable + ZSTD_OPT_NUM + 1;
+			zc->seqStore.priceTable = (ZSTD_optimal_t *)ptr;
+			ptr = zc->seqStore.priceTable + ZSTD_OPT_NUM + 1;
+			zc->seqStore.litLengthSum = 0;
+		}
+		zc->seqStore.sequencesStart = (seqDef *)ptr;
+		ptr = zc->seqStore.sequencesStart + maxNbSeq;
+		zc->seqStore.llCode = (BYTE *)ptr;
+		zc->seqStore.mlCode = zc->seqStore.llCode + maxNbSeq;
+		zc->seqStore.ofCode = zc->seqStore.mlCode + maxNbSeq;
+		zc->seqStore.litStart = zc->seqStore.ofCode + maxNbSeq;
+
+		zc->stage = ZSTDcs_init;
+		zc->dictID = 0;
+		zc->loadedDictEnd = 0;
+
+		return 0;
+	}
+}
+
+/* ZSTD_invalidateRepCodes() :
+ * ensures next compression will not use repcodes from previous block.
+ * Note : only works with regular variant;
+ *        do not use with extDict variant ! */
+void ZSTD_invalidateRepCodes(ZSTD_CCtx *cctx)
+{
+	int i;
+	for (i = 0; i < ZSTD_REP_NUM; i++)
+		cctx->rep[i] = 0;
+}
+
+/*! ZSTD_copyCCtx() :
+*   Duplicate an existing context `srcCCtx` into another one `dstCCtx`.
+*   Only works during stage ZSTDcs_init (i.e. after creation, but before first call to ZSTD_compressContinue()).
+*   @return : 0, or an error code */
+size_t ZSTD_copyCCtx(ZSTD_CCtx *dstCCtx, const ZSTD_CCtx *srcCCtx, unsigned long long pledgedSrcSize)
+{
+	if (srcCCtx->stage != ZSTDcs_init)
+		return ERROR(stage_wrong);
+
+	memcpy(&dstCCtx->customMem, &srcCCtx->customMem, sizeof(ZSTD_customMem));
+	{
+		ZSTD_parameters params = srcCCtx->params;
+		params.fParams.contentSizeFlag = (pledgedSrcSize > 0);
+		ZSTD_resetCCtx_advanced(dstCCtx, params, pledgedSrcSize, ZSTDcrp_noMemset);
+	}
+
+	/* copy tables */
+	{
+		size_t const chainSize = (srcCCtx->params.cParams.strategy == ZSTD_fast) ? 0 : (1 << srcCCtx->params.cParams.chainLog);
+		size_t const hSize = ((size_t)1) << srcCCtx->params.cParams.hashLog;
+		size_t const h3Size = (size_t)1 << srcCCtx->hashLog3;
+		size_t const tableSpace = (chainSize + hSize + h3Size) * sizeof(U32);
+		memcpy(dstCCtx->workSpace, srcCCtx->workSpace, tableSpace);
+	}
+
+	/* copy dictionary offsets */
+	dstCCtx->nextToUpdate = srcCCtx->nextToUpdate;
+	dstCCtx->nextToUpdate3 = srcCCtx->nextToUpdate3;
+	dstCCtx->nextSrc = srcCCtx->nextSrc;
+	dstCCtx->base = srcCCtx->base;
+	dstCCtx->dictBase = srcCCtx->dictBase;
+	dstCCtx->dictLimit = srcCCtx->dictLimit;
+	dstCCtx->lowLimit = srcCCtx->lowLimit;
+	dstCCtx->loadedDictEnd = srcCCtx->loadedDictEnd;
+	dstCCtx->dictID = srcCCtx->dictID;
+
+	/* copy entropy tables */
+	dstCCtx->flagStaticTables = srcCCtx->flagStaticTables;
+	dstCCtx->flagStaticHufTable = srcCCtx->flagStaticHufTable;
+	if (srcCCtx->flagStaticTables) {
+		memcpy(dstCCtx->litlengthCTable, srcCCtx->litlengthCTable, sizeof(dstCCtx->litlengthCTable));
+		memcpy(dstCCtx->matchlengthCTable, srcCCtx->matchlengthCTable, sizeof(dstCCtx->matchlengthCTable));
+		memcpy(dstCCtx->offcodeCTable, srcCCtx->offcodeCTable, sizeof(dstCCtx->offcodeCTable));
+	}
+	if (srcCCtx->flagStaticHufTable) {
+		memcpy(dstCCtx->hufTable, srcCCtx->hufTable, 256 * 4);
+	}
+
+	return 0;
+}
+
+/*! ZSTD_reduceTable() :
+*   reduce table indexes by `reducerValue` */
+static void ZSTD_reduceTable(U32 *const table, U32 const size, U32 const reducerValue)
+{
+	U32 u;
+	for (u = 0; u < size; u++) {
+		if (table[u] < reducerValue)
+			table[u] = 0;
+		else
+			table[u] -= reducerValue;
+	}
+}
+
+/*! ZSTD_reduceIndex() :
+*   rescale all indexes to avoid future overflow (indexes are U32) */
+static void ZSTD_reduceIndex(ZSTD_CCtx *zc, const U32 reducerValue)
+{
+	{
+		U32 const hSize = 1 << zc->params.cParams.hashLog;
+		ZSTD_reduceTable(zc->hashTable, hSize, reducerValue);
+	}
+
+	{
+		U32 const chainSize = (zc->params.cParams.strategy == ZSTD_fast) ? 0 : (1 << zc->params.cParams.chainLog);
+		ZSTD_reduceTable(zc->chainTable, chainSize, reducerValue);
+	}
+
+	{
+		U32 const h3Size = (zc->hashLog3) ? 1 << zc->hashLog3 : 0;
+		ZSTD_reduceTable(zc->hashTable3, h3Size, reducerValue);
+	}
+}
+
+/*-*******************************************************
+*  Block entropic compression
+*********************************************************/
+
+/* See doc/zstd_compression_format.md for detailed format description */
+
+size_t ZSTD_noCompressBlock(void *dst, size_t dstCapacity, const void *src, size_t srcSize)
+{
+	if (srcSize + ZSTD_blockHeaderSize > dstCapacity)
+		return ERROR(dstSize_tooSmall);
+	memcpy((BYTE *)dst + ZSTD_blockHeaderSize, src, srcSize);
+	ZSTD_writeLE24(dst, (U32)(srcSize << 2) + (U32)bt_raw);
+	return ZSTD_blockHeaderSize + srcSize;
+}
+
+static size_t ZSTD_noCompressLiterals(void *dst, size_t dstCapacity, const void *src, size_t srcSize)
+{
+	BYTE *const ostart = (BYTE * const)dst;
+	U32 const flSize = 1 + (srcSize > 31) + (srcSize > 4095);
+
+	if (srcSize + flSize > dstCapacity)
+		return ERROR(dstSize_tooSmall);
+
+	switch (flSize) {
+	case 1: /* 2 - 1 - 5 */ ostart[0] = (BYTE)((U32)set_basic + (srcSize << 3)); break;
+	case 2: /* 2 - 2 - 12 */ ZSTD_writeLE16(ostart, (U16)((U32)set_basic + (1 << 2) + (srcSize << 4))); break;
+	default: /*note : should not be necessary : flSize is within {1,2,3} */
+	case 3: /* 2 - 2 - 20 */ ZSTD_writeLE32(ostart, (U32)((U32)set_basic + (3 << 2) + (srcSize << 4))); break;
+	}
+
+	memcpy(ostart + flSize, src, srcSize);
+	return srcSize + flSize;
+}
+
+static size_t ZSTD_compressRleLiteralsBlock(void *dst, size_t dstCapacity, const void *src, size_t srcSize)
+{
+	BYTE *const ostart = (BYTE * const)dst;
+	U32 const flSize = 1 + (srcSize > 31) + (srcSize > 4095);
+
+	(void)dstCapacity; /* dstCapacity already guaranteed to be >=4, hence large enough */
+
+	switch (flSize) {
+	case 1: /* 2 - 1 - 5 */ ostart[0] = (BYTE)((U32)set_rle + (srcSize << 3)); break;
+	case 2: /* 2 - 2 - 12 */ ZSTD_writeLE16(ostart, (U16)((U32)set_rle + (1 << 2) + (srcSize << 4))); break;
+	default: /*note : should not be necessary : flSize is necessarily within {1,2,3} */
+	case 3: /* 2 - 2 - 20 */ ZSTD_writeLE32(ostart, (U32)((U32)set_rle + (3 << 2) + (srcSize << 4))); break;
+	}
+
+	ostart[flSize] = *(const BYTE *)src;
+	return flSize + 1;
+}
+
+static size_t ZSTD_minGain(size_t srcSize) { return (srcSize >> 6) + 2; }
+
+static size_t ZSTD_compressLiterals(ZSTD_CCtx *zc, void *dst, size_t dstCapacity, const void *src, size_t srcSize)
+{
+	size_t const minGain = ZSTD_minGain(srcSize);
+	size_t const lhSize = 3 + (srcSize >= 1 KB) + (srcSize >= 16 KB);
+	BYTE *const ostart = (BYTE *)dst;
+	U32 singleStream = srcSize < 256;
+	symbolEncodingType_e hType = set_compressed;
+	size_t cLitSize;
+
+/* small ? don't even attempt compression (speed opt) */
+#define LITERAL_NOENTROPY 63
+	{
+		size_t const minLitSize = zc->flagStaticHufTable == HUF_repeat_valid ? 6 : LITERAL_NOENTROPY;
+		if (srcSize <= minLitSize)
+			return ZSTD_noCompressLiterals(dst, dstCapacity, src, srcSize);
+	}
+
+	if (dstCapacity < lhSize + 1)
+		return ERROR(dstSize_tooSmall); /* not enough space for compression */
+	{
+		HUF_repeat repeat = zc->flagStaticHufTable;
+		int const preferRepeat = zc->params.cParams.strategy < ZSTD_lazy ? srcSize <= 1024 : 0;
+		if (repeat == HUF_repeat_valid && lhSize == 3)
+			singleStream = 1;
+		cLitSize = singleStream ? HUF_compress1X_repeat(ostart + lhSize, dstCapacity - lhSize, src, srcSize, 255, 11, zc->tmpCounters,
+								sizeof(zc->tmpCounters), zc->hufTable, &repeat, preferRepeat)
+					: HUF_compress4X_repeat(ostart + lhSize, dstCapacity - lhSize, src, srcSize, 255, 11, zc->tmpCounters,
+								sizeof(zc->tmpCounters), zc->hufTable, &repeat, preferRepeat);
+		if (repeat != HUF_repeat_none) {
+			hType = set_repeat;
+		} /* reused the existing table */
+		else {
+			zc->flagStaticHufTable = HUF_repeat_check;
+		} /* now have a table to reuse */
+	}
+
+	if ((cLitSize == 0) | (cLitSize >= srcSize - minGain)) {
+		zc->flagStaticHufTable = HUF_repeat_none;
+		return ZSTD_noCompressLiterals(dst, dstCapacity, src, srcSize);
+	}
+	if (cLitSize == 1) {
+		zc->flagStaticHufTable = HUF_repeat_none;
+		return ZSTD_compressRleLiteralsBlock(dst, dstCapacity, src, srcSize);
+	}
+
+	/* Build header */
+	switch (lhSize) {
+	case 3: /* 2 - 2 - 10 - 10 */
+	{
+		U32 const lhc = hType + ((!singleStream) << 2) + ((U32)srcSize << 4) + ((U32)cLitSize << 14);
+		ZSTD_writeLE24(ostart, lhc);
+		break;
+	}
+	case 4: /* 2 - 2 - 14 - 14 */
+	{
+		U32 const lhc = hType + (2 << 2) + ((U32)srcSize << 4) + ((U32)cLitSize << 18);
+		ZSTD_writeLE32(ostart, lhc);
+		break;
+	}
+	default: /* should not be necessary, lhSize is only {3,4,5} */
+	case 5:  /* 2 - 2 - 18 - 18 */
+	{
+		U32 const lhc = hType + (3 << 2) + ((U32)srcSize << 4) + ((U32)cLitSize << 22);
+		ZSTD_writeLE32(ostart, lhc);
+		ostart[4] = (BYTE)(cLitSize >> 10);
+		break;
+	}
+	}
+	return lhSize + cLitSize;
+}
+
+static const BYTE LL_Code[64] = {0,  1,  2,  3,  4,  5,  6,  7,  8,  9,  10, 11, 12, 13, 14, 15, 16, 16, 17, 17, 18, 18,
+				 19, 19, 20, 20, 20, 20, 21, 21, 21, 21, 22, 22, 22, 22, 22, 22, 22, 22, 23, 23, 23, 23,
+				 23, 23, 23, 23, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24};
+
+static const BYTE ML_Code[128] = {0,  1,  2,  3,  4,  5,  6,  7,  8,  9,  10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25,
+				  26, 27, 28, 29, 30, 31, 32, 32, 33, 33, 34, 34, 35, 35, 36, 36, 36, 36, 37, 37, 37, 37, 38, 38, 38, 38,
+				  38, 38, 38, 38, 39, 39, 39, 39, 39, 39, 39, 39, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40,
+				  40, 40, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 42, 42, 42, 42, 42, 42, 42, 42,
+				  42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42};
+
+void ZSTD_seqToCodes(const seqStore_t *seqStorePtr)
+{
+	BYTE const LL_deltaCode = 19;
+	BYTE const ML_deltaCode = 36;
+	const seqDef *const sequences = seqStorePtr->sequencesStart;
+	BYTE *const llCodeTable = seqStorePtr->llCode;
+	BYTE *const ofCodeTable = seqStorePtr->ofCode;
+	BYTE *const mlCodeTable = seqStorePtr->mlCode;
+	U32 const nbSeq = (U32)(seqStorePtr->sequences - seqStorePtr->sequencesStart);
+	U32 u;
+	for (u = 0; u < nbSeq; u++) {
+		U32 const llv = sequences[u].litLength;
+		U32 const mlv = sequences[u].matchLength;
+		llCodeTable[u] = (llv > 63) ? (BYTE)ZSTD_highbit32(llv) + LL_deltaCode : LL_Code[llv];
+		ofCodeTable[u] = (BYTE)ZSTD_highbit32(sequences[u].offset);
+		mlCodeTable[u] = (mlv > 127) ? (BYTE)ZSTD_highbit32(mlv) + ML_deltaCode : ML_Code[mlv];
+	}
+	if (seqStorePtr->longLengthID == 1)
+		llCodeTable[seqStorePtr->longLengthPos] = MaxLL;
+	if (seqStorePtr->longLengthID == 2)
+		mlCodeTable[seqStorePtr->longLengthPos] = MaxML;
+}
+
+ZSTD_STATIC size_t ZSTD_compressSequences_internal(ZSTD_CCtx *zc, void *dst, size_t dstCapacity)
+{
+	const int longOffsets = zc->params.cParams.windowLog > STREAM_ACCUMULATOR_MIN;
+	const seqStore_t *seqStorePtr = &(zc->seqStore);
+	FSE_CTable *CTable_LitLength = zc->litlengthCTable;
+	FSE_CTable *CTable_OffsetBits = zc->offcodeCTable;
+	FSE_CTable *CTable_MatchLength = zc->matchlengthCTable;
+	U32 LLtype, Offtype, MLtype; /* compressed, raw or rle */
+	const seqDef *const sequences = seqStorePtr->sequencesStart;
+	const BYTE *const ofCodeTable = seqStorePtr->ofCode;
+	const BYTE *const llCodeTable = seqStorePtr->llCode;
+	const BYTE *const mlCodeTable = seqStorePtr->mlCode;
+	BYTE *const ostart = (BYTE *)dst;
+	BYTE *const oend = ostart + dstCapacity;
+	BYTE *op = ostart;
+	size_t const nbSeq = seqStorePtr->sequences - seqStorePtr->sequencesStart;
+	BYTE *seqHead;
+
+	U32 *count;
+	S16 *norm;
+	U32 *workspace;
+	size_t workspaceSize = sizeof(zc->tmpCounters);
+	{
+		size_t spaceUsed32 = 0;
+		count = (U32 *)zc->tmpCounters + spaceUsed32;
+		spaceUsed32 += MaxSeq + 1;
+		norm = (S16 *)((U32 *)zc->tmpCounters + spaceUsed32);
+		spaceUsed32 += ALIGN(sizeof(S16) * (MaxSeq + 1), sizeof(U32)) >> 2;
+
+		workspace = (U32 *)zc->tmpCounters + spaceUsed32;
+		workspaceSize -= (spaceUsed32 << 2);
+	}
+
+	/* Compress literals */
+	{
+		const BYTE *const literals = seqStorePtr->litStart;
+		size_t const litSize = seqStorePtr->lit - literals;
+		size_t const cSize = ZSTD_compressLiterals(zc, op, dstCapacity, literals, litSize);
+		if (ZSTD_isError(cSize))
+			return cSize;
+		op += cSize;
+	}
+
+	/* Sequences Header */
+	if ((oend - op) < 3 /*max nbSeq Size*/ + 1 /*seqHead */)
+		return ERROR(dstSize_tooSmall);
+	if (nbSeq < 0x7F)
+		*op++ = (BYTE)nbSeq;
+	else if (nbSeq < LONGNBSEQ)
+		op[0] = (BYTE)((nbSeq >> 8) + 0x80), op[1] = (BYTE)nbSeq, op += 2;
+	else
+		op[0] = 0xFF, ZSTD_writeLE16(op + 1, (U16)(nbSeq - LONGNBSEQ)), op += 3;
+	if (nbSeq == 0)
+		return op - ostart;
+
+	/* seqHead : flags for FSE encoding type */
+	seqHead = op++;
+
+#define MIN_SEQ_FOR_DYNAMIC_FSE 64
+#define MAX_SEQ_FOR_STATIC_FSE 1000
+
+	/* convert length/distances into codes */
+	ZSTD_seqToCodes(seqStorePtr);
+
+	/* CTable for Literal Lengths */
+	{
+		U32 max = MaxLL;
+		size_t const mostFrequent = FSE_countFast_wksp(count, &max, llCodeTable, nbSeq, workspace);
+		if ((mostFrequent == nbSeq) && (nbSeq > 2)) {
+			*op++ = llCodeTable[0];
+			FSE_buildCTable_rle(CTable_LitLength, (BYTE)max);
+			LLtype = set_rle;
+		} else if ((zc->flagStaticTables) && (nbSeq < MAX_SEQ_FOR_STATIC_FSE)) {
+			LLtype = set_repeat;
+		} else if ((nbSeq < MIN_SEQ_FOR_DYNAMIC_FSE) || (mostFrequent < (nbSeq >> (LL_defaultNormLog - 1)))) {
+			FSE_buildCTable_wksp(CTable_LitLength, LL_defaultNorm, MaxLL, LL_defaultNormLog, workspace, workspaceSize);
+			LLtype = set_basic;
+		} else {
+			size_t nbSeq_1 = nbSeq;
+			const U32 tableLog = FSE_optimalTableLog(LLFSELog, nbSeq, max);
+			if (count[llCodeTable[nbSeq - 1]] > 1) {
+				count[llCodeTable[nbSeq - 1]]--;
+				nbSeq_1--;
+			}
+			FSE_normalizeCount(norm, tableLog, count, nbSeq_1, max);
+			{
+				size_t const NCountSize = FSE_writeNCount(op, oend - op, norm, max, tableLog); /* overflow protected */
+				if (FSE_isError(NCountSize))
+					return NCountSize;
+				op += NCountSize;
+			}
+			FSE_buildCTable_wksp(CTable_LitLength, norm, max, tableLog, workspace, workspaceSize);
+			LLtype = set_compressed;
+		}
+	}
+
+	/* CTable for Offsets */
+	{
+		U32 max = MaxOff;
+		size_t const mostFrequent = FSE_countFast_wksp(count, &max, ofCodeTable, nbSeq, workspace);
+		if ((mostFrequent == nbSeq) && (nbSeq > 2)) {
+			*op++ = ofCodeTable[0];
+			FSE_buildCTable_rle(CTable_OffsetBits, (BYTE)max);
+			Offtype = set_rle;
+		} else if ((zc->flagStaticTables) && (nbSeq < MAX_SEQ_FOR_STATIC_FSE)) {
+			Offtype = set_repeat;
+		} else if ((nbSeq < MIN_SEQ_FOR_DYNAMIC_FSE) || (mostFrequent < (nbSeq >> (OF_defaultNormLog - 1)))) {
+			FSE_buildCTable_wksp(CTable_OffsetBits, OF_defaultNorm, MaxOff, OF_defaultNormLog, workspace, workspaceSize);
+			Offtype = set_basic;
+		} else {
+			size_t nbSeq_1 = nbSeq;
+			const U32 tableLog = FSE_optimalTableLog(OffFSELog, nbSeq, max);
+			if (count[ofCodeTable[nbSeq - 1]] > 1) {
+				count[ofCodeTable[nbSeq - 1]]--;
+				nbSeq_1--;
+			}
+			FSE_normalizeCount(norm, tableLog, count, nbSeq_1, max);
+			{
+				size_t const NCountSize = FSE_writeNCount(op, oend - op, norm, max, tableLog); /* overflow protected */
+				if (FSE_isError(NCountSize))
+					return NCountSize;
+				op += NCountSize;
+			}
+			FSE_buildCTable_wksp(CTable_OffsetBits, norm, max, tableLog, workspace, workspaceSize);
+			Offtype = set_compressed;
+		}
+	}
+
+	/* CTable for MatchLengths */
+	{
+		U32 max = MaxML;
+		size_t const mostFrequent = FSE_countFast_wksp(count, &max, mlCodeTable, nbSeq, workspace);
+		if ((mostFrequent == nbSeq) && (nbSeq > 2)) {
+			*op++ = *mlCodeTable;
+			FSE_buildCTable_rle(CTable_MatchLength, (BYTE)max);
+			MLtype = set_rle;
+		} else if ((zc->flagStaticTables) && (nbSeq < MAX_SEQ_FOR_STATIC_FSE)) {
+			MLtype = set_repeat;
+		} else if ((nbSeq < MIN_SEQ_FOR_DYNAMIC_FSE) || (mostFrequent < (nbSeq >> (ML_defaultNormLog - 1)))) {
+			FSE_buildCTable_wksp(CTable_MatchLength, ML_defaultNorm, MaxML, ML_defaultNormLog, workspace, workspaceSize);
+			MLtype = set_basic;
+		} else {
+			size_t nbSeq_1 = nbSeq;
+			const U32 tableLog = FSE_optimalTableLog(MLFSELog, nbSeq, max);
+			if (count[mlCodeTable[nbSeq - 1]] > 1) {
+				count[mlCodeTable[nbSeq - 1]]--;
+				nbSeq_1--;
+			}
+			FSE_normalizeCount(norm, tableLog, count, nbSeq_1, max);
+			{
+				size_t const NCountSize = FSE_writeNCount(op, oend - op, norm, max, tableLog); /* overflow protected */
+				if (FSE_isError(NCountSize))
+					return NCountSize;
+				op += NCountSize;
+			}
+			FSE_buildCTable_wksp(CTable_MatchLength, norm, max, tableLog, workspace, workspaceSize);
+			MLtype = set_compressed;
+		}
+	}
+
+	*seqHead = (BYTE)((LLtype << 6) + (Offtype << 4) + (MLtype << 2));
+	zc->flagStaticTables = 0;
+
+	/* Encoding Sequences */
+	{
+		BIT_CStream_t blockStream;
+		FSE_CState_t stateMatchLength;
+		FSE_CState_t stateOffsetBits;
+		FSE_CState_t stateLitLength;
+
+		CHECK_E(BIT_initCStream(&blockStream, op, oend - op), dstSize_tooSmall); /* not enough space remaining */
+
+		/* first symbols */
+		FSE_initCState2(&stateMatchLength, CTable_MatchLength, mlCodeTable[nbSeq - 1]);
+		FSE_initCState2(&stateOffsetBits, CTable_OffsetBits, ofCodeTable[nbSeq - 1]);
+		FSE_initCState2(&stateLitLength, CTable_LitLength, llCodeTable[nbSeq - 1]);
+		BIT_addBits(&blockStream, sequences[nbSeq - 1].litLength, LL_bits[llCodeTable[nbSeq - 1]]);
+		if (ZSTD_32bits())
+			BIT_flushBits(&blockStream);
+		BIT_addBits(&blockStream, sequences[nbSeq - 1].matchLength, ML_bits[mlCodeTable[nbSeq - 1]]);
+		if (ZSTD_32bits())
+			BIT_flushBits(&blockStream);
+		if (longOffsets) {
+			U32 const ofBits = ofCodeTable[nbSeq - 1];
+			int const extraBits = ofBits - MIN(ofBits, STREAM_ACCUMULATOR_MIN - 1);
+			if (extraBits) {
+				BIT_addBits(&blockStream, sequences[nbSeq - 1].offset, extraBits);
+				BIT_flushBits(&blockStream);
+			}
+			BIT_addBits(&blockStream, sequences[nbSeq - 1].offset >> extraBits, ofBits - extraBits);
+		} else {
+			BIT_addBits(&blockStream, sequences[nbSeq - 1].offset, ofCodeTable[nbSeq - 1]);
+		}
+		BIT_flushBits(&blockStream);
+
+		{
+			size_t n;
+			for (n = nbSeq - 2; n < nbSeq; n--) { /* intentional underflow */
+				BYTE const llCode = llCodeTable[n];
+				BYTE const ofCode = ofCodeTable[n];
+				BYTE const mlCode = mlCodeTable[n];
+				U32 const llBits = LL_bits[llCode];
+				U32 const ofBits = ofCode; /* 32b*/ /* 64b*/
+				U32 const mlBits = ML_bits[mlCode];
+				/* (7)*/							    /* (7)*/
+				FSE_encodeSymbol(&blockStream, &stateOffsetBits, ofCode); /* 15 */  /* 15 */
+				FSE_encodeSymbol(&blockStream, &stateMatchLength, mlCode); /* 24 */ /* 24 */
+				if (ZSTD_32bits())
+					BIT_flushBits(&blockStream);				  /* (7)*/
+				FSE_encodeSymbol(&blockStream, &stateLitLength, llCode); /* 16 */ /* 33 */
+				if (ZSTD_32bits() || (ofBits + mlBits + llBits >= 64 - 7 - (LLFSELog + MLFSELog + OffFSELog)))
+					BIT_flushBits(&blockStream); /* (7)*/
+				BIT_addBits(&blockStream, sequences[n].litLength, llBits);
+				if (ZSTD_32bits() && ((llBits + mlBits) > 24))
+					BIT_flushBits(&blockStream);
+				BIT_addBits(&blockStream, sequences[n].matchLength, mlBits);
+				if (ZSTD_32bits())
+					BIT_flushBits(&blockStream); /* (7)*/
+				if (longOffsets) {
+					int const extraBits = ofBits - MIN(ofBits, STREAM_ACCUMULATOR_MIN - 1);
+					if (extraBits) {
+						BIT_addBits(&blockStream, sequences[n].offset, extraBits);
+						BIT_flushBits(&blockStream); /* (7)*/
+					}
+					BIT_addBits(&blockStream, sequences[n].offset >> extraBits, ofBits - extraBits); /* 31 */
+				} else {
+					BIT_addBits(&blockStream, sequences[n].offset, ofBits); /* 31 */
+				}
+				BIT_flushBits(&blockStream); /* (7)*/
+			}
+		}
+
+		FSE_flushCState(&blockStream, &stateMatchLength);
+		FSE_flushCState(&blockStream, &stateOffsetBits);
+		FSE_flushCState(&blockStream, &stateLitLength);
+
+		{
+			size_t const streamSize = BIT_closeCStream(&blockStream);
+			if (streamSize == 0)
+				return ERROR(dstSize_tooSmall); /* not enough space */
+			op += streamSize;
+		}
+	}
+	return op - ostart;
+}
+
+ZSTD_STATIC size_t ZSTD_compressSequences(ZSTD_CCtx *zc, void *dst, size_t dstCapacity, size_t srcSize)
+{
+	size_t const cSize = ZSTD_compressSequences_internal(zc, dst, dstCapacity);
+	size_t const minGain = ZSTD_minGain(srcSize);
+	size_t const maxCSize = srcSize - minGain;
+	/* If the srcSize <= dstCapacity, then there is enough space to write a
+	 * raw uncompressed block. Since we ran out of space, the block must not
+	 * be compressible, so fall back to a raw uncompressed block.
+	 */
+	int const uncompressibleError = cSize == ERROR(dstSize_tooSmall) && srcSize <= dstCapacity;
+	int i;
+
+	if (ZSTD_isError(cSize) && !uncompressibleError)
+		return cSize;
+	if (cSize >= maxCSize || uncompressibleError) {
+		zc->flagStaticHufTable = HUF_repeat_none;
+		return 0;
+	}
+	/* confirm repcodes */
+	for (i = 0; i < ZSTD_REP_NUM; i++)
+		zc->rep[i] = zc->repToConfirm[i];
+	return cSize;
+}
+
+/*! ZSTD_storeSeq() :
+	Store a sequence (literal length, literals, offset code and match length code) into seqStore_t.
+	`offsetCode` : distance to match, or 0 == repCode.
+	`matchCode` : matchLength - MINMATCH
+*/
+ZSTD_STATIC void ZSTD_storeSeq(seqStore_t *seqStorePtr, size_t litLength, const void *literals, U32 offsetCode, size_t matchCode)
+{
+	/* copy Literals */
+	ZSTD_wildcopy(seqStorePtr->lit, literals, litLength);
+	seqStorePtr->lit += litLength;
+
+	/* literal Length */
+	if (litLength > 0xFFFF) {
+		seqStorePtr->longLengthID = 1;
+		seqStorePtr->longLengthPos = (U32)(seqStorePtr->sequences - seqStorePtr->sequencesStart);
+	}
+	seqStorePtr->sequences[0].litLength = (U16)litLength;
+
+	/* match offset */
+	seqStorePtr->sequences[0].offset = offsetCode + 1;
+
+	/* match Length */
+	if (matchCode > 0xFFFF) {
+		seqStorePtr->longLengthID = 2;
+		seqStorePtr->longLengthPos = (U32)(seqStorePtr->sequences - seqStorePtr->sequencesStart);
+	}
+	seqStorePtr->sequences[0].matchLength = (U16)matchCode;
+
+	seqStorePtr->sequences++;
+}
+
+/*-*************************************
+*  Match length counter
+***************************************/
+static unsigned ZSTD_NbCommonBytes(register size_t val)
+{
+	if (ZSTD_isLittleEndian()) {
+		if (ZSTD_64bits()) {
+			return (__builtin_ctzll((U64)val) >> 3);
+		} else { /* 32 bits */
+			return (__builtin_ctz((U32)val) >> 3);
+		}
+	} else { /* Big Endian CPU */
+		if (ZSTD_64bits()) {
+			return (__builtin_clzll(val) >> 3);
+		} else { /* 32 bits */
+			return (__builtin_clz((U32)val) >> 3);
+		}
+	}
+}
+
+static size_t ZSTD_count(const BYTE *pIn, const BYTE *pMatch, const BYTE *const pInLimit)
+{
+	const BYTE *const pStart = pIn;
+	const BYTE *const pInLoopLimit = pInLimit - (sizeof(size_t) - 1);
+
+	while (pIn < pInLoopLimit) {
+		size_t const diff = ZSTD_readST(pMatch) ^ ZSTD_readST(pIn);
+		if (!diff) {
+			pIn += sizeof(size_t);
+			pMatch += sizeof(size_t);
+			continue;
+		}
+		pIn += ZSTD_NbCommonBytes(diff);
+		return (size_t)(pIn - pStart);
+	}
+	if (ZSTD_64bits())
+		if ((pIn < (pInLimit - 3)) && (ZSTD_read32(pMatch) == ZSTD_read32(pIn))) {
+			pIn += 4;
+			pMatch += 4;
+		}
+	if ((pIn < (pInLimit - 1)) && (ZSTD_read16(pMatch) == ZSTD_read16(pIn))) {
+		pIn += 2;
+		pMatch += 2;
+	}
+	if ((pIn < pInLimit) && (*pMatch == *pIn))
+		pIn++;
+	return (size_t)(pIn - pStart);
+}
+
+/** ZSTD_count_2segments() :
+*   can count match length with `ip` & `match` in 2 different segments.
+*   convention : on reaching mEnd, match count continue starting from iStart
+*/
+static size_t ZSTD_count_2segments(const BYTE *ip, const BYTE *match, const BYTE *iEnd, const BYTE *mEnd, const BYTE *iStart)
+{
+	const BYTE *const vEnd = MIN(ip + (mEnd - match), iEnd);
+	size_t const matchLength = ZSTD_count(ip, match, vEnd);
+	if (match + matchLength != mEnd)
+		return matchLength;
+	return matchLength + ZSTD_count(ip + matchLength, iStart, iEnd);
+}
+
+/*-*************************************
+*  Hashes
+***************************************/
+static const U32 prime3bytes = 506832829U;
+static U32 ZSTD_hash3(U32 u, U32 h) { return ((u << (32 - 24)) * prime3bytes) >> (32 - h); }
+ZSTD_STATIC size_t ZSTD_hash3Ptr(const void *ptr, U32 h) { return ZSTD_hash3(ZSTD_readLE32(ptr), h); } /* only in zstd_opt.h */
+
+static const U32 prime4bytes = 2654435761U;
+static U32 ZSTD_hash4(U32 u, U32 h) { return (u * prime4bytes) >> (32 - h); }
+static size_t ZSTD_hash4Ptr(const void *ptr, U32 h) { return ZSTD_hash4(ZSTD_read32(ptr), h); }
+
+static const U64 prime5bytes = 889523592379ULL;
+static size_t ZSTD_hash5(U64 u, U32 h) { return (size_t)(((u << (64 - 40)) * prime5bytes) >> (64 - h)); }
+static size_t ZSTD_hash5Ptr(const void *p, U32 h) { return ZSTD_hash5(ZSTD_readLE64(p), h); }
+
+static const U64 prime6bytes = 227718039650203ULL;
+static size_t ZSTD_hash6(U64 u, U32 h) { return (size_t)(((u << (64 - 48)) * prime6bytes) >> (64 - h)); }
+static size_t ZSTD_hash6Ptr(const void *p, U32 h) { return ZSTD_hash6(ZSTD_readLE64(p), h); }
+
+static const U64 prime7bytes = 58295818150454627ULL;
+static size_t ZSTD_hash7(U64 u, U32 h) { return (size_t)(((u << (64 - 56)) * prime7bytes) >> (64 - h)); }
+static size_t ZSTD_hash7Ptr(const void *p, U32 h) { return ZSTD_hash7(ZSTD_readLE64(p), h); }
+
+static const U64 prime8bytes = 0xCF1BBCDCB7A56463ULL;
+static size_t ZSTD_hash8(U64 u, U32 h) { return (size_t)(((u)*prime8bytes) >> (64 - h)); }
+static size_t ZSTD_hash8Ptr(const void *p, U32 h) { return ZSTD_hash8(ZSTD_readLE64(p), h); }
+
+static size_t ZSTD_hashPtr(const void *p, U32 hBits, U32 mls)
+{
+	switch (mls) {
+	// case 3: return ZSTD_hash3Ptr(p, hBits);
+	default:
+	case 4: return ZSTD_hash4Ptr(p, hBits);
+	case 5: return ZSTD_hash5Ptr(p, hBits);
+	case 6: return ZSTD_hash6Ptr(p, hBits);
+	case 7: return ZSTD_hash7Ptr(p, hBits);
+	case 8: return ZSTD_hash8Ptr(p, hBits);
+	}
+}
+
+/*-*************************************
+*  Fast Scan
+***************************************/
+static void ZSTD_fillHashTable(ZSTD_CCtx *zc, const void *end, const U32 mls)
+{
+	U32 *const hashTable = zc->hashTable;
+	U32 const hBits = zc->params.cParams.hashLog;
+	const BYTE *const base = zc->base;
+	const BYTE *ip = base + zc->nextToUpdate;
+	const BYTE *const iend = ((const BYTE *)end) - HASH_READ_SIZE;
+	const size_t fastHashFillStep = 3;
+
+	while (ip <= iend) {
+		hashTable[ZSTD_hashPtr(ip, hBits, mls)] = (U32)(ip - base);
+		ip += fastHashFillStep;
+	}
+}
+
+FORCE_INLINE
+void ZSTD_compressBlock_fast_generic(ZSTD_CCtx *cctx, const void *src, size_t srcSize, const U32 mls)
+{
+	U32 *const hashTable = cctx->hashTable;
+	U32 const hBits = cctx->params.cParams.hashLog;
+	seqStore_t *seqStorePtr = &(cctx->seqStore);
+	const BYTE *const base = cctx->base;
+	const BYTE *const istart = (const BYTE *)src;
+	const BYTE *ip = istart;
+	const BYTE *anchor = istart;
+	const U32 lowestIndex = cctx->dictLimit;
+	const BYTE *const lowest = base + lowestIndex;
+	const BYTE *const iend = istart + srcSize;
+	const BYTE *const ilimit = iend - HASH_READ_SIZE;
+	U32 offset_1 = cctx->rep[0], offset_2 = cctx->rep[1];
+	U32 offsetSaved = 0;
+
+	/* init */
+	ip += (ip == lowest);
+	{
+		U32 const maxRep = (U32)(ip - lowest);
+		if (offset_2 > maxRep)
+			offsetSaved = offset_2, offset_2 = 0;
+		if (offset_1 > maxRep)
+			offsetSaved = offset_1, offset_1 = 0;
+	}
+
+	/* Main Search Loop */
+	while (ip < ilimit) { /* < instead of <=, because repcode check at (ip+1) */
+		size_t mLength;
+		size_t const h = ZSTD_hashPtr(ip, hBits, mls);
+		U32 const curr = (U32)(ip - base);
+		U32 const matchIndex = hashTable[h];
+		const BYTE *match = base + matchIndex;
+		hashTable[h] = curr; /* update hash table */
+
+		if ((offset_1 > 0) & (ZSTD_read32(ip + 1 - offset_1) == ZSTD_read32(ip + 1))) {
+			mLength = ZSTD_count(ip + 1 + 4, ip + 1 + 4 - offset_1, iend) + 4;
+			ip++;
+			ZSTD_storeSeq(seqStorePtr, ip - anchor, anchor, 0, mLength - MINMATCH);
+		} else {
+			U32 offset;
+			if ((matchIndex <= lowestIndex) || (ZSTD_read32(match) != ZSTD_read32(ip))) {
+				ip += ((ip - anchor) >> g_searchStrength) + 1;
+				continue;
+			}
+			mLength = ZSTD_count(ip + 4, match + 4, iend) + 4;
+			offset = (U32)(ip - match);
+			while (((ip > anchor) & (match > lowest)) && (ip[-1] == match[-1])) {
+				ip--;
+				match--;
+				mLength++;
+			} /* catch up */
+			offset_2 = offset_1;
+			offset_1 = offset;
+
+			ZSTD_storeSeq(seqStorePtr, ip - anchor, anchor, offset + ZSTD_REP_MOVE, mLength - MINMATCH);
+		}
+
+		/* match found */
+		ip += mLength;
+		anchor = ip;
+
+		if (ip <= ilimit) {
+			/* Fill Table */
+			hashTable[ZSTD_hashPtr(base + curr + 2, hBits, mls)] = curr + 2; /* here because curr+2 could be > iend-8 */
+			hashTable[ZSTD_hashPtr(ip - 2, hBits, mls)] = (U32)(ip - 2 - base);
+			/* check immediate repcode */
+			while ((ip <= ilimit) && ((offset_2 > 0) & (ZSTD_read32(ip) == ZSTD_read32(ip - offset_2)))) {
+				/* store sequence */
+				size_t const rLength = ZSTD_count(ip + 4, ip + 4 - offset_2, iend) + 4;
+				{
+					U32 const tmpOff = offset_2;
+					offset_2 = offset_1;
+					offset_1 = tmpOff;
+				} /* swap offset_2 <=> offset_1 */
+				hashTable[ZSTD_hashPtr(ip, hBits, mls)] = (U32)(ip - base);
+				ZSTD_storeSeq(seqStorePtr, 0, anchor, 0, rLength - MINMATCH);
+				ip += rLength;
+				anchor = ip;
+				continue; /* faster when present ... (?) */
+			}
+		}
+	}
+
+	/* save reps for next block */
+	cctx->repToConfirm[0] = offset_1 ? offset_1 : offsetSaved;
+	cctx->repToConfirm[1] = offset_2 ? offset_2 : offsetSaved;
+
+	/* Last Literals */
+	{
+		size_t const lastLLSize = iend - anchor;
+		memcpy(seqStorePtr->lit, anchor, lastLLSize);
+		seqStorePtr->lit += lastLLSize;
+	}
+}
+
+static void ZSTD_compressBlock_fast(ZSTD_CCtx *ctx, const void *src, size_t srcSize)
+{
+	const U32 mls = ctx->params.cParams.searchLength;
+	switch (mls) {
+	default: /* includes case 3 */
+	case 4: ZSTD_compressBlock_fast_generic(ctx, src, srcSize, 4); return;
+	case 5: ZSTD_compressBlock_fast_generic(ctx, src, srcSize, 5); return;
+	case 6: ZSTD_compressBlock_fast_generic(ctx, src, srcSize, 6); return;
+	case 7: ZSTD_compressBlock_fast_generic(ctx, src, srcSize, 7); return;
+	}
+}
+
+static void ZSTD_compressBlock_fast_extDict_generic(ZSTD_CCtx *ctx, const void *src, size_t srcSize, const U32 mls)
+{
+	U32 *hashTable = ctx->hashTable;
+	const U32 hBits = ctx->params.cParams.hashLog;
+	seqStore_t *seqStorePtr = &(ctx->seqStore);
+	const BYTE *const base = ctx->base;
+	const BYTE *const dictBase = ctx->dictBase;
+	const BYTE *const istart = (const BYTE *)src;
+	const BYTE *ip = istart;
+	const BYTE *anchor = istart;
+	const U32 lowestIndex = ctx->lowLimit;
+	const BYTE *const dictStart = dictBase + lowestIndex;
+	const U32 dictLimit = ctx->dictLimit;
+	const BYTE *const lowPrefixPtr = base + dictLimit;
+	const BYTE *const dictEnd = dictBase + dictLimit;
+	const BYTE *const iend = istart + srcSize;
+	const BYTE *const ilimit = iend - 8;
+	U32 offset_1 = ctx->rep[0], offset_2 = ctx->rep[1];
+
+	/* Search Loop */
+	while (ip < ilimit) { /* < instead of <=, because (ip+1) */
+		const size_t h = ZSTD_hashPtr(ip, hBits, mls);
+		const U32 matchIndex = hashTable[h];
+		const BYTE *matchBase = matchIndex < dictLimit ? dictBase : base;
+		const BYTE *match = matchBase + matchIndex;
+		const U32 curr = (U32)(ip - base);
+		const U32 repIndex = curr + 1 - offset_1; /* offset_1 expected <= curr +1 */
+		const BYTE *repBase = repIndex < dictLimit ? dictBase : base;
+		const BYTE *repMatch = repBase + repIndex;
+		size_t mLength;
+		hashTable[h] = curr; /* update hash table */
+
+		if ((((U32)((dictLimit - 1) - repIndex) >= 3) /* intentional underflow */ & (repIndex > lowestIndex)) &&
+		    (ZSTD_read32(repMatch) == ZSTD_read32(ip + 1))) {
+			const BYTE *repMatchEnd = repIndex < dictLimit ? dictEnd : iend;
+			mLength = ZSTD_count_2segments(ip + 1 + EQUAL_READ32, repMatch + EQUAL_READ32, iend, repMatchEnd, lowPrefixPtr) + EQUAL_READ32;
+			ip++;
+			ZSTD_storeSeq(seqStorePtr, ip - anchor, anchor, 0, mLength - MINMATCH);
+		} else {
+			if ((matchIndex < lowestIndex) || (ZSTD_read32(match) != ZSTD_read32(ip))) {
+				ip += ((ip - anchor) >> g_searchStrength) + 1;
+				continue;
+			}
+			{
+				const BYTE *matchEnd = matchIndex < dictLimit ? dictEnd : iend;
+				const BYTE *lowMatchPtr = matchIndex < dictLimit ? dictStart : lowPrefixPtr;
+				U32 offset;
+				mLength = ZSTD_count_2segments(ip + EQUAL_READ32, match + EQUAL_READ32, iend, matchEnd, lowPrefixPtr) + EQUAL_READ32;
+				while (((ip > anchor) & (match > lowMatchPtr)) && (ip[-1] == match[-1])) {
+					ip--;
+					match--;
+					mLength++;
+				} /* catch up */
+				offset = curr - matchIndex;
+				offset_2 = offset_1;
+				offset_1 = offset;
+				ZSTD_storeSeq(seqStorePtr, ip - anchor, anchor, offset + ZSTD_REP_MOVE, mLength - MINMATCH);
+			}
+		}
+
+		/* found a match : store it */
+		ip += mLength;
+		anchor = ip;
+
+		if (ip <= ilimit) {
+			/* Fill Table */
+			hashTable[ZSTD_hashPtr(base + curr + 2, hBits, mls)] = curr + 2;
+			hashTable[ZSTD_hashPtr(ip - 2, hBits, mls)] = (U32)(ip - 2 - base);
+			/* check immediate repcode */
+			while (ip <= ilimit) {
+				U32 const curr2 = (U32)(ip - base);
+				U32 const repIndex2 = curr2 - offset_2;
+				const BYTE *repMatch2 = repIndex2 < dictLimit ? dictBase + repIndex2 : base + repIndex2;
+				if ((((U32)((dictLimit - 1) - repIndex2) >= 3) & (repIndex2 > lowestIndex)) /* intentional overflow */
+				    && (ZSTD_read32(repMatch2) == ZSTD_read32(ip))) {
+					const BYTE *const repEnd2 = repIndex2 < dictLimit ? dictEnd : iend;
+					size_t repLength2 =
+					    ZSTD_count_2segments(ip + EQUAL_READ32, repMatch2 + EQUAL_READ32, iend, repEnd2, lowPrefixPtr) + EQUAL_READ32;
+					U32 tmpOffset = offset_2;
+					offset_2 = offset_1;
+					offset_1 = tmpOffset; /* swap offset_2 <=> offset_1 */
+					ZSTD_storeSeq(seqStorePtr, 0, anchor, 0, repLength2 - MINMATCH);
+					hashTable[ZSTD_hashPtr(ip, hBits, mls)] = curr2;
+					ip += repLength2;
+					anchor = ip;
+					continue;
+				}
+				break;
+			}
+		}
+	}
+
+	/* save reps for next block */
+	ctx->repToConfirm[0] = offset_1;
+	ctx->repToConfirm[1] = offset_2;
+
+	/* Last Literals */
+	{
+		size_t const lastLLSize = iend - anchor;
+		memcpy(seqStorePtr->lit, anchor, lastLLSize);
+		seqStorePtr->lit += lastLLSize;
+	}
+}
+
+static void ZSTD_compressBlock_fast_extDict(ZSTD_CCtx *ctx, const void *src, size_t srcSize)
+{
+	U32 const mls = ctx->params.cParams.searchLength;
+	switch (mls) {
+	default: /* includes case 3 */
+	case 4: ZSTD_compressBlock_fast_extDict_generic(ctx, src, srcSize, 4); return;
+	case 5: ZSTD_compressBlock_fast_extDict_generic(ctx, src, srcSize, 5); return;
+	case 6: ZSTD_compressBlock_fast_extDict_generic(ctx, src, srcSize, 6); return;
+	case 7: ZSTD_compressBlock_fast_extDict_generic(ctx, src, srcSize, 7); return;
+	}
+}
+
+/*-*************************************
+*  Double Fast
+***************************************/
+static void ZSTD_fillDoubleHashTable(ZSTD_CCtx *cctx, const void *end, const U32 mls)
+{
+	U32 *const hashLarge = cctx->hashTable;
+	U32 const hBitsL = cctx->params.cParams.hashLog;
+	U32 *const hashSmall = cctx->chainTable;
+	U32 const hBitsS = cctx->params.cParams.chainLog;
+	const BYTE *const base = cctx->base;
+	const BYTE *ip = base + cctx->nextToUpdate;
+	const BYTE *const iend = ((const BYTE *)end) - HASH_READ_SIZE;
+	const size_t fastHashFillStep = 3;
+
+	while (ip <= iend) {
+		hashSmall[ZSTD_hashPtr(ip, hBitsS, mls)] = (U32)(ip - base);
+		hashLarge[ZSTD_hashPtr(ip, hBitsL, 8)] = (U32)(ip - base);
+		ip += fastHashFillStep;
+	}
+}
+
+FORCE_INLINE
+void ZSTD_compressBlock_doubleFast_generic(ZSTD_CCtx *cctx, const void *src, size_t srcSize, const U32 mls)
+{
+	U32 *const hashLong = cctx->hashTable;
+	const U32 hBitsL = cctx->params.cParams.hashLog;
+	U32 *const hashSmall = cctx->chainTable;
+	const U32 hBitsS = cctx->params.cParams.chainLog;
+	seqStore_t *seqStorePtr = &(cctx->seqStore);
+	const BYTE *const base = cctx->base;
+	const BYTE *const istart = (const BYTE *)src;
+	const BYTE *ip = istart;
+	const BYTE *anchor = istart;
+	const U32 lowestIndex = cctx->dictLimit;
+	const BYTE *const lowest = base + lowestIndex;
+	const BYTE *const iend = istart + srcSize;
+	const BYTE *const ilimit = iend - HASH_READ_SIZE;
+	U32 offset_1 = cctx->rep[0], offset_2 = cctx->rep[1];
+	U32 offsetSaved = 0;
+
+	/* init */
+	ip += (ip == lowest);
+	{
+		U32 const maxRep = (U32)(ip - lowest);
+		if (offset_2 > maxRep)
+			offsetSaved = offset_2, offset_2 = 0;
+		if (offset_1 > maxRep)
+			offsetSaved = offset_1, offset_1 = 0;
+	}
+
+	/* Main Search Loop */
+	while (ip < ilimit) { /* < instead of <=, because repcode check at (ip+1) */
+		size_t mLength;
+		size_t const h2 = ZSTD_hashPtr(ip, hBitsL, 8);
+		size_t const h = ZSTD_hashPtr(ip, hBitsS, mls);
+		U32 const curr = (U32)(ip - base);
+		U32 const matchIndexL = hashLong[h2];
+		U32 const matchIndexS = hashSmall[h];
+		const BYTE *matchLong = base + matchIndexL;
+		const BYTE *match = base + matchIndexS;
+		hashLong[h2] = hashSmall[h] = curr; /* update hash tables */
+
+		if ((offset_1 > 0) & (ZSTD_read32(ip + 1 - offset_1) == ZSTD_read32(ip + 1))) { /* note : by construction, offset_1 <= curr */
+			mLength = ZSTD_count(ip + 1 + 4, ip + 1 + 4 - offset_1, iend) + 4;
+			ip++;
+			ZSTD_storeSeq(seqStorePtr, ip - anchor, anchor, 0, mLength - MINMATCH);
+		} else {
+			U32 offset;
+			if ((matchIndexL > lowestIndex) && (ZSTD_read64(matchLong) == ZSTD_read64(ip))) {
+				mLength = ZSTD_count(ip + 8, matchLong + 8, iend) + 8;
+				offset = (U32)(ip - matchLong);
+				while (((ip > anchor) & (matchLong > lowest)) && (ip[-1] == matchLong[-1])) {
+					ip--;
+					matchLong--;
+					mLength++;
+				} /* catch up */
+			} else if ((matchIndexS > lowestIndex) && (ZSTD_read32(match) == ZSTD_read32(ip))) {
+				size_t const h3 = ZSTD_hashPtr(ip + 1, hBitsL, 8);
+				U32 const matchIndex3 = hashLong[h3];
+				const BYTE *match3 = base + matchIndex3;
+				hashLong[h3] = curr + 1;
+				if ((matchIndex3 > lowestIndex) && (ZSTD_read64(match3) == ZSTD_read64(ip + 1))) {
+					mLength = ZSTD_count(ip + 9, match3 + 8, iend) + 8;
+					ip++;
+					offset = (U32)(ip - match3);
+					while (((ip > anchor) & (match3 > lowest)) && (ip[-1] == match3[-1])) {
+						ip--;
+						match3--;
+						mLength++;
+					} /* catch up */
+				} else {
+					mLength = ZSTD_count(ip + 4, match + 4, iend) + 4;
+					offset = (U32)(ip - match);
+					while (((ip > anchor) & (match > lowest)) && (ip[-1] == match[-1])) {
+						ip--;
+						match--;
+						mLength++;
+					} /* catch up */
+				}
+			} else {
+				ip += ((ip - anchor) >> g_searchStrength) + 1;
+				continue;
+			}
+
+			offset_2 = offset_1;
+			offset_1 = offset;
+
+			ZSTD_storeSeq(seqStorePtr, ip - anchor, anchor, offset + ZSTD_REP_MOVE, mLength - MINMATCH);
+		}
+
+		/* match found */
+		ip += mLength;
+		anchor = ip;
+
+		if (ip <= ilimit) {
+			/* Fill Table */
+			hashLong[ZSTD_hashPtr(base + curr + 2, hBitsL, 8)] = hashSmall[ZSTD_hashPtr(base + curr + 2, hBitsS, mls)] =
+			    curr + 2; /* here because curr+2 could be > iend-8 */
+			hashLong[ZSTD_hashPtr(ip - 2, hBitsL, 8)] = hashSmall[ZSTD_hashPtr(ip - 2, hBitsS, mls)] = (U32)(ip - 2 - base);
+
+			/* check immediate repcode */
+			while ((ip <= ilimit) && ((offset_2 > 0) & (ZSTD_read32(ip) == ZSTD_read32(ip - offset_2)))) {
+				/* store sequence */
+				size_t const rLength = ZSTD_count(ip + 4, ip + 4 - offset_2, iend) + 4;
+				{
+					U32 const tmpOff = offset_2;
+					offset_2 = offset_1;
+					offset_1 = tmpOff;
+				} /* swap offset_2 <=> offset_1 */
+				hashSmall[ZSTD_hashPtr(ip, hBitsS, mls)] = (U32)(ip - base);
+				hashLong[ZSTD_hashPtr(ip, hBitsL, 8)] = (U32)(ip - base);
+				ZSTD_storeSeq(seqStorePtr, 0, anchor, 0, rLength - MINMATCH);
+				ip += rLength;
+				anchor = ip;
+				continue; /* faster when present ... (?) */
+			}
+		}
+	}
+
+	/* save reps for next block */
+	cctx->repToConfirm[0] = offset_1 ? offset_1 : offsetSaved;
+	cctx->repToConfirm[1] = offset_2 ? offset_2 : offsetSaved;
+
+	/* Last Literals */
+	{
+		size_t const lastLLSize = iend - anchor;
+		memcpy(seqStorePtr->lit, anchor, lastLLSize);
+		seqStorePtr->lit += lastLLSize;
+	}
+}
+
+static void ZSTD_compressBlock_doubleFast(ZSTD_CCtx *ctx, const void *src, size_t srcSize)
+{
+	const U32 mls = ctx->params.cParams.searchLength;
+	switch (mls) {
+	default: /* includes case 3 */
+	case 4: ZSTD_compressBlock_doubleFast_generic(ctx, src, srcSize, 4); return;
+	case 5: ZSTD_compressBlock_doubleFast_generic(ctx, src, srcSize, 5); return;
+	case 6: ZSTD_compressBlock_doubleFast_generic(ctx, src, srcSize, 6); return;
+	case 7: ZSTD_compressBlock_doubleFast_generic(ctx, src, srcSize, 7); return;
+	}
+}
+
+static void ZSTD_compressBlock_doubleFast_extDict_generic(ZSTD_CCtx *ctx, const void *src, size_t srcSize, const U32 mls)
+{
+	U32 *const hashLong = ctx->hashTable;
+	U32 const hBitsL = ctx->params.cParams.hashLog;
+	U32 *const hashSmall = ctx->chainTable;
+	U32 const hBitsS = ctx->params.cParams.chainLog;
+	seqStore_t *seqStorePtr = &(ctx->seqStore);
+	const BYTE *const base = ctx->base;
+	const BYTE *const dictBase = ctx->dictBase;
+	const BYTE *const istart = (const BYTE *)src;
+	const BYTE *ip = istart;
+	const BYTE *anchor = istart;
+	const U32 lowestIndex = ctx->lowLimit;
+	const BYTE *const dictStart = dictBase + lowestIndex;
+	const U32 dictLimit = ctx->dictLimit;
+	const BYTE *const lowPrefixPtr = base + dictLimit;
+	const BYTE *const dictEnd = dictBase + dictLimit;
+	const BYTE *const iend = istart + srcSize;
+	const BYTE *const ilimit = iend - 8;
+	U32 offset_1 = ctx->rep[0], offset_2 = ctx->rep[1];
+
+	/* Search Loop */
+	while (ip < ilimit) { /* < instead of <=, because (ip+1) */
+		const size_t hSmall = ZSTD_hashPtr(ip, hBitsS, mls);
+		const U32 matchIndex = hashSmall[hSmall];
+		const BYTE *matchBase = matchIndex < dictLimit ? dictBase : base;
+		const BYTE *match = matchBase + matchIndex;
+
+		const size_t hLong = ZSTD_hashPtr(ip, hBitsL, 8);
+		const U32 matchLongIndex = hashLong[hLong];
+		const BYTE *matchLongBase = matchLongIndex < dictLimit ? dictBase : base;
+		const BYTE *matchLong = matchLongBase + matchLongIndex;
+
+		const U32 curr = (U32)(ip - base);
+		const U32 repIndex = curr + 1 - offset_1; /* offset_1 expected <= curr +1 */
+		const BYTE *repBase = repIndex < dictLimit ? dictBase : base;
+		const BYTE *repMatch = repBase + repIndex;
+		size_t mLength;
+		hashSmall[hSmall] = hashLong[hLong] = curr; /* update hash table */
+
+		if ((((U32)((dictLimit - 1) - repIndex) >= 3) /* intentional underflow */ & (repIndex > lowestIndex)) &&
+		    (ZSTD_read32(repMatch) == ZSTD_read32(ip + 1))) {
+			const BYTE *repMatchEnd = repIndex < dictLimit ? dictEnd : iend;
+			mLength = ZSTD_count_2segments(ip + 1 + 4, repMatch + 4, iend, repMatchEnd, lowPrefixPtr) + 4;
+			ip++;
+			ZSTD_storeSeq(seqStorePtr, ip - anchor, anchor, 0, mLength - MINMATCH);
+		} else {
+			if ((matchLongIndex > lowestIndex) && (ZSTD_read64(matchLong) == ZSTD_read64(ip))) {
+				const BYTE *matchEnd = matchLongIndex < dictLimit ? dictEnd : iend;
+				const BYTE *lowMatchPtr = matchLongIndex < dictLimit ? dictStart : lowPrefixPtr;
+				U32 offset;
+				mLength = ZSTD_count_2segments(ip + 8, matchLong + 8, iend, matchEnd, lowPrefixPtr) + 8;
+				offset = curr - matchLongIndex;
+				while (((ip > anchor) & (matchLong > lowMatchPtr)) && (ip[-1] == matchLong[-1])) {
+					ip--;
+					matchLong--;
+					mLength++;
+				} /* catch up */
+				offset_2 = offset_1;
+				offset_1 = offset;
+				ZSTD_storeSeq(seqStorePtr, ip - anchor, anchor, offset + ZSTD_REP_MOVE, mLength - MINMATCH);
+
+			} else if ((matchIndex > lowestIndex) && (ZSTD_read32(match) == ZSTD_read32(ip))) {
+				size_t const h3 = ZSTD_hashPtr(ip + 1, hBitsL, 8);
+				U32 const matchIndex3 = hashLong[h3];
+				const BYTE *const match3Base = matchIndex3 < dictLimit ? dictBase : base;
+				const BYTE *match3 = match3Base + matchIndex3;
+				U32 offset;
+				hashLong[h3] = curr + 1;
+				if ((matchIndex3 > lowestIndex) && (ZSTD_read64(match3) == ZSTD_read64(ip + 1))) {
+					const BYTE *matchEnd = matchIndex3 < dictLimit ? dictEnd : iend;
+					const BYTE *lowMatchPtr = matchIndex3 < dictLimit ? dictStart : lowPrefixPtr;
+					mLength = ZSTD_count_2segments(ip + 9, match3 + 8, iend, matchEnd, lowPrefixPtr) + 8;
+					ip++;
+					offset = curr + 1 - matchIndex3;
+					while (((ip > anchor) & (match3 > lowMatchPtr)) && (ip[-1] == match3[-1])) {
+						ip--;
+						match3--;
+						mLength++;
+					} /* catch up */
+				} else {
+					const BYTE *matchEnd = matchIndex < dictLimit ? dictEnd : iend;
+					const BYTE *lowMatchPtr = matchIndex < dictLimit ? dictStart : lowPrefixPtr;
+					mLength = ZSTD_count_2segments(ip + 4, match + 4, iend, matchEnd, lowPrefixPtr) + 4;
+					offset = curr - matchIndex;
+					while (((ip > anchor) & (match > lowMatchPtr)) && (ip[-1] == match[-1])) {
+						ip--;
+						match--;
+						mLength++;
+					} /* catch up */
+				}
+				offset_2 = offset_1;
+				offset_1 = offset;
+				ZSTD_storeSeq(seqStorePtr, ip - anchor, anchor, offset + ZSTD_REP_MOVE, mLength - MINMATCH);
+
+			} else {
+				ip += ((ip - anchor) >> g_searchStrength) + 1;
+				continue;
+			}
+		}
+
+		/* found a match : store it */
+		ip += mLength;
+		anchor = ip;
+
+		if (ip <= ilimit) {
+			/* Fill Table */
+			hashSmall[ZSTD_hashPtr(base + curr + 2, hBitsS, mls)] = curr + 2;
+			hashLong[ZSTD_hashPtr(base + curr + 2, hBitsL, 8)] = curr + 2;
+			hashSmall[ZSTD_hashPtr(ip - 2, hBitsS, mls)] = (U32)(ip - 2 - base);
+			hashLong[ZSTD_hashPtr(ip - 2, hBitsL, 8)] = (U32)(ip - 2 - base);
+			/* check immediate repcode */
+			while (ip <= ilimit) {
+				U32 const curr2 = (U32)(ip - base);
+				U32 const repIndex2 = curr2 - offset_2;
+				const BYTE *repMatch2 = repIndex2 < dictLimit ? dictBase + repIndex2 : base + repIndex2;
+				if ((((U32)((dictLimit - 1) - repIndex2) >= 3) & (repIndex2 > lowestIndex)) /* intentional overflow */
+				    && (ZSTD_read32(repMatch2) == ZSTD_read32(ip))) {
+					const BYTE *const repEnd2 = repIndex2 < dictLimit ? dictEnd : iend;
+					size_t const repLength2 =
+					    ZSTD_count_2segments(ip + EQUAL_READ32, repMatch2 + EQUAL_READ32, iend, repEnd2, lowPrefixPtr) + EQUAL_READ32;
+					U32 tmpOffset = offset_2;
+					offset_2 = offset_1;
+					offset_1 = tmpOffset; /* swap offset_2 <=> offset_1 */
+					ZSTD_storeSeq(seqStorePtr, 0, anchor, 0, repLength2 - MINMATCH);
+					hashSmall[ZSTD_hashPtr(ip, hBitsS, mls)] = curr2;
+					hashLong[ZSTD_hashPtr(ip, hBitsL, 8)] = curr2;
+					ip += repLength2;
+					anchor = ip;
+					continue;
+				}
+				break;
+			}
+		}
+	}
+
+	/* save reps for next block */
+	ctx->repToConfirm[0] = offset_1;
+	ctx->repToConfirm[1] = offset_2;
+
+	/* Last Literals */
+	{
+		size_t const lastLLSize = iend - anchor;
+		memcpy(seqStorePtr->lit, anchor, lastLLSize);
+		seqStorePtr->lit += lastLLSize;
+	}
+}
+
+static void ZSTD_compressBlock_doubleFast_extDict(ZSTD_CCtx *ctx, const void *src, size_t srcSize)
+{
+	U32 const mls = ctx->params.cParams.searchLength;
+	switch (mls) {
+	default: /* includes case 3 */
+	case 4: ZSTD_compressBlock_doubleFast_extDict_generic(ctx, src, srcSize, 4); return;
+	case 5: ZSTD_compressBlock_doubleFast_extDict_generic(ctx, src, srcSize, 5); return;
+	case 6: ZSTD_compressBlock_doubleFast_extDict_generic(ctx, src, srcSize, 6); return;
+	case 7: ZSTD_compressBlock_doubleFast_extDict_generic(ctx, src, srcSize, 7); return;
+	}
+}
+
+/*-*************************************
+*  Binary Tree search
+***************************************/
+/** ZSTD_insertBt1() : add one or multiple positions to tree.
+*   ip : assumed <= iend-8 .
+*   @return : nb of positions added */
+static U32 ZSTD_insertBt1(ZSTD_CCtx *zc, const BYTE *const ip, const U32 mls, const BYTE *const iend, U32 nbCompares, U32 extDict)
+{
+	U32 *const hashTable = zc->hashTable;
+	U32 const hashLog = zc->params.cParams.hashLog;
+	size_t const h = ZSTD_hashPtr(ip, hashLog, mls);
+	U32 *const bt = zc->chainTable;
+	U32 const btLog = zc->params.cParams.chainLog - 1;
+	U32 const btMask = (1 << btLog) - 1;
+	U32 matchIndex = hashTable[h];
+	size_t commonLengthSmaller = 0, commonLengthLarger = 0;
+	const BYTE *const base = zc->base;
+	const BYTE *const dictBase = zc->dictBase;
+	const U32 dictLimit = zc->dictLimit;
+	const BYTE *const dictEnd = dictBase + dictLimit;
+	const BYTE *const prefixStart = base + dictLimit;
+	const BYTE *match;
+	const U32 curr = (U32)(ip - base);
+	const U32 btLow = btMask >= curr ? 0 : curr - btMask;
+	U32 *smallerPtr = bt + 2 * (curr & btMask);
+	U32 *largerPtr = smallerPtr + 1;
+	U32 dummy32; /* to be nullified at the end */
+	U32 const windowLow = zc->lowLimit;
+	U32 matchEndIdx = curr + 8;
+	size_t bestLength = 8;
+
+	hashTable[h] = curr; /* Update Hash Table */
+
+	while (nbCompares-- && (matchIndex > windowLow)) {
+		U32 *const nextPtr = bt + 2 * (matchIndex & btMask);
+		size_t matchLength = MIN(commonLengthSmaller, commonLengthLarger); /* guaranteed minimum nb of common bytes */
+
+		if ((!extDict) || (matchIndex + matchLength >= dictLimit)) {
+			match = base + matchIndex;
+			if (match[matchLength] == ip[matchLength])
+				matchLength += ZSTD_count(ip + matchLength + 1, match + matchLength + 1, iend) + 1;
+		} else {
+			match = dictBase + matchIndex;
+			matchLength += ZSTD_count_2segments(ip + matchLength, match + matchLength, iend, dictEnd, prefixStart);
+			if (matchIndex + matchLength >= dictLimit)
+				match = base + matchIndex; /* to prepare for next usage of match[matchLength] */
+		}
+
+		if (matchLength > bestLength) {
+			bestLength = matchLength;
+			if (matchLength > matchEndIdx - matchIndex)
+				matchEndIdx = matchIndex + (U32)matchLength;
+		}
+
+		if (ip + matchLength == iend) /* equal : no way to know if inf or sup */
+			break;		      /* drop , to guarantee consistency ; miss a bit of compression, but other solutions can corrupt the tree */
+
+		if (match[matchLength] < ip[matchLength]) { /* necessarily within correct buffer */
+			/* match is smaller than curr */
+			*smallerPtr = matchIndex;	  /* update smaller idx */
+			commonLengthSmaller = matchLength; /* all smaller will now have at least this guaranteed common length */
+			if (matchIndex <= btLow) {
+				smallerPtr = &dummy32;
+				break;
+			}			  /* beyond tree size, stop the search */
+			smallerPtr = nextPtr + 1; /* new "smaller" => larger of match */
+			matchIndex = nextPtr[1];  /* new matchIndex larger than previous (closer to curr) */
+		} else {
+			/* match is larger than curr */
+			*largerPtr = matchIndex;
+			commonLengthLarger = matchLength;
+			if (matchIndex <= btLow) {
+				largerPtr = &dummy32;
+				break;
+			} /* beyond tree size, stop the search */
+			largerPtr = nextPtr;
+			matchIndex = nextPtr[0];
+		}
+	}
+
+	*smallerPtr = *largerPtr = 0;
+	if (bestLength > 384)
+		return MIN(192, (U32)(bestLength - 384)); /* speed optimization */
+	if (matchEndIdx > curr + 8)
+		return matchEndIdx - curr - 8;
+	return 1;
+}
+
+static size_t ZSTD_insertBtAndFindBestMatch(ZSTD_CCtx *zc, const BYTE *const ip, const BYTE *const iend, size_t *offsetPtr, U32 nbCompares, const U32 mls,
+					    U32 extDict)
+{
+	U32 *const hashTable = zc->hashTable;
+	U32 const hashLog = zc->params.cParams.hashLog;
+	size_t const h = ZSTD_hashPtr(ip, hashLog, mls);
+	U32 *const bt = zc->chainTable;
+	U32 const btLog = zc->params.cParams.chainLog - 1;
+	U32 const btMask = (1 << btLog) - 1;
+	U32 matchIndex = hashTable[h];
+	size_t commonLengthSmaller = 0, commonLengthLarger = 0;
+	const BYTE *const base = zc->base;
+	const BYTE *const dictBase = zc->dictBase;
+	const U32 dictLimit = zc->dictLimit;
+	const BYTE *const dictEnd = dictBase + dictLimit;
+	const BYTE *const prefixStart = base + dictLimit;
+	const U32 curr = (U32)(ip - base);
+	const U32 btLow = btMask >= curr ? 0 : curr - btMask;
+	const U32 windowLow = zc->lowLimit;
+	U32 *smallerPtr = bt + 2 * (curr & btMask);
+	U32 *largerPtr = bt + 2 * (curr & btMask) + 1;
+	U32 matchEndIdx = curr + 8;
+	U32 dummy32; /* to be nullified at the end */
+	size_t bestLength = 0;
+
+	hashTable[h] = curr; /* Update Hash Table */
+
+	while (nbCompares-- && (matchIndex > windowLow)) {
+		U32 *const nextPtr = bt + 2 * (matchIndex & btMask);
+		size_t matchLength = MIN(commonLengthSmaller, commonLengthLarger); /* guaranteed minimum nb of common bytes */
+		const BYTE *match;
+
+		if ((!extDict) || (matchIndex + matchLength >= dictLimit)) {
+			match = base + matchIndex;
+			if (match[matchLength] == ip[matchLength])
+				matchLength += ZSTD_count(ip + matchLength + 1, match + matchLength + 1, iend) + 1;
+		} else {
+			match = dictBase + matchIndex;
+			matchLength += ZSTD_count_2segments(ip + matchLength, match + matchLength, iend, dictEnd, prefixStart);
+			if (matchIndex + matchLength >= dictLimit)
+				match = base + matchIndex; /* to prepare for next usage of match[matchLength] */
+		}
+
+		if (matchLength > bestLength) {
+			if (matchLength > matchEndIdx - matchIndex)
+				matchEndIdx = matchIndex + (U32)matchLength;
+			if ((4 * (int)(matchLength - bestLength)) > (int)(ZSTD_highbit32(curr - matchIndex + 1) - ZSTD_highbit32((U32)offsetPtr[0] + 1)))
+				bestLength = matchLength, *offsetPtr = ZSTD_REP_MOVE + curr - matchIndex;
+			if (ip + matchLength == iend) /* equal : no way to know if inf or sup */
+				break;		      /* drop, to guarantee consistency (miss a little bit of compression) */
+		}
+
+		if (match[matchLength] < ip[matchLength]) {
+			/* match is smaller than curr */
+			*smallerPtr = matchIndex;	  /* update smaller idx */
+			commonLengthSmaller = matchLength; /* all smaller will now have at least this guaranteed common length */
+			if (matchIndex <= btLow) {
+				smallerPtr = &dummy32;
+				break;
+			}			  /* beyond tree size, stop the search */
+			smallerPtr = nextPtr + 1; /* new "smaller" => larger of match */
+			matchIndex = nextPtr[1];  /* new matchIndex larger than previous (closer to curr) */
+		} else {
+			/* match is larger than curr */
+			*largerPtr = matchIndex;
+			commonLengthLarger = matchLength;
+			if (matchIndex <= btLow) {
+				largerPtr = &dummy32;
+				break;
+			} /* beyond tree size, stop the search */
+			largerPtr = nextPtr;
+			matchIndex = nextPtr[0];
+		}
+	}
+
+	*smallerPtr = *largerPtr = 0;
+
+	zc->nextToUpdate = (matchEndIdx > curr + 8) ? matchEndIdx - 8 : curr + 1;
+	return bestLength;
+}
+
+static void ZSTD_updateTree(ZSTD_CCtx *zc, const BYTE *const ip, const BYTE *const iend, const U32 nbCompares, const U32 mls)
+{
+	const BYTE *const base = zc->base;
+	const U32 target = (U32)(ip - base);
+	U32 idx = zc->nextToUpdate;
+
+	while (idx < target)
+		idx += ZSTD_insertBt1(zc, base + idx, mls, iend, nbCompares, 0);
+}
+
+/** ZSTD_BtFindBestMatch() : Tree updater, providing best match */
+static size_t ZSTD_BtFindBestMatch(ZSTD_CCtx *zc, const BYTE *const ip, const BYTE *const iLimit, size_t *offsetPtr, const U32 maxNbAttempts, const U32 mls)
+{
+	if (ip < zc->base + zc->nextToUpdate)
+		return 0; /* skipped area */
+	ZSTD_updateTree(zc, ip, iLimit, maxNbAttempts, mls);
+	return ZSTD_insertBtAndFindBestMatch(zc, ip, iLimit, offsetPtr, maxNbAttempts, mls, 0);
+}
+
+static size_t ZSTD_BtFindBestMatch_selectMLS(ZSTD_CCtx *zc, /* Index table will be updated */
+					     const BYTE *ip, const BYTE *const iLimit, size_t *offsetPtr, const U32 maxNbAttempts, const U32 matchLengthSearch)
+{
+	switch (matchLengthSearch) {
+	default: /* includes case 3 */
+	case 4: return ZSTD_BtFindBestMatch(zc, ip, iLimit, offsetPtr, maxNbAttempts, 4);
+	case 5: return ZSTD_BtFindBestMatch(zc, ip, iLimit, offsetPtr, maxNbAttempts, 5);
+	case 7:
+	case 6: return ZSTD_BtFindBestMatch(zc, ip, iLimit, offsetPtr, maxNbAttempts, 6);
+	}
+}
+
+static void ZSTD_updateTree_extDict(ZSTD_CCtx *zc, const BYTE *const ip, const BYTE *const iend, const U32 nbCompares, const U32 mls)
+{
+	const BYTE *const base = zc->base;
+	const U32 target = (U32)(ip - base);
+	U32 idx = zc->nextToUpdate;
+
+	while (idx < target)
+		idx += ZSTD_insertBt1(zc, base + idx, mls, iend, nbCompares, 1);
+}
+
+/** Tree updater, providing best match */
+static size_t ZSTD_BtFindBestMatch_extDict(ZSTD_CCtx *zc, const BYTE *const ip, const BYTE *const iLimit, size_t *offsetPtr, const U32 maxNbAttempts,
+					   const U32 mls)
+{
+	if (ip < zc->base + zc->nextToUpdate)
+		return 0; /* skipped area */
+	ZSTD_updateTree_extDict(zc, ip, iLimit, maxNbAttempts, mls);
+	return ZSTD_insertBtAndFindBestMatch(zc, ip, iLimit, offsetPtr, maxNbAttempts, mls, 1);
+}
+
+static size_t ZSTD_BtFindBestMatch_selectMLS_extDict(ZSTD_CCtx *zc, /* Index table will be updated */
+						     const BYTE *ip, const BYTE *const iLimit, size_t *offsetPtr, const U32 maxNbAttempts,
+						     const U32 matchLengthSearch)
+{
+	switch (matchLengthSearch) {
+	default: /* includes case 3 */
+	case 4: return ZSTD_BtFindBestMatch_extDict(zc, ip, iLimit, offsetPtr, maxNbAttempts, 4);
+	case 5: return ZSTD_BtFindBestMatch_extDict(zc, ip, iLimit, offsetPtr, maxNbAttempts, 5);
+	case 7:
+	case 6: return ZSTD_BtFindBestMatch_extDict(zc, ip, iLimit, offsetPtr, maxNbAttempts, 6);
+	}
+}
+
+/* *********************************
+*  Hash Chain
+***********************************/
+#define NEXT_IN_CHAIN(d, mask) chainTable[(d)&mask]
+
+/* Update chains up to ip (excluded)
+   Assumption : always within prefix (i.e. not within extDict) */
+FORCE_INLINE
+U32 ZSTD_insertAndFindFirstIndex(ZSTD_CCtx *zc, const BYTE *ip, U32 mls)
+{
+	U32 *const hashTable = zc->hashTable;
+	const U32 hashLog = zc->params.cParams.hashLog;
+	U32 *const chainTable = zc->chainTable;
+	const U32 chainMask = (1 << zc->params.cParams.chainLog) - 1;
+	const BYTE *const base = zc->base;
+	const U32 target = (U32)(ip - base);
+	U32 idx = zc->nextToUpdate;
+
+	while (idx < target) { /* catch up */
+		size_t const h = ZSTD_hashPtr(base + idx, hashLog, mls);
+		NEXT_IN_CHAIN(idx, chainMask) = hashTable[h];
+		hashTable[h] = idx;
+		idx++;
+	}
+
+	zc->nextToUpdate = target;
+	return hashTable[ZSTD_hashPtr(ip, hashLog, mls)];
+}
+
+/* inlining is important to hardwire a hot branch (template emulation) */
+FORCE_INLINE
+size_t ZSTD_HcFindBestMatch_generic(ZSTD_CCtx *zc, /* Index table will be updated */
+				    const BYTE *const ip, const BYTE *const iLimit, size_t *offsetPtr, const U32 maxNbAttempts, const U32 mls,
+				    const U32 extDict)
+{
+	U32 *const chainTable = zc->chainTable;
+	const U32 chainSize = (1 << zc->params.cParams.chainLog);
+	const U32 chainMask = chainSize - 1;
+	const BYTE *const base = zc->base;
+	const BYTE *const dictBase = zc->dictBase;
+	const U32 dictLimit = zc->dictLimit;
+	const BYTE *const prefixStart = base + dictLimit;
+	const BYTE *const dictEnd = dictBase + dictLimit;
+	const U32 lowLimit = zc->lowLimit;
+	const U32 curr = (U32)(ip - base);
+	const U32 minChain = curr > chainSize ? curr - chainSize : 0;
+	int nbAttempts = maxNbAttempts;
+	size_t ml = EQUAL_READ32 - 1;
+
+	/* HC4 match finder */
+	U32 matchIndex = ZSTD_insertAndFindFirstIndex(zc, ip, mls);
+
+	for (; (matchIndex > lowLimit) & (nbAttempts > 0); nbAttempts--) {
+		const BYTE *match;
+		size_t currMl = 0;
+		if ((!extDict) || matchIndex >= dictLimit) {
+			match = base + matchIndex;
+			if (match[ml] == ip[ml]) /* potentially better */
+				currMl = ZSTD_count(ip, match, iLimit);
+		} else {
+			match = dictBase + matchIndex;
+			if (ZSTD_read32(match) == ZSTD_read32(ip)) /* assumption : matchIndex <= dictLimit-4 (by table construction) */
+				currMl = ZSTD_count_2segments(ip + EQUAL_READ32, match + EQUAL_READ32, iLimit, dictEnd, prefixStart) + EQUAL_READ32;
+		}
+
+		/* save best solution */
+		if (currMl > ml) {
+			ml = currMl;
+			*offsetPtr = curr - matchIndex + ZSTD_REP_MOVE;
+			if (ip + currMl == iLimit)
+				break; /* best possible, and avoid read overflow*/
+		}
+
+		if (matchIndex <= minChain)
+			break;
+		matchIndex = NEXT_IN_CHAIN(matchIndex, chainMask);
+	}
+
+	return ml;
+}
+
+FORCE_INLINE size_t ZSTD_HcFindBestMatch_selectMLS(ZSTD_CCtx *zc, const BYTE *ip, const BYTE *const iLimit, size_t *offsetPtr, const U32 maxNbAttempts,
+						   const U32 matchLengthSearch)
+{
+	switch (matchLengthSearch) {
+	default: /* includes case 3 */
+	case 4: return ZSTD_HcFindBestMatch_generic(zc, ip, iLimit, offsetPtr, maxNbAttempts, 4, 0);
+	case 5: return ZSTD_HcFindBestMatch_generic(zc, ip, iLimit, offsetPtr, maxNbAttempts, 5, 0);
+	case 7:
+	case 6: return ZSTD_HcFindBestMatch_generic(zc, ip, iLimit, offsetPtr, maxNbAttempts, 6, 0);
+	}
+}
+
+FORCE_INLINE size_t ZSTD_HcFindBestMatch_extDict_selectMLS(ZSTD_CCtx *zc, const BYTE *ip, const BYTE *const iLimit, size_t *offsetPtr, const U32 maxNbAttempts,
+							   const U32 matchLengthSearch)
+{
+	switch (matchLengthSearch) {
+	default: /* includes case 3 */
+	case 4: return ZSTD_HcFindBestMatch_generic(zc, ip, iLimit, offsetPtr, maxNbAttempts, 4, 1);
+	case 5: return ZSTD_HcFindBestMatch_generic(zc, ip, iLimit, offsetPtr, maxNbAttempts, 5, 1);
+	case 7:
+	case 6: return ZSTD_HcFindBestMatch_generic(zc, ip, iLimit, offsetPtr, maxNbAttempts, 6, 1);
+	}
+}
+
+/* *******************************
+*  Common parser - lazy strategy
+*********************************/
+FORCE_INLINE
+void ZSTD_compressBlock_lazy_generic(ZSTD_CCtx *ctx, const void *src, size_t srcSize, const U32 searchMethod, const U32 depth)
+{
+	seqStore_t *seqStorePtr = &(ctx->seqStore);
+	const BYTE *const istart = (const BYTE *)src;
+	const BYTE *ip = istart;
+	const BYTE *anchor = istart;
+	const BYTE *const iend = istart + srcSize;
+	const BYTE *const ilimit = iend - 8;
+	const BYTE *const base = ctx->base + ctx->dictLimit;
+
+	U32 const maxSearches = 1 << ctx->params.cParams.searchLog;
+	U32 const mls = ctx->params.cParams.searchLength;
+
+	typedef size_t (*searchMax_f)(ZSTD_CCtx * zc, const BYTE *ip, const BYTE *iLimit, size_t *offsetPtr, U32 maxNbAttempts, U32 matchLengthSearch);
+	searchMax_f const searchMax = searchMethod ? ZSTD_BtFindBestMatch_selectMLS : ZSTD_HcFindBestMatch_selectMLS;
+	U32 offset_1 = ctx->rep[0], offset_2 = ctx->rep[1], savedOffset = 0;
+
+	/* init */
+	ip += (ip == base);
+	ctx->nextToUpdate3 = ctx->nextToUpdate;
+	{
+		U32 const maxRep = (U32)(ip - base);
+		if (offset_2 > maxRep)
+			savedOffset = offset_2, offset_2 = 0;
+		if (offset_1 > maxRep)
+			savedOffset = offset_1, offset_1 = 0;
+	}
+
+	/* Match Loop */
+	while (ip < ilimit) {
+		size_t matchLength = 0;
+		size_t offset = 0;
+		const BYTE *start = ip + 1;
+
+		/* check repCode */
+		if ((offset_1 > 0) & (ZSTD_read32(ip + 1) == ZSTD_read32(ip + 1 - offset_1))) {
+			/* repcode : we take it */
+			matchLength = ZSTD_count(ip + 1 + EQUAL_READ32, ip + 1 + EQUAL_READ32 - offset_1, iend) + EQUAL_READ32;
+			if (depth == 0)
+				goto _storeSequence;
+		}
+
+		/* first search (depth 0) */
+		{
+			size_t offsetFound = 99999999;
+			size_t const ml2 = searchMax(ctx, ip, iend, &offsetFound, maxSearches, mls);
+			if (ml2 > matchLength)
+				matchLength = ml2, start = ip, offset = offsetFound;
+		}
+
+		if (matchLength < EQUAL_READ32) {
+			ip += ((ip - anchor) >> g_searchStrength) + 1; /* jump faster over incompressible sections */
+			continue;
+		}
+
+		/* let's try to find a better solution */
+		if (depth >= 1)
+			while (ip < ilimit) {
+				ip++;
+				if ((offset) && ((offset_1 > 0) & (ZSTD_read32(ip) == ZSTD_read32(ip - offset_1)))) {
+					size_t const mlRep = ZSTD_count(ip + EQUAL_READ32, ip + EQUAL_READ32 - offset_1, iend) + EQUAL_READ32;
+					int const gain2 = (int)(mlRep * 3);
+					int const gain1 = (int)(matchLength * 3 - ZSTD_highbit32((U32)offset + 1) + 1);
+					if ((mlRep >= EQUAL_READ32) && (gain2 > gain1))
+						matchLength = mlRep, offset = 0, start = ip;
+				}
+				{
+					size_t offset2 = 99999999;
+					size_t const ml2 = searchMax(ctx, ip, iend, &offset2, maxSearches, mls);
+					int const gain2 = (int)(ml2 * 4 - ZSTD_highbit32((U32)offset2 + 1)); /* raw approx */
+					int const gain1 = (int)(matchLength * 4 - ZSTD_highbit32((U32)offset + 1) + 4);
+					if ((ml2 >= EQUAL_READ32) && (gain2 > gain1)) {
+						matchLength = ml2, offset = offset2, start = ip;
+						continue; /* search a better one */
+					}
+				}
+
+				/* let's find an even better one */
+				if ((depth == 2) && (ip < ilimit)) {
+					ip++;
+					if ((offset) && ((offset_1 > 0) & (ZSTD_read32(ip) == ZSTD_read32(ip - offset_1)))) {
+						size_t const ml2 = ZSTD_count(ip + EQUAL_READ32, ip + EQUAL_READ32 - offset_1, iend) + EQUAL_READ32;
+						int const gain2 = (int)(ml2 * 4);
+						int const gain1 = (int)(matchLength * 4 - ZSTD_highbit32((U32)offset + 1) + 1);
+						if ((ml2 >= EQUAL_READ32) && (gain2 > gain1))
+							matchLength = ml2, offset = 0, start = ip;
+					}
+					{
+						size_t offset2 = 99999999;
+						size_t const ml2 = searchMax(ctx, ip, iend, &offset2, maxSearches, mls);
+						int const gain2 = (int)(ml2 * 4 - ZSTD_highbit32((U32)offset2 + 1)); /* raw approx */
+						int const gain1 = (int)(matchLength * 4 - ZSTD_highbit32((U32)offset + 1) + 7);
+						if ((ml2 >= EQUAL_READ32) && (gain2 > gain1)) {
+							matchLength = ml2, offset = offset2, start = ip;
+							continue;
+						}
+					}
+				}
+				break; /* nothing found : store previous solution */
+			}
+
+		/* NOTE:
+		 * start[-offset+ZSTD_REP_MOVE-1] is undefined behavior.
+		 * (-offset+ZSTD_REP_MOVE-1) is unsigned, and is added to start, which
+		 * overflows the pointer, which is undefined behavior.
+		 */
+		/* catch up */
+		if (offset) {
+			while ((start > anchor) && (start > base + offset - ZSTD_REP_MOVE) &&
+			       (start[-1] == (start-offset+ZSTD_REP_MOVE)[-1])) /* only search for offset within prefix */
+			{
+				start--;
+				matchLength++;
+			}
+			offset_2 = offset_1;
+			offset_1 = (U32)(offset - ZSTD_REP_MOVE);
+		}
+
+	/* store sequence */
+_storeSequence:
+		{
+			size_t const litLength = start - anchor;
+			ZSTD_storeSeq(seqStorePtr, litLength, anchor, (U32)offset, matchLength - MINMATCH);
+			anchor = ip = start + matchLength;
+		}
+
+		/* check immediate repcode */
+		while ((ip <= ilimit) && ((offset_2 > 0) & (ZSTD_read32(ip) == ZSTD_read32(ip - offset_2)))) {
+			/* store sequence */
+			matchLength = ZSTD_count(ip + EQUAL_READ32, ip + EQUAL_READ32 - offset_2, iend) + EQUAL_READ32;
+			offset = offset_2;
+			offset_2 = offset_1;
+			offset_1 = (U32)offset; /* swap repcodes */
+			ZSTD_storeSeq(seqStorePtr, 0, anchor, 0, matchLength - MINMATCH);
+			ip += matchLength;
+			anchor = ip;
+			continue; /* faster when present ... (?) */
+		}
+	}
+
+	/* Save reps for next block */
+	ctx->repToConfirm[0] = offset_1 ? offset_1 : savedOffset;
+	ctx->repToConfirm[1] = offset_2 ? offset_2 : savedOffset;
+
+	/* Last Literals */
+	{
+		size_t const lastLLSize = iend - anchor;
+		memcpy(seqStorePtr->lit, anchor, lastLLSize);
+		seqStorePtr->lit += lastLLSize;
+	}
+}
+
+static void ZSTD_compressBlock_btlazy2(ZSTD_CCtx *ctx, const void *src, size_t srcSize) { ZSTD_compressBlock_lazy_generic(ctx, src, srcSize, 1, 2); }
+
+static void ZSTD_compressBlock_lazy2(ZSTD_CCtx *ctx, const void *src, size_t srcSize) { ZSTD_compressBlock_lazy_generic(ctx, src, srcSize, 0, 2); }
+
+static void ZSTD_compressBlock_lazy(ZSTD_CCtx *ctx, const void *src, size_t srcSize) { ZSTD_compressBlock_lazy_generic(ctx, src, srcSize, 0, 1); }
+
+static void ZSTD_compressBlock_greedy(ZSTD_CCtx *ctx, const void *src, size_t srcSize) { ZSTD_compressBlock_lazy_generic(ctx, src, srcSize, 0, 0); }
+
+FORCE_INLINE
+void ZSTD_compressBlock_lazy_extDict_generic(ZSTD_CCtx *ctx, const void *src, size_t srcSize, const U32 searchMethod, const U32 depth)
+{
+	seqStore_t *seqStorePtr = &(ctx->seqStore);
+	const BYTE *const istart = (const BYTE *)src;
+	const BYTE *ip = istart;
+	const BYTE *anchor = istart;
+	const BYTE *const iend = istart + srcSize;
+	const BYTE *const ilimit = iend - 8;
+	const BYTE *const base = ctx->base;
+	const U32 dictLimit = ctx->dictLimit;
+	const U32 lowestIndex = ctx->lowLimit;
+	const BYTE *const prefixStart = base + dictLimit;
+	const BYTE *const dictBase = ctx->dictBase;
+	const BYTE *const dictEnd = dictBase + dictLimit;
+	const BYTE *const dictStart = dictBase + ctx->lowLimit;
+
+	const U32 maxSearches = 1 << ctx->params.cParams.searchLog;
+	const U32 mls = ctx->params.cParams.searchLength;
+
+	typedef size_t (*searchMax_f)(ZSTD_CCtx * zc, const BYTE *ip, const BYTE *iLimit, size_t *offsetPtr, U32 maxNbAttempts, U32 matchLengthSearch);
+	searchMax_f searchMax = searchMethod ? ZSTD_BtFindBestMatch_selectMLS_extDict : ZSTD_HcFindBestMatch_extDict_selectMLS;
+
+	U32 offset_1 = ctx->rep[0], offset_2 = ctx->rep[1];
+
+	/* init */
+	ctx->nextToUpdate3 = ctx->nextToUpdate;
+	ip += (ip == prefixStart);
+
+	/* Match Loop */
+	while (ip < ilimit) {
+		size_t matchLength = 0;
+		size_t offset = 0;
+		const BYTE *start = ip + 1;
+		U32 curr = (U32)(ip - base);
+
+		/* check repCode */
+		{
+			const U32 repIndex = (U32)(curr + 1 - offset_1);
+			const BYTE *const repBase = repIndex < dictLimit ? dictBase : base;
+			const BYTE *const repMatch = repBase + repIndex;
+			if (((U32)((dictLimit - 1) - repIndex) >= 3) & (repIndex > lowestIndex)) /* intentional overflow */
+				if (ZSTD_read32(ip + 1) == ZSTD_read32(repMatch)) {
+					/* repcode detected we should take it */
+					const BYTE *const repEnd = repIndex < dictLimit ? dictEnd : iend;
+					matchLength =
+					    ZSTD_count_2segments(ip + 1 + EQUAL_READ32, repMatch + EQUAL_READ32, iend, repEnd, prefixStart) + EQUAL_READ32;
+					if (depth == 0)
+						goto _storeSequence;
+				}
+		}
+
+		/* first search (depth 0) */
+		{
+			size_t offsetFound = 99999999;
+			size_t const ml2 = searchMax(ctx, ip, iend, &offsetFound, maxSearches, mls);
+			if (ml2 > matchLength)
+				matchLength = ml2, start = ip, offset = offsetFound;
+		}
+
+		if (matchLength < EQUAL_READ32) {
+			ip += ((ip - anchor) >> g_searchStrength) + 1; /* jump faster over incompressible sections */
+			continue;
+		}
+
+		/* let's try to find a better solution */
+		if (depth >= 1)
+			while (ip < ilimit) {
+				ip++;
+				curr++;
+				/* check repCode */
+				if (offset) {
+					const U32 repIndex = (U32)(curr - offset_1);
+					const BYTE *const repBase = repIndex < dictLimit ? dictBase : base;
+					const BYTE *const repMatch = repBase + repIndex;
+					if (((U32)((dictLimit - 1) - repIndex) >= 3) & (repIndex > lowestIndex)) /* intentional overflow */
+						if (ZSTD_read32(ip) == ZSTD_read32(repMatch)) {
+							/* repcode detected */
+							const BYTE *const repEnd = repIndex < dictLimit ? dictEnd : iend;
+							size_t const repLength =
+							    ZSTD_count_2segments(ip + EQUAL_READ32, repMatch + EQUAL_READ32, iend, repEnd, prefixStart) +
+							    EQUAL_READ32;
+							int const gain2 = (int)(repLength * 3);
+							int const gain1 = (int)(matchLength * 3 - ZSTD_highbit32((U32)offset + 1) + 1);
+							if ((repLength >= EQUAL_READ32) && (gain2 > gain1))
+								matchLength = repLength, offset = 0, start = ip;
+						}
+				}
+
+				/* search match, depth 1 */
+				{
+					size_t offset2 = 99999999;
+					size_t const ml2 = searchMax(ctx, ip, iend, &offset2, maxSearches, mls);
+					int const gain2 = (int)(ml2 * 4 - ZSTD_highbit32((U32)offset2 + 1)); /* raw approx */
+					int const gain1 = (int)(matchLength * 4 - ZSTD_highbit32((U32)offset + 1) + 4);
+					if ((ml2 >= EQUAL_READ32) && (gain2 > gain1)) {
+						matchLength = ml2, offset = offset2, start = ip;
+						continue; /* search a better one */
+					}
+				}
+
+				/* let's find an even better one */
+				if ((depth == 2) && (ip < ilimit)) {
+					ip++;
+					curr++;
+					/* check repCode */
+					if (offset) {
+						const U32 repIndex = (U32)(curr - offset_1);
+						const BYTE *const repBase = repIndex < dictLimit ? dictBase : base;
+						const BYTE *const repMatch = repBase + repIndex;
+						if (((U32)((dictLimit - 1) - repIndex) >= 3) & (repIndex > lowestIndex)) /* intentional overflow */
+							if (ZSTD_read32(ip) == ZSTD_read32(repMatch)) {
+								/* repcode detected */
+								const BYTE *const repEnd = repIndex < dictLimit ? dictEnd : iend;
+								size_t repLength = ZSTD_count_2segments(ip + EQUAL_READ32, repMatch + EQUAL_READ32, iend,
+													repEnd, prefixStart) +
+										   EQUAL_READ32;
+								int gain2 = (int)(repLength * 4);
+								int gain1 = (int)(matchLength * 4 - ZSTD_highbit32((U32)offset + 1) + 1);
+								if ((repLength >= EQUAL_READ32) && (gain2 > gain1))
+									matchLength = repLength, offset = 0, start = ip;
+							}
+					}
+
+					/* search match, depth 2 */
+					{
+						size_t offset2 = 99999999;
+						size_t const ml2 = searchMax(ctx, ip, iend, &offset2, maxSearches, mls);
+						int const gain2 = (int)(ml2 * 4 - ZSTD_highbit32((U32)offset2 + 1)); /* raw approx */
+						int const gain1 = (int)(matchLength * 4 - ZSTD_highbit32((U32)offset + 1) + 7);
+						if ((ml2 >= EQUAL_READ32) && (gain2 > gain1)) {
+							matchLength = ml2, offset = offset2, start = ip;
+							continue;
+						}
+					}
+				}
+				break; /* nothing found : store previous solution */
+			}
+
+		/* catch up */
+		if (offset) {
+			U32 const matchIndex = (U32)((start - base) - (offset - ZSTD_REP_MOVE));
+			const BYTE *match = (matchIndex < dictLimit) ? dictBase + matchIndex : base + matchIndex;
+			const BYTE *const mStart = (matchIndex < dictLimit) ? dictStart : prefixStart;
+			while ((start > anchor) && (match > mStart) && (start[-1] == match[-1])) {
+				start--;
+				match--;
+				matchLength++;
+			} /* catch up */
+			offset_2 = offset_1;
+			offset_1 = (U32)(offset - ZSTD_REP_MOVE);
+		}
+
+	/* store sequence */
+	_storeSequence : {
+		size_t const litLength = start - anchor;
+		ZSTD_storeSeq(seqStorePtr, litLength, anchor, (U32)offset, matchLength - MINMATCH);
+		anchor = ip = start + matchLength;
+	}
+
+		/* check immediate repcode */
+		while (ip <= ilimit) {
+			const U32 repIndex = (U32)((ip - base) - offset_2);
+			const BYTE *const repBase = repIndex < dictLimit ? dictBase : base;
+			const BYTE *const repMatch = repBase + repIndex;
+			if (((U32)((dictLimit - 1) - repIndex) >= 3) & (repIndex > lowestIndex)) /* intentional overflow */
+				if (ZSTD_read32(ip) == ZSTD_read32(repMatch)) {
+					/* repcode detected we should take it */
+					const BYTE *const repEnd = repIndex < dictLimit ? dictEnd : iend;
+					matchLength =
+					    ZSTD_count_2segments(ip + EQUAL_READ32, repMatch + EQUAL_READ32, iend, repEnd, prefixStart) + EQUAL_READ32;
+					offset = offset_2;
+					offset_2 = offset_1;
+					offset_1 = (U32)offset; /* swap offset history */
+					ZSTD_storeSeq(seqStorePtr, 0, anchor, 0, matchLength - MINMATCH);
+					ip += matchLength;
+					anchor = ip;
+					continue; /* faster when present ... (?) */
+				}
+			break;
+		}
+	}
+
+	/* Save reps for next block */
+	ctx->repToConfirm[0] = offset_1;
+	ctx->repToConfirm[1] = offset_2;
+
+	/* Last Literals */
+	{
+		size_t const lastLLSize = iend - anchor;
+		memcpy(seqStorePtr->lit, anchor, lastLLSize);
+		seqStorePtr->lit += lastLLSize;
+	}
+}
+
+void ZSTD_compressBlock_greedy_extDict(ZSTD_CCtx *ctx, const void *src, size_t srcSize) { ZSTD_compressBlock_lazy_extDict_generic(ctx, src, srcSize, 0, 0); }
+
+static void ZSTD_compressBlock_lazy_extDict(ZSTD_CCtx *ctx, const void *src, size_t srcSize)
+{
+	ZSTD_compressBlock_lazy_extDict_generic(ctx, src, srcSize, 0, 1);
+}
+
+static void ZSTD_compressBlock_lazy2_extDict(ZSTD_CCtx *ctx, const void *src, size_t srcSize)
+{
+	ZSTD_compressBlock_lazy_extDict_generic(ctx, src, srcSize, 0, 2);
+}
+
+static void ZSTD_compressBlock_btlazy2_extDict(ZSTD_CCtx *ctx, const void *src, size_t srcSize)
+{
+	ZSTD_compressBlock_lazy_extDict_generic(ctx, src, srcSize, 1, 2);
+}
+
+/* The optimal parser */
+#include "zstd_opt.h"
+
+static void ZSTD_compressBlock_btopt(ZSTD_CCtx *ctx, const void *src, size_t srcSize)
+{
+#ifdef ZSTD_OPT_H_91842398743
+	ZSTD_compressBlock_opt_generic(ctx, src, srcSize, 0);
+#else
+	(void)ctx;
+	(void)src;
+	(void)srcSize;
+	return;
+#endif
+}
+
+static void ZSTD_compressBlock_btopt2(ZSTD_CCtx *ctx, const void *src, size_t srcSize)
+{
+#ifdef ZSTD_OPT_H_91842398743
+	ZSTD_compressBlock_opt_generic(ctx, src, srcSize, 1);
+#else
+	(void)ctx;
+	(void)src;
+	(void)srcSize;
+	return;
+#endif
+}
+
+static void ZSTD_compressBlock_btopt_extDict(ZSTD_CCtx *ctx, const void *src, size_t srcSize)
+{
+#ifdef ZSTD_OPT_H_91842398743
+	ZSTD_compressBlock_opt_extDict_generic(ctx, src, srcSize, 0);
+#else
+	(void)ctx;
+	(void)src;
+	(void)srcSize;
+	return;
+#endif
+}
+
+static void ZSTD_compressBlock_btopt2_extDict(ZSTD_CCtx *ctx, const void *src, size_t srcSize)
+{
+#ifdef ZSTD_OPT_H_91842398743
+	ZSTD_compressBlock_opt_extDict_generic(ctx, src, srcSize, 1);
+#else
+	(void)ctx;
+	(void)src;
+	(void)srcSize;
+	return;
+#endif
+}
+
+typedef void (*ZSTD_blockCompressor)(ZSTD_CCtx *ctx, const void *src, size_t srcSize);
+
+static ZSTD_blockCompressor ZSTD_selectBlockCompressor(ZSTD_strategy strat, int extDict)
+{
+	static const ZSTD_blockCompressor blockCompressor[2][8] = {
+	    {ZSTD_compressBlock_fast, ZSTD_compressBlock_doubleFast, ZSTD_compressBlock_greedy, ZSTD_compressBlock_lazy, ZSTD_compressBlock_lazy2,
+	     ZSTD_compressBlock_btlazy2, ZSTD_compressBlock_btopt, ZSTD_compressBlock_btopt2},
+	    {ZSTD_compressBlock_fast_extDict, ZSTD_compressBlock_doubleFast_extDict, ZSTD_compressBlock_greedy_extDict, ZSTD_compressBlock_lazy_extDict,
+	     ZSTD_compressBlock_lazy2_extDict, ZSTD_compressBlock_btlazy2_extDict, ZSTD_compressBlock_btopt_extDict, ZSTD_compressBlock_btopt2_extDict}};
+
+	return blockCompressor[extDict][(U32)strat];
+}
+
+static size_t ZSTD_compressBlock_internal(ZSTD_CCtx *zc, void *dst, size_t dstCapacity, const void *src, size_t srcSize)
+{
+	ZSTD_blockCompressor const blockCompressor = ZSTD_selectBlockCompressor(zc->params.cParams.strategy, zc->lowLimit < zc->dictLimit);
+	const BYTE *const base = zc->base;
+	const BYTE *const istart = (const BYTE *)src;
+	const U32 curr = (U32)(istart - base);
+	if (srcSize < MIN_CBLOCK_SIZE + ZSTD_blockHeaderSize + 1)
+		return 0; /* don't even attempt compression below a certain srcSize */
+	ZSTD_resetSeqStore(&(zc->seqStore));
+	if (curr > zc->nextToUpdate + 384)
+		zc->nextToUpdate = curr - MIN(192, (U32)(curr - zc->nextToUpdate - 384)); /* update tree not updated after finding very long rep matches */
+	blockCompressor(zc, src, srcSize);
+	return ZSTD_compressSequences(zc, dst, dstCapacity, srcSize);
+}
+
+/*! ZSTD_compress_generic() :
+*   Compress a chunk of data into one or multiple blocks.
+*   All blocks will be terminated, all input will be consumed.
+*   Function will issue an error if there is not enough `dstCapacity` to hold the compressed content.
+*   Frame is supposed already started (header already produced)
+*   @return : compressed size, or an error code
+*/
+static size_t ZSTD_compress_generic(ZSTD_CCtx *cctx, void *dst, size_t dstCapacity, const void *src, size_t srcSize, U32 lastFrameChunk)
+{
+	size_t blockSize = cctx->blockSize;
+	size_t remaining = srcSize;
+	const BYTE *ip = (const BYTE *)src;
+	BYTE *const ostart = (BYTE *)dst;
+	BYTE *op = ostart;
+	U32 const maxDist = 1 << cctx->params.cParams.windowLog;
+
+	if (cctx->params.fParams.checksumFlag && srcSize)
+		xxh64_update(&cctx->xxhState, src, srcSize);
+
+	while (remaining) {
+		U32 const lastBlock = lastFrameChunk & (blockSize >= remaining);
+		size_t cSize;
+
+		if (dstCapacity < ZSTD_blockHeaderSize + MIN_CBLOCK_SIZE)
+			return ERROR(dstSize_tooSmall); /* not enough space to store compressed block */
+		if (remaining < blockSize)
+			blockSize = remaining;
+
+		/* preemptive overflow correction */
+		if (cctx->lowLimit > (3U << 29)) {
+			U32 const cycleMask = (1 << ZSTD_cycleLog(cctx->params.cParams.hashLog, cctx->params.cParams.strategy)) - 1;
+			U32 const curr = (U32)(ip - cctx->base);
+			U32 const newCurr = (curr & cycleMask) + (1 << cctx->params.cParams.windowLog);
+			U32 const correction = curr - newCurr;
+			ZSTD_STATIC_ASSERT(ZSTD_WINDOWLOG_MAX_64 <= 30);
+			ZSTD_reduceIndex(cctx, correction);
+			cctx->base += correction;
+			cctx->dictBase += correction;
+			cctx->lowLimit -= correction;
+			cctx->dictLimit -= correction;
+			if (cctx->nextToUpdate < correction)
+				cctx->nextToUpdate = 0;
+			else
+				cctx->nextToUpdate -= correction;
+		}
+
+		if ((U32)(ip + blockSize - cctx->base) > cctx->loadedDictEnd + maxDist) {
+			/* enforce maxDist */
+			U32 const newLowLimit = (U32)(ip + blockSize - cctx->base) - maxDist;
+			if (cctx->lowLimit < newLowLimit)
+				cctx->lowLimit = newLowLimit;
+			if (cctx->dictLimit < cctx->lowLimit)
+				cctx->dictLimit = cctx->lowLimit;
+		}
+
+		cSize = ZSTD_compressBlock_internal(cctx, op + ZSTD_blockHeaderSize, dstCapacity - ZSTD_blockHeaderSize, ip, blockSize);
+		if (ZSTD_isError(cSize))
+			return cSize;
+
+		if (cSize == 0) { /* block is not compressible */
+			U32 const cBlockHeader24 = lastBlock + (((U32)bt_raw) << 1) + (U32)(blockSize << 3);
+			if (blockSize + ZSTD_blockHeaderSize > dstCapacity)
+				return ERROR(dstSize_tooSmall);
+			ZSTD_writeLE32(op, cBlockHeader24); /* no pb, 4th byte will be overwritten */
+			memcpy(op + ZSTD_blockHeaderSize, ip, blockSize);
+			cSize = ZSTD_blockHeaderSize + blockSize;
+		} else {
+			U32 const cBlockHeader24 = lastBlock + (((U32)bt_compressed) << 1) + (U32)(cSize << 3);
+			ZSTD_writeLE24(op, cBlockHeader24);
+			cSize += ZSTD_blockHeaderSize;
+		}
+
+		remaining -= blockSize;
+		dstCapacity -= cSize;
+		ip += blockSize;
+		op += cSize;
+	}
+
+	if (lastFrameChunk && (op > ostart))
+		cctx->stage = ZSTDcs_ending;
+	return op - ostart;
+}
+
+static size_t ZSTD_writeFrameHeader(void *dst, size_t dstCapacity, ZSTD_parameters params, U64 pledgedSrcSize, U32 dictID)
+{
+	BYTE *const op = (BYTE *)dst;
+	U32 const dictIDSizeCode = (dictID > 0) + (dictID >= 256) + (dictID >= 65536); /* 0-3 */
+	U32 const checksumFlag = params.fParams.checksumFlag > 0;
+	U32 const windowSize = 1U << params.cParams.windowLog;
+	U32 const singleSegment = params.fParams.contentSizeFlag && (windowSize >= pledgedSrcSize);
+	BYTE const windowLogByte = (BYTE)((params.cParams.windowLog - ZSTD_WINDOWLOG_ABSOLUTEMIN) << 3);
+	U32 const fcsCode =
+	    params.fParams.contentSizeFlag ? (pledgedSrcSize >= 256) + (pledgedSrcSize >= 65536 + 256) + (pledgedSrcSize >= 0xFFFFFFFFU) : 0; /* 0-3 */
+	BYTE const frameHeaderDecriptionByte = (BYTE)(dictIDSizeCode + (checksumFlag << 2) + (singleSegment << 5) + (fcsCode << 6));
+	size_t pos;
+
+	if (dstCapacity < ZSTD_frameHeaderSize_max)
+		return ERROR(dstSize_tooSmall);
+
+	ZSTD_writeLE32(dst, ZSTD_MAGICNUMBER);
+	op[4] = frameHeaderDecriptionByte;
+	pos = 5;
+	if (!singleSegment)
+		op[pos++] = windowLogByte;
+	switch (dictIDSizeCode) {
+	default: /* impossible */
+	case 0: break;
+	case 1:
+		op[pos] = (BYTE)(dictID);
+		pos++;
+		break;
+	case 2:
+		ZSTD_writeLE16(op + pos, (U16)dictID);
+		pos += 2;
+		break;
+	case 3:
+		ZSTD_writeLE32(op + pos, dictID);
+		pos += 4;
+		break;
+	}
+	switch (fcsCode) {
+	default: /* impossible */
+	case 0:
+		if (singleSegment)
+			op[pos++] = (BYTE)(pledgedSrcSize);
+		break;
+	case 1:
+		ZSTD_writeLE16(op + pos, (U16)(pledgedSrcSize - 256));
+		pos += 2;
+		break;
+	case 2:
+		ZSTD_writeLE32(op + pos, (U32)(pledgedSrcSize));
+		pos += 4;
+		break;
+	case 3:
+		ZSTD_writeLE64(op + pos, (U64)(pledgedSrcSize));
+		pos += 8;
+		break;
+	}
+	return pos;
+}
+
+static size_t ZSTD_compressContinue_internal(ZSTD_CCtx *cctx, void *dst, size_t dstCapacity, const void *src, size_t srcSize, U32 frame, U32 lastFrameChunk)
+{
+	const BYTE *const ip = (const BYTE *)src;
+	size_t fhSize = 0;
+
+	if (cctx->stage == ZSTDcs_created)
+		return ERROR(stage_wrong); /* missing init (ZSTD_compressBegin) */
+
+	if (frame && (cctx->stage == ZSTDcs_init)) {
+		fhSize = ZSTD_writeFrameHeader(dst, dstCapacity, cctx->params, cctx->frameContentSize, cctx->dictID);
+		if (ZSTD_isError(fhSize))
+			return fhSize;
+		dstCapacity -= fhSize;
+		dst = (char *)dst + fhSize;
+		cctx->stage = ZSTDcs_ongoing;
+	}
+
+	/* Check if blocks follow each other */
+	if (src != cctx->nextSrc) {
+		/* not contiguous */
+		ptrdiff_t const delta = cctx->nextSrc - ip;
+		cctx->lowLimit = cctx->dictLimit;
+		cctx->dictLimit = (U32)(cctx->nextSrc - cctx->base);
+		cctx->dictBase = cctx->base;
+		cctx->base -= delta;
+		cctx->nextToUpdate = cctx->dictLimit;
+		if (cctx->dictLimit - cctx->lowLimit < HASH_READ_SIZE)
+			cctx->lowLimit = cctx->dictLimit; /* too small extDict */
+	}
+
+	/* if input and dictionary overlap : reduce dictionary (area presumed modified by input) */
+	if ((ip + srcSize > cctx->dictBase + cctx->lowLimit) & (ip < cctx->dictBase + cctx->dictLimit)) {
+		ptrdiff_t const highInputIdx = (ip + srcSize) - cctx->dictBase;
+		U32 const lowLimitMax = (highInputIdx > (ptrdiff_t)cctx->dictLimit) ? cctx->dictLimit : (U32)highInputIdx;
+		cctx->lowLimit = lowLimitMax;
+	}
+
+	cctx->nextSrc = ip + srcSize;
+
+	if (srcSize) {
+		size_t const cSize = frame ? ZSTD_compress_generic(cctx, dst, dstCapacity, src, srcSize, lastFrameChunk)
+					   : ZSTD_compressBlock_internal(cctx, dst, dstCapacity, src, srcSize);
+		if (ZSTD_isError(cSize))
+			return cSize;
+		return cSize + fhSize;
+	} else
+		return fhSize;
+}
+
+size_t ZSTD_compressContinue(ZSTD_CCtx *cctx, void *dst, size_t dstCapacity, const void *src, size_t srcSize)
+{
+	return ZSTD_compressContinue_internal(cctx, dst, dstCapacity, src, srcSize, 1, 0);
+}
+
+size_t ZSTD_getBlockSizeMax(ZSTD_CCtx *cctx) { return MIN(ZSTD_BLOCKSIZE_ABSOLUTEMAX, 1 << cctx->params.cParams.windowLog); }
+
+size_t ZSTD_compressBlock(ZSTD_CCtx *cctx, void *dst, size_t dstCapacity, const void *src, size_t srcSize)
+{
+	size_t const blockSizeMax = ZSTD_getBlockSizeMax(cctx);
+	if (srcSize > blockSizeMax)
+		return ERROR(srcSize_wrong);
+	return ZSTD_compressContinue_internal(cctx, dst, dstCapacity, src, srcSize, 0, 0);
+}
+
+/*! ZSTD_loadDictionaryContent() :
+ *  @return : 0, or an error code
+ */
+static size_t ZSTD_loadDictionaryContent(ZSTD_CCtx *zc, const void *src, size_t srcSize)
+{
+	const BYTE *const ip = (const BYTE *)src;
+	const BYTE *const iend = ip + srcSize;
+
+	/* input becomes curr prefix */
+	zc->lowLimit = zc->dictLimit;
+	zc->dictLimit = (U32)(zc->nextSrc - zc->base);
+	zc->dictBase = zc->base;
+	zc->base += ip - zc->nextSrc;
+	zc->nextToUpdate = zc->dictLimit;
+	zc->loadedDictEnd = zc->forceWindow ? 0 : (U32)(iend - zc->base);
+
+	zc->nextSrc = iend;
+	if (srcSize <= HASH_READ_SIZE)
+		return 0;
+
+	switch (zc->params.cParams.strategy) {
+	case ZSTD_fast: ZSTD_fillHashTable(zc, iend, zc->params.cParams.searchLength); break;
+
+	case ZSTD_dfast: ZSTD_fillDoubleHashTable(zc, iend, zc->params.cParams.searchLength); break;
+
+	case ZSTD_greedy:
+	case ZSTD_lazy:
+	case ZSTD_lazy2:
+		if (srcSize >= HASH_READ_SIZE)
+			ZSTD_insertAndFindFirstIndex(zc, iend - HASH_READ_SIZE, zc->params.cParams.searchLength);
+		break;
+
+	case ZSTD_btlazy2:
+	case ZSTD_btopt:
+	case ZSTD_btopt2:
+		if (srcSize >= HASH_READ_SIZE)
+			ZSTD_updateTree(zc, iend - HASH_READ_SIZE, iend, 1 << zc->params.cParams.searchLog, zc->params.cParams.searchLength);
+		break;
+
+	default:
+		return ERROR(GENERIC); /* strategy doesn't exist; impossible */
+	}
+
+	zc->nextToUpdate = (U32)(iend - zc->base);
+	return 0;
+}
+
+/* Dictionaries that assign zero probability to symbols that show up causes problems
+   when FSE encoding.  Refuse dictionaries that assign zero probability to symbols
+   that we may encounter during compression.
+   NOTE: This behavior is not standard and could be improved in the future. */
+static size_t ZSTD_checkDictNCount(short *normalizedCounter, unsigned dictMaxSymbolValue, unsigned maxSymbolValue)
+{
+	U32 s;
+	if (dictMaxSymbolValue < maxSymbolValue)
+		return ERROR(dictionary_corrupted);
+	for (s = 0; s <= maxSymbolValue; ++s) {
+		if (normalizedCounter[s] == 0)
+			return ERROR(dictionary_corrupted);
+	}
+	return 0;
+}
+
+/* Dictionary format :
+ * See :
+ * https://github.com/facebook/zstd/blob/master/doc/zstd_compression_format.md#dictionary-format
+ */
+/*! ZSTD_loadZstdDictionary() :
+ * @return : 0, or an error code
+ *  assumptions : magic number supposed already checked
+ *                dictSize supposed > 8
+ */
+static size_t ZSTD_loadZstdDictionary(ZSTD_CCtx *cctx, const void *dict, size_t dictSize)
+{
+	const BYTE *dictPtr = (const BYTE *)dict;
+	const BYTE *const dictEnd = dictPtr + dictSize;
+	short offcodeNCount[MaxOff + 1];
+	unsigned offcodeMaxValue = MaxOff;
+
+	dictPtr += 4; /* skip magic number */
+	cctx->dictID = cctx->params.fParams.noDictIDFlag ? 0 : ZSTD_readLE32(dictPtr);
+	dictPtr += 4;
+
+	{
+		size_t const hufHeaderSize = HUF_readCTable_wksp(cctx->hufTable, 255, dictPtr, dictEnd - dictPtr, cctx->tmpCounters, sizeof(cctx->tmpCounters));
+		if (HUF_isError(hufHeaderSize))
+			return ERROR(dictionary_corrupted);
+		dictPtr += hufHeaderSize;
+	}
+
+	{
+		unsigned offcodeLog;
+		size_t const offcodeHeaderSize = FSE_readNCount(offcodeNCount, &offcodeMaxValue, &offcodeLog, dictPtr, dictEnd - dictPtr);
+		if (FSE_isError(offcodeHeaderSize))
+			return ERROR(dictionary_corrupted);
+		if (offcodeLog > OffFSELog)
+			return ERROR(dictionary_corrupted);
+		/* Defer checking offcodeMaxValue because we need to know the size of the dictionary content */
+		CHECK_E(FSE_buildCTable_wksp(cctx->offcodeCTable, offcodeNCount, offcodeMaxValue, offcodeLog, cctx->tmpCounters, sizeof(cctx->tmpCounters)),
+			dictionary_corrupted);
+		dictPtr += offcodeHeaderSize;
+	}
+
+	{
+		short matchlengthNCount[MaxML + 1];
+		unsigned matchlengthMaxValue = MaxML, matchlengthLog;
+		size_t const matchlengthHeaderSize = FSE_readNCount(matchlengthNCount, &matchlengthMaxValue, &matchlengthLog, dictPtr, dictEnd - dictPtr);
+		if (FSE_isError(matchlengthHeaderSize))
+			return ERROR(dictionary_corrupted);
+		if (matchlengthLog > MLFSELog)
+			return ERROR(dictionary_corrupted);
+		/* Every match length code must have non-zero probability */
+		CHECK_F(ZSTD_checkDictNCount(matchlengthNCount, matchlengthMaxValue, MaxML));
+		CHECK_E(
+		    FSE_buildCTable_wksp(cctx->matchlengthCTable, matchlengthNCount, matchlengthMaxValue, matchlengthLog, cctx->tmpCounters, sizeof(cctx->tmpCounters)),
+		    dictionary_corrupted);
+		dictPtr += matchlengthHeaderSize;
+	}
+
+	{
+		short litlengthNCount[MaxLL + 1];
+		unsigned litlengthMaxValue = MaxLL, litlengthLog;
+		size_t const litlengthHeaderSize = FSE_readNCount(litlengthNCount, &litlengthMaxValue, &litlengthLog, dictPtr, dictEnd - dictPtr);
+		if (FSE_isError(litlengthHeaderSize))
+			return ERROR(dictionary_corrupted);
+		if (litlengthLog > LLFSELog)
+			return ERROR(dictionary_corrupted);
+		/* Every literal length code must have non-zero probability */
+		CHECK_F(ZSTD_checkDictNCount(litlengthNCount, litlengthMaxValue, MaxLL));
+		CHECK_E(FSE_buildCTable_wksp(cctx->litlengthCTable, litlengthNCount, litlengthMaxValue, litlengthLog, cctx->tmpCounters, sizeof(cctx->tmpCounters)),
+			dictionary_corrupted);
+		dictPtr += litlengthHeaderSize;
+	}
+
+	if (dictPtr + 12 > dictEnd)
+		return ERROR(dictionary_corrupted);
+	cctx->rep[0] = ZSTD_readLE32(dictPtr + 0);
+	cctx->rep[1] = ZSTD_readLE32(dictPtr + 4);
+	cctx->rep[2] = ZSTD_readLE32(dictPtr + 8);
+	dictPtr += 12;
+
+	{
+		size_t const dictContentSize = (size_t)(dictEnd - dictPtr);
+		U32 offcodeMax = MaxOff;
+		if (dictContentSize <= ((U32)-1) - 128 KB) {
+			U32 const maxOffset = (U32)dictContentSize + 128 KB; /* The maximum offset that must be supported */
+			offcodeMax = ZSTD_highbit32(maxOffset);		     /* Calculate minimum offset code required to represent maxOffset */
+		}
+		/* All offset values <= dictContentSize + 128 KB must be representable */
+		CHECK_F(ZSTD_checkDictNCount(offcodeNCount, offcodeMaxValue, MIN(offcodeMax, MaxOff)));
+		/* All repCodes must be <= dictContentSize and != 0*/
+		{
+			U32 u;
+			for (u = 0; u < 3; u++) {
+				if (cctx->rep[u] == 0)
+					return ERROR(dictionary_corrupted);
+				if (cctx->rep[u] > dictContentSize)
+					return ERROR(dictionary_corrupted);
+			}
+		}
+
+		cctx->flagStaticTables = 1;
+		cctx->flagStaticHufTable = HUF_repeat_valid;
+		return ZSTD_loadDictionaryContent(cctx, dictPtr, dictContentSize);
+	}
+}
+
+/** ZSTD_compress_insertDictionary() :
+*   @return : 0, or an error code */
+static size_t ZSTD_compress_insertDictionary(ZSTD_CCtx *cctx, const void *dict, size_t dictSize)
+{
+	if ((dict == NULL) || (dictSize <= 8))
+		return 0;
+
+	/* dict as pure content */
+	if ((ZSTD_readLE32(dict) != ZSTD_DICT_MAGIC) || (cctx->forceRawDict))
+		return ZSTD_loadDictionaryContent(cctx, dict, dictSize);
+
+	/* dict as zstd dictionary */
+	return ZSTD_loadZstdDictionary(cctx, dict, dictSize);
+}
+
+/*! ZSTD_compressBegin_internal() :
+*   @return : 0, or an error code */
+static size_t ZSTD_compressBegin_internal(ZSTD_CCtx *cctx, const void *dict, size_t dictSize, ZSTD_parameters params, U64 pledgedSrcSize)
+{
+	ZSTD_compResetPolicy_e const crp = dictSize ? ZSTDcrp_fullReset : ZSTDcrp_continue;
+	CHECK_F(ZSTD_resetCCtx_advanced(cctx, params, pledgedSrcSize, crp));
+	return ZSTD_compress_insertDictionary(cctx, dict, dictSize);
+}
+
+/*! ZSTD_compressBegin_advanced() :
+*   @return : 0, or an error code */
+size_t ZSTD_compressBegin_advanced(ZSTD_CCtx *cctx, const void *dict, size_t dictSize, ZSTD_parameters params, unsigned long long pledgedSrcSize)
+{
+	/* compression parameters verification and optimization */
+	CHECK_F(ZSTD_checkCParams(params.cParams));
+	return ZSTD_compressBegin_internal(cctx, dict, dictSize, params, pledgedSrcSize);
+}
+
+size_t ZSTD_compressBegin_usingDict(ZSTD_CCtx *cctx, const void *dict, size_t dictSize, int compressionLevel)
+{
+	ZSTD_parameters const params = ZSTD_getParams(compressionLevel, 0, dictSize);
+	return ZSTD_compressBegin_internal(cctx, dict, dictSize, params, 0);
+}
+
+size_t ZSTD_compressBegin(ZSTD_CCtx *cctx, int compressionLevel) { return ZSTD_compressBegin_usingDict(cctx, NULL, 0, compressionLevel); }
+
+/*! ZSTD_writeEpilogue() :
+*   Ends a frame.
+*   @return : nb of bytes written into dst (or an error code) */
+static size_t ZSTD_writeEpilogue(ZSTD_CCtx *cctx, void *dst, size_t dstCapacity)
+{
+	BYTE *const ostart = (BYTE *)dst;
+	BYTE *op = ostart;
+	size_t fhSize = 0;
+
+	if (cctx->stage == ZSTDcs_created)
+		return ERROR(stage_wrong); /* init missing */
+
+	/* special case : empty frame */
+	if (cctx->stage == ZSTDcs_init) {
+		fhSize = ZSTD_writeFrameHeader(dst, dstCapacity, cctx->params, 0, 0);
+		if (ZSTD_isError(fhSize))
+			return fhSize;
+		dstCapacity -= fhSize;
+		op += fhSize;
+		cctx->stage = ZSTDcs_ongoing;
+	}
+
+	if (cctx->stage != ZSTDcs_ending) {
+		/* write one last empty block, make it the "last" block */
+		U32 const cBlockHeader24 = 1 /* last block */ + (((U32)bt_raw) << 1) + 0;
+		if (dstCapacity < 4)
+			return ERROR(dstSize_tooSmall);
+		ZSTD_writeLE32(op, cBlockHeader24);
+		op += ZSTD_blockHeaderSize;
+		dstCapacity -= ZSTD_blockHeaderSize;
+	}
+
+	if (cctx->params.fParams.checksumFlag) {
+		U32 const checksum = (U32)xxh64_digest(&cctx->xxhState);
+		if (dstCapacity < 4)
+			return ERROR(dstSize_tooSmall);
+		ZSTD_writeLE32(op, checksum);
+		op += 4;
+	}
+
+	cctx->stage = ZSTDcs_created; /* return to "created but no init" status */
+	return op - ostart;
+}
+
+size_t ZSTD_compressEnd(ZSTD_CCtx *cctx, void *dst, size_t dstCapacity, const void *src, size_t srcSize)
+{
+	size_t endResult;
+	size_t const cSize = ZSTD_compressContinue_internal(cctx, dst, dstCapacity, src, srcSize, 1, 1);
+	if (ZSTD_isError(cSize))
+		return cSize;
+	endResult = ZSTD_writeEpilogue(cctx, (char *)dst + cSize, dstCapacity - cSize);
+	if (ZSTD_isError(endResult))
+		return endResult;
+	return cSize + endResult;
+}
+
+static size_t ZSTD_compress_internal(ZSTD_CCtx *cctx, void *dst, size_t dstCapacity, const void *src, size_t srcSize, const void *dict, size_t dictSize,
+				     ZSTD_parameters params)
+{
+	CHECK_F(ZSTD_compressBegin_internal(cctx, dict, dictSize, params, srcSize));
+	return ZSTD_compressEnd(cctx, dst, dstCapacity, src, srcSize);
+}
+
+size_t ZSTD_compress_usingDict(ZSTD_CCtx *ctx, void *dst, size_t dstCapacity, const void *src, size_t srcSize, const void *dict, size_t dictSize,
+			       ZSTD_parameters params)
+{
+	return ZSTD_compress_internal(ctx, dst, dstCapacity, src, srcSize, dict, dictSize, params);
+}
+
+size_t ZSTD_compressCCtx(ZSTD_CCtx *ctx, void *dst, size_t dstCapacity, const void *src, size_t srcSize, ZSTD_parameters params)
+{
+	return ZSTD_compress_internal(ctx, dst, dstCapacity, src, srcSize, NULL, 0, params);
+}
+
+/* =====  Dictionary API  ===== */
+
+struct ZSTD_CDict_s {
+	void *dictBuffer;
+	const void *dictContent;
+	size_t dictContentSize;
+	ZSTD_CCtx *refContext;
+}; /* typedef'd tp ZSTD_CDict within "zstd.h" */
+
+size_t ZSTD_CDictWorkspaceBound(ZSTD_compressionParameters cParams) { return ZSTD_CCtxWorkspaceBound(cParams) + ZSTD_ALIGN(sizeof(ZSTD_CDict)); }
+
+static ZSTD_CDict *ZSTD_createCDict_advanced(const void *dictBuffer, size_t dictSize, unsigned byReference, ZSTD_parameters params, ZSTD_customMem customMem)
+{
+	if (!customMem.customAlloc || !customMem.customFree)
+		return NULL;
+
+	{
+		ZSTD_CDict *const cdict = (ZSTD_CDict *)ZSTD_malloc(sizeof(ZSTD_CDict), customMem);
+		ZSTD_CCtx *const cctx = ZSTD_createCCtx_advanced(customMem);
+
+		if (!cdict || !cctx) {
+			ZSTD_free(cdict, customMem);
+			ZSTD_freeCCtx(cctx);
+			return NULL;
+		}
+
+		if ((byReference) || (!dictBuffer) || (!dictSize)) {
+			cdict->dictBuffer = NULL;
+			cdict->dictContent = dictBuffer;
+		} else {
+			void *const internalBuffer = ZSTD_malloc(dictSize, customMem);
+			if (!internalBuffer) {
+				ZSTD_free(cctx, customMem);
+				ZSTD_free(cdict, customMem);
+				return NULL;
+			}
+			memcpy(internalBuffer, dictBuffer, dictSize);
+			cdict->dictBuffer = internalBuffer;
+			cdict->dictContent = internalBuffer;
+		}
+
+		{
+			size_t const errorCode = ZSTD_compressBegin_advanced(cctx, cdict->dictContent, dictSize, params, 0);
+			if (ZSTD_isError(errorCode)) {
+				ZSTD_free(cdict->dictBuffer, customMem);
+				ZSTD_free(cdict, customMem);
+				ZSTD_freeCCtx(cctx);
+				return NULL;
+			}
+		}
+
+		cdict->refContext = cctx;
+		cdict->dictContentSize = dictSize;
+		return cdict;
+	}
+}
+
+ZSTD_CDict *ZSTD_initCDict(const void *dict, size_t dictSize, ZSTD_parameters params, void *workspace, size_t workspaceSize)
+{
+	ZSTD_customMem const stackMem = ZSTD_initStack(workspace, workspaceSize);
+	return ZSTD_createCDict_advanced(dict, dictSize, 1, params, stackMem);
+}
+
+size_t ZSTD_freeCDict(ZSTD_CDict *cdict)
+{
+	if (cdict == NULL)
+		return 0; /* support free on NULL */
+	{
+		ZSTD_customMem const cMem = cdict->refContext->customMem;
+		ZSTD_freeCCtx(cdict->refContext);
+		ZSTD_free(cdict->dictBuffer, cMem);
+		ZSTD_free(cdict, cMem);
+		return 0;
+	}
+}
+
+static ZSTD_parameters ZSTD_getParamsFromCDict(const ZSTD_CDict *cdict) { return ZSTD_getParamsFromCCtx(cdict->refContext); }
+
+size_t ZSTD_compressBegin_usingCDict(ZSTD_CCtx *cctx, const ZSTD_CDict *cdict, unsigned long long pledgedSrcSize)
+{
+	if (cdict->dictContentSize)
+		CHECK_F(ZSTD_copyCCtx(cctx, cdict->refContext, pledgedSrcSize))
+	else {
+		ZSTD_parameters params = cdict->refContext->params;
+		params.fParams.contentSizeFlag = (pledgedSrcSize > 0);
+		CHECK_F(ZSTD_compressBegin_advanced(cctx, NULL, 0, params, pledgedSrcSize));
+	}
+	return 0;
+}
+
+/*! ZSTD_compress_usingCDict() :
+*   Compression using a digested Dictionary.
+*   Faster startup than ZSTD_compress_usingDict(), recommended when same dictionary is used multiple times.
+*   Note that compression level is decided during dictionary creation */
+size_t ZSTD_compress_usingCDict(ZSTD_CCtx *cctx, void *dst, size_t dstCapacity, const void *src, size_t srcSize, const ZSTD_CDict *cdict)
+{
+	CHECK_F(ZSTD_compressBegin_usingCDict(cctx, cdict, srcSize));
+
+	if (cdict->refContext->params.fParams.contentSizeFlag == 1) {
+		cctx->params.fParams.contentSizeFlag = 1;
+		cctx->frameContentSize = srcSize;
+	} else {
+		cctx->params.fParams.contentSizeFlag = 0;
+	}
+
+	return ZSTD_compressEnd(cctx, dst, dstCapacity, src, srcSize);
+}
+
+/* ******************************************************************
+*  Streaming
+********************************************************************/
+
+typedef enum { zcss_init, zcss_load, zcss_flush, zcss_final } ZSTD_cStreamStage;
+
+struct ZSTD_CStream_s {
+	ZSTD_CCtx *cctx;
+	ZSTD_CDict *cdictLocal;
+	const ZSTD_CDict *cdict;
+	char *inBuff;
+	size_t inBuffSize;
+	size_t inToCompress;
+	size_t inBuffPos;
+	size_t inBuffTarget;
+	size_t blockSize;
+	char *outBuff;
+	size_t outBuffSize;
+	size_t outBuffContentSize;
+	size_t outBuffFlushedSize;
+	ZSTD_cStreamStage stage;
+	U32 checksum;
+	U32 frameEnded;
+	U64 pledgedSrcSize;
+	U64 inputProcessed;
+	ZSTD_parameters params;
+	ZSTD_customMem customMem;
+}; /* typedef'd to ZSTD_CStream within "zstd.h" */
+
+size_t ZSTD_CStreamWorkspaceBound(ZSTD_compressionParameters cParams)
+{
+	size_t const inBuffSize = (size_t)1 << cParams.windowLog;
+	size_t const blockSize = MIN(ZSTD_BLOCKSIZE_ABSOLUTEMAX, inBuffSize);
+	size_t const outBuffSize = ZSTD_compressBound(blockSize) + 1;
+
+	return ZSTD_CCtxWorkspaceBound(cParams) + ZSTD_ALIGN(sizeof(ZSTD_CStream)) + ZSTD_ALIGN(inBuffSize) + ZSTD_ALIGN(outBuffSize);
+}
+
+ZSTD_CStream *ZSTD_createCStream_advanced(ZSTD_customMem customMem)
+{
+	ZSTD_CStream *zcs;
+
+	if (!customMem.customAlloc || !customMem.customFree)
+		return NULL;
+
+	zcs = (ZSTD_CStream *)ZSTD_malloc(sizeof(ZSTD_CStream), customMem);
+	if (zcs == NULL)
+		return NULL;
+	memset(zcs, 0, sizeof(ZSTD_CStream));
+	memcpy(&zcs->customMem, &customMem, sizeof(ZSTD_customMem));
+	zcs->cctx = ZSTD_createCCtx_advanced(customMem);
+	if (zcs->cctx == NULL) {
+		ZSTD_freeCStream(zcs);
+		return NULL;
+	}
+	return zcs;
+}
+
+size_t ZSTD_freeCStream(ZSTD_CStream *zcs)
+{
+	if (zcs == NULL)
+		return 0; /* support free on NULL */
+	{
+		ZSTD_customMem const cMem = zcs->customMem;
+		ZSTD_freeCCtx(zcs->cctx);
+		zcs->cctx = NULL;
+		ZSTD_freeCDict(zcs->cdictLocal);
+		zcs->cdictLocal = NULL;
+		ZSTD_free(zcs->inBuff, cMem);
+		zcs->inBuff = NULL;
+		ZSTD_free(zcs->outBuff, cMem);
+		zcs->outBuff = NULL;
+		ZSTD_free(zcs, cMem);
+		return 0;
+	}
+}
+
+/*======   Initialization   ======*/
+
+size_t ZSTD_CStreamInSize(void) { return ZSTD_BLOCKSIZE_ABSOLUTEMAX; }
+size_t ZSTD_CStreamOutSize(void) { return ZSTD_compressBound(ZSTD_BLOCKSIZE_ABSOLUTEMAX) + ZSTD_blockHeaderSize + 4 /* 32-bits hash */; }
+
+static size_t ZSTD_resetCStream_internal(ZSTD_CStream *zcs, unsigned long long pledgedSrcSize)
+{
+	if (zcs->inBuffSize == 0)
+		return ERROR(stage_wrong); /* zcs has not been init at least once => can't reset */
+
+	if (zcs->cdict)
+		CHECK_F(ZSTD_compressBegin_usingCDict(zcs->cctx, zcs->cdict, pledgedSrcSize))
+	else
+		CHECK_F(ZSTD_compressBegin_advanced(zcs->cctx, NULL, 0, zcs->params, pledgedSrcSize));
+
+	zcs->inToCompress = 0;
+	zcs->inBuffPos = 0;
+	zcs->inBuffTarget = zcs->blockSize;
+	zcs->outBuffContentSize = zcs->outBuffFlushedSize = 0;
+	zcs->stage = zcss_load;
+	zcs->frameEnded = 0;
+	zcs->pledgedSrcSize = pledgedSrcSize;
+	zcs->inputProcessed = 0;
+	return 0; /* ready to go */
+}
+
+size_t ZSTD_resetCStream(ZSTD_CStream *zcs, unsigned long long pledgedSrcSize)
+{
+
+	zcs->params.fParams.contentSizeFlag = (pledgedSrcSize > 0);
+
+	return ZSTD_resetCStream_internal(zcs, pledgedSrcSize);
+}
+
+static size_t ZSTD_initCStream_advanced(ZSTD_CStream *zcs, const void *dict, size_t dictSize, ZSTD_parameters params, unsigned long long pledgedSrcSize)
+{
+	/* allocate buffers */
+	{
+		size_t const neededInBuffSize = (size_t)1 << params.cParams.windowLog;
+		if (zcs->inBuffSize < neededInBuffSize) {
+			zcs->inBuffSize = neededInBuffSize;
+			ZSTD_free(zcs->inBuff, zcs->customMem);
+			zcs->inBuff = (char *)ZSTD_malloc(neededInBuffSize, zcs->customMem);
+			if (zcs->inBuff == NULL)
+				return ERROR(memory_allocation);
+		}
+		zcs->blockSize = MIN(ZSTD_BLOCKSIZE_ABSOLUTEMAX, neededInBuffSize);
+	}
+	if (zcs->outBuffSize < ZSTD_compressBound(zcs->blockSize) + 1) {
+		zcs->outBuffSize = ZSTD_compressBound(zcs->blockSize) + 1;
+		ZSTD_free(zcs->outBuff, zcs->customMem);
+		zcs->outBuff = (char *)ZSTD_malloc(zcs->outBuffSize, zcs->customMem);
+		if (zcs->outBuff == NULL)
+			return ERROR(memory_allocation);
+	}
+
+	if (dict && dictSize >= 8) {
+		ZSTD_freeCDict(zcs->cdictLocal);
+		zcs->cdictLocal = ZSTD_createCDict_advanced(dict, dictSize, 0, params, zcs->customMem);
+		if (zcs->cdictLocal == NULL)
+			return ERROR(memory_allocation);
+		zcs->cdict = zcs->cdictLocal;
+	} else
+		zcs->cdict = NULL;
+
+	zcs->checksum = params.fParams.checksumFlag > 0;
+	zcs->params = params;
+
+	return ZSTD_resetCStream_internal(zcs, pledgedSrcSize);
+}
+
+ZSTD_CStream *ZSTD_initCStream(ZSTD_parameters params, unsigned long long pledgedSrcSize, void *workspace, size_t workspaceSize)
+{
+	ZSTD_customMem const stackMem = ZSTD_initStack(workspace, workspaceSize);
+	ZSTD_CStream *const zcs = ZSTD_createCStream_advanced(stackMem);
+	if (zcs) {
+		size_t const code = ZSTD_initCStream_advanced(zcs, NULL, 0, params, pledgedSrcSize);
+		if (ZSTD_isError(code)) {
+			return NULL;
+		}
+	}
+	return zcs;
+}
+
+ZSTD_CStream *ZSTD_initCStream_usingCDict(const ZSTD_CDict *cdict, unsigned long long pledgedSrcSize, void *workspace, size_t workspaceSize)
+{
+	ZSTD_parameters const params = ZSTD_getParamsFromCDict(cdict);
+	ZSTD_CStream *const zcs = ZSTD_initCStream(params, pledgedSrcSize, workspace, workspaceSize);
+	if (zcs) {
+		zcs->cdict = cdict;
+		if (ZSTD_isError(ZSTD_resetCStream_internal(zcs, pledgedSrcSize))) {
+			return NULL;
+		}
+	}
+	return zcs;
+}
+
+/*======   Compression   ======*/
+
+typedef enum { zsf_gather, zsf_flush, zsf_end } ZSTD_flush_e;
+
+ZSTD_STATIC size_t ZSTD_limitCopy(void *dst, size_t dstCapacity, const void *src, size_t srcSize)
+{
+	size_t const length = MIN(dstCapacity, srcSize);
+	memcpy(dst, src, length);
+	return length;
+}
+
+static size_t ZSTD_compressStream_generic(ZSTD_CStream *zcs, void *dst, size_t *dstCapacityPtr, const void *src, size_t *srcSizePtr, ZSTD_flush_e const flush)
+{
+	U32 someMoreWork = 1;
+	const char *const istart = (const char *)src;
+	const char *const iend = istart + *srcSizePtr;
+	const char *ip = istart;
+	char *const ostart = (char *)dst;
+	char *const oend = ostart + *dstCapacityPtr;
+	char *op = ostart;
+
+	while (someMoreWork) {
+		switch (zcs->stage) {
+		case zcss_init:
+			return ERROR(init_missing); /* call ZBUFF_compressInit() first ! */
+
+		case zcss_load:
+			/* complete inBuffer */
+			{
+				size_t const toLoad = zcs->inBuffTarget - zcs->inBuffPos;
+				size_t const loaded = ZSTD_limitCopy(zcs->inBuff + zcs->inBuffPos, toLoad, ip, iend - ip);
+				zcs->inBuffPos += loaded;
+				ip += loaded;
+				if ((zcs->inBuffPos == zcs->inToCompress) || (!flush && (toLoad != loaded))) {
+					someMoreWork = 0;
+					break; /* not enough input to get a full block : stop there, wait for more */
+				}
+			}
+			/* compress curr block (note : this stage cannot be stopped in the middle) */
+			{
+				void *cDst;
+				size_t cSize;
+				size_t const iSize = zcs->inBuffPos - zcs->inToCompress;
+				size_t oSize = oend - op;
+				if (oSize >= ZSTD_compressBound(iSize))
+					cDst = op; /* compress directly into output buffer (avoid flush stage) */
+				else
+					cDst = zcs->outBuff, oSize = zcs->outBuffSize;
+				cSize = (flush == zsf_end) ? ZSTD_compressEnd(zcs->cctx, cDst, oSize, zcs->inBuff + zcs->inToCompress, iSize)
+							   : ZSTD_compressContinue(zcs->cctx, cDst, oSize, zcs->inBuff + zcs->inToCompress, iSize);
+				if (ZSTD_isError(cSize))
+					return cSize;
+				if (flush == zsf_end)
+					zcs->frameEnded = 1;
+				/* prepare next block */
+				zcs->inBuffTarget = zcs->inBuffPos + zcs->blockSize;
+				if (zcs->inBuffTarget > zcs->inBuffSize)
+					zcs->inBuffPos = 0, zcs->inBuffTarget = zcs->blockSize; /* note : inBuffSize >= blockSize */
+				zcs->inToCompress = zcs->inBuffPos;
+				if (cDst == op) {
+					op += cSize;
+					break;
+				} /* no need to flush */
+				zcs->outBuffContentSize = cSize;
+				zcs->outBuffFlushedSize = 0;
+				zcs->stage = zcss_flush; /* pass-through to flush stage */
+			}
+
+		case zcss_flush: {
+			size_t const toFlush = zcs->outBuffContentSize - zcs->outBuffFlushedSize;
+			size_t const flushed = ZSTD_limitCopy(op, oend - op, zcs->outBuff + zcs->outBuffFlushedSize, toFlush);
+			op += flushed;
+			zcs->outBuffFlushedSize += flushed;
+			if (toFlush != flushed) {
+				someMoreWork = 0;
+				break;
+			} /* dst too small to store flushed data : stop there */
+			zcs->outBuffContentSize = zcs->outBuffFlushedSize = 0;
+			zcs->stage = zcss_load;
+			break;
+		}
+
+		case zcss_final:
+			someMoreWork = 0; /* do nothing */
+			break;
+
+		default:
+			return ERROR(GENERIC); /* impossible */
+		}
+	}
+
+	*srcSizePtr = ip - istart;
+	*dstCapacityPtr = op - ostart;
+	zcs->inputProcessed += *srcSizePtr;
+	if (zcs->frameEnded)
+		return 0;
+	{
+		size_t hintInSize = zcs->inBuffTarget - zcs->inBuffPos;
+		if (hintInSize == 0)
+			hintInSize = zcs->blockSize;
+		return hintInSize;
+	}
+}
+
+size_t ZSTD_compressStream(ZSTD_CStream *zcs, ZSTD_outBuffer *output, ZSTD_inBuffer *input)
+{
+	size_t sizeRead = input->size - input->pos;
+	size_t sizeWritten = output->size - output->pos;
+	size_t const result =
+	    ZSTD_compressStream_generic(zcs, (char *)(output->dst) + output->pos, &sizeWritten, (const char *)(input->src) + input->pos, &sizeRead, zsf_gather);
+	input->pos += sizeRead;
+	output->pos += sizeWritten;
+	return result;
+}
+
+/*======   Finalize   ======*/
+
+/*! ZSTD_flushStream() :
+*   @return : amount of data remaining to flush */
+size_t ZSTD_flushStream(ZSTD_CStream *zcs, ZSTD_outBuffer *output)
+{
+	size_t srcSize = 0;
+	size_t sizeWritten = output->size - output->pos;
+	size_t const result = ZSTD_compressStream_generic(zcs, (char *)(output->dst) + output->pos, &sizeWritten, &srcSize,
+							  &srcSize, /* use a valid src address instead of NULL */
+							  zsf_flush);
+	output->pos += sizeWritten;
+	if (ZSTD_isError(result))
+		return result;
+	return zcs->outBuffContentSize - zcs->outBuffFlushedSize; /* remaining to flush */
+}
+
+size_t ZSTD_endStream(ZSTD_CStream *zcs, ZSTD_outBuffer *output)
+{
+	BYTE *const ostart = (BYTE *)(output->dst) + output->pos;
+	BYTE *const oend = (BYTE *)(output->dst) + output->size;
+	BYTE *op = ostart;
+
+	if ((zcs->pledgedSrcSize) && (zcs->inputProcessed != zcs->pledgedSrcSize))
+		return ERROR(srcSize_wrong); /* pledgedSrcSize not respected */
+
+	if (zcs->stage != zcss_final) {
+		/* flush whatever remains */
+		size_t srcSize = 0;
+		size_t sizeWritten = output->size - output->pos;
+		size_t const notEnded =
+		    ZSTD_compressStream_generic(zcs, ostart, &sizeWritten, &srcSize, &srcSize, zsf_end); /* use a valid src address instead of NULL */
+		size_t const remainingToFlush = zcs->outBuffContentSize - zcs->outBuffFlushedSize;
+		op += sizeWritten;
+		if (remainingToFlush) {
+			output->pos += sizeWritten;
+			return remainingToFlush + ZSTD_BLOCKHEADERSIZE /* final empty block */ + (zcs->checksum * 4);
+		}
+		/* create epilogue */
+		zcs->stage = zcss_final;
+		zcs->outBuffContentSize = !notEnded ? 0 : ZSTD_compressEnd(zcs->cctx, zcs->outBuff, zcs->outBuffSize, NULL,
+									   0); /* write epilogue, including final empty block, into outBuff */
+	}
+
+	/* flush epilogue */
+	{
+		size_t const toFlush = zcs->outBuffContentSize - zcs->outBuffFlushedSize;
+		size_t const flushed = ZSTD_limitCopy(op, oend - op, zcs->outBuff + zcs->outBuffFlushedSize, toFlush);
+		op += flushed;
+		zcs->outBuffFlushedSize += flushed;
+		output->pos += op - ostart;
+		if (toFlush == flushed)
+			zcs->stage = zcss_init; /* end reached */
+		return toFlush - flushed;
+	}
+}
+
+/*-=====  Pre-defined compression levels  =====-*/
+
+#define ZSTD_DEFAULT_CLEVEL 1
+#define ZSTD_MAX_CLEVEL 22
+int ZSTD_maxCLevel(void) { return ZSTD_MAX_CLEVEL; }
+
+static const ZSTD_compressionParameters ZSTD_defaultCParameters[4][ZSTD_MAX_CLEVEL + 1] = {
+    {
+	/* "default" */
+	/* W,  C,  H,  S,  L, TL, strat */
+	{18, 12, 12, 1, 7, 16, ZSTD_fast},    /* level  0 - never used */
+	{19, 13, 14, 1, 7, 16, ZSTD_fast},    /* level  1 */
+	{19, 15, 16, 1, 6, 16, ZSTD_fast},    /* level  2 */
+	{20, 16, 17, 1, 5, 16, ZSTD_dfast},   /* level  3.*/
+	{20, 18, 18, 1, 5, 16, ZSTD_dfast},   /* level  4.*/
+	{20, 15, 18, 3, 5, 16, ZSTD_greedy},  /* level  5 */
+	{21, 16, 19, 2, 5, 16, ZSTD_lazy},    /* level  6 */
+	{21, 17, 20, 3, 5, 16, ZSTD_lazy},    /* level  7 */
+	{21, 18, 20, 3, 5, 16, ZSTD_lazy2},   /* level  8 */
+	{21, 20, 20, 3, 5, 16, ZSTD_lazy2},   /* level  9 */
+	{21, 19, 21, 4, 5, 16, ZSTD_lazy2},   /* level 10 */
+	{22, 20, 22, 4, 5, 16, ZSTD_lazy2},   /* level 11 */
+	{22, 20, 22, 5, 5, 16, ZSTD_lazy2},   /* level 12 */
+	{22, 21, 22, 5, 5, 16, ZSTD_lazy2},   /* level 13 */
+	{22, 21, 22, 6, 5, 16, ZSTD_lazy2},   /* level 14 */
+	{22, 21, 21, 5, 5, 16, ZSTD_btlazy2}, /* level 15 */
+	{23, 22, 22, 5, 5, 16, ZSTD_btlazy2}, /* level 16 */
+	{23, 21, 22, 4, 5, 24, ZSTD_btopt},   /* level 17 */
+	{23, 23, 22, 6, 5, 32, ZSTD_btopt},   /* level 18 */
+	{23, 23, 22, 6, 3, 48, ZSTD_btopt},   /* level 19 */
+	{25, 25, 23, 7, 3, 64, ZSTD_btopt2},  /* level 20 */
+	{26, 26, 23, 7, 3, 256, ZSTD_btopt2}, /* level 21 */
+	{27, 27, 25, 9, 3, 512, ZSTD_btopt2}, /* level 22 */
+    },
+    {
+	/* for srcSize <= 256 KB */
+	/* W,  C,  H,  S,  L,  T, strat */
+	{0, 0, 0, 0, 0, 0, ZSTD_fast},	 /* level  0 - not used */
+	{18, 13, 14, 1, 6, 8, ZSTD_fast},      /* level  1 */
+	{18, 14, 13, 1, 5, 8, ZSTD_dfast},     /* level  2 */
+	{18, 16, 15, 1, 5, 8, ZSTD_dfast},     /* level  3 */
+	{18, 15, 17, 1, 5, 8, ZSTD_greedy},    /* level  4.*/
+	{18, 16, 17, 4, 5, 8, ZSTD_greedy},    /* level  5.*/
+	{18, 16, 17, 3, 5, 8, ZSTD_lazy},      /* level  6.*/
+	{18, 17, 17, 4, 4, 8, ZSTD_lazy},      /* level  7 */
+	{18, 17, 17, 4, 4, 8, ZSTD_lazy2},     /* level  8 */
+	{18, 17, 17, 5, 4, 8, ZSTD_lazy2},     /* level  9 */
+	{18, 17, 17, 6, 4, 8, ZSTD_lazy2},     /* level 10 */
+	{18, 18, 17, 6, 4, 8, ZSTD_lazy2},     /* level 11.*/
+	{18, 18, 17, 7, 4, 8, ZSTD_lazy2},     /* level 12.*/
+	{18, 19, 17, 6, 4, 8, ZSTD_btlazy2},   /* level 13 */
+	{18, 18, 18, 4, 4, 16, ZSTD_btopt},    /* level 14.*/
+	{18, 18, 18, 4, 3, 16, ZSTD_btopt},    /* level 15.*/
+	{18, 19, 18, 6, 3, 32, ZSTD_btopt},    /* level 16.*/
+	{18, 19, 18, 8, 3, 64, ZSTD_btopt},    /* level 17.*/
+	{18, 19, 18, 9, 3, 128, ZSTD_btopt},   /* level 18.*/
+	{18, 19, 18, 10, 3, 256, ZSTD_btopt},  /* level 19.*/
+	{18, 19, 18, 11, 3, 512, ZSTD_btopt2}, /* level 20.*/
+	{18, 19, 18, 12, 3, 512, ZSTD_btopt2}, /* level 21.*/
+	{18, 19, 18, 13, 3, 512, ZSTD_btopt2}, /* level 22.*/
+    },
+    {
+	/* for srcSize <= 128 KB */
+	/* W,  C,  H,  S,  L,  T, strat */
+	{17, 12, 12, 1, 7, 8, ZSTD_fast},      /* level  0 - not used */
+	{17, 12, 13, 1, 6, 8, ZSTD_fast},      /* level  1 */
+	{17, 13, 16, 1, 5, 8, ZSTD_fast},      /* level  2 */
+	{17, 16, 16, 2, 5, 8, ZSTD_dfast},     /* level  3 */
+	{17, 13, 15, 3, 4, 8, ZSTD_greedy},    /* level  4 */
+	{17, 15, 17, 4, 4, 8, ZSTD_greedy},    /* level  5 */
+	{17, 16, 17, 3, 4, 8, ZSTD_lazy},      /* level  6 */
+	{17, 15, 17, 4, 4, 8, ZSTD_lazy2},     /* level  7 */
+	{17, 17, 17, 4, 4, 8, ZSTD_lazy2},     /* level  8 */
+	{17, 17, 17, 5, 4, 8, ZSTD_lazy2},     /* level  9 */
+	{17, 17, 17, 6, 4, 8, ZSTD_lazy2},     /* level 10 */
+	{17, 17, 17, 7, 4, 8, ZSTD_lazy2},     /* level 11 */
+	{17, 17, 17, 8, 4, 8, ZSTD_lazy2},     /* level 12 */
+	{17, 18, 17, 6, 4, 8, ZSTD_btlazy2},   /* level 13.*/
+	{17, 17, 17, 7, 3, 8, ZSTD_btopt},     /* level 14.*/
+	{17, 17, 17, 7, 3, 16, ZSTD_btopt},    /* level 15.*/
+	{17, 18, 17, 7, 3, 32, ZSTD_btopt},    /* level 16.*/
+	{17, 18, 17, 7, 3, 64, ZSTD_btopt},    /* level 17.*/
+	{17, 18, 17, 7, 3, 256, ZSTD_btopt},   /* level 18.*/
+	{17, 18, 17, 8, 3, 256, ZSTD_btopt},   /* level 19.*/
+	{17, 18, 17, 9, 3, 256, ZSTD_btopt2},  /* level 20.*/
+	{17, 18, 17, 10, 3, 256, ZSTD_btopt2}, /* level 21.*/
+	{17, 18, 17, 11, 3, 512, ZSTD_btopt2}, /* level 22.*/
+    },
+    {
+	/* for srcSize <= 16 KB */
+	/* W,  C,  H,  S,  L,  T, strat */
+	{14, 12, 12, 1, 7, 6, ZSTD_fast},      /* level  0 - not used */
+	{14, 14, 14, 1, 6, 6, ZSTD_fast},      /* level  1 */
+	{14, 14, 14, 1, 4, 6, ZSTD_fast},      /* level  2 */
+	{14, 14, 14, 1, 4, 6, ZSTD_dfast},     /* level  3.*/
+	{14, 14, 14, 4, 4, 6, ZSTD_greedy},    /* level  4.*/
+	{14, 14, 14, 3, 4, 6, ZSTD_lazy},      /* level  5.*/
+	{14, 14, 14, 4, 4, 6, ZSTD_lazy2},     /* level  6 */
+	{14, 14, 14, 5, 4, 6, ZSTD_lazy2},     /* level  7 */
+	{14, 14, 14, 6, 4, 6, ZSTD_lazy2},     /* level  8.*/
+	{14, 15, 14, 6, 4, 6, ZSTD_btlazy2},   /* level  9.*/
+	{14, 15, 14, 3, 3, 6, ZSTD_btopt},     /* level 10.*/
+	{14, 15, 14, 6, 3, 8, ZSTD_btopt},     /* level 11.*/
+	{14, 15, 14, 6, 3, 16, ZSTD_btopt},    /* level 12.*/
+	{14, 15, 14, 6, 3, 24, ZSTD_btopt},    /* level 13.*/
+	{14, 15, 15, 6, 3, 48, ZSTD_btopt},    /* level 14.*/
+	{14, 15, 15, 6, 3, 64, ZSTD_btopt},    /* level 15.*/
+	{14, 15, 15, 6, 3, 96, ZSTD_btopt},    /* level 16.*/
+	{14, 15, 15, 6, 3, 128, ZSTD_btopt},   /* level 17.*/
+	{14, 15, 15, 6, 3, 256, ZSTD_btopt},   /* level 18.*/
+	{14, 15, 15, 7, 3, 256, ZSTD_btopt},   /* level 19.*/
+	{14, 15, 15, 8, 3, 256, ZSTD_btopt2},  /* level 20.*/
+	{14, 15, 15, 9, 3, 256, ZSTD_btopt2},  /* level 21.*/
+	{14, 15, 15, 10, 3, 256, ZSTD_btopt2}, /* level 22.*/
+    },
+};
+
+/*! ZSTD_getCParams() :
+*   @return ZSTD_compressionParameters structure for a selected compression level, `srcSize` and `dictSize`.
+*   Size values are optional, provide 0 if not known or unused */
+ZSTD_compressionParameters ZSTD_getCParams(int compressionLevel, unsigned long long srcSize, size_t dictSize)
+{
+	ZSTD_compressionParameters cp;
+	size_t const addedSize = srcSize ? 0 : 500;
+	U64 const rSize = srcSize + dictSize ? srcSize + dictSize + addedSize : (U64)-1;
+	U32 const tableID = (rSize <= 256 KB) + (rSize <= 128 KB) + (rSize <= 16 KB); /* intentional underflow for srcSizeHint == 0 */
+	if (compressionLevel <= 0)
+		compressionLevel = ZSTD_DEFAULT_CLEVEL; /* 0 == default; no negative compressionLevel yet */
+	if (compressionLevel > ZSTD_MAX_CLEVEL)
+		compressionLevel = ZSTD_MAX_CLEVEL;
+	cp = ZSTD_defaultCParameters[tableID][compressionLevel];
+	if (ZSTD_32bits()) { /* auto-correction, for 32-bits mode */
+		if (cp.windowLog > ZSTD_WINDOWLOG_MAX)
+			cp.windowLog = ZSTD_WINDOWLOG_MAX;
+		if (cp.chainLog > ZSTD_CHAINLOG_MAX)
+			cp.chainLog = ZSTD_CHAINLOG_MAX;
+		if (cp.hashLog > ZSTD_HASHLOG_MAX)
+			cp.hashLog = ZSTD_HASHLOG_MAX;
+	}
+	cp = ZSTD_adjustCParams(cp, srcSize, dictSize);
+	return cp;
+}
+
+/*! ZSTD_getParams() :
+*   same as ZSTD_getCParams(), but @return a `ZSTD_parameters` object (instead of `ZSTD_compressionParameters`).
+*   All fields of `ZSTD_frameParameters` are set to default (0) */
+ZSTD_parameters ZSTD_getParams(int compressionLevel, unsigned long long srcSize, size_t dictSize)
+{
+	ZSTD_parameters params;
+	ZSTD_compressionParameters const cParams = ZSTD_getCParams(compressionLevel, srcSize, dictSize);
+	memset(&params, 0, sizeof(params));
+	params.cParams = cParams;
+	return params;
+}
+
+EXPORT_SYMBOL(ZSTD_maxCLevel);
+EXPORT_SYMBOL(ZSTD_compressBound);
+
+EXPORT_SYMBOL(ZSTD_CCtxWorkspaceBound);
+EXPORT_SYMBOL(ZSTD_initCCtx);
+EXPORT_SYMBOL(ZSTD_compressCCtx);
+EXPORT_SYMBOL(ZSTD_compress_usingDict);
+
+EXPORT_SYMBOL(ZSTD_CDictWorkspaceBound);
+EXPORT_SYMBOL(ZSTD_initCDict);
+EXPORT_SYMBOL(ZSTD_compress_usingCDict);
+
+EXPORT_SYMBOL(ZSTD_CStreamWorkspaceBound);
+EXPORT_SYMBOL(ZSTD_initCStream);
+EXPORT_SYMBOL(ZSTD_initCStream_usingCDict);
+EXPORT_SYMBOL(ZSTD_resetCStream);
+EXPORT_SYMBOL(ZSTD_compressStream);
+EXPORT_SYMBOL(ZSTD_flushStream);
+EXPORT_SYMBOL(ZSTD_endStream);
+EXPORT_SYMBOL(ZSTD_CStreamInSize);
+EXPORT_SYMBOL(ZSTD_CStreamOutSize);
+
+EXPORT_SYMBOL(ZSTD_getCParams);
+EXPORT_SYMBOL(ZSTD_getParams);
+EXPORT_SYMBOL(ZSTD_checkCParams);
+EXPORT_SYMBOL(ZSTD_adjustCParams);
+
+EXPORT_SYMBOL(ZSTD_compressBegin);
+EXPORT_SYMBOL(ZSTD_compressBegin_usingDict);
+EXPORT_SYMBOL(ZSTD_compressBegin_advanced);
+EXPORT_SYMBOL(ZSTD_copyCCtx);
+EXPORT_SYMBOL(ZSTD_compressBegin_usingCDict);
+EXPORT_SYMBOL(ZSTD_compressContinue);
+EXPORT_SYMBOL(ZSTD_compressEnd);
+
+EXPORT_SYMBOL(ZSTD_getBlockSizeMax);
+EXPORT_SYMBOL(ZSTD_compressBlock);
+
+MODULE_LICENSE("Dual BSD/GPL");
+MODULE_DESCRIPTION("Zstd Compressor");
diff -Naurp -x debian.hwe linux-4.10.x.ori/lib/zstd/decompress.c linux-4.10.x/lib/zstd/decompress.c
--- linux-4.10.x.ori/lib/zstd/decompress.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-4.10.x/lib/zstd/decompress.c	2017-10-30 10:05:19.610447000 +0100
@@ -0,0 +1,2526 @@
+/**
+ * Copyright (c) 2016-present, Yann Collet, Facebook, Inc.
+ * All rights reserved.
+ *
+ * This source code is licensed under the BSD-style license found in the
+ * LICENSE file in the root directory of https://github.com/facebook/zstd.
+ *
+ * This program is free software; you can redistribute it and/or modify it under
+ * the terms of the GNU General Public License version 2 as published by the
+ * Free Software Foundation. This program is dual-licensed; you may select
+ * either version 2 of the GNU General Public License ("GPL") or BSD license
+ * ("BSD").
+ */
+
+/* ***************************************************************
+*  Tuning parameters
+*****************************************************************/
+/*!
+*  MAXWINDOWSIZE_DEFAULT :
+*  maximum window size accepted by DStream, by default.
+*  Frames requiring more memory will be rejected.
+*/
+#ifndef ZSTD_MAXWINDOWSIZE_DEFAULT
+#define ZSTD_MAXWINDOWSIZE_DEFAULT ((1 << ZSTD_WINDOWLOG_MAX) + 1) /* defined within zstd.h */
+#endif
+
+/*-*******************************************************
+*  Dependencies
+*********************************************************/
+#include "fse.h"
+#include "huf.h"
+#include "mem.h" /* low level memory routines */
+#include "zstd_internal.h"
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/string.h> /* memcpy, memmove, memset */
+
+#define ZSTD_PREFETCH(ptr) __builtin_prefetch(ptr, 0, 0)
+
+/*-*************************************
+*  Macros
+***************************************/
+#define ZSTD_isError ERR_isError /* for inlining */
+#define FSE_isError ERR_isError
+#define HUF_isError ERR_isError
+
+/*_*******************************************************
+*  Memory operations
+**********************************************************/
+static void ZSTD_copy4(void *dst, const void *src) { memcpy(dst, src, 4); }
+
+/*-*************************************************************
+*   Context management
+***************************************************************/
+typedef enum {
+	ZSTDds_getFrameHeaderSize,
+	ZSTDds_decodeFrameHeader,
+	ZSTDds_decodeBlockHeader,
+	ZSTDds_decompressBlock,
+	ZSTDds_decompressLastBlock,
+	ZSTDds_checkChecksum,
+	ZSTDds_decodeSkippableHeader,
+	ZSTDds_skipFrame
+} ZSTD_dStage;
+
+typedef struct {
+	FSE_DTable LLTable[FSE_DTABLE_SIZE_U32(LLFSELog)];
+	FSE_DTable OFTable[FSE_DTABLE_SIZE_U32(OffFSELog)];
+	FSE_DTable MLTable[FSE_DTABLE_SIZE_U32(MLFSELog)];
+	HUF_DTable hufTable[HUF_DTABLE_SIZE(HufLog)]; /* can accommodate HUF_decompress4X */
+	U64 workspace[HUF_DECOMPRESS_WORKSPACE_SIZE_U32 / 2];
+	U32 rep[ZSTD_REP_NUM];
+} ZSTD_entropyTables_t;
+
+struct ZSTD_DCtx_s {
+	const FSE_DTable *LLTptr;
+	const FSE_DTable *MLTptr;
+	const FSE_DTable *OFTptr;
+	const HUF_DTable *HUFptr;
+	ZSTD_entropyTables_t entropy;
+	const void *previousDstEnd; /* detect continuity */
+	const void *base;	   /* start of curr segment */
+	const void *vBase;	  /* virtual start of previous segment if it was just before curr one */
+	const void *dictEnd;	/* end of previous segment */
+	size_t expected;
+	ZSTD_frameParams fParams;
+	blockType_e bType; /* used in ZSTD_decompressContinue(), to transfer blockType between header decoding and block decoding stages */
+	ZSTD_dStage stage;
+	U32 litEntropy;
+	U32 fseEntropy;
+	struct xxh64_state xxhState;
+	size_t headerSize;
+	U32 dictID;
+	const BYTE *litPtr;
+	ZSTD_customMem customMem;
+	size_t litSize;
+	size_t rleSize;
+	BYTE litBuffer[ZSTD_BLOCKSIZE_ABSOLUTEMAX + WILDCOPY_OVERLENGTH];
+	BYTE headerBuffer[ZSTD_FRAMEHEADERSIZE_MAX];
+}; /* typedef'd to ZSTD_DCtx within "zstd.h" */
+
+size_t ZSTD_DCtxWorkspaceBound(void) { return ZSTD_ALIGN(sizeof(ZSTD_stack)) + ZSTD_ALIGN(sizeof(ZSTD_DCtx)); }
+
+size_t ZSTD_decompressBegin(ZSTD_DCtx *dctx)
+{
+	dctx->expected = ZSTD_frameHeaderSize_prefix;
+	dctx->stage = ZSTDds_getFrameHeaderSize;
+	dctx->previousDstEnd = NULL;
+	dctx->base = NULL;
+	dctx->vBase = NULL;
+	dctx->dictEnd = NULL;
+	dctx->entropy.hufTable[0] = (HUF_DTable)((HufLog)*0x1000001); /* cover both little and big endian */
+	dctx->litEntropy = dctx->fseEntropy = 0;
+	dctx->dictID = 0;
+	ZSTD_STATIC_ASSERT(sizeof(dctx->entropy.rep) == sizeof(repStartValue));
+	memcpy(dctx->entropy.rep, repStartValue, sizeof(repStartValue)); /* initial repcodes */
+	dctx->LLTptr = dctx->entropy.LLTable;
+	dctx->MLTptr = dctx->entropy.MLTable;
+	dctx->OFTptr = dctx->entropy.OFTable;
+	dctx->HUFptr = dctx->entropy.hufTable;
+	return 0;
+}
+
+ZSTD_DCtx *ZSTD_createDCtx_advanced(ZSTD_customMem customMem)
+{
+	ZSTD_DCtx *dctx;
+
+	if (!customMem.customAlloc || !customMem.customFree)
+		return NULL;
+
+	dctx = (ZSTD_DCtx *)ZSTD_malloc(sizeof(ZSTD_DCtx), customMem);
+	if (!dctx)
+		return NULL;
+	memcpy(&dctx->customMem, &customMem, sizeof(customMem));
+	ZSTD_decompressBegin(dctx);
+	return dctx;
+}
+
+ZSTD_DCtx *ZSTD_initDCtx(void *workspace, size_t workspaceSize)
+{
+	ZSTD_customMem const stackMem = ZSTD_initStack(workspace, workspaceSize);
+	return ZSTD_createDCtx_advanced(stackMem);
+}
+
+size_t ZSTD_freeDCtx(ZSTD_DCtx *dctx)
+{
+	if (dctx == NULL)
+		return 0; /* support free on NULL */
+	ZSTD_free(dctx, dctx->customMem);
+	return 0; /* reserved as a potential error code in the future */
+}
+
+void ZSTD_copyDCtx(ZSTD_DCtx *dstDCtx, const ZSTD_DCtx *srcDCtx)
+{
+	size_t const workSpaceSize = (ZSTD_BLOCKSIZE_ABSOLUTEMAX + WILDCOPY_OVERLENGTH) + ZSTD_frameHeaderSize_max;
+	memcpy(dstDCtx, srcDCtx, sizeof(ZSTD_DCtx) - workSpaceSize); /* no need to copy workspace */
+}
+
+static void ZSTD_refDDict(ZSTD_DCtx *dstDCtx, const ZSTD_DDict *ddict);
+
+/*-*************************************************************
+*   Decompression section
+***************************************************************/
+
+/*! ZSTD_isFrame() :
+ *  Tells if the content of `buffer` starts with a valid Frame Identifier.
+ *  Note : Frame Identifier is 4 bytes. If `size < 4`, @return will always be 0.
+ *  Note 2 : Legacy Frame Identifiers are considered valid only if Legacy Support is enabled.
+ *  Note 3 : Skippable Frame Identifiers are considered valid. */
+unsigned ZSTD_isFrame(const void *buffer, size_t size)
+{
+	if (size < 4)
+		return 0;
+	{
+		U32 const magic = ZSTD_readLE32(buffer);
+		if (magic == ZSTD_MAGICNUMBER)
+			return 1;
+		if ((magic & 0xFFFFFFF0U) == ZSTD_MAGIC_SKIPPABLE_START)
+			return 1;
+	}
+	return 0;
+}
+
+/** ZSTD_frameHeaderSize() :
+*   srcSize must be >= ZSTD_frameHeaderSize_prefix.
+*   @return : size of the Frame Header */
+static size_t ZSTD_frameHeaderSize(const void *src, size_t srcSize)
+{
+	if (srcSize < ZSTD_frameHeaderSize_prefix)
+		return ERROR(srcSize_wrong);
+	{
+		BYTE const fhd = ((const BYTE *)src)[4];
+		U32 const dictID = fhd & 3;
+		U32 const singleSegment = (fhd >> 5) & 1;
+		U32 const fcsId = fhd >> 6;
+		return ZSTD_frameHeaderSize_prefix + !singleSegment + ZSTD_did_fieldSize[dictID] + ZSTD_fcs_fieldSize[fcsId] + (singleSegment && !fcsId);
+	}
+}
+
+/** ZSTD_getFrameParams() :
+*   decode Frame Header, or require larger `srcSize`.
+*   @return : 0, `fparamsPtr` is correctly filled,
+*            >0, `srcSize` is too small, result is expected `srcSize`,
+*             or an error code, which can be tested using ZSTD_isError() */
+size_t ZSTD_getFrameParams(ZSTD_frameParams *fparamsPtr, const void *src, size_t srcSize)
+{
+	const BYTE *ip = (const BYTE *)src;
+
+	if (srcSize < ZSTD_frameHeaderSize_prefix)
+		return ZSTD_frameHeaderSize_prefix;
+	if (ZSTD_readLE32(src) != ZSTD_MAGICNUMBER) {
+		if ((ZSTD_readLE32(src) & 0xFFFFFFF0U) == ZSTD_MAGIC_SKIPPABLE_START) {
+			if (srcSize < ZSTD_skippableHeaderSize)
+				return ZSTD_skippableHeaderSize; /* magic number + skippable frame length */
+			memset(fparamsPtr, 0, sizeof(*fparamsPtr));
+			fparamsPtr->frameContentSize = ZSTD_readLE32((const char *)src + 4);
+			fparamsPtr->windowSize = 0; /* windowSize==0 means a frame is skippable */
+			return 0;
+		}
+		return ERROR(prefix_unknown);
+	}
+
+	/* ensure there is enough `srcSize` to fully read/decode frame header */
+	{
+		size_t const fhsize = ZSTD_frameHeaderSize(src, srcSize);
+		if (srcSize < fhsize)
+			return fhsize;
+	}
+
+	{
+		BYTE const fhdByte = ip[4];
+		size_t pos = 5;
+		U32 const dictIDSizeCode = fhdByte & 3;
+		U32 const checksumFlag = (fhdByte >> 2) & 1;
+		U32 const singleSegment = (fhdByte >> 5) & 1;
+		U32 const fcsID = fhdByte >> 6;
+		U32 const windowSizeMax = 1U << ZSTD_WINDOWLOG_MAX;
+		U32 windowSize = 0;
+		U32 dictID = 0;
+		U64 frameContentSize = 0;
+		if ((fhdByte & 0x08) != 0)
+			return ERROR(frameParameter_unsupported); /* reserved bits, which must be zero */
+		if (!singleSegment) {
+			BYTE const wlByte = ip[pos++];
+			U32 const windowLog = (wlByte >> 3) + ZSTD_WINDOWLOG_ABSOLUTEMIN;
+			if (windowLog > ZSTD_WINDOWLOG_MAX)
+				return ERROR(frameParameter_windowTooLarge); /* avoids issue with 1 << windowLog */
+			windowSize = (1U << windowLog);
+			windowSize += (windowSize >> 3) * (wlByte & 7);
+		}
+
+		switch (dictIDSizeCode) {
+		default: /* impossible */
+		case 0: break;
+		case 1:
+			dictID = ip[pos];
+			pos++;
+			break;
+		case 2:
+			dictID = ZSTD_readLE16(ip + pos);
+			pos += 2;
+			break;
+		case 3:
+			dictID = ZSTD_readLE32(ip + pos);
+			pos += 4;
+			break;
+		}
+		switch (fcsID) {
+		default: /* impossible */
+		case 0:
+			if (singleSegment)
+				frameContentSize = ip[pos];
+			break;
+		case 1: frameContentSize = ZSTD_readLE16(ip + pos) + 256; break;
+		case 2: frameContentSize = ZSTD_readLE32(ip + pos); break;
+		case 3: frameContentSize = ZSTD_readLE64(ip + pos); break;
+		}
+		if (!windowSize)
+			windowSize = (U32)frameContentSize;
+		if (windowSize > windowSizeMax)
+			return ERROR(frameParameter_windowTooLarge);
+		fparamsPtr->frameContentSize = frameContentSize;
+		fparamsPtr->windowSize = windowSize;
+		fparamsPtr->dictID = dictID;
+		fparamsPtr->checksumFlag = checksumFlag;
+	}
+	return 0;
+}
+
+/** ZSTD_getFrameContentSize() :
+*   compatible with legacy mode
+*   @return : decompressed size of the single frame pointed to be `src` if known, otherwise
+*             - ZSTD_CONTENTSIZE_UNKNOWN if the size cannot be determined
+*             - ZSTD_CONTENTSIZE_ERROR if an error occurred (e.g. invalid magic number, srcSize too small) */
+unsigned long long ZSTD_getFrameContentSize(const void *src, size_t srcSize)
+{
+	{
+		ZSTD_frameParams fParams;
+		if (ZSTD_getFrameParams(&fParams, src, srcSize) != 0)
+			return ZSTD_CONTENTSIZE_ERROR;
+		if (fParams.windowSize == 0) {
+			/* Either skippable or empty frame, size == 0 either way */
+			return 0;
+		} else if (fParams.frameContentSize != 0) {
+			return fParams.frameContentSize;
+		} else {
+			return ZSTD_CONTENTSIZE_UNKNOWN;
+		}
+	}
+}
+
+/** ZSTD_findDecompressedSize() :
+ *  compatible with legacy mode
+ *  `srcSize` must be the exact length of some number of ZSTD compressed and/or
+ *      skippable frames
+ *  @return : decompressed size of the frames contained */
+unsigned long long ZSTD_findDecompressedSize(const void *src, size_t srcSize)
+{
+	{
+		unsigned long long totalDstSize = 0;
+		while (srcSize >= ZSTD_frameHeaderSize_prefix) {
+			const U32 magicNumber = ZSTD_readLE32(src);
+
+			if ((magicNumber & 0xFFFFFFF0U) == ZSTD_MAGIC_SKIPPABLE_START) {
+				size_t skippableSize;
+				if (srcSize < ZSTD_skippableHeaderSize)
+					return ERROR(srcSize_wrong);
+				skippableSize = ZSTD_readLE32((const BYTE *)src + 4) + ZSTD_skippableHeaderSize;
+				if (srcSize < skippableSize) {
+					return ZSTD_CONTENTSIZE_ERROR;
+				}
+
+				src = (const BYTE *)src + skippableSize;
+				srcSize -= skippableSize;
+				continue;
+			}
+
+			{
+				unsigned long long const ret = ZSTD_getFrameContentSize(src, srcSize);
+				if (ret >= ZSTD_CONTENTSIZE_ERROR)
+					return ret;
+
+				/* check for overflow */
+				if (totalDstSize + ret < totalDstSize)
+					return ZSTD_CONTENTSIZE_ERROR;
+				totalDstSize += ret;
+			}
+			{
+				size_t const frameSrcSize = ZSTD_findFrameCompressedSize(src, srcSize);
+				if (ZSTD_isError(frameSrcSize)) {
+					return ZSTD_CONTENTSIZE_ERROR;
+				}
+
+				src = (const BYTE *)src + frameSrcSize;
+				srcSize -= frameSrcSize;
+			}
+		}
+
+		if (srcSize) {
+			return ZSTD_CONTENTSIZE_ERROR;
+		}
+
+		return totalDstSize;
+	}
+}
+
+/** ZSTD_decodeFrameHeader() :
+*   `headerSize` must be the size provided by ZSTD_frameHeaderSize().
+*   @return : 0 if success, or an error code, which can be tested using ZSTD_isError() */
+static size_t ZSTD_decodeFrameHeader(ZSTD_DCtx *dctx, const void *src, size_t headerSize)
+{
+	size_t const result = ZSTD_getFrameParams(&(dctx->fParams), src, headerSize);
+	if (ZSTD_isError(result))
+		return result; /* invalid header */
+	if (result > 0)
+		return ERROR(srcSize_wrong); /* headerSize too small */
+	if (dctx->fParams.dictID && (dctx->dictID != dctx->fParams.dictID))
+		return ERROR(dictionary_wrong);
+	if (dctx->fParams.checksumFlag)
+		xxh64_reset(&dctx->xxhState, 0);
+	return 0;
+}
+
+typedef struct {
+	blockType_e blockType;
+	U32 lastBlock;
+	U32 origSize;
+} blockProperties_t;
+
+/*! ZSTD_getcBlockSize() :
+*   Provides the size of compressed block from block header `src` */
+size_t ZSTD_getcBlockSize(const void *src, size_t srcSize, blockProperties_t *bpPtr)
+{
+	if (srcSize < ZSTD_blockHeaderSize)
+		return ERROR(srcSize_wrong);
+	{
+		U32 const cBlockHeader = ZSTD_readLE24(src);
+		U32 const cSize = cBlockHeader >> 3;
+		bpPtr->lastBlock = cBlockHeader & 1;
+		bpPtr->blockType = (blockType_e)((cBlockHeader >> 1) & 3);
+		bpPtr->origSize = cSize; /* only useful for RLE */
+		if (bpPtr->blockType == bt_rle)
+			return 1;
+		if (bpPtr->blockType == bt_reserved)
+			return ERROR(corruption_detected);
+		return cSize;
+	}
+}
+
+static size_t ZSTD_copyRawBlock(void *dst, size_t dstCapacity, const void *src, size_t srcSize)
+{
+	if (srcSize > dstCapacity)
+		return ERROR(dstSize_tooSmall);
+	memcpy(dst, src, srcSize);
+	return srcSize;
+}
+
+static size_t ZSTD_setRleBlock(void *dst, size_t dstCapacity, const void *src, size_t srcSize, size_t regenSize)
+{
+	if (srcSize != 1)
+		return ERROR(srcSize_wrong);
+	if (regenSize > dstCapacity)
+		return ERROR(dstSize_tooSmall);
+	memset(dst, *(const BYTE *)src, regenSize);
+	return regenSize;
+}
+
+/*! ZSTD_decodeLiteralsBlock() :
+	@return : nb of bytes read from src (< srcSize ) */
+size_t ZSTD_decodeLiteralsBlock(ZSTD_DCtx *dctx, const void *src, size_t srcSize) /* note : srcSize < BLOCKSIZE */
+{
+	if (srcSize < MIN_CBLOCK_SIZE)
+		return ERROR(corruption_detected);
+
+	{
+		const BYTE *const istart = (const BYTE *)src;
+		symbolEncodingType_e const litEncType = (symbolEncodingType_e)(istart[0] & 3);
+
+		switch (litEncType) {
+		case set_repeat:
+			if (dctx->litEntropy == 0)
+				return ERROR(dictionary_corrupted);
+		/* fall-through */
+		case set_compressed:
+			if (srcSize < 5)
+				return ERROR(corruption_detected); /* srcSize >= MIN_CBLOCK_SIZE == 3; here we need up to 5 for case 3 */
+			{
+				size_t lhSize, litSize, litCSize;
+				U32 singleStream = 0;
+				U32 const lhlCode = (istart[0] >> 2) & 3;
+				U32 const lhc = ZSTD_readLE32(istart);
+				switch (lhlCode) {
+				case 0:
+				case 1:
+				default: /* note : default is impossible, since lhlCode into [0..3] */
+					/* 2 - 2 - 10 - 10 */
+					singleStream = !lhlCode;
+					lhSize = 3;
+					litSize = (lhc >> 4) & 0x3FF;
+					litCSize = (lhc >> 14) & 0x3FF;
+					break;
+				case 2:
+					/* 2 - 2 - 14 - 14 */
+					lhSize = 4;
+					litSize = (lhc >> 4) & 0x3FFF;
+					litCSize = lhc >> 18;
+					break;
+				case 3:
+					/* 2 - 2 - 18 - 18 */
+					lhSize = 5;
+					litSize = (lhc >> 4) & 0x3FFFF;
+					litCSize = (lhc >> 22) + (istart[4] << 10);
+					break;
+				}
+				if (litSize > ZSTD_BLOCKSIZE_ABSOLUTEMAX)
+					return ERROR(corruption_detected);
+				if (litCSize + lhSize > srcSize)
+					return ERROR(corruption_detected);
+
+				if (HUF_isError(
+					(litEncType == set_repeat)
+					    ? (singleStream ? HUF_decompress1X_usingDTable(dctx->litBuffer, litSize, istart + lhSize, litCSize, dctx->HUFptr)
+							    : HUF_decompress4X_usingDTable(dctx->litBuffer, litSize, istart + lhSize, litCSize, dctx->HUFptr))
+					    : (singleStream
+						   ? HUF_decompress1X2_DCtx_wksp(dctx->entropy.hufTable, dctx->litBuffer, litSize, istart + lhSize, litCSize,
+										 dctx->entropy.workspace, sizeof(dctx->entropy.workspace))
+						   : HUF_decompress4X_hufOnly_wksp(dctx->entropy.hufTable, dctx->litBuffer, litSize, istart + lhSize, litCSize,
+										   dctx->entropy.workspace, sizeof(dctx->entropy.workspace)))))
+					return ERROR(corruption_detected);
+
+				dctx->litPtr = dctx->litBuffer;
+				dctx->litSize = litSize;
+				dctx->litEntropy = 1;
+				if (litEncType == set_compressed)
+					dctx->HUFptr = dctx->entropy.hufTable;
+				memset(dctx->litBuffer + dctx->litSize, 0, WILDCOPY_OVERLENGTH);
+				return litCSize + lhSize;
+			}
+
+		case set_basic: {
+			size_t litSize, lhSize;
+			U32 const lhlCode = ((istart[0]) >> 2) & 3;
+			switch (lhlCode) {
+			case 0:
+			case 2:
+			default: /* note : default is impossible, since lhlCode into [0..3] */
+				lhSize = 1;
+				litSize = istart[0] >> 3;
+				break;
+			case 1:
+				lhSize = 2;
+				litSize = ZSTD_readLE16(istart) >> 4;
+				break;
+			case 3:
+				lhSize = 3;
+				litSize = ZSTD_readLE24(istart) >> 4;
+				break;
+			}
+
+			if (lhSize + litSize + WILDCOPY_OVERLENGTH > srcSize) { /* risk reading beyond src buffer with wildcopy */
+				if (litSize + lhSize > srcSize)
+					return ERROR(corruption_detected);
+				memcpy(dctx->litBuffer, istart + lhSize, litSize);
+				dctx->litPtr = dctx->litBuffer;
+				dctx->litSize = litSize;
+				memset(dctx->litBuffer + dctx->litSize, 0, WILDCOPY_OVERLENGTH);
+				return lhSize + litSize;
+			}
+			/* direct reference into compressed stream */
+			dctx->litPtr = istart + lhSize;
+			dctx->litSize = litSize;
+			return lhSize + litSize;
+		}
+
+		case set_rle: {
+			U32 const lhlCode = ((istart[0]) >> 2) & 3;
+			size_t litSize, lhSize;
+			switch (lhlCode) {
+			case 0:
+			case 2:
+			default: /* note : default is impossible, since lhlCode into [0..3] */
+				lhSize = 1;
+				litSize = istart[0] >> 3;
+				break;
+			case 1:
+				lhSize = 2;
+				litSize = ZSTD_readLE16(istart) >> 4;
+				break;
+			case 3:
+				lhSize = 3;
+				litSize = ZSTD_readLE24(istart) >> 4;
+				if (srcSize < 4)
+					return ERROR(corruption_detected); /* srcSize >= MIN_CBLOCK_SIZE == 3; here we need lhSize+1 = 4 */
+				break;
+			}
+			if (litSize > ZSTD_BLOCKSIZE_ABSOLUTEMAX)
+				return ERROR(corruption_detected);
+			memset(dctx->litBuffer, istart[lhSize], litSize + WILDCOPY_OVERLENGTH);
+			dctx->litPtr = dctx->litBuffer;
+			dctx->litSize = litSize;
+			return lhSize + 1;
+		}
+		default:
+			return ERROR(corruption_detected); /* impossible */
+		}
+	}
+}
+
+typedef union {
+	FSE_decode_t realData;
+	U32 alignedBy4;
+} FSE_decode_t4;
+
+static const FSE_decode_t4 LL_defaultDTable[(1 << LL_DEFAULTNORMLOG) + 1] = {
+    {{LL_DEFAULTNORMLOG, 1, 1}}, /* header : tableLog, fastMode, fastMode */
+    {{0, 0, 4}},		 /* 0 : base, symbol, bits */
+    {{16, 0, 4}},
+    {{32, 1, 5}},
+    {{0, 3, 5}},
+    {{0, 4, 5}},
+    {{0, 6, 5}},
+    {{0, 7, 5}},
+    {{0, 9, 5}},
+    {{0, 10, 5}},
+    {{0, 12, 5}},
+    {{0, 14, 6}},
+    {{0, 16, 5}},
+    {{0, 18, 5}},
+    {{0, 19, 5}},
+    {{0, 21, 5}},
+    {{0, 22, 5}},
+    {{0, 24, 5}},
+    {{32, 25, 5}},
+    {{0, 26, 5}},
+    {{0, 27, 6}},
+    {{0, 29, 6}},
+    {{0, 31, 6}},
+    {{32, 0, 4}},
+    {{0, 1, 4}},
+    {{0, 2, 5}},
+    {{32, 4, 5}},
+    {{0, 5, 5}},
+    {{32, 7, 5}},
+    {{0, 8, 5}},
+    {{32, 10, 5}},
+    {{0, 11, 5}},
+    {{0, 13, 6}},
+    {{32, 16, 5}},
+    {{0, 17, 5}},
+    {{32, 19, 5}},
+    {{0, 20, 5}},
+    {{32, 22, 5}},
+    {{0, 23, 5}},
+    {{0, 25, 4}},
+    {{16, 25, 4}},
+    {{32, 26, 5}},
+    {{0, 28, 6}},
+    {{0, 30, 6}},
+    {{48, 0, 4}},
+    {{16, 1, 4}},
+    {{32, 2, 5}},
+    {{32, 3, 5}},
+    {{32, 5, 5}},
+    {{32, 6, 5}},
+    {{32, 8, 5}},
+    {{32, 9, 5}},
+    {{32, 11, 5}},
+    {{32, 12, 5}},
+    {{0, 15, 6}},
+    {{32, 17, 5}},
+    {{32, 18, 5}},
+    {{32, 20, 5}},
+    {{32, 21, 5}},
+    {{32, 23, 5}},
+    {{32, 24, 5}},
+    {{0, 35, 6}},
+    {{0, 34, 6}},
+    {{0, 33, 6}},
+    {{0, 32, 6}},
+}; /* LL_defaultDTable */
+
+static const FSE_decode_t4 ML_defaultDTable[(1 << ML_DEFAULTNORMLOG) + 1] = {
+    {{ML_DEFAULTNORMLOG, 1, 1}}, /* header : tableLog, fastMode, fastMode */
+    {{0, 0, 6}},		 /* 0 : base, symbol, bits */
+    {{0, 1, 4}},
+    {{32, 2, 5}},
+    {{0, 3, 5}},
+    {{0, 5, 5}},
+    {{0, 6, 5}},
+    {{0, 8, 5}},
+    {{0, 10, 6}},
+    {{0, 13, 6}},
+    {{0, 16, 6}},
+    {{0, 19, 6}},
+    {{0, 22, 6}},
+    {{0, 25, 6}},
+    {{0, 28, 6}},
+    {{0, 31, 6}},
+    {{0, 33, 6}},
+    {{0, 35, 6}},
+    {{0, 37, 6}},
+    {{0, 39, 6}},
+    {{0, 41, 6}},
+    {{0, 43, 6}},
+    {{0, 45, 6}},
+    {{16, 1, 4}},
+    {{0, 2, 4}},
+    {{32, 3, 5}},
+    {{0, 4, 5}},
+    {{32, 6, 5}},
+    {{0, 7, 5}},
+    {{0, 9, 6}},
+    {{0, 12, 6}},
+    {{0, 15, 6}},
+    {{0, 18, 6}},
+    {{0, 21, 6}},
+    {{0, 24, 6}},
+    {{0, 27, 6}},
+    {{0, 30, 6}},
+    {{0, 32, 6}},
+    {{0, 34, 6}},
+    {{0, 36, 6}},
+    {{0, 38, 6}},
+    {{0, 40, 6}},
+    {{0, 42, 6}},
+    {{0, 44, 6}},
+    {{32, 1, 4}},
+    {{48, 1, 4}},
+    {{16, 2, 4}},
+    {{32, 4, 5}},
+    {{32, 5, 5}},
+    {{32, 7, 5}},
+    {{32, 8, 5}},
+    {{0, 11, 6}},
+    {{0, 14, 6}},
+    {{0, 17, 6}},
+    {{0, 20, 6}},
+    {{0, 23, 6}},
+    {{0, 26, 6}},
+    {{0, 29, 6}},
+    {{0, 52, 6}},
+    {{0, 51, 6}},
+    {{0, 50, 6}},
+    {{0, 49, 6}},
+    {{0, 48, 6}},
+    {{0, 47, 6}},
+    {{0, 46, 6}},
+}; /* ML_defaultDTable */
+
+static const FSE_decode_t4 OF_defaultDTable[(1 << OF_DEFAULTNORMLOG) + 1] = {
+    {{OF_DEFAULTNORMLOG, 1, 1}}, /* header : tableLog, fastMode, fastMode */
+    {{0, 0, 5}},		 /* 0 : base, symbol, bits */
+    {{0, 6, 4}},
+    {{0, 9, 5}},
+    {{0, 15, 5}},
+    {{0, 21, 5}},
+    {{0, 3, 5}},
+    {{0, 7, 4}},
+    {{0, 12, 5}},
+    {{0, 18, 5}},
+    {{0, 23, 5}},
+    {{0, 5, 5}},
+    {{0, 8, 4}},
+    {{0, 14, 5}},
+    {{0, 20, 5}},
+    {{0, 2, 5}},
+    {{16, 7, 4}},
+    {{0, 11, 5}},
+    {{0, 17, 5}},
+    {{0, 22, 5}},
+    {{0, 4, 5}},
+    {{16, 8, 4}},
+    {{0, 13, 5}},
+    {{0, 19, 5}},
+    {{0, 1, 5}},
+    {{16, 6, 4}},
+    {{0, 10, 5}},
+    {{0, 16, 5}},
+    {{0, 28, 5}},
+    {{0, 27, 5}},
+    {{0, 26, 5}},
+    {{0, 25, 5}},
+    {{0, 24, 5}},
+}; /* OF_defaultDTable */
+
+/*! ZSTD_buildSeqTable() :
+	@return : nb bytes read from src,
+			  or an error code if it fails, testable with ZSTD_isError()
+*/
+static size_t ZSTD_buildSeqTable(FSE_DTable *DTableSpace, const FSE_DTable **DTablePtr, symbolEncodingType_e type, U32 max, U32 maxLog, const void *src,
+				 size_t srcSize, const FSE_decode_t4 *defaultTable, U32 flagRepeatTable, void *workspace, size_t workspaceSize)
+{
+	const void *const tmpPtr = defaultTable; /* bypass strict aliasing */
+	switch (type) {
+	case set_rle:
+		if (!srcSize)
+			return ERROR(srcSize_wrong);
+		if ((*(const BYTE *)src) > max)
+			return ERROR(corruption_detected);
+		FSE_buildDTable_rle(DTableSpace, *(const BYTE *)src);
+		*DTablePtr = DTableSpace;
+		return 1;
+	case set_basic: *DTablePtr = (const FSE_DTable *)tmpPtr; return 0;
+	case set_repeat:
+		if (!flagRepeatTable)
+			return ERROR(corruption_detected);
+		return 0;
+	default: /* impossible */
+	case set_compressed: {
+		U32 tableLog;
+		S16 *norm = (S16 *)workspace;
+		size_t const spaceUsed32 = ALIGN(sizeof(S16) * (MaxSeq + 1), sizeof(U32)) >> 2;
+
+		if ((spaceUsed32 << 2) > workspaceSize)
+			return ERROR(GENERIC);
+		workspace = (U32 *)workspace + spaceUsed32;
+		workspaceSize -= (spaceUsed32 << 2);
+		{
+			size_t const headerSize = FSE_readNCount(norm, &max, &tableLog, src, srcSize);
+			if (FSE_isError(headerSize))
+				return ERROR(corruption_detected);
+			if (tableLog > maxLog)
+				return ERROR(corruption_detected);
+			FSE_buildDTable_wksp(DTableSpace, norm, max, tableLog, workspace, workspaceSize);
+			*DTablePtr = DTableSpace;
+			return headerSize;
+		}
+	}
+	}
+}
+
+size_t ZSTD_decodeSeqHeaders(ZSTD_DCtx *dctx, int *nbSeqPtr, const void *src, size_t srcSize)
+{
+	const BYTE *const istart = (const BYTE *const)src;
+	const BYTE *const iend = istart + srcSize;
+	const BYTE *ip = istart;
+
+	/* check */
+	if (srcSize < MIN_SEQUENCES_SIZE)
+		return ERROR(srcSize_wrong);
+
+	/* SeqHead */
+	{
+		int nbSeq = *ip++;
+		if (!nbSeq) {
+			*nbSeqPtr = 0;
+			return 1;
+		}
+		if (nbSeq > 0x7F) {
+			if (nbSeq == 0xFF) {
+				if (ip + 2 > iend)
+					return ERROR(srcSize_wrong);
+				nbSeq = ZSTD_readLE16(ip) + LONGNBSEQ, ip += 2;
+			} else {
+				if (ip >= iend)
+					return ERROR(srcSize_wrong);
+				nbSeq = ((nbSeq - 0x80) << 8) + *ip++;
+			}
+		}
+		*nbSeqPtr = nbSeq;
+	}
+
+	/* FSE table descriptors */
+	if (ip + 4 > iend)
+		return ERROR(srcSize_wrong); /* minimum possible size */
+	{
+		symbolEncodingType_e const LLtype = (symbolEncodingType_e)(*ip >> 6);
+		symbolEncodingType_e const OFtype = (symbolEncodingType_e)((*ip >> 4) & 3);
+		symbolEncodingType_e const MLtype = (symbolEncodingType_e)((*ip >> 2) & 3);
+		ip++;
+
+		/* Build DTables */
+		{
+			size_t const llhSize = ZSTD_buildSeqTable(dctx->entropy.LLTable, &dctx->LLTptr, LLtype, MaxLL, LLFSELog, ip, iend - ip,
+								  LL_defaultDTable, dctx->fseEntropy, dctx->entropy.workspace, sizeof(dctx->entropy.workspace));
+			if (ZSTD_isError(llhSize))
+				return ERROR(corruption_detected);
+			ip += llhSize;
+		}
+		{
+			size_t const ofhSize = ZSTD_buildSeqTable(dctx->entropy.OFTable, &dctx->OFTptr, OFtype, MaxOff, OffFSELog, ip, iend - ip,
+								  OF_defaultDTable, dctx->fseEntropy, dctx->entropy.workspace, sizeof(dctx->entropy.workspace));
+			if (ZSTD_isError(ofhSize))
+				return ERROR(corruption_detected);
+			ip += ofhSize;
+		}
+		{
+			size_t const mlhSize = ZSTD_buildSeqTable(dctx->entropy.MLTable, &dctx->MLTptr, MLtype, MaxML, MLFSELog, ip, iend - ip,
+								  ML_defaultDTable, dctx->fseEntropy, dctx->entropy.workspace, sizeof(dctx->entropy.workspace));
+			if (ZSTD_isError(mlhSize))
+				return ERROR(corruption_detected);
+			ip += mlhSize;
+		}
+	}
+
+	return ip - istart;
+}
+
+typedef struct {
+	size_t litLength;
+	size_t matchLength;
+	size_t offset;
+	const BYTE *match;
+} seq_t;
+
+typedef struct {
+	BIT_DStream_t DStream;
+	FSE_DState_t stateLL;
+	FSE_DState_t stateOffb;
+	FSE_DState_t stateML;
+	size_t prevOffset[ZSTD_REP_NUM];
+	const BYTE *base;
+	size_t pos;
+	uPtrDiff gotoDict;
+} seqState_t;
+
+FORCE_NOINLINE
+size_t ZSTD_execSequenceLast7(BYTE *op, BYTE *const oend, seq_t sequence, const BYTE **litPtr, const BYTE *const litLimit, const BYTE *const base,
+			      const BYTE *const vBase, const BYTE *const dictEnd)
+{
+	BYTE *const oLitEnd = op + sequence.litLength;
+	size_t const sequenceLength = sequence.litLength + sequence.matchLength;
+	BYTE *const oMatchEnd = op + sequenceLength; /* risk : address space overflow (32-bits) */
+	BYTE *const oend_w = oend - WILDCOPY_OVERLENGTH;
+	const BYTE *const iLitEnd = *litPtr + sequence.litLength;
+	const BYTE *match = oLitEnd - sequence.offset;
+
+	/* check */
+	if (oMatchEnd > oend)
+		return ERROR(dstSize_tooSmall); /* last match must start at a minimum distance of WILDCOPY_OVERLENGTH from oend */
+	if (iLitEnd > litLimit)
+		return ERROR(corruption_detected); /* over-read beyond lit buffer */
+	if (oLitEnd <= oend_w)
+		return ERROR(GENERIC); /* Precondition */
+
+	/* copy literals */
+	if (op < oend_w) {
+		ZSTD_wildcopy(op, *litPtr, oend_w - op);
+		*litPtr += oend_w - op;
+		op = oend_w;
+	}
+	while (op < oLitEnd)
+		*op++ = *(*litPtr)++;
+
+	/* copy Match */
+	if (sequence.offset > (size_t)(oLitEnd - base)) {
+		/* offset beyond prefix */
+		if (sequence.offset > (size_t)(oLitEnd - vBase))
+			return ERROR(corruption_detected);
+		match = dictEnd - (base - match);
+		if (match + sequence.matchLength <= dictEnd) {
+			memmove(oLitEnd, match, sequence.matchLength);
+			return sequenceLength;
+		}
+		/* span extDict & currPrefixSegment */
+		{
+			size_t const length1 = dictEnd - match;
+			memmove(oLitEnd, match, length1);
+			op = oLitEnd + length1;
+			sequence.matchLength -= length1;
+			match = base;
+		}
+	}
+	while (op < oMatchEnd)
+		*op++ = *match++;
+	return sequenceLength;
+}
+
+static seq_t ZSTD_decodeSequence(seqState_t *seqState)
+{
+	seq_t seq;
+
+	U32 const llCode = FSE_peekSymbol(&seqState->stateLL);
+	U32 const mlCode = FSE_peekSymbol(&seqState->stateML);
+	U32 const ofCode = FSE_peekSymbol(&seqState->stateOffb); /* <= maxOff, by table construction */
+
+	U32 const llBits = LL_bits[llCode];
+	U32 const mlBits = ML_bits[mlCode];
+	U32 const ofBits = ofCode;
+	U32 const totalBits = llBits + mlBits + ofBits;
+
+	static const U32 LL_base[MaxLL + 1] = {0,  1,  2,  3,  4,  5,  6,  7,  8,    9,     10,    11,    12,    13,     14,     15,     16,     18,
+					       20, 22, 24, 28, 32, 40, 48, 64, 0x80, 0x100, 0x200, 0x400, 0x800, 0x1000, 0x2000, 0x4000, 0x8000, 0x10000};
+
+	static const U32 ML_base[MaxML + 1] = {3,  4,  5,  6,  7,  8,  9,  10,   11,    12,    13,    14,    15,     16,     17,     18,     19,     20,
+					       21, 22, 23, 24, 25, 26, 27, 28,   29,    30,    31,    32,    33,     34,     35,     37,     39,     41,
+					       43, 47, 51, 59, 67, 83, 99, 0x83, 0x103, 0x203, 0x403, 0x803, 0x1003, 0x2003, 0x4003, 0x8003, 0x10003};
+
+	static const U32 OF_base[MaxOff + 1] = {0,       1,	1,	5,	0xD,      0x1D,      0x3D,      0x7D,      0xFD,     0x1FD,
+						0x3FD,   0x7FD,    0xFFD,    0x1FFD,   0x3FFD,   0x7FFD,    0xFFFD,    0x1FFFD,   0x3FFFD,  0x7FFFD,
+						0xFFFFD, 0x1FFFFD, 0x3FFFFD, 0x7FFFFD, 0xFFFFFD, 0x1FFFFFD, 0x3FFFFFD, 0x7FFFFFD, 0xFFFFFFD};
+
+	/* sequence */
+	{
+		size_t offset;
+		if (!ofCode)
+			offset = 0;
+		else {
+			offset = OF_base[ofCode] + BIT_readBitsFast(&seqState->DStream, ofBits); /* <=  (ZSTD_WINDOWLOG_MAX-1) bits */
+			if (ZSTD_32bits())
+				BIT_reloadDStream(&seqState->DStream);
+		}
+
+		if (ofCode <= 1) {
+			offset += (llCode == 0);
+			if (offset) {
+				size_t temp = (offset == 3) ? seqState->prevOffset[0] - 1 : seqState->prevOffset[offset];
+				temp += !temp; /* 0 is not valid; input is corrupted; force offset to 1 */
+				if (offset != 1)
+					seqState->prevOffset[2] = seqState->prevOffset[1];
+				seqState->prevOffset[1] = seqState->prevOffset[0];
+				seqState->prevOffset[0] = offset = temp;
+			} else {
+				offset = seqState->prevOffset[0];
+			}
+		} else {
+			seqState->prevOffset[2] = seqState->prevOffset[1];
+			seqState->prevOffset[1] = seqState->prevOffset[0];
+			seqState->prevOffset[0] = offset;
+		}
+		seq.offset = offset;
+	}
+
+	seq.matchLength = ML_base[mlCode] + ((mlCode > 31) ? BIT_readBitsFast(&seqState->DStream, mlBits) : 0); /* <=  16 bits */
+	if (ZSTD_32bits() && (mlBits + llBits > 24))
+		BIT_reloadDStream(&seqState->DStream);
+
+	seq.litLength = LL_base[llCode] + ((llCode > 15) ? BIT_readBitsFast(&seqState->DStream, llBits) : 0); /* <=  16 bits */
+	if (ZSTD_32bits() || (totalBits > 64 - 7 - (LLFSELog + MLFSELog + OffFSELog)))
+		BIT_reloadDStream(&seqState->DStream);
+
+	/* ANS state update */
+	FSE_updateState(&seqState->stateLL, &seqState->DStream); /* <=  9 bits */
+	FSE_updateState(&seqState->stateML, &seqState->DStream); /* <=  9 bits */
+	if (ZSTD_32bits())
+		BIT_reloadDStream(&seqState->DStream);		   /* <= 18 bits */
+	FSE_updateState(&seqState->stateOffb, &seqState->DStream); /* <=  8 bits */
+
+	seq.match = NULL;
+
+	return seq;
+}
+
+FORCE_INLINE
+size_t ZSTD_execSequence(BYTE *op, BYTE *const oend, seq_t sequence, const BYTE **litPtr, const BYTE *const litLimit, const BYTE *const base,
+			 const BYTE *const vBase, const BYTE *const dictEnd)
+{
+	BYTE *const oLitEnd = op + sequence.litLength;
+	size_t const sequenceLength = sequence.litLength + sequence.matchLength;
+	BYTE *const oMatchEnd = op + sequenceLength; /* risk : address space overflow (32-bits) */
+	BYTE *const oend_w = oend - WILDCOPY_OVERLENGTH;
+	const BYTE *const iLitEnd = *litPtr + sequence.litLength;
+	const BYTE *match = oLitEnd - sequence.offset;
+
+	/* check */
+	if (oMatchEnd > oend)
+		return ERROR(dstSize_tooSmall); /* last match must start at a minimum distance of WILDCOPY_OVERLENGTH from oend */
+	if (iLitEnd > litLimit)
+		return ERROR(corruption_detected); /* over-read beyond lit buffer */
+	if (oLitEnd > oend_w)
+		return ZSTD_execSequenceLast7(op, oend, sequence, litPtr, litLimit, base, vBase, dictEnd);
+
+	/* copy Literals */
+	ZSTD_copy8(op, *litPtr);
+	if (sequence.litLength > 8)
+		ZSTD_wildcopy(op + 8, (*litPtr) + 8,
+			      sequence.litLength - 8); /* note : since oLitEnd <= oend-WILDCOPY_OVERLENGTH, no risk of overwrite beyond oend */
+	op = oLitEnd;
+	*litPtr = iLitEnd; /* update for next sequence */
+
+	/* copy Match */
+	if (sequence.offset > (size_t)(oLitEnd - base)) {
+		/* offset beyond prefix */
+		if (sequence.offset > (size_t)(oLitEnd - vBase))
+			return ERROR(corruption_detected);
+		match = dictEnd + (match - base);
+		if (match + sequence.matchLength <= dictEnd) {
+			memmove(oLitEnd, match, sequence.matchLength);
+			return sequenceLength;
+		}
+		/* span extDict & currPrefixSegment */
+		{
+			size_t const length1 = dictEnd - match;
+			memmove(oLitEnd, match, length1);
+			op = oLitEnd + length1;
+			sequence.matchLength -= length1;
+			match = base;
+			if (op > oend_w || sequence.matchLength < MINMATCH) {
+				U32 i;
+				for (i = 0; i < sequence.matchLength; ++i)
+					op[i] = match[i];
+				return sequenceLength;
+			}
+		}
+	}
+	/* Requirement: op <= oend_w && sequence.matchLength >= MINMATCH */
+
+	/* match within prefix */
+	if (sequence.offset < 8) {
+		/* close range match, overlap */
+		static const U32 dec32table[] = {0, 1, 2, 1, 4, 4, 4, 4};   /* added */
+		static const int dec64table[] = {8, 8, 8, 7, 8, 9, 10, 11}; /* subtracted */
+		int const sub2 = dec64table[sequence.offset];
+		op[0] = match[0];
+		op[1] = match[1];
+		op[2] = match[2];
+		op[3] = match[3];
+		match += dec32table[sequence.offset];
+		ZSTD_copy4(op + 4, match);
+		match -= sub2;
+	} else {
+		ZSTD_copy8(op, match);
+	}
+	op += 8;
+	match += 8;
+
+	if (oMatchEnd > oend - (16 - MINMATCH)) {
+		if (op < oend_w) {
+			ZSTD_wildcopy(op, match, oend_w - op);
+			match += oend_w - op;
+			op = oend_w;
+		}
+		while (op < oMatchEnd)
+			*op++ = *match++;
+	} else {
+		ZSTD_wildcopy(op, match, (ptrdiff_t)sequence.matchLength - 8); /* works even if matchLength < 8 */
+	}
+	return sequenceLength;
+}
+
+static size_t ZSTD_decompressSequences(ZSTD_DCtx *dctx, void *dst, size_t maxDstSize, const void *seqStart, size_t seqSize)
+{
+	const BYTE *ip = (const BYTE *)seqStart;
+	const BYTE *const iend = ip + seqSize;
+	BYTE *const ostart = (BYTE * const)dst;
+	BYTE *const oend = ostart + maxDstSize;
+	BYTE *op = ostart;
+	const BYTE *litPtr = dctx->litPtr;
+	const BYTE *const litEnd = litPtr + dctx->litSize;
+	const BYTE *const base = (const BYTE *)(dctx->base);
+	const BYTE *const vBase = (const BYTE *)(dctx->vBase);
+	const BYTE *const dictEnd = (const BYTE *)(dctx->dictEnd);
+	int nbSeq;
+
+	/* Build Decoding Tables */
+	{
+		size_t const seqHSize = ZSTD_decodeSeqHeaders(dctx, &nbSeq, ip, seqSize);
+		if (ZSTD_isError(seqHSize))
+			return seqHSize;
+		ip += seqHSize;
+	}
+
+	/* Regen sequences */
+	if (nbSeq) {
+		seqState_t seqState;
+		dctx->fseEntropy = 1;
+		{
+			U32 i;
+			for (i = 0; i < ZSTD_REP_NUM; i++)
+				seqState.prevOffset[i] = dctx->entropy.rep[i];
+		}
+		CHECK_E(BIT_initDStream(&seqState.DStream, ip, iend - ip), corruption_detected);
+		FSE_initDState(&seqState.stateLL, &seqState.DStream, dctx->LLTptr);
+		FSE_initDState(&seqState.stateOffb, &seqState.DStream, dctx->OFTptr);
+		FSE_initDState(&seqState.stateML, &seqState.DStream, dctx->MLTptr);
+
+		for (; (BIT_reloadDStream(&(seqState.DStream)) <= BIT_DStream_completed) && nbSeq;) {
+			nbSeq--;
+			{
+				seq_t const sequence = ZSTD_decodeSequence(&seqState);
+				size_t const oneSeqSize = ZSTD_execSequence(op, oend, sequence, &litPtr, litEnd, base, vBase, dictEnd);
+				if (ZSTD_isError(oneSeqSize))
+					return oneSeqSize;
+				op += oneSeqSize;
+			}
+		}
+
+		/* check if reached exact end */
+		if (nbSeq)
+			return ERROR(corruption_detected);
+		/* save reps for next block */
+		{
+			U32 i;
+			for (i = 0; i < ZSTD_REP_NUM; i++)
+				dctx->entropy.rep[i] = (U32)(seqState.prevOffset[i]);
+		}
+	}
+
+	/* last literal segment */
+	{
+		size_t const lastLLSize = litEnd - litPtr;
+		if (lastLLSize > (size_t)(oend - op))
+			return ERROR(dstSize_tooSmall);
+		memcpy(op, litPtr, lastLLSize);
+		op += lastLLSize;
+	}
+
+	return op - ostart;
+}
+
+FORCE_INLINE seq_t ZSTD_decodeSequenceLong_generic(seqState_t *seqState, int const longOffsets)
+{
+	seq_t seq;
+
+	U32 const llCode = FSE_peekSymbol(&seqState->stateLL);
+	U32 const mlCode = FSE_peekSymbol(&seqState->stateML);
+	U32 const ofCode = FSE_peekSymbol(&seqState->stateOffb); /* <= maxOff, by table construction */
+
+	U32 const llBits = LL_bits[llCode];
+	U32 const mlBits = ML_bits[mlCode];
+	U32 const ofBits = ofCode;
+	U32 const totalBits = llBits + mlBits + ofBits;
+
+	static const U32 LL_base[MaxLL + 1] = {0,  1,  2,  3,  4,  5,  6,  7,  8,    9,     10,    11,    12,    13,     14,     15,     16,     18,
+					       20, 22, 24, 28, 32, 40, 48, 64, 0x80, 0x100, 0x200, 0x400, 0x800, 0x1000, 0x2000, 0x4000, 0x8000, 0x10000};
+
+	static const U32 ML_base[MaxML + 1] = {3,  4,  5,  6,  7,  8,  9,  10,   11,    12,    13,    14,    15,     16,     17,     18,     19,     20,
+					       21, 22, 23, 24, 25, 26, 27, 28,   29,    30,    31,    32,    33,     34,     35,     37,     39,     41,
+					       43, 47, 51, 59, 67, 83, 99, 0x83, 0x103, 0x203, 0x403, 0x803, 0x1003, 0x2003, 0x4003, 0x8003, 0x10003};
+
+	static const U32 OF_base[MaxOff + 1] = {0,       1,	1,	5,	0xD,      0x1D,      0x3D,      0x7D,      0xFD,     0x1FD,
+						0x3FD,   0x7FD,    0xFFD,    0x1FFD,   0x3FFD,   0x7FFD,    0xFFFD,    0x1FFFD,   0x3FFFD,  0x7FFFD,
+						0xFFFFD, 0x1FFFFD, 0x3FFFFD, 0x7FFFFD, 0xFFFFFD, 0x1FFFFFD, 0x3FFFFFD, 0x7FFFFFD, 0xFFFFFFD};
+
+	/* sequence */
+	{
+		size_t offset;
+		if (!ofCode)
+			offset = 0;
+		else {
+			if (longOffsets) {
+				int const extraBits = ofBits - MIN(ofBits, STREAM_ACCUMULATOR_MIN);
+				offset = OF_base[ofCode] + (BIT_readBitsFast(&seqState->DStream, ofBits - extraBits) << extraBits);
+				if (ZSTD_32bits() || extraBits)
+					BIT_reloadDStream(&seqState->DStream);
+				if (extraBits)
+					offset += BIT_readBitsFast(&seqState->DStream, extraBits);
+			} else {
+				offset = OF_base[ofCode] + BIT_readBitsFast(&seqState->DStream, ofBits); /* <=  (ZSTD_WINDOWLOG_MAX-1) bits */
+				if (ZSTD_32bits())
+					BIT_reloadDStream(&seqState->DStream);
+			}
+		}
+
+		if (ofCode <= 1) {
+			offset += (llCode == 0);
+			if (offset) {
+				size_t temp = (offset == 3) ? seqState->prevOffset[0] - 1 : seqState->prevOffset[offset];
+				temp += !temp; /* 0 is not valid; input is corrupted; force offset to 1 */
+				if (offset != 1)
+					seqState->prevOffset[2] = seqState->prevOffset[1];
+				seqState->prevOffset[1] = seqState->prevOffset[0];
+				seqState->prevOffset[0] = offset = temp;
+			} else {
+				offset = seqState->prevOffset[0];
+			}
+		} else {
+			seqState->prevOffset[2] = seqState->prevOffset[1];
+			seqState->prevOffset[1] = seqState->prevOffset[0];
+			seqState->prevOffset[0] = offset;
+		}
+		seq.offset = offset;
+	}
+
+	seq.matchLength = ML_base[mlCode] + ((mlCode > 31) ? BIT_readBitsFast(&seqState->DStream, mlBits) : 0); /* <=  16 bits */
+	if (ZSTD_32bits() && (mlBits + llBits > 24))
+		BIT_reloadDStream(&seqState->DStream);
+
+	seq.litLength = LL_base[llCode] + ((llCode > 15) ? BIT_readBitsFast(&seqState->DStream, llBits) : 0); /* <=  16 bits */
+	if (ZSTD_32bits() || (totalBits > 64 - 7 - (LLFSELog + MLFSELog + OffFSELog)))
+		BIT_reloadDStream(&seqState->DStream);
+
+	{
+		size_t const pos = seqState->pos + seq.litLength;
+		seq.match = seqState->base + pos - seq.offset; /* single memory segment */
+		if (seq.offset > pos)
+			seq.match += seqState->gotoDict; /* separate memory segment */
+		seqState->pos = pos + seq.matchLength;
+	}
+
+	/* ANS state update */
+	FSE_updateState(&seqState->stateLL, &seqState->DStream); /* <=  9 bits */
+	FSE_updateState(&seqState->stateML, &seqState->DStream); /* <=  9 bits */
+	if (ZSTD_32bits())
+		BIT_reloadDStream(&seqState->DStream);		   /* <= 18 bits */
+	FSE_updateState(&seqState->stateOffb, &seqState->DStream); /* <=  8 bits */
+
+	return seq;
+}
+
+static seq_t ZSTD_decodeSequenceLong(seqState_t *seqState, unsigned const windowSize)
+{
+	if (ZSTD_highbit32(windowSize) > STREAM_ACCUMULATOR_MIN) {
+		return ZSTD_decodeSequenceLong_generic(seqState, 1);
+	} else {
+		return ZSTD_decodeSequenceLong_generic(seqState, 0);
+	}
+}
+
+FORCE_INLINE
+size_t ZSTD_execSequenceLong(BYTE *op, BYTE *const oend, seq_t sequence, const BYTE **litPtr, const BYTE *const litLimit, const BYTE *const base,
+			     const BYTE *const vBase, const BYTE *const dictEnd)
+{
+	BYTE *const oLitEnd = op + sequence.litLength;
+	size_t const sequenceLength = sequence.litLength + sequence.matchLength;
+	BYTE *const oMatchEnd = op + sequenceLength; /* risk : address space overflow (32-bits) */
+	BYTE *const oend_w = oend - WILDCOPY_OVERLENGTH;
+	const BYTE *const iLitEnd = *litPtr + sequence.litLength;
+	const BYTE *match = sequence.match;
+
+	/* check */
+	if (oMatchEnd > oend)
+		return ERROR(dstSize_tooSmall); /* last match must start at a minimum distance of WILDCOPY_OVERLENGTH from oend */
+	if (iLitEnd > litLimit)
+		return ERROR(corruption_detected); /* over-read beyond lit buffer */
+	if (oLitEnd > oend_w)
+		return ZSTD_execSequenceLast7(op, oend, sequence, litPtr, litLimit, base, vBase, dictEnd);
+
+	/* copy Literals */
+	ZSTD_copy8(op, *litPtr);
+	if (sequence.litLength > 8)
+		ZSTD_wildcopy(op + 8, (*litPtr) + 8,
+			      sequence.litLength - 8); /* note : since oLitEnd <= oend-WILDCOPY_OVERLENGTH, no risk of overwrite beyond oend */
+	op = oLitEnd;
+	*litPtr = iLitEnd; /* update for next sequence */
+
+	/* copy Match */
+	if (sequence.offset > (size_t)(oLitEnd - base)) {
+		/* offset beyond prefix */
+		if (sequence.offset > (size_t)(oLitEnd - vBase))
+			return ERROR(corruption_detected);
+		if (match + sequence.matchLength <= dictEnd) {
+			memmove(oLitEnd, match, sequence.matchLength);
+			return sequenceLength;
+		}
+		/* span extDict & currPrefixSegment */
+		{
+			size_t const length1 = dictEnd - match;
+			memmove(oLitEnd, match, length1);
+			op = oLitEnd + length1;
+			sequence.matchLength -= length1;
+			match = base;
+			if (op > oend_w || sequence.matchLength < MINMATCH) {
+				U32 i;
+				for (i = 0; i < sequence.matchLength; ++i)
+					op[i] = match[i];
+				return sequenceLength;
+			}
+		}
+	}
+	/* Requirement: op <= oend_w && sequence.matchLength >= MINMATCH */
+
+	/* match within prefix */
+	if (sequence.offset < 8) {
+		/* close range match, overlap */
+		static const U32 dec32table[] = {0, 1, 2, 1, 4, 4, 4, 4};   /* added */
+		static const int dec64table[] = {8, 8, 8, 7, 8, 9, 10, 11}; /* subtracted */
+		int const sub2 = dec64table[sequence.offset];
+		op[0] = match[0];
+		op[1] = match[1];
+		op[2] = match[2];
+		op[3] = match[3];
+		match += dec32table[sequence.offset];
+		ZSTD_copy4(op + 4, match);
+		match -= sub2;
+	} else {
+		ZSTD_copy8(op, match);
+	}
+	op += 8;
+	match += 8;
+
+	if (oMatchEnd > oend - (16 - MINMATCH)) {
+		if (op < oend_w) {
+			ZSTD_wildcopy(op, match, oend_w - op);
+			match += oend_w - op;
+			op = oend_w;
+		}
+		while (op < oMatchEnd)
+			*op++ = *match++;
+	} else {
+		ZSTD_wildcopy(op, match, (ptrdiff_t)sequence.matchLength - 8); /* works even if matchLength < 8 */
+	}
+	return sequenceLength;
+}
+
+static size_t ZSTD_decompressSequencesLong(ZSTD_DCtx *dctx, void *dst, size_t maxDstSize, const void *seqStart, size_t seqSize)
+{
+	const BYTE *ip = (const BYTE *)seqStart;
+	const BYTE *const iend = ip + seqSize;
+	BYTE *const ostart = (BYTE * const)dst;
+	BYTE *const oend = ostart + maxDstSize;
+	BYTE *op = ostart;
+	const BYTE *litPtr = dctx->litPtr;
+	const BYTE *const litEnd = litPtr + dctx->litSize;
+	const BYTE *const base = (const BYTE *)(dctx->base);
+	const BYTE *const vBase = (const BYTE *)(dctx->vBase);
+	const BYTE *const dictEnd = (const BYTE *)(dctx->dictEnd);
+	unsigned const windowSize = dctx->fParams.windowSize;
+	int nbSeq;
+
+	/* Build Decoding Tables */
+	{
+		size_t const seqHSize = ZSTD_decodeSeqHeaders(dctx, &nbSeq, ip, seqSize);
+		if (ZSTD_isError(seqHSize))
+			return seqHSize;
+		ip += seqHSize;
+	}
+
+	/* Regen sequences */
+	if (nbSeq) {
+#define STORED_SEQS 4
+#define STOSEQ_MASK (STORED_SEQS - 1)
+#define ADVANCED_SEQS 4
+		seq_t *sequences = (seq_t *)dctx->entropy.workspace;
+		int const seqAdvance = MIN(nbSeq, ADVANCED_SEQS);
+		seqState_t seqState;
+		int seqNb;
+		ZSTD_STATIC_ASSERT(sizeof(dctx->entropy.workspace) >= sizeof(seq_t) * STORED_SEQS);
+		dctx->fseEntropy = 1;
+		{
+			U32 i;
+			for (i = 0; i < ZSTD_REP_NUM; i++)
+				seqState.prevOffset[i] = dctx->entropy.rep[i];
+		}
+		seqState.base = base;
+		seqState.pos = (size_t)(op - base);
+		seqState.gotoDict = (uPtrDiff)dictEnd - (uPtrDiff)base; /* cast to avoid undefined behaviour */
+		CHECK_E(BIT_initDStream(&seqState.DStream, ip, iend - ip), corruption_detected);
+		FSE_initDState(&seqState.stateLL, &seqState.DStream, dctx->LLTptr);
+		FSE_initDState(&seqState.stateOffb, &seqState.DStream, dctx->OFTptr);
+		FSE_initDState(&seqState.stateML, &seqState.DStream, dctx->MLTptr);
+
+		/* prepare in advance */
+		for (seqNb = 0; (BIT_reloadDStream(&seqState.DStream) <= BIT_DStream_completed) && seqNb < seqAdvance; seqNb++) {
+			sequences[seqNb] = ZSTD_decodeSequenceLong(&seqState, windowSize);
+		}
+		if (seqNb < seqAdvance)
+			return ERROR(corruption_detected);
+
+		/* decode and decompress */
+		for (; (BIT_reloadDStream(&(seqState.DStream)) <= BIT_DStream_completed) && seqNb < nbSeq; seqNb++) {
+			seq_t const sequence = ZSTD_decodeSequenceLong(&seqState, windowSize);
+			size_t const oneSeqSize =
+			    ZSTD_execSequenceLong(op, oend, sequences[(seqNb - ADVANCED_SEQS) & STOSEQ_MASK], &litPtr, litEnd, base, vBase, dictEnd);
+			if (ZSTD_isError(oneSeqSize))
+				return oneSeqSize;
+			ZSTD_PREFETCH(sequence.match);
+			sequences[seqNb & STOSEQ_MASK] = sequence;
+			op += oneSeqSize;
+		}
+		if (seqNb < nbSeq)
+			return ERROR(corruption_detected);
+
+		/* finish queue */
+		seqNb -= seqAdvance;
+		for (; seqNb < nbSeq; seqNb++) {
+			size_t const oneSeqSize = ZSTD_execSequenceLong(op, oend, sequences[seqNb & STOSEQ_MASK], &litPtr, litEnd, base, vBase, dictEnd);
+			if (ZSTD_isError(oneSeqSize))
+				return oneSeqSize;
+			op += oneSeqSize;
+		}
+
+		/* save reps for next block */
+		{
+			U32 i;
+			for (i = 0; i < ZSTD_REP_NUM; i++)
+				dctx->entropy.rep[i] = (U32)(seqState.prevOffset[i]);
+		}
+	}
+
+	/* last literal segment */
+	{
+		size_t const lastLLSize = litEnd - litPtr;
+		if (lastLLSize > (size_t)(oend - op))
+			return ERROR(dstSize_tooSmall);
+		memcpy(op, litPtr, lastLLSize);
+		op += lastLLSize;
+	}
+
+	return op - ostart;
+}
+
+static size_t ZSTD_decompressBlock_internal(ZSTD_DCtx *dctx, void *dst, size_t dstCapacity, const void *src, size_t srcSize)
+{ /* blockType == blockCompressed */
+	const BYTE *ip = (const BYTE *)src;
+
+	if (srcSize >= ZSTD_BLOCKSIZE_ABSOLUTEMAX)
+		return ERROR(srcSize_wrong);
+
+	/* Decode literals section */
+	{
+		size_t const litCSize = ZSTD_decodeLiteralsBlock(dctx, src, srcSize);
+		if (ZSTD_isError(litCSize))
+			return litCSize;
+		ip += litCSize;
+		srcSize -= litCSize;
+	}
+	if (sizeof(size_t) > 4) /* do not enable prefetching on 32-bits x86, as it's performance detrimental */
+				/* likely because of register pressure */
+				/* if that's the correct cause, then 32-bits ARM should be affected differently */
+				/* it would be good to test this on ARM real hardware, to see if prefetch version improves speed */
+		if (dctx->fParams.windowSize > (1 << 23))
+			return ZSTD_decompressSequencesLong(dctx, dst, dstCapacity, ip, srcSize);
+	return ZSTD_decompressSequences(dctx, dst, dstCapacity, ip, srcSize);
+}
+
+static void ZSTD_checkContinuity(ZSTD_DCtx *dctx, const void *dst)
+{
+	if (dst != dctx->previousDstEnd) { /* not contiguous */
+		dctx->dictEnd = dctx->previousDstEnd;
+		dctx->vBase = (const char *)dst - ((const char *)(dctx->previousDstEnd) - (const char *)(dctx->base));
+		dctx->base = dst;
+		dctx->previousDstEnd = dst;
+	}
+}
+
+size_t ZSTD_decompressBlock(ZSTD_DCtx *dctx, void *dst, size_t dstCapacity, const void *src, size_t srcSize)
+{
+	size_t dSize;
+	ZSTD_checkContinuity(dctx, dst);
+	dSize = ZSTD_decompressBlock_internal(dctx, dst, dstCapacity, src, srcSize);
+	dctx->previousDstEnd = (char *)dst + dSize;
+	return dSize;
+}
+
+/** ZSTD_insertBlock() :
+	insert `src` block into `dctx` history. Useful to track uncompressed blocks. */
+size_t ZSTD_insertBlock(ZSTD_DCtx *dctx, const void *blockStart, size_t blockSize)
+{
+	ZSTD_checkContinuity(dctx, blockStart);
+	dctx->previousDstEnd = (const char *)blockStart + blockSize;
+	return blockSize;
+}
+
+size_t ZSTD_generateNxBytes(void *dst, size_t dstCapacity, BYTE byte, size_t length)
+{
+	if (length > dstCapacity)
+		return ERROR(dstSize_tooSmall);
+	memset(dst, byte, length);
+	return length;
+}
+
+/** ZSTD_findFrameCompressedSize() :
+ *  compatible with legacy mode
+ *  `src` must point to the start of a ZSTD frame, ZSTD legacy frame, or skippable frame
+ *  `srcSize` must be at least as large as the frame contained
+ *  @return : the compressed size of the frame starting at `src` */
+size_t ZSTD_findFrameCompressedSize(const void *src, size_t srcSize)
+{
+	if (srcSize >= ZSTD_skippableHeaderSize && (ZSTD_readLE32(src) & 0xFFFFFFF0U) == ZSTD_MAGIC_SKIPPABLE_START) {
+		return ZSTD_skippableHeaderSize + ZSTD_readLE32((const BYTE *)src + 4);
+	} else {
+		const BYTE *ip = (const BYTE *)src;
+		const BYTE *const ipstart = ip;
+		size_t remainingSize = srcSize;
+		ZSTD_frameParams fParams;
+
+		size_t const headerSize = ZSTD_frameHeaderSize(ip, remainingSize);
+		if (ZSTD_isError(headerSize))
+			return headerSize;
+
+		/* Frame Header */
+		{
+			size_t const ret = ZSTD_getFrameParams(&fParams, ip, remainingSize);
+			if (ZSTD_isError(ret))
+				return ret;
+			if (ret > 0)
+				return ERROR(srcSize_wrong);
+		}
+
+		ip += headerSize;
+		remainingSize -= headerSize;
+
+		/* Loop on each block */
+		while (1) {
+			blockProperties_t blockProperties;
+			size_t const cBlockSize = ZSTD_getcBlockSize(ip, remainingSize, &blockProperties);
+			if (ZSTD_isError(cBlockSize))
+				return cBlockSize;
+
+			if (ZSTD_blockHeaderSize + cBlockSize > remainingSize)
+				return ERROR(srcSize_wrong);
+
+			ip += ZSTD_blockHeaderSize + cBlockSize;
+			remainingSize -= ZSTD_blockHeaderSize + cBlockSize;
+
+			if (blockProperties.lastBlock)
+				break;
+		}
+
+		if (fParams.checksumFlag) { /* Frame content checksum */
+			if (remainingSize < 4)
+				return ERROR(srcSize_wrong);
+			ip += 4;
+			remainingSize -= 4;
+		}
+
+		return ip - ipstart;
+	}
+}
+
+/*! ZSTD_decompressFrame() :
+*   @dctx must be properly initialized */
+static size_t ZSTD_decompressFrame(ZSTD_DCtx *dctx, void *dst, size_t dstCapacity, const void **srcPtr, size_t *srcSizePtr)
+{
+	const BYTE *ip = (const BYTE *)(*srcPtr);
+	BYTE *const ostart = (BYTE * const)dst;
+	BYTE *const oend = ostart + dstCapacity;
+	BYTE *op = ostart;
+	size_t remainingSize = *srcSizePtr;
+
+	/* check */
+	if (remainingSize < ZSTD_frameHeaderSize_min + ZSTD_blockHeaderSize)
+		return ERROR(srcSize_wrong);
+
+	/* Frame Header */
+	{
+		size_t const frameHeaderSize = ZSTD_frameHeaderSize(ip, ZSTD_frameHeaderSize_prefix);
+		if (ZSTD_isError(frameHeaderSize))
+			return frameHeaderSize;
+		if (remainingSize < frameHeaderSize + ZSTD_blockHeaderSize)
+			return ERROR(srcSize_wrong);
+		CHECK_F(ZSTD_decodeFrameHeader(dctx, ip, frameHeaderSize));
+		ip += frameHeaderSize;
+		remainingSize -= frameHeaderSize;
+	}
+
+	/* Loop on each block */
+	while (1) {
+		size_t decodedSize;
+		blockProperties_t blockProperties;
+		size_t const cBlockSize = ZSTD_getcBlockSize(ip, remainingSize, &blockProperties);
+		if (ZSTD_isError(cBlockSize))
+			return cBlockSize;
+
+		ip += ZSTD_blockHeaderSize;
+		remainingSize -= ZSTD_blockHeaderSize;
+		if (cBlockSize > remainingSize)
+			return ERROR(srcSize_wrong);
+
+		switch (blockProperties.blockType) {
+		case bt_compressed: decodedSize = ZSTD_decompressBlock_internal(dctx, op, oend - op, ip, cBlockSize); break;
+		case bt_raw: decodedSize = ZSTD_copyRawBlock(op, oend - op, ip, cBlockSize); break;
+		case bt_rle: decodedSize = ZSTD_generateNxBytes(op, oend - op, *ip, blockProperties.origSize); break;
+		case bt_reserved:
+		default: return ERROR(corruption_detected);
+		}
+
+		if (ZSTD_isError(decodedSize))
+			return decodedSize;
+		if (dctx->fParams.checksumFlag)
+			xxh64_update(&dctx->xxhState, op, decodedSize);
+		op += decodedSize;
+		ip += cBlockSize;
+		remainingSize -= cBlockSize;
+		if (blockProperties.lastBlock)
+			break;
+	}
+
+	if (dctx->fParams.checksumFlag) { /* Frame content checksum verification */
+		U32 const checkCalc = (U32)xxh64_digest(&dctx->xxhState);
+		U32 checkRead;
+		if (remainingSize < 4)
+			return ERROR(checksum_wrong);
+		checkRead = ZSTD_readLE32(ip);
+		if (checkRead != checkCalc)
+			return ERROR(checksum_wrong);
+		ip += 4;
+		remainingSize -= 4;
+	}
+
+	/* Allow caller to get size read */
+	*srcPtr = ip;
+	*srcSizePtr = remainingSize;
+	return op - ostart;
+}
+
+static const void *ZSTD_DDictDictContent(const ZSTD_DDict *ddict);
+static size_t ZSTD_DDictDictSize(const ZSTD_DDict *ddict);
+
+static size_t ZSTD_decompressMultiFrame(ZSTD_DCtx *dctx, void *dst, size_t dstCapacity, const void *src, size_t srcSize, const void *dict, size_t dictSize,
+					const ZSTD_DDict *ddict)
+{
+	void *const dststart = dst;
+
+	if (ddict) {
+		if (dict) {
+			/* programmer error, these two cases should be mutually exclusive */
+			return ERROR(GENERIC);
+		}
+
+		dict = ZSTD_DDictDictContent(ddict);
+		dictSize = ZSTD_DDictDictSize(ddict);
+	}
+
+	while (srcSize >= ZSTD_frameHeaderSize_prefix) {
+		U32 magicNumber;
+
+		magicNumber = ZSTD_readLE32(src);
+		if (magicNumber != ZSTD_MAGICNUMBER) {
+			if ((magicNumber & 0xFFFFFFF0U) == ZSTD_MAGIC_SKIPPABLE_START) {
+				size_t skippableSize;
+				if (srcSize < ZSTD_skippableHeaderSize)
+					return ERROR(srcSize_wrong);
+				skippableSize = ZSTD_readLE32((const BYTE *)src + 4) + ZSTD_skippableHeaderSize;
+				if (srcSize < skippableSize) {
+					return ERROR(srcSize_wrong);
+				}
+
+				src = (const BYTE *)src + skippableSize;
+				srcSize -= skippableSize;
+				continue;
+			} else {
+				return ERROR(prefix_unknown);
+			}
+		}
+
+		if (ddict) {
+			/* we were called from ZSTD_decompress_usingDDict */
+			ZSTD_refDDict(dctx, ddict);
+		} else {
+			/* this will initialize correctly with no dict if dict == NULL, so
+			 * use this in all cases but ddict */
+			CHECK_F(ZSTD_decompressBegin_usingDict(dctx, dict, dictSize));
+		}
+		ZSTD_checkContinuity(dctx, dst);
+
+		{
+			const size_t res = ZSTD_decompressFrame(dctx, dst, dstCapacity, &src, &srcSize);
+			if (ZSTD_isError(res))
+				return res;
+			/* don't need to bounds check this, ZSTD_decompressFrame will have
+			 * already */
+			dst = (BYTE *)dst + res;
+			dstCapacity -= res;
+		}
+	}
+
+	if (srcSize)
+		return ERROR(srcSize_wrong); /* input not entirely consumed */
+
+	return (BYTE *)dst - (BYTE *)dststart;
+}
+
+size_t ZSTD_decompress_usingDict(ZSTD_DCtx *dctx, void *dst, size_t dstCapacity, const void *src, size_t srcSize, const void *dict, size_t dictSize)
+{
+	return ZSTD_decompressMultiFrame(dctx, dst, dstCapacity, src, srcSize, dict, dictSize, NULL);
+}
+
+size_t ZSTD_decompressDCtx(ZSTD_DCtx *dctx, void *dst, size_t dstCapacity, const void *src, size_t srcSize)
+{
+	return ZSTD_decompress_usingDict(dctx, dst, dstCapacity, src, srcSize, NULL, 0);
+}
+
+/*-**************************************
+*   Advanced Streaming Decompression API
+*   Bufferless and synchronous
+****************************************/
+size_t ZSTD_nextSrcSizeToDecompress(ZSTD_DCtx *dctx) { return dctx->expected; }
+
+ZSTD_nextInputType_e ZSTD_nextInputType(ZSTD_DCtx *dctx)
+{
+	switch (dctx->stage) {
+	default: /* should not happen */
+	case ZSTDds_getFrameHeaderSize:
+	case ZSTDds_decodeFrameHeader: return ZSTDnit_frameHeader;
+	case ZSTDds_decodeBlockHeader: return ZSTDnit_blockHeader;
+	case ZSTDds_decompressBlock: return ZSTDnit_block;
+	case ZSTDds_decompressLastBlock: return ZSTDnit_lastBlock;
+	case ZSTDds_checkChecksum: return ZSTDnit_checksum;
+	case ZSTDds_decodeSkippableHeader:
+	case ZSTDds_skipFrame: return ZSTDnit_skippableFrame;
+	}
+}
+
+int ZSTD_isSkipFrame(ZSTD_DCtx *dctx) { return dctx->stage == ZSTDds_skipFrame; } /* for zbuff */
+
+/** ZSTD_decompressContinue() :
+*   @return : nb of bytes generated into `dst` (necessarily <= `dstCapacity)
+*             or an error code, which can be tested using ZSTD_isError() */
+size_t ZSTD_decompressContinue(ZSTD_DCtx *dctx, void *dst, size_t dstCapacity, const void *src, size_t srcSize)
+{
+	/* Sanity check */
+	if (srcSize != dctx->expected)
+		return ERROR(srcSize_wrong);
+	if (dstCapacity)
+		ZSTD_checkContinuity(dctx, dst);
+
+	switch (dctx->stage) {
+	case ZSTDds_getFrameHeaderSize:
+		if (srcSize != ZSTD_frameHeaderSize_prefix)
+			return ERROR(srcSize_wrong);					/* impossible */
+		if ((ZSTD_readLE32(src) & 0xFFFFFFF0U) == ZSTD_MAGIC_SKIPPABLE_START) { /* skippable frame */
+			memcpy(dctx->headerBuffer, src, ZSTD_frameHeaderSize_prefix);
+			dctx->expected = ZSTD_skippableHeaderSize - ZSTD_frameHeaderSize_prefix; /* magic number + skippable frame length */
+			dctx->stage = ZSTDds_decodeSkippableHeader;
+			return 0;
+		}
+		dctx->headerSize = ZSTD_frameHeaderSize(src, ZSTD_frameHeaderSize_prefix);
+		if (ZSTD_isError(dctx->headerSize))
+			return dctx->headerSize;
+		memcpy(dctx->headerBuffer, src, ZSTD_frameHeaderSize_prefix);
+		if (dctx->headerSize > ZSTD_frameHeaderSize_prefix) {
+			dctx->expected = dctx->headerSize - ZSTD_frameHeaderSize_prefix;
+			dctx->stage = ZSTDds_decodeFrameHeader;
+			return 0;
+		}
+		dctx->expected = 0; /* not necessary to copy more */
+
+	case ZSTDds_decodeFrameHeader:
+		memcpy(dctx->headerBuffer + ZSTD_frameHeaderSize_prefix, src, dctx->expected);
+		CHECK_F(ZSTD_decodeFrameHeader(dctx, dctx->headerBuffer, dctx->headerSize));
+		dctx->expected = ZSTD_blockHeaderSize;
+		dctx->stage = ZSTDds_decodeBlockHeader;
+		return 0;
+
+	case ZSTDds_decodeBlockHeader: {
+		blockProperties_t bp;
+		size_t const cBlockSize = ZSTD_getcBlockSize(src, ZSTD_blockHeaderSize, &bp);
+		if (ZSTD_isError(cBlockSize))
+			return cBlockSize;
+		dctx->expected = cBlockSize;
+		dctx->bType = bp.blockType;
+		dctx->rleSize = bp.origSize;
+		if (cBlockSize) {
+			dctx->stage = bp.lastBlock ? ZSTDds_decompressLastBlock : ZSTDds_decompressBlock;
+			return 0;
+		}
+		/* empty block */
+		if (bp.lastBlock) {
+			if (dctx->fParams.checksumFlag) {
+				dctx->expected = 4;
+				dctx->stage = ZSTDds_checkChecksum;
+			} else {
+				dctx->expected = 0; /* end of frame */
+				dctx->stage = ZSTDds_getFrameHeaderSize;
+			}
+		} else {
+			dctx->expected = 3; /* go directly to next header */
+			dctx->stage = ZSTDds_decodeBlockHeader;
+		}
+		return 0;
+	}
+	case ZSTDds_decompressLastBlock:
+	case ZSTDds_decompressBlock: {
+		size_t rSize;
+		switch (dctx->bType) {
+		case bt_compressed: rSize = ZSTD_decompressBlock_internal(dctx, dst, dstCapacity, src, srcSize); break;
+		case bt_raw: rSize = ZSTD_copyRawBlock(dst, dstCapacity, src, srcSize); break;
+		case bt_rle: rSize = ZSTD_setRleBlock(dst, dstCapacity, src, srcSize, dctx->rleSize); break;
+		case bt_reserved: /* should never happen */
+		default: return ERROR(corruption_detected);
+		}
+		if (ZSTD_isError(rSize))
+			return rSize;
+		if (dctx->fParams.checksumFlag)
+			xxh64_update(&dctx->xxhState, dst, rSize);
+
+		if (dctx->stage == ZSTDds_decompressLastBlock) { /* end of frame */
+			if (dctx->fParams.checksumFlag) {	/* another round for frame checksum */
+				dctx->expected = 4;
+				dctx->stage = ZSTDds_checkChecksum;
+			} else {
+				dctx->expected = 0; /* ends here */
+				dctx->stage = ZSTDds_getFrameHeaderSize;
+			}
+		} else {
+			dctx->stage = ZSTDds_decodeBlockHeader;
+			dctx->expected = ZSTD_blockHeaderSize;
+			dctx->previousDstEnd = (char *)dst + rSize;
+		}
+		return rSize;
+	}
+	case ZSTDds_checkChecksum: {
+		U32 const h32 = (U32)xxh64_digest(&dctx->xxhState);
+		U32 const check32 = ZSTD_readLE32(src); /* srcSize == 4, guaranteed by dctx->expected */
+		if (check32 != h32)
+			return ERROR(checksum_wrong);
+		dctx->expected = 0;
+		dctx->stage = ZSTDds_getFrameHeaderSize;
+		return 0;
+	}
+	case ZSTDds_decodeSkippableHeader: {
+		memcpy(dctx->headerBuffer + ZSTD_frameHeaderSize_prefix, src, dctx->expected);
+		dctx->expected = ZSTD_readLE32(dctx->headerBuffer + 4);
+		dctx->stage = ZSTDds_skipFrame;
+		return 0;
+	}
+	case ZSTDds_skipFrame: {
+		dctx->expected = 0;
+		dctx->stage = ZSTDds_getFrameHeaderSize;
+		return 0;
+	}
+	default:
+		return ERROR(GENERIC); /* impossible */
+	}
+}
+
+static size_t ZSTD_refDictContent(ZSTD_DCtx *dctx, const void *dict, size_t dictSize)
+{
+	dctx->dictEnd = dctx->previousDstEnd;
+	dctx->vBase = (const char *)dict - ((const char *)(dctx->previousDstEnd) - (const char *)(dctx->base));
+	dctx->base = dict;
+	dctx->previousDstEnd = (const char *)dict + dictSize;
+	return 0;
+}
+
+/* ZSTD_loadEntropy() :
+ * dict : must point at beginning of a valid zstd dictionary
+ * @return : size of entropy tables read */
+static size_t ZSTD_loadEntropy(ZSTD_entropyTables_t *entropy, const void *const dict, size_t const dictSize)
+{
+	const BYTE *dictPtr = (const BYTE *)dict;
+	const BYTE *const dictEnd = dictPtr + dictSize;
+
+	if (dictSize <= 8)
+		return ERROR(dictionary_corrupted);
+	dictPtr += 8; /* skip header = magic + dictID */
+
+	{
+		size_t const hSize = HUF_readDTableX4_wksp(entropy->hufTable, dictPtr, dictEnd - dictPtr, entropy->workspace, sizeof(entropy->workspace));
+		if (HUF_isError(hSize))
+			return ERROR(dictionary_corrupted);
+		dictPtr += hSize;
+	}
+
+	{
+		short offcodeNCount[MaxOff + 1];
+		U32 offcodeMaxValue = MaxOff, offcodeLog;
+		size_t const offcodeHeaderSize = FSE_readNCount(offcodeNCount, &offcodeMaxValue, &offcodeLog, dictPtr, dictEnd - dictPtr);
+		if (FSE_isError(offcodeHeaderSize))
+			return ERROR(dictionary_corrupted);
+		if (offcodeLog > OffFSELog)
+			return ERROR(dictionary_corrupted);
+		CHECK_E(FSE_buildDTable_wksp(entropy->OFTable, offcodeNCount, offcodeMaxValue, offcodeLog, entropy->workspace, sizeof(entropy->workspace)), dictionary_corrupted);
+		dictPtr += offcodeHeaderSize;
+	}
+
+	{
+		short matchlengthNCount[MaxML + 1];
+		unsigned matchlengthMaxValue = MaxML, matchlengthLog;
+		size_t const matchlengthHeaderSize = FSE_readNCount(matchlengthNCount, &matchlengthMaxValue, &matchlengthLog, dictPtr, dictEnd - dictPtr);
+		if (FSE_isError(matchlengthHeaderSize))
+			return ERROR(dictionary_corrupted);
+		if (matchlengthLog > MLFSELog)
+			return ERROR(dictionary_corrupted);
+		CHECK_E(FSE_buildDTable_wksp(entropy->MLTable, matchlengthNCount, matchlengthMaxValue, matchlengthLog, entropy->workspace, sizeof(entropy->workspace)), dictionary_corrupted);
+		dictPtr += matchlengthHeaderSize;
+	}
+
+	{
+		short litlengthNCount[MaxLL + 1];
+		unsigned litlengthMaxValue = MaxLL, litlengthLog;
+		size_t const litlengthHeaderSize = FSE_readNCount(litlengthNCount, &litlengthMaxValue, &litlengthLog, dictPtr, dictEnd - dictPtr);
+		if (FSE_isError(litlengthHeaderSize))
+			return ERROR(dictionary_corrupted);
+		if (litlengthLog > LLFSELog)
+			return ERROR(dictionary_corrupted);
+		CHECK_E(FSE_buildDTable_wksp(entropy->LLTable, litlengthNCount, litlengthMaxValue, litlengthLog, entropy->workspace, sizeof(entropy->workspace)), dictionary_corrupted);
+		dictPtr += litlengthHeaderSize;
+	}
+
+	if (dictPtr + 12 > dictEnd)
+		return ERROR(dictionary_corrupted);
+	{
+		int i;
+		size_t const dictContentSize = (size_t)(dictEnd - (dictPtr + 12));
+		for (i = 0; i < 3; i++) {
+			U32 const rep = ZSTD_readLE32(dictPtr);
+			dictPtr += 4;
+			if (rep == 0 || rep >= dictContentSize)
+				return ERROR(dictionary_corrupted);
+			entropy->rep[i] = rep;
+		}
+	}
+
+	return dictPtr - (const BYTE *)dict;
+}
+
+static size_t ZSTD_decompress_insertDictionary(ZSTD_DCtx *dctx, const void *dict, size_t dictSize)
+{
+	if (dictSize < 8)
+		return ZSTD_refDictContent(dctx, dict, dictSize);
+	{
+		U32 const magic = ZSTD_readLE32(dict);
+		if (magic != ZSTD_DICT_MAGIC) {
+			return ZSTD_refDictContent(dctx, dict, dictSize); /* pure content mode */
+		}
+	}
+	dctx->dictID = ZSTD_readLE32((const char *)dict + 4);
+
+	/* load entropy tables */
+	{
+		size_t const eSize = ZSTD_loadEntropy(&dctx->entropy, dict, dictSize);
+		if (ZSTD_isError(eSize))
+			return ERROR(dictionary_corrupted);
+		dict = (const char *)dict + eSize;
+		dictSize -= eSize;
+	}
+	dctx->litEntropy = dctx->fseEntropy = 1;
+
+	/* reference dictionary content */
+	return ZSTD_refDictContent(dctx, dict, dictSize);
+}
+
+size_t ZSTD_decompressBegin_usingDict(ZSTD_DCtx *dctx, const void *dict, size_t dictSize)
+{
+	CHECK_F(ZSTD_decompressBegin(dctx));
+	if (dict && dictSize)
+		CHECK_E(ZSTD_decompress_insertDictionary(dctx, dict, dictSize), dictionary_corrupted);
+	return 0;
+}
+
+/* ======   ZSTD_DDict   ====== */
+
+struct ZSTD_DDict_s {
+	void *dictBuffer;
+	const void *dictContent;
+	size_t dictSize;
+	ZSTD_entropyTables_t entropy;
+	U32 dictID;
+	U32 entropyPresent;
+	ZSTD_customMem cMem;
+}; /* typedef'd to ZSTD_DDict within "zstd.h" */
+
+size_t ZSTD_DDictWorkspaceBound(void) { return ZSTD_ALIGN(sizeof(ZSTD_stack)) + ZSTD_ALIGN(sizeof(ZSTD_DDict)); }
+
+static const void *ZSTD_DDictDictContent(const ZSTD_DDict *ddict) { return ddict->dictContent; }
+
+static size_t ZSTD_DDictDictSize(const ZSTD_DDict *ddict) { return ddict->dictSize; }
+
+static void ZSTD_refDDict(ZSTD_DCtx *dstDCtx, const ZSTD_DDict *ddict)
+{
+	ZSTD_decompressBegin(dstDCtx); /* init */
+	if (ddict) {		       /* support refDDict on NULL */
+		dstDCtx->dictID = ddict->dictID;
+		dstDCtx->base = ddict->dictContent;
+		dstDCtx->vBase = ddict->dictContent;
+		dstDCtx->dictEnd = (const BYTE *)ddict->dictContent + ddict->dictSize;
+		dstDCtx->previousDstEnd = dstDCtx->dictEnd;
+		if (ddict->entropyPresent) {
+			dstDCtx->litEntropy = 1;
+			dstDCtx->fseEntropy = 1;
+			dstDCtx->LLTptr = ddict->entropy.LLTable;
+			dstDCtx->MLTptr = ddict->entropy.MLTable;
+			dstDCtx->OFTptr = ddict->entropy.OFTable;
+			dstDCtx->HUFptr = ddict->entropy.hufTable;
+			dstDCtx->entropy.rep[0] = ddict->entropy.rep[0];
+			dstDCtx->entropy.rep[1] = ddict->entropy.rep[1];
+			dstDCtx->entropy.rep[2] = ddict->entropy.rep[2];
+		} else {
+			dstDCtx->litEntropy = 0;
+			dstDCtx->fseEntropy = 0;
+		}
+	}
+}
+
+static size_t ZSTD_loadEntropy_inDDict(ZSTD_DDict *ddict)
+{
+	ddict->dictID = 0;
+	ddict->entropyPresent = 0;
+	if (ddict->dictSize < 8)
+		return 0;
+	{
+		U32 const magic = ZSTD_readLE32(ddict->dictContent);
+		if (magic != ZSTD_DICT_MAGIC)
+			return 0; /* pure content mode */
+	}
+	ddict->dictID = ZSTD_readLE32((const char *)ddict->dictContent + 4);
+
+	/* load entropy tables */
+	CHECK_E(ZSTD_loadEntropy(&ddict->entropy, ddict->dictContent, ddict->dictSize), dictionary_corrupted);
+	ddict->entropyPresent = 1;
+	return 0;
+}
+
+static ZSTD_DDict *ZSTD_createDDict_advanced(const void *dict, size_t dictSize, unsigned byReference, ZSTD_customMem customMem)
+{
+	if (!customMem.customAlloc || !customMem.customFree)
+		return NULL;
+
+	{
+		ZSTD_DDict *const ddict = (ZSTD_DDict *)ZSTD_malloc(sizeof(ZSTD_DDict), customMem);
+		if (!ddict)
+			return NULL;
+		ddict->cMem = customMem;
+
+		if ((byReference) || (!dict) || (!dictSize)) {
+			ddict->dictBuffer = NULL;
+			ddict->dictContent = dict;
+		} else {
+			void *const internalBuffer = ZSTD_malloc(dictSize, customMem);
+			if (!internalBuffer) {
+				ZSTD_freeDDict(ddict);
+				return NULL;
+			}
+			memcpy(internalBuffer, dict, dictSize);
+			ddict->dictBuffer = internalBuffer;
+			ddict->dictContent = internalBuffer;
+		}
+		ddict->dictSize = dictSize;
+		ddict->entropy.hufTable[0] = (HUF_DTable)((HufLog)*0x1000001); /* cover both little and big endian */
+		/* parse dictionary content */
+		{
+			size_t const errorCode = ZSTD_loadEntropy_inDDict(ddict);
+			if (ZSTD_isError(errorCode)) {
+				ZSTD_freeDDict(ddict);
+				return NULL;
+			}
+		}
+
+		return ddict;
+	}
+}
+
+/*! ZSTD_initDDict() :
+*   Create a digested dictionary, to start decompression without startup delay.
+*   `dict` content is copied inside DDict.
+*   Consequently, `dict` can be released after `ZSTD_DDict` creation */
+ZSTD_DDict *ZSTD_initDDict(const void *dict, size_t dictSize, void *workspace, size_t workspaceSize)
+{
+	ZSTD_customMem const stackMem = ZSTD_initStack(workspace, workspaceSize);
+	return ZSTD_createDDict_advanced(dict, dictSize, 1, stackMem);
+}
+
+size_t ZSTD_freeDDict(ZSTD_DDict *ddict)
+{
+	if (ddict == NULL)
+		return 0; /* support free on NULL */
+	{
+		ZSTD_customMem const cMem = ddict->cMem;
+		ZSTD_free(ddict->dictBuffer, cMem);
+		ZSTD_free(ddict, cMem);
+		return 0;
+	}
+}
+
+/*! ZSTD_getDictID_fromDict() :
+ *  Provides the dictID stored within dictionary.
+ *  if @return == 0, the dictionary is not conformant with Zstandard specification.
+ *  It can still be loaded, but as a content-only dictionary. */
+unsigned ZSTD_getDictID_fromDict(const void *dict, size_t dictSize)
+{
+	if (dictSize < 8)
+		return 0;
+	if (ZSTD_readLE32(dict) != ZSTD_DICT_MAGIC)
+		return 0;
+	return ZSTD_readLE32((const char *)dict + 4);
+}
+
+/*! ZSTD_getDictID_fromDDict() :
+ *  Provides the dictID of the dictionary loaded into `ddict`.
+ *  If @return == 0, the dictionary is not conformant to Zstandard specification, or empty.
+ *  Non-conformant dictionaries can still be loaded, but as content-only dictionaries. */
+unsigned ZSTD_getDictID_fromDDict(const ZSTD_DDict *ddict)
+{
+	if (ddict == NULL)
+		return 0;
+	return ZSTD_getDictID_fromDict(ddict->dictContent, ddict->dictSize);
+}
+
+/*! ZSTD_getDictID_fromFrame() :
+ *  Provides the dictID required to decompressed the frame stored within `src`.
+ *  If @return == 0, the dictID could not be decoded.
+ *  This could for one of the following reasons :
+ *  - The frame does not require a dictionary to be decoded (most common case).
+ *  - The frame was built with dictID intentionally removed. Whatever dictionary is necessary is a hidden information.
+ *    Note : this use case also happens when using a non-conformant dictionary.
+ *  - `srcSize` is too small, and as a result, the frame header could not be decoded (only possible if `srcSize < ZSTD_FRAMEHEADERSIZE_MAX`).
+ *  - This is not a Zstandard frame.
+ *  When identifying the exact failure cause, it's possible to used ZSTD_getFrameParams(), which will provide a more precise error code. */
+unsigned ZSTD_getDictID_fromFrame(const void *src, size_t srcSize)
+{
+	ZSTD_frameParams zfp = {0, 0, 0, 0};
+	size_t const hError = ZSTD_getFrameParams(&zfp, src, srcSize);
+	if (ZSTD_isError(hError))
+		return 0;
+	return zfp.dictID;
+}
+
+/*! ZSTD_decompress_usingDDict() :
+*   Decompression using a pre-digested Dictionary
+*   Use dictionary without significant overhead. */
+size_t ZSTD_decompress_usingDDict(ZSTD_DCtx *dctx, void *dst, size_t dstCapacity, const void *src, size_t srcSize, const ZSTD_DDict *ddict)
+{
+	/* pass content and size in case legacy frames are encountered */
+	return ZSTD_decompressMultiFrame(dctx, dst, dstCapacity, src, srcSize, NULL, 0, ddict);
+}
+
+/*=====================================
+*   Streaming decompression
+*====================================*/
+
+typedef enum { zdss_init, zdss_loadHeader, zdss_read, zdss_load, zdss_flush } ZSTD_dStreamStage;
+
+/* *** Resource management *** */
+struct ZSTD_DStream_s {
+	ZSTD_DCtx *dctx;
+	ZSTD_DDict *ddictLocal;
+	const ZSTD_DDict *ddict;
+	ZSTD_frameParams fParams;
+	ZSTD_dStreamStage stage;
+	char *inBuff;
+	size_t inBuffSize;
+	size_t inPos;
+	size_t maxWindowSize;
+	char *outBuff;
+	size_t outBuffSize;
+	size_t outStart;
+	size_t outEnd;
+	size_t blockSize;
+	BYTE headerBuffer[ZSTD_FRAMEHEADERSIZE_MAX]; /* tmp buffer to store frame header */
+	size_t lhSize;
+	ZSTD_customMem customMem;
+	void *legacyContext;
+	U32 previousLegacyVersion;
+	U32 legacyVersion;
+	U32 hostageByte;
+}; /* typedef'd to ZSTD_DStream within "zstd.h" */
+
+size_t ZSTD_DStreamWorkspaceBound(size_t maxWindowSize)
+{
+	size_t const blockSize = MIN(maxWindowSize, ZSTD_BLOCKSIZE_ABSOLUTEMAX);
+	size_t const inBuffSize = blockSize;
+	size_t const outBuffSize = maxWindowSize + blockSize + WILDCOPY_OVERLENGTH * 2;
+	return ZSTD_DCtxWorkspaceBound() + ZSTD_ALIGN(sizeof(ZSTD_DStream)) + ZSTD_ALIGN(inBuffSize) + ZSTD_ALIGN(outBuffSize);
+}
+
+static ZSTD_DStream *ZSTD_createDStream_advanced(ZSTD_customMem customMem)
+{
+	ZSTD_DStream *zds;
+
+	if (!customMem.customAlloc || !customMem.customFree)
+		return NULL;
+
+	zds = (ZSTD_DStream *)ZSTD_malloc(sizeof(ZSTD_DStream), customMem);
+	if (zds == NULL)
+		return NULL;
+	memset(zds, 0, sizeof(ZSTD_DStream));
+	memcpy(&zds->customMem, &customMem, sizeof(ZSTD_customMem));
+	zds->dctx = ZSTD_createDCtx_advanced(customMem);
+	if (zds->dctx == NULL) {
+		ZSTD_freeDStream(zds);
+		return NULL;
+	}
+	zds->stage = zdss_init;
+	zds->maxWindowSize = ZSTD_MAXWINDOWSIZE_DEFAULT;
+	return zds;
+}
+
+ZSTD_DStream *ZSTD_initDStream(size_t maxWindowSize, void *workspace, size_t workspaceSize)
+{
+	ZSTD_customMem const stackMem = ZSTD_initStack(workspace, workspaceSize);
+	ZSTD_DStream *zds = ZSTD_createDStream_advanced(stackMem);
+	if (!zds) {
+		return NULL;
+	}
+
+	zds->maxWindowSize = maxWindowSize;
+	zds->stage = zdss_loadHeader;
+	zds->lhSize = zds->inPos = zds->outStart = zds->outEnd = 0;
+	ZSTD_freeDDict(zds->ddictLocal);
+	zds->ddictLocal = NULL;
+	zds->ddict = zds->ddictLocal;
+	zds->legacyVersion = 0;
+	zds->hostageByte = 0;
+
+	{
+		size_t const blockSize = MIN(zds->maxWindowSize, ZSTD_BLOCKSIZE_ABSOLUTEMAX);
+		size_t const neededOutSize = zds->maxWindowSize + blockSize + WILDCOPY_OVERLENGTH * 2;
+
+		zds->inBuff = (char *)ZSTD_malloc(blockSize, zds->customMem);
+		zds->inBuffSize = blockSize;
+		zds->outBuff = (char *)ZSTD_malloc(neededOutSize, zds->customMem);
+		zds->outBuffSize = neededOutSize;
+		if (zds->inBuff == NULL || zds->outBuff == NULL) {
+			ZSTD_freeDStream(zds);
+			return NULL;
+		}
+	}
+	return zds;
+}
+
+ZSTD_DStream *ZSTD_initDStream_usingDDict(size_t maxWindowSize, const ZSTD_DDict *ddict, void *workspace, size_t workspaceSize)
+{
+	ZSTD_DStream *zds = ZSTD_initDStream(maxWindowSize, workspace, workspaceSize);
+	if (zds) {
+		zds->ddict = ddict;
+	}
+	return zds;
+}
+
+size_t ZSTD_freeDStream(ZSTD_DStream *zds)
+{
+	if (zds == NULL)
+		return 0; /* support free on null */
+	{
+		ZSTD_customMem const cMem = zds->customMem;
+		ZSTD_freeDCtx(zds->dctx);
+		zds->dctx = NULL;
+		ZSTD_freeDDict(zds->ddictLocal);
+		zds->ddictLocal = NULL;
+		ZSTD_free(zds->inBuff, cMem);
+		zds->inBuff = NULL;
+		ZSTD_free(zds->outBuff, cMem);
+		zds->outBuff = NULL;
+		ZSTD_free(zds, cMem);
+		return 0;
+	}
+}
+
+/* *** Initialization *** */
+
+size_t ZSTD_DStreamInSize(void) { return ZSTD_BLOCKSIZE_ABSOLUTEMAX + ZSTD_blockHeaderSize; }
+size_t ZSTD_DStreamOutSize(void) { return ZSTD_BLOCKSIZE_ABSOLUTEMAX; }
+
+size_t ZSTD_resetDStream(ZSTD_DStream *zds)
+{
+	zds->stage = zdss_loadHeader;
+	zds->lhSize = zds->inPos = zds->outStart = zds->outEnd = 0;
+	zds->legacyVersion = 0;
+	zds->hostageByte = 0;
+	return ZSTD_frameHeaderSize_prefix;
+}
+
+/* *****   Decompression   ***** */
+
+ZSTD_STATIC size_t ZSTD_limitCopy(void *dst, size_t dstCapacity, const void *src, size_t srcSize)
+{
+	size_t const length = MIN(dstCapacity, srcSize);
+	memcpy(dst, src, length);
+	return length;
+}
+
+size_t ZSTD_decompressStream(ZSTD_DStream *zds, ZSTD_outBuffer *output, ZSTD_inBuffer *input)
+{
+	const char *const istart = (const char *)(input->src) + input->pos;
+	const char *const iend = (const char *)(input->src) + input->size;
+	const char *ip = istart;
+	char *const ostart = (char *)(output->dst) + output->pos;
+	char *const oend = (char *)(output->dst) + output->size;
+	char *op = ostart;
+	U32 someMoreWork = 1;
+
+	while (someMoreWork) {
+		switch (zds->stage) {
+		case zdss_init:
+			ZSTD_resetDStream(zds); /* transparent reset on starting decoding a new frame */
+						/* fall-through */
+
+		case zdss_loadHeader: {
+			size_t const hSize = ZSTD_getFrameParams(&zds->fParams, zds->headerBuffer, zds->lhSize);
+			if (ZSTD_isError(hSize))
+				return hSize;
+			if (hSize != 0) {				   /* need more input */
+				size_t const toLoad = hSize - zds->lhSize; /* if hSize!=0, hSize > zds->lhSize */
+				if (toLoad > (size_t)(iend - ip)) {	/* not enough input to load full header */
+					memcpy(zds->headerBuffer + zds->lhSize, ip, iend - ip);
+					zds->lhSize += iend - ip;
+					input->pos = input->size;
+					return (MAX(ZSTD_frameHeaderSize_min, hSize) - zds->lhSize) +
+					       ZSTD_blockHeaderSize; /* remaining header bytes + next block header */
+				}
+				memcpy(zds->headerBuffer + zds->lhSize, ip, toLoad);
+				zds->lhSize = hSize;
+				ip += toLoad;
+				break;
+			}
+
+			/* check for single-pass mode opportunity */
+			if (zds->fParams.frameContentSize && zds->fParams.windowSize /* skippable frame if == 0 */
+			    && (U64)(size_t)(oend - op) >= zds->fParams.frameContentSize) {
+				size_t const cSize = ZSTD_findFrameCompressedSize(istart, iend - istart);
+				if (cSize <= (size_t)(iend - istart)) {
+					size_t const decompressedSize = ZSTD_decompress_usingDDict(zds->dctx, op, oend - op, istart, cSize, zds->ddict);
+					if (ZSTD_isError(decompressedSize))
+						return decompressedSize;
+					ip = istart + cSize;
+					op += decompressedSize;
+					zds->dctx->expected = 0;
+					zds->stage = zdss_init;
+					someMoreWork = 0;
+					break;
+				}
+			}
+
+			/* Consume header */
+			ZSTD_refDDict(zds->dctx, zds->ddict);
+			{
+				size_t const h1Size = ZSTD_nextSrcSizeToDecompress(zds->dctx); /* == ZSTD_frameHeaderSize_prefix */
+				CHECK_F(ZSTD_decompressContinue(zds->dctx, NULL, 0, zds->headerBuffer, h1Size));
+				{
+					size_t const h2Size = ZSTD_nextSrcSizeToDecompress(zds->dctx);
+					CHECK_F(ZSTD_decompressContinue(zds->dctx, NULL, 0, zds->headerBuffer + h1Size, h2Size));
+				}
+			}
+
+			zds->fParams.windowSize = MAX(zds->fParams.windowSize, 1U << ZSTD_WINDOWLOG_ABSOLUTEMIN);
+			if (zds->fParams.windowSize > zds->maxWindowSize)
+				return ERROR(frameParameter_windowTooLarge);
+
+			/* Buffers are preallocated, but double check */
+			{
+				size_t const blockSize = MIN(zds->maxWindowSize, ZSTD_BLOCKSIZE_ABSOLUTEMAX);
+				size_t const neededOutSize = zds->maxWindowSize + blockSize + WILDCOPY_OVERLENGTH * 2;
+				if (zds->inBuffSize < blockSize) {
+					return ERROR(GENERIC);
+				}
+				if (zds->outBuffSize < neededOutSize) {
+					return ERROR(GENERIC);
+				}
+				zds->blockSize = blockSize;
+			}
+			zds->stage = zdss_read;
+		}
+		/* pass-through */
+
+		case zdss_read: {
+			size_t const neededInSize = ZSTD_nextSrcSizeToDecompress(zds->dctx);
+			if (neededInSize == 0) { /* end of frame */
+				zds->stage = zdss_init;
+				someMoreWork = 0;
+				break;
+			}
+			if ((size_t)(iend - ip) >= neededInSize) { /* decode directly from src */
+				const int isSkipFrame = ZSTD_isSkipFrame(zds->dctx);
+				size_t const decodedSize = ZSTD_decompressContinue(zds->dctx, zds->outBuff + zds->outStart,
+										   (isSkipFrame ? 0 : zds->outBuffSize - zds->outStart), ip, neededInSize);
+				if (ZSTD_isError(decodedSize))
+					return decodedSize;
+				ip += neededInSize;
+				if (!decodedSize && !isSkipFrame)
+					break; /* this was just a header */
+				zds->outEnd = zds->outStart + decodedSize;
+				zds->stage = zdss_flush;
+				break;
+			}
+			if (ip == iend) {
+				someMoreWork = 0;
+				break;
+			} /* no more input */
+			zds->stage = zdss_load;
+			/* pass-through */
+		}
+
+		case zdss_load: {
+			size_t const neededInSize = ZSTD_nextSrcSizeToDecompress(zds->dctx);
+			size_t const toLoad = neededInSize - zds->inPos; /* should always be <= remaining space within inBuff */
+			size_t loadedSize;
+			if (toLoad > zds->inBuffSize - zds->inPos)
+				return ERROR(corruption_detected); /* should never happen */
+			loadedSize = ZSTD_limitCopy(zds->inBuff + zds->inPos, toLoad, ip, iend - ip);
+			ip += loadedSize;
+			zds->inPos += loadedSize;
+			if (loadedSize < toLoad) {
+				someMoreWork = 0;
+				break;
+			} /* not enough input, wait for more */
+
+			/* decode loaded input */
+			{
+				const int isSkipFrame = ZSTD_isSkipFrame(zds->dctx);
+				size_t const decodedSize = ZSTD_decompressContinue(zds->dctx, zds->outBuff + zds->outStart, zds->outBuffSize - zds->outStart,
+										   zds->inBuff, neededInSize);
+				if (ZSTD_isError(decodedSize))
+					return decodedSize;
+				zds->inPos = 0; /* input is consumed */
+				if (!decodedSize && !isSkipFrame) {
+					zds->stage = zdss_read;
+					break;
+				} /* this was just a header */
+				zds->outEnd = zds->outStart + decodedSize;
+				zds->stage = zdss_flush;
+				/* pass-through */
+			}
+		}
+
+		case zdss_flush: {
+			size_t const toFlushSize = zds->outEnd - zds->outStart;
+			size_t const flushedSize = ZSTD_limitCopy(op, oend - op, zds->outBuff + zds->outStart, toFlushSize);
+			op += flushedSize;
+			zds->outStart += flushedSize;
+			if (flushedSize == toFlushSize) { /* flush completed */
+				zds->stage = zdss_read;
+				if (zds->outStart + zds->blockSize > zds->outBuffSize)
+					zds->outStart = zds->outEnd = 0;
+				break;
+			}
+			/* cannot complete flush */
+			someMoreWork = 0;
+			break;
+		}
+		default:
+			return ERROR(GENERIC); /* impossible */
+		}
+	}
+
+	/* result */
+	input->pos += (size_t)(ip - istart);
+	output->pos += (size_t)(op - ostart);
+	{
+		size_t nextSrcSizeHint = ZSTD_nextSrcSizeToDecompress(zds->dctx);
+		if (!nextSrcSizeHint) {			    /* frame fully decoded */
+			if (zds->outEnd == zds->outStart) { /* output fully flushed */
+				if (zds->hostageByte) {
+					if (input->pos >= input->size) {
+						zds->stage = zdss_read;
+						return 1;
+					}	     /* can't release hostage (not present) */
+					input->pos++; /* release hostage */
+				}
+				return 0;
+			}
+			if (!zds->hostageByte) { /* output not fully flushed; keep last byte as hostage; will be released when all output is flushed */
+				input->pos--;    /* note : pos > 0, otherwise, impossible to finish reading last block */
+				zds->hostageByte = 1;
+			}
+			return 1;
+		}
+		nextSrcSizeHint += ZSTD_blockHeaderSize * (ZSTD_nextInputType(zds->dctx) == ZSTDnit_block); /* preload header of next block */
+		if (zds->inPos > nextSrcSizeHint)
+			return ERROR(GENERIC); /* should never happen */
+		nextSrcSizeHint -= zds->inPos; /* already loaded*/
+		return nextSrcSizeHint;
+	}
+}
+
+EXPORT_SYMBOL(ZSTD_DCtxWorkspaceBound);
+EXPORT_SYMBOL(ZSTD_initDCtx);
+EXPORT_SYMBOL(ZSTD_decompressDCtx);
+EXPORT_SYMBOL(ZSTD_decompress_usingDict);
+
+EXPORT_SYMBOL(ZSTD_DDictWorkspaceBound);
+EXPORT_SYMBOL(ZSTD_initDDict);
+EXPORT_SYMBOL(ZSTD_decompress_usingDDict);
+
+EXPORT_SYMBOL(ZSTD_DStreamWorkspaceBound);
+EXPORT_SYMBOL(ZSTD_initDStream);
+EXPORT_SYMBOL(ZSTD_initDStream_usingDDict);
+EXPORT_SYMBOL(ZSTD_resetDStream);
+EXPORT_SYMBOL(ZSTD_decompressStream);
+EXPORT_SYMBOL(ZSTD_DStreamInSize);
+EXPORT_SYMBOL(ZSTD_DStreamOutSize);
+
+EXPORT_SYMBOL(ZSTD_findFrameCompressedSize);
+EXPORT_SYMBOL(ZSTD_getFrameContentSize);
+EXPORT_SYMBOL(ZSTD_findDecompressedSize);
+
+EXPORT_SYMBOL(ZSTD_isFrame);
+EXPORT_SYMBOL(ZSTD_getDictID_fromDict);
+EXPORT_SYMBOL(ZSTD_getDictID_fromDDict);
+EXPORT_SYMBOL(ZSTD_getDictID_fromFrame);
+
+EXPORT_SYMBOL(ZSTD_getFrameParams);
+EXPORT_SYMBOL(ZSTD_decompressBegin);
+EXPORT_SYMBOL(ZSTD_decompressBegin_usingDict);
+EXPORT_SYMBOL(ZSTD_copyDCtx);
+EXPORT_SYMBOL(ZSTD_nextSrcSizeToDecompress);
+EXPORT_SYMBOL(ZSTD_decompressContinue);
+EXPORT_SYMBOL(ZSTD_nextInputType);
+
+EXPORT_SYMBOL(ZSTD_decompressBlock);
+EXPORT_SYMBOL(ZSTD_insertBlock);
+
+MODULE_LICENSE("Dual BSD/GPL");
+MODULE_DESCRIPTION("Zstd Decompressor");
diff -Naurp -x debian.hwe linux-4.10.x.ori/lib/zstd/entropy_common.c linux-4.10.x/lib/zstd/entropy_common.c
--- linux-4.10.x.ori/lib/zstd/entropy_common.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-4.10.x/lib/zstd/entropy_common.c	2017-10-30 10:05:19.610447000 +0100
@@ -0,0 +1,243 @@
+/*
+ * Common functions of New Generation Entropy library
+ * Copyright (C) 2016, Yann Collet.
+ *
+ * BSD 2-Clause License (http://www.opensource.org/licenses/bsd-license.php)
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ * notice, this list of conditions and the following disclaimer.
+ *   * Redistributions in binary form must reproduce the above
+ * copyright notice, this list of conditions and the following disclaimer
+ * in the documentation and/or other materials provided with the
+ * distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ * This program is free software; you can redistribute it and/or modify it under
+ * the terms of the GNU General Public License version 2 as published by the
+ * Free Software Foundation. This program is dual-licensed; you may select
+ * either version 2 of the GNU General Public License ("GPL") or BSD license
+ * ("BSD").
+ *
+ * You can contact the author at :
+ * - Source repository : https://github.com/Cyan4973/FiniteStateEntropy
+ */
+
+/* *************************************
+*  Dependencies
+***************************************/
+#include "error_private.h" /* ERR_*, ERROR */
+#include "fse.h"
+#include "huf.h"
+#include "mem.h"
+
+/*===   Version   ===*/
+unsigned FSE_versionNumber(void) { return FSE_VERSION_NUMBER; }
+
+/*===   Error Management   ===*/
+unsigned FSE_isError(size_t code) { return ERR_isError(code); }
+
+unsigned HUF_isError(size_t code) { return ERR_isError(code); }
+
+/*-**************************************************************
+*  FSE NCount encoding-decoding
+****************************************************************/
+size_t FSE_readNCount(short *normalizedCounter, unsigned *maxSVPtr, unsigned *tableLogPtr, const void *headerBuffer, size_t hbSize)
+{
+	const BYTE *const istart = (const BYTE *)headerBuffer;
+	const BYTE *const iend = istart + hbSize;
+	const BYTE *ip = istart;
+	int nbBits;
+	int remaining;
+	int threshold;
+	U32 bitStream;
+	int bitCount;
+	unsigned charnum = 0;
+	int previous0 = 0;
+
+	if (hbSize < 4)
+		return ERROR(srcSize_wrong);
+	bitStream = ZSTD_readLE32(ip);
+	nbBits = (bitStream & 0xF) + FSE_MIN_TABLELOG; /* extract tableLog */
+	if (nbBits > FSE_TABLELOG_ABSOLUTE_MAX)
+		return ERROR(tableLog_tooLarge);
+	bitStream >>= 4;
+	bitCount = 4;
+	*tableLogPtr = nbBits;
+	remaining = (1 << nbBits) + 1;
+	threshold = 1 << nbBits;
+	nbBits++;
+
+	while ((remaining > 1) & (charnum <= *maxSVPtr)) {
+		if (previous0) {
+			unsigned n0 = charnum;
+			while ((bitStream & 0xFFFF) == 0xFFFF) {
+				n0 += 24;
+				if (ip < iend - 5) {
+					ip += 2;
+					bitStream = ZSTD_readLE32(ip) >> bitCount;
+				} else {
+					bitStream >>= 16;
+					bitCount += 16;
+				}
+			}
+			while ((bitStream & 3) == 3) {
+				n0 += 3;
+				bitStream >>= 2;
+				bitCount += 2;
+			}
+			n0 += bitStream & 3;
+			bitCount += 2;
+			if (n0 > *maxSVPtr)
+				return ERROR(maxSymbolValue_tooSmall);
+			while (charnum < n0)
+				normalizedCounter[charnum++] = 0;
+			if ((ip <= iend - 7) || (ip + (bitCount >> 3) <= iend - 4)) {
+				ip += bitCount >> 3;
+				bitCount &= 7;
+				bitStream = ZSTD_readLE32(ip) >> bitCount;
+			} else {
+				bitStream >>= 2;
+			}
+		}
+		{
+			int const max = (2 * threshold - 1) - remaining;
+			int count;
+
+			if ((bitStream & (threshold - 1)) < (U32)max) {
+				count = bitStream & (threshold - 1);
+				bitCount += nbBits - 1;
+			} else {
+				count = bitStream & (2 * threshold - 1);
+				if (count >= threshold)
+					count -= max;
+				bitCount += nbBits;
+			}
+
+			count--;				 /* extra accuracy */
+			remaining -= count < 0 ? -count : count; /* -1 means +1 */
+			normalizedCounter[charnum++] = (short)count;
+			previous0 = !count;
+			while (remaining < threshold) {
+				nbBits--;
+				threshold >>= 1;
+			}
+
+			if ((ip <= iend - 7) || (ip + (bitCount >> 3) <= iend - 4)) {
+				ip += bitCount >> 3;
+				bitCount &= 7;
+			} else {
+				bitCount -= (int)(8 * (iend - 4 - ip));
+				ip = iend - 4;
+			}
+			bitStream = ZSTD_readLE32(ip) >> (bitCount & 31);
+		}
+	} /* while ((remaining>1) & (charnum<=*maxSVPtr)) */
+	if (remaining != 1)
+		return ERROR(corruption_detected);
+	if (bitCount > 32)
+		return ERROR(corruption_detected);
+	*maxSVPtr = charnum - 1;
+
+	ip += (bitCount + 7) >> 3;
+	return ip - istart;
+}
+
+/*! HUF_readStats() :
+	Read compact Huffman tree, saved by HUF_writeCTable().
+	`huffWeight` is destination buffer.
+	`rankStats` is assumed to be a table of at least HUF_TABLELOG_MAX U32.
+	@return : size read from `src` , or an error Code .
+	Note : Needed by HUF_readCTable() and HUF_readDTableX?() .
+*/
+size_t HUF_readStats_wksp(BYTE *huffWeight, size_t hwSize, U32 *rankStats, U32 *nbSymbolsPtr, U32 *tableLogPtr, const void *src, size_t srcSize, void *workspace, size_t workspaceSize)
+{
+	U32 weightTotal;
+	const BYTE *ip = (const BYTE *)src;
+	size_t iSize;
+	size_t oSize;
+
+	if (!srcSize)
+		return ERROR(srcSize_wrong);
+	iSize = ip[0];
+	/* memset(huffWeight, 0, hwSize);   */ /* is not necessary, even though some analyzer complain ... */
+
+	if (iSize >= 128) { /* special header */
+		oSize = iSize - 127;
+		iSize = ((oSize + 1) / 2);
+		if (iSize + 1 > srcSize)
+			return ERROR(srcSize_wrong);
+		if (oSize >= hwSize)
+			return ERROR(corruption_detected);
+		ip += 1;
+		{
+			U32 n;
+			for (n = 0; n < oSize; n += 2) {
+				huffWeight[n] = ip[n / 2] >> 4;
+				huffWeight[n + 1] = ip[n / 2] & 15;
+			}
+		}
+	} else {						 /* header compressed with FSE (normal case) */
+		if (iSize + 1 > srcSize)
+			return ERROR(srcSize_wrong);
+		oSize = FSE_decompress_wksp(huffWeight, hwSize - 1, ip + 1, iSize, 6, workspace, workspaceSize); /* max (hwSize-1) values decoded, as last one is implied */
+		if (FSE_isError(oSize))
+			return oSize;
+	}
+
+	/* collect weight stats */
+	memset(rankStats, 0, (HUF_TABLELOG_MAX + 1) * sizeof(U32));
+	weightTotal = 0;
+	{
+		U32 n;
+		for (n = 0; n < oSize; n++) {
+			if (huffWeight[n] >= HUF_TABLELOG_MAX)
+				return ERROR(corruption_detected);
+			rankStats[huffWeight[n]]++;
+			weightTotal += (1 << huffWeight[n]) >> 1;
+		}
+	}
+	if (weightTotal == 0)
+		return ERROR(corruption_detected);
+
+	/* get last non-null symbol weight (implied, total must be 2^n) */
+	{
+		U32 const tableLog = BIT_highbit32(weightTotal) + 1;
+		if (tableLog > HUF_TABLELOG_MAX)
+			return ERROR(corruption_detected);
+		*tableLogPtr = tableLog;
+		/* determine last weight */
+		{
+			U32 const total = 1 << tableLog;
+			U32 const rest = total - weightTotal;
+			U32 const verif = 1 << BIT_highbit32(rest);
+			U32 const lastWeight = BIT_highbit32(rest) + 1;
+			if (verif != rest)
+				return ERROR(corruption_detected); /* last value must be a clean power of 2 */
+			huffWeight[oSize] = (BYTE)lastWeight;
+			rankStats[lastWeight]++;
+		}
+	}
+
+	/* check tree construction validity */
+	if ((rankStats[1] < 2) || (rankStats[1] & 1))
+		return ERROR(corruption_detected); /* by construction : at least 2 elts of rank 1, must be even */
+
+	/* results */
+	*nbSymbolsPtr = (U32)(oSize + 1);
+	return iSize + 1;
+}
diff -Naurp -x debian.hwe linux-4.10.x.ori/lib/zstd/error_private.h linux-4.10.x/lib/zstd/error_private.h
--- linux-4.10.x.ori/lib/zstd/error_private.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-4.10.x/lib/zstd/error_private.h	2017-10-30 10:05:19.610447000 +0100
@@ -0,0 +1,51 @@
+/**
+ * Copyright (c) 2016-present, Yann Collet, Facebook, Inc.
+ * All rights reserved.
+ *
+ * This source code is licensed under the BSD-style license found in the
+ * LICENSE file in the root directory of https://github.com/facebook/zstd.
+ *
+ * This program is free software; you can redistribute it and/or modify it under
+ * the terms of the GNU General Public License version 2 as published by the
+ * Free Software Foundation. This program is dual-licensed; you may select
+ * either version 2 of the GNU General Public License ("GPL") or BSD license
+ * ("BSD").
+ */
+
+/* Note : this module is expected to remain private, do not expose it */
+
+#ifndef ERROR_H_MODULE
+#define ERROR_H_MODULE
+
+/* ****************************************
+*  Dependencies
+******************************************/
+#include <linux/types.h> /* size_t */
+#include <linux/zstd.h>  /* enum list */
+
+/* ****************************************
+*  Compiler-specific
+******************************************/
+#define ERR_STATIC static __attribute__((unused))
+
+/*-****************************************
+*  Customization (error_public.h)
+******************************************/
+typedef ZSTD_ErrorCode ERR_enum;
+#define PREFIX(name) ZSTD_error_##name
+
+/*-****************************************
+*  Error codes handling
+******************************************/
+#define ERROR(name) ((size_t)-PREFIX(name))
+
+ERR_STATIC unsigned ERR_isError(size_t code) { return (code > ERROR(maxCode)); }
+
+ERR_STATIC ERR_enum ERR_getErrorCode(size_t code)
+{
+	if (!ERR_isError(code))
+		return (ERR_enum)0;
+	return (ERR_enum)(0 - code);
+}
+
+#endif /* ERROR_H_MODULE */
diff -Naurp -x debian.hwe linux-4.10.x.ori/lib/zstd/fse_compress.c linux-4.10.x/lib/zstd/fse_compress.c
--- linux-4.10.x.ori/lib/zstd/fse_compress.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-4.10.x/lib/zstd/fse_compress.c	2017-10-30 10:05:19.610447000 +0100
@@ -0,0 +1,795 @@
+/*
+ * FSE : Finite State Entropy encoder
+ * Copyright (C) 2013-2015, Yann Collet.
+ *
+ * BSD 2-Clause License (http://www.opensource.org/licenses/bsd-license.php)
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ * notice, this list of conditions and the following disclaimer.
+ *   * Redistributions in binary form must reproduce the above
+ * copyright notice, this list of conditions and the following disclaimer
+ * in the documentation and/or other materials provided with the
+ * distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ * This program is free software; you can redistribute it and/or modify it under
+ * the terms of the GNU General Public License version 2 as published by the
+ * Free Software Foundation. This program is dual-licensed; you may select
+ * either version 2 of the GNU General Public License ("GPL") or BSD license
+ * ("BSD").
+ *
+ * You can contact the author at :
+ * - Source repository : https://github.com/Cyan4973/FiniteStateEntropy
+ */
+
+/* **************************************************************
+*  Compiler specifics
+****************************************************************/
+#define FORCE_INLINE static __always_inline
+
+/* **************************************************************
+*  Includes
+****************************************************************/
+#include "bitstream.h"
+#include "fse.h"
+#include <linux/compiler.h>
+#include <linux/kernel.h>
+#include <linux/math64.h>
+#include <linux/string.h> /* memcpy, memset */
+
+/* **************************************************************
+*  Error Management
+****************************************************************/
+#define FSE_STATIC_ASSERT(c)                                   \
+	{                                                      \
+		enum { FSE_static_assert = 1 / (int)(!!(c)) }; \
+	} /* use only *after* variable declarations */
+
+/* **************************************************************
+*  Templates
+****************************************************************/
+/*
+  designed to be included
+  for type-specific functions (template emulation in C)
+  Objective is to write these functions only once, for improved maintenance
+*/
+
+/* safety checks */
+#ifndef FSE_FUNCTION_EXTENSION
+#error "FSE_FUNCTION_EXTENSION must be defined"
+#endif
+#ifndef FSE_FUNCTION_TYPE
+#error "FSE_FUNCTION_TYPE must be defined"
+#endif
+
+/* Function names */
+#define FSE_CAT(X, Y) X##Y
+#define FSE_FUNCTION_NAME(X, Y) FSE_CAT(X, Y)
+#define FSE_TYPE_NAME(X, Y) FSE_CAT(X, Y)
+
+/* Function templates */
+
+/* FSE_buildCTable_wksp() :
+ * Same as FSE_buildCTable(), but using an externally allocated scratch buffer (`workSpace`).
+ * wkspSize should be sized to handle worst case situation, which is `1<<max_tableLog * sizeof(FSE_FUNCTION_TYPE)`
+ * workSpace must also be properly aligned with FSE_FUNCTION_TYPE requirements
+ */
+size_t FSE_buildCTable_wksp(FSE_CTable *ct, const short *normalizedCounter, unsigned maxSymbolValue, unsigned tableLog, void *workspace, size_t workspaceSize)
+{
+	U32 const tableSize = 1 << tableLog;
+	U32 const tableMask = tableSize - 1;
+	void *const ptr = ct;
+	U16 *const tableU16 = ((U16 *)ptr) + 2;
+	void *const FSCT = ((U32 *)ptr) + 1 /* header */ + (tableLog ? tableSize >> 1 : 1);
+	FSE_symbolCompressionTransform *const symbolTT = (FSE_symbolCompressionTransform *)(FSCT);
+	U32 const step = FSE_TABLESTEP(tableSize);
+	U32 highThreshold = tableSize - 1;
+
+	U32 *cumul;
+	FSE_FUNCTION_TYPE *tableSymbol;
+	size_t spaceUsed32 = 0;
+
+	cumul = (U32 *)workspace + spaceUsed32;
+	spaceUsed32 += FSE_MAX_SYMBOL_VALUE + 2;
+	tableSymbol = (FSE_FUNCTION_TYPE *)((U32 *)workspace + spaceUsed32);
+	spaceUsed32 += ALIGN(sizeof(FSE_FUNCTION_TYPE) * ((size_t)1 << tableLog), sizeof(U32)) >> 2;
+
+	if ((spaceUsed32 << 2) > workspaceSize)
+		return ERROR(tableLog_tooLarge);
+	workspace = (U32 *)workspace + spaceUsed32;
+	workspaceSize -= (spaceUsed32 << 2);
+
+	/* CTable header */
+	tableU16[-2] = (U16)tableLog;
+	tableU16[-1] = (U16)maxSymbolValue;
+
+	/* For explanations on how to distribute symbol values over the table :
+	*  http://fastcompression.blogspot.fr/2014/02/fse-distributing-symbol-values.html */
+
+	/* symbol start positions */
+	{
+		U32 u;
+		cumul[0] = 0;
+		for (u = 1; u <= maxSymbolValue + 1; u++) {
+			if (normalizedCounter[u - 1] == -1) { /* Low proba symbol */
+				cumul[u] = cumul[u - 1] + 1;
+				tableSymbol[highThreshold--] = (FSE_FUNCTION_TYPE)(u - 1);
+			} else {
+				cumul[u] = cumul[u - 1] + normalizedCounter[u - 1];
+			}
+		}
+		cumul[maxSymbolValue + 1] = tableSize + 1;
+	}
+
+	/* Spread symbols */
+	{
+		U32 position = 0;
+		U32 symbol;
+		for (symbol = 0; symbol <= maxSymbolValue; symbol++) {
+			int nbOccurences;
+			for (nbOccurences = 0; nbOccurences < normalizedCounter[symbol]; nbOccurences++) {
+				tableSymbol[position] = (FSE_FUNCTION_TYPE)symbol;
+				position = (position + step) & tableMask;
+				while (position > highThreshold)
+					position = (position + step) & tableMask; /* Low proba area */
+			}
+		}
+
+		if (position != 0)
+			return ERROR(GENERIC); /* Must have gone through all positions */
+	}
+
+	/* Build table */
+	{
+		U32 u;
+		for (u = 0; u < tableSize; u++) {
+			FSE_FUNCTION_TYPE s = tableSymbol[u];	/* note : static analyzer may not understand tableSymbol is properly initialized */
+			tableU16[cumul[s]++] = (U16)(tableSize + u); /* TableU16 : sorted by symbol order; gives next state value */
+		}
+	}
+
+	/* Build Symbol Transformation Table */
+	{
+		unsigned total = 0;
+		unsigned s;
+		for (s = 0; s <= maxSymbolValue; s++) {
+			switch (normalizedCounter[s]) {
+			case 0: break;
+
+			case -1:
+			case 1:
+				symbolTT[s].deltaNbBits = (tableLog << 16) - (1 << tableLog);
+				symbolTT[s].deltaFindState = total - 1;
+				total++;
+				break;
+			default: {
+				U32 const maxBitsOut = tableLog - BIT_highbit32(normalizedCounter[s] - 1);
+				U32 const minStatePlus = normalizedCounter[s] << maxBitsOut;
+				symbolTT[s].deltaNbBits = (maxBitsOut << 16) - minStatePlus;
+				symbolTT[s].deltaFindState = total - normalizedCounter[s];
+				total += normalizedCounter[s];
+			}
+			}
+		}
+	}
+
+	return 0;
+}
+
+/*-**************************************************************
+*  FSE NCount encoding-decoding
+****************************************************************/
+size_t FSE_NCountWriteBound(unsigned maxSymbolValue, unsigned tableLog)
+{
+	size_t const maxHeaderSize = (((maxSymbolValue + 1) * tableLog) >> 3) + 3;
+	return maxSymbolValue ? maxHeaderSize : FSE_NCOUNTBOUND; /* maxSymbolValue==0 ? use default */
+}
+
+static size_t FSE_writeNCount_generic(void *header, size_t headerBufferSize, const short *normalizedCounter, unsigned maxSymbolValue, unsigned tableLog,
+				      unsigned writeIsSafe)
+{
+	BYTE *const ostart = (BYTE *)header;
+	BYTE *out = ostart;
+	BYTE *const oend = ostart + headerBufferSize;
+	int nbBits;
+	const int tableSize = 1 << tableLog;
+	int remaining;
+	int threshold;
+	U32 bitStream;
+	int bitCount;
+	unsigned charnum = 0;
+	int previous0 = 0;
+
+	bitStream = 0;
+	bitCount = 0;
+	/* Table Size */
+	bitStream += (tableLog - FSE_MIN_TABLELOG) << bitCount;
+	bitCount += 4;
+
+	/* Init */
+	remaining = tableSize + 1; /* +1 for extra accuracy */
+	threshold = tableSize;
+	nbBits = tableLog + 1;
+
+	while (remaining > 1) { /* stops at 1 */
+		if (previous0) {
+			unsigned start = charnum;
+			while (!normalizedCounter[charnum])
+				charnum++;
+			while (charnum >= start + 24) {
+				start += 24;
+				bitStream += 0xFFFFU << bitCount;
+				if ((!writeIsSafe) && (out > oend - 2))
+					return ERROR(dstSize_tooSmall); /* Buffer overflow */
+				out[0] = (BYTE)bitStream;
+				out[1] = (BYTE)(bitStream >> 8);
+				out += 2;
+				bitStream >>= 16;
+			}
+			while (charnum >= start + 3) {
+				start += 3;
+				bitStream += 3 << bitCount;
+				bitCount += 2;
+			}
+			bitStream += (charnum - start) << bitCount;
+			bitCount += 2;
+			if (bitCount > 16) {
+				if ((!writeIsSafe) && (out > oend - 2))
+					return ERROR(dstSize_tooSmall); /* Buffer overflow */
+				out[0] = (BYTE)bitStream;
+				out[1] = (BYTE)(bitStream >> 8);
+				out += 2;
+				bitStream >>= 16;
+				bitCount -= 16;
+			}
+		}
+		{
+			int count = normalizedCounter[charnum++];
+			int const max = (2 * threshold - 1) - remaining;
+			remaining -= count < 0 ? -count : count;
+			count++; /* +1 for extra accuracy */
+			if (count >= threshold)
+				count += max; /* [0..max[ [max..threshold[ (...) [threshold+max 2*threshold[ */
+			bitStream += count << bitCount;
+			bitCount += nbBits;
+			bitCount -= (count < max);
+			previous0 = (count == 1);
+			if (remaining < 1)
+				return ERROR(GENERIC);
+			while (remaining < threshold)
+				nbBits--, threshold >>= 1;
+		}
+		if (bitCount > 16) {
+			if ((!writeIsSafe) && (out > oend - 2))
+				return ERROR(dstSize_tooSmall); /* Buffer overflow */
+			out[0] = (BYTE)bitStream;
+			out[1] = (BYTE)(bitStream >> 8);
+			out += 2;
+			bitStream >>= 16;
+			bitCount -= 16;
+		}
+	}
+
+	/* flush remaining bitStream */
+	if ((!writeIsSafe) && (out > oend - 2))
+		return ERROR(dstSize_tooSmall); /* Buffer overflow */
+	out[0] = (BYTE)bitStream;
+	out[1] = (BYTE)(bitStream >> 8);
+	out += (bitCount + 7) / 8;
+
+	if (charnum > maxSymbolValue + 1)
+		return ERROR(GENERIC);
+
+	return (out - ostart);
+}
+
+size_t FSE_writeNCount(void *buffer, size_t bufferSize, const short *normalizedCounter, unsigned maxSymbolValue, unsigned tableLog)
+{
+	if (tableLog > FSE_MAX_TABLELOG)
+		return ERROR(tableLog_tooLarge); /* Unsupported */
+	if (tableLog < FSE_MIN_TABLELOG)
+		return ERROR(GENERIC); /* Unsupported */
+
+	if (bufferSize < FSE_NCountWriteBound(maxSymbolValue, tableLog))
+		return FSE_writeNCount_generic(buffer, bufferSize, normalizedCounter, maxSymbolValue, tableLog, 0);
+
+	return FSE_writeNCount_generic(buffer, bufferSize, normalizedCounter, maxSymbolValue, tableLog, 1);
+}
+
+/*-**************************************************************
+*  Counting histogram
+****************************************************************/
+/*! FSE_count_simple
+	This function counts byte values within `src`, and store the histogram into table `count`.
+	It doesn't use any additional memory.
+	But this function is unsafe : it doesn't check that all values within `src` can fit into `count`.
+	For this reason, prefer using a table `count` with 256 elements.
+	@return : count of most numerous element
+*/
+size_t FSE_count_simple(unsigned *count, unsigned *maxSymbolValuePtr, const void *src, size_t srcSize)
+{
+	const BYTE *ip = (const BYTE *)src;
+	const BYTE *const end = ip + srcSize;
+	unsigned maxSymbolValue = *maxSymbolValuePtr;
+	unsigned max = 0;
+
+	memset(count, 0, (maxSymbolValue + 1) * sizeof(*count));
+	if (srcSize == 0) {
+		*maxSymbolValuePtr = 0;
+		return 0;
+	}
+
+	while (ip < end)
+		count[*ip++]++;
+
+	while (!count[maxSymbolValue])
+		maxSymbolValue--;
+	*maxSymbolValuePtr = maxSymbolValue;
+
+	{
+		U32 s;
+		for (s = 0; s <= maxSymbolValue; s++)
+			if (count[s] > max)
+				max = count[s];
+	}
+
+	return (size_t)max;
+}
+
+/* FSE_count_parallel_wksp() :
+ * Same as FSE_count_parallel(), but using an externally provided scratch buffer.
+ * `workSpace` size must be a minimum of `1024 * sizeof(unsigned)`` */
+static size_t FSE_count_parallel_wksp(unsigned *count, unsigned *maxSymbolValuePtr, const void *source, size_t sourceSize, unsigned checkMax,
+				      unsigned *const workSpace)
+{
+	const BYTE *ip = (const BYTE *)source;
+	const BYTE *const iend = ip + sourceSize;
+	unsigned maxSymbolValue = *maxSymbolValuePtr;
+	unsigned max = 0;
+	U32 *const Counting1 = workSpace;
+	U32 *const Counting2 = Counting1 + 256;
+	U32 *const Counting3 = Counting2 + 256;
+	U32 *const Counting4 = Counting3 + 256;
+
+	memset(Counting1, 0, 4 * 256 * sizeof(unsigned));
+
+	/* safety checks */
+	if (!sourceSize) {
+		memset(count, 0, maxSymbolValue + 1);
+		*maxSymbolValuePtr = 0;
+		return 0;
+	}
+	if (!maxSymbolValue)
+		maxSymbolValue = 255; /* 0 == default */
+
+	/* by stripes of 16 bytes */
+	{
+		U32 cached = ZSTD_read32(ip);
+		ip += 4;
+		while (ip < iend - 15) {
+			U32 c = cached;
+			cached = ZSTD_read32(ip);
+			ip += 4;
+			Counting1[(BYTE)c]++;
+			Counting2[(BYTE)(c >> 8)]++;
+			Counting3[(BYTE)(c >> 16)]++;
+			Counting4[c >> 24]++;
+			c = cached;
+			cached = ZSTD_read32(ip);
+			ip += 4;
+			Counting1[(BYTE)c]++;
+			Counting2[(BYTE)(c >> 8)]++;
+			Counting3[(BYTE)(c >> 16)]++;
+			Counting4[c >> 24]++;
+			c = cached;
+			cached = ZSTD_read32(ip);
+			ip += 4;
+			Counting1[(BYTE)c]++;
+			Counting2[(BYTE)(c >> 8)]++;
+			Counting3[(BYTE)(c >> 16)]++;
+			Counting4[c >> 24]++;
+			c = cached;
+			cached = ZSTD_read32(ip);
+			ip += 4;
+			Counting1[(BYTE)c]++;
+			Counting2[(BYTE)(c >> 8)]++;
+			Counting3[(BYTE)(c >> 16)]++;
+			Counting4[c >> 24]++;
+		}
+		ip -= 4;
+	}
+
+	/* finish last symbols */
+	while (ip < iend)
+		Counting1[*ip++]++;
+
+	if (checkMax) { /* verify stats will fit into destination table */
+		U32 s;
+		for (s = 255; s > maxSymbolValue; s--) {
+			Counting1[s] += Counting2[s] + Counting3[s] + Counting4[s];
+			if (Counting1[s])
+				return ERROR(maxSymbolValue_tooSmall);
+		}
+	}
+
+	{
+		U32 s;
+		for (s = 0; s <= maxSymbolValue; s++) {
+			count[s] = Counting1[s] + Counting2[s] + Counting3[s] + Counting4[s];
+			if (count[s] > max)
+				max = count[s];
+		}
+	}
+
+	while (!count[maxSymbolValue])
+		maxSymbolValue--;
+	*maxSymbolValuePtr = maxSymbolValue;
+	return (size_t)max;
+}
+
+/* FSE_countFast_wksp() :
+ * Same as FSE_countFast(), but using an externally provided scratch buffer.
+ * `workSpace` size must be table of >= `1024` unsigned */
+size_t FSE_countFast_wksp(unsigned *count, unsigned *maxSymbolValuePtr, const void *source, size_t sourceSize, unsigned *workSpace)
+{
+	if (sourceSize < 1500)
+		return FSE_count_simple(count, maxSymbolValuePtr, source, sourceSize);
+	return FSE_count_parallel_wksp(count, maxSymbolValuePtr, source, sourceSize, 0, workSpace);
+}
+
+/* FSE_count_wksp() :
+ * Same as FSE_count(), but using an externally provided scratch buffer.
+ * `workSpace` size must be table of >= `1024` unsigned */
+size_t FSE_count_wksp(unsigned *count, unsigned *maxSymbolValuePtr, const void *source, size_t sourceSize, unsigned *workSpace)
+{
+	if (*maxSymbolValuePtr < 255)
+		return FSE_count_parallel_wksp(count, maxSymbolValuePtr, source, sourceSize, 1, workSpace);
+	*maxSymbolValuePtr = 255;
+	return FSE_countFast_wksp(count, maxSymbolValuePtr, source, sourceSize, workSpace);
+}
+
+/*-**************************************************************
+*  FSE Compression Code
+****************************************************************/
+/*! FSE_sizeof_CTable() :
+	FSE_CTable is a variable size structure which contains :
+	`U16 tableLog;`
+	`U16 maxSymbolValue;`
+	`U16 nextStateNumber[1 << tableLog];`                         // This size is variable
+	`FSE_symbolCompressionTransform symbolTT[maxSymbolValue+1];`  // This size is variable
+Allocation is manual (C standard does not support variable-size structures).
+*/
+size_t FSE_sizeof_CTable(unsigned maxSymbolValue, unsigned tableLog)
+{
+	if (tableLog > FSE_MAX_TABLELOG)
+		return ERROR(tableLog_tooLarge);
+	return FSE_CTABLE_SIZE_U32(tableLog, maxSymbolValue) * sizeof(U32);
+}
+
+/* provides the minimum logSize to safely represent a distribution */
+static unsigned FSE_minTableLog(size_t srcSize, unsigned maxSymbolValue)
+{
+	U32 minBitsSrc = BIT_highbit32((U32)(srcSize - 1)) + 1;
+	U32 minBitsSymbols = BIT_highbit32(maxSymbolValue) + 2;
+	U32 minBits = minBitsSrc < minBitsSymbols ? minBitsSrc : minBitsSymbols;
+	return minBits;
+}
+
+unsigned FSE_optimalTableLog_internal(unsigned maxTableLog, size_t srcSize, unsigned maxSymbolValue, unsigned minus)
+{
+	U32 maxBitsSrc = BIT_highbit32((U32)(srcSize - 1)) - minus;
+	U32 tableLog = maxTableLog;
+	U32 minBits = FSE_minTableLog(srcSize, maxSymbolValue);
+	if (tableLog == 0)
+		tableLog = FSE_DEFAULT_TABLELOG;
+	if (maxBitsSrc < tableLog)
+		tableLog = maxBitsSrc; /* Accuracy can be reduced */
+	if (minBits > tableLog)
+		tableLog = minBits; /* Need a minimum to safely represent all symbol values */
+	if (tableLog < FSE_MIN_TABLELOG)
+		tableLog = FSE_MIN_TABLELOG;
+	if (tableLog > FSE_MAX_TABLELOG)
+		tableLog = FSE_MAX_TABLELOG;
+	return tableLog;
+}
+
+unsigned FSE_optimalTableLog(unsigned maxTableLog, size_t srcSize, unsigned maxSymbolValue)
+{
+	return FSE_optimalTableLog_internal(maxTableLog, srcSize, maxSymbolValue, 2);
+}
+
+/* Secondary normalization method.
+   To be used when primary method fails. */
+
+static size_t FSE_normalizeM2(short *norm, U32 tableLog, const unsigned *count, size_t total, U32 maxSymbolValue)
+{
+	short const NOT_YET_ASSIGNED = -2;
+	U32 s;
+	U32 distributed = 0;
+	U32 ToDistribute;
+
+	/* Init */
+	U32 const lowThreshold = (U32)(total >> tableLog);
+	U32 lowOne = (U32)((total * 3) >> (tableLog + 1));
+
+	for (s = 0; s <= maxSymbolValue; s++) {
+		if (count[s] == 0) {
+			norm[s] = 0;
+			continue;
+		}
+		if (count[s] <= lowThreshold) {
+			norm[s] = -1;
+			distributed++;
+			total -= count[s];
+			continue;
+		}
+		if (count[s] <= lowOne) {
+			norm[s] = 1;
+			distributed++;
+			total -= count[s];
+			continue;
+		}
+
+		norm[s] = NOT_YET_ASSIGNED;
+	}
+	ToDistribute = (1 << tableLog) - distributed;
+
+	if ((total / ToDistribute) > lowOne) {
+		/* risk of rounding to zero */
+		lowOne = (U32)((total * 3) / (ToDistribute * 2));
+		for (s = 0; s <= maxSymbolValue; s++) {
+			if ((norm[s] == NOT_YET_ASSIGNED) && (count[s] <= lowOne)) {
+				norm[s] = 1;
+				distributed++;
+				total -= count[s];
+				continue;
+			}
+		}
+		ToDistribute = (1 << tableLog) - distributed;
+	}
+
+	if (distributed == maxSymbolValue + 1) {
+		/* all values are pretty poor;
+		   probably incompressible data (should have already been detected);
+		   find max, then give all remaining points to max */
+		U32 maxV = 0, maxC = 0;
+		for (s = 0; s <= maxSymbolValue; s++)
+			if (count[s] > maxC)
+				maxV = s, maxC = count[s];
+		norm[maxV] += (short)ToDistribute;
+		return 0;
+	}
+
+	if (total == 0) {
+		/* all of the symbols were low enough for the lowOne or lowThreshold */
+		for (s = 0; ToDistribute > 0; s = (s + 1) % (maxSymbolValue + 1))
+			if (norm[s] > 0)
+				ToDistribute--, norm[s]++;
+		return 0;
+	}
+
+	{
+		U64 const vStepLog = 62 - tableLog;
+		U64 const mid = (1ULL << (vStepLog - 1)) - 1;
+		U64 const rStep = div_u64((((U64)1 << vStepLog) * ToDistribute) + mid, (U32)total); /* scale on remaining */
+		U64 tmpTotal = mid;
+		for (s = 0; s <= maxSymbolValue; s++) {
+			if (norm[s] == NOT_YET_ASSIGNED) {
+				U64 const end = tmpTotal + (count[s] * rStep);
+				U32 const sStart = (U32)(tmpTotal >> vStepLog);
+				U32 const sEnd = (U32)(end >> vStepLog);
+				U32 const weight = sEnd - sStart;
+				if (weight < 1)
+					return ERROR(GENERIC);
+				norm[s] = (short)weight;
+				tmpTotal = end;
+			}
+		}
+	}
+
+	return 0;
+}
+
+size_t FSE_normalizeCount(short *normalizedCounter, unsigned tableLog, const unsigned *count, size_t total, unsigned maxSymbolValue)
+{
+	/* Sanity checks */
+	if (tableLog == 0)
+		tableLog = FSE_DEFAULT_TABLELOG;
+	if (tableLog < FSE_MIN_TABLELOG)
+		return ERROR(GENERIC); /* Unsupported size */
+	if (tableLog > FSE_MAX_TABLELOG)
+		return ERROR(tableLog_tooLarge); /* Unsupported size */
+	if (tableLog < FSE_minTableLog(total, maxSymbolValue))
+		return ERROR(GENERIC); /* Too small tableLog, compression potentially impossible */
+
+	{
+		U32 const rtbTable[] = {0, 473195, 504333, 520860, 550000, 700000, 750000, 830000};
+		U64 const scale = 62 - tableLog;
+		U64 const step = div_u64((U64)1 << 62, (U32)total); /* <== here, one division ! */
+		U64 const vStep = 1ULL << (scale - 20);
+		int stillToDistribute = 1 << tableLog;
+		unsigned s;
+		unsigned largest = 0;
+		short largestP = 0;
+		U32 lowThreshold = (U32)(total >> tableLog);
+
+		for (s = 0; s <= maxSymbolValue; s++) {
+			if (count[s] == total)
+				return 0; /* rle special case */
+			if (count[s] == 0) {
+				normalizedCounter[s] = 0;
+				continue;
+			}
+			if (count[s] <= lowThreshold) {
+				normalizedCounter[s] = -1;
+				stillToDistribute--;
+			} else {
+				short proba = (short)((count[s] * step) >> scale);
+				if (proba < 8) {
+					U64 restToBeat = vStep * rtbTable[proba];
+					proba += (count[s] * step) - ((U64)proba << scale) > restToBeat;
+				}
+				if (proba > largestP)
+					largestP = proba, largest = s;
+				normalizedCounter[s] = proba;
+				stillToDistribute -= proba;
+			}
+		}
+		if (-stillToDistribute >= (normalizedCounter[largest] >> 1)) {
+			/* corner case, need another normalization method */
+			size_t const errorCode = FSE_normalizeM2(normalizedCounter, tableLog, count, total, maxSymbolValue);
+			if (FSE_isError(errorCode))
+				return errorCode;
+		} else
+			normalizedCounter[largest] += (short)stillToDistribute;
+	}
+
+	return tableLog;
+}
+
+/* fake FSE_CTable, for raw (uncompressed) input */
+size_t FSE_buildCTable_raw(FSE_CTable *ct, unsigned nbBits)
+{
+	const unsigned tableSize = 1 << nbBits;
+	const unsigned tableMask = tableSize - 1;
+	const unsigned maxSymbolValue = tableMask;
+	void *const ptr = ct;
+	U16 *const tableU16 = ((U16 *)ptr) + 2;
+	void *const FSCT = ((U32 *)ptr) + 1 /* header */ + (tableSize >> 1); /* assumption : tableLog >= 1 */
+	FSE_symbolCompressionTransform *const symbolTT = (FSE_symbolCompressionTransform *)(FSCT);
+	unsigned s;
+
+	/* Sanity checks */
+	if (nbBits < 1)
+		return ERROR(GENERIC); /* min size */
+
+	/* header */
+	tableU16[-2] = (U16)nbBits;
+	tableU16[-1] = (U16)maxSymbolValue;
+
+	/* Build table */
+	for (s = 0; s < tableSize; s++)
+		tableU16[s] = (U16)(tableSize + s);
+
+	/* Build Symbol Transformation Table */
+	{
+		const U32 deltaNbBits = (nbBits << 16) - (1 << nbBits);
+		for (s = 0; s <= maxSymbolValue; s++) {
+			symbolTT[s].deltaNbBits = deltaNbBits;
+			symbolTT[s].deltaFindState = s - 1;
+		}
+	}
+
+	return 0;
+}
+
+/* fake FSE_CTable, for rle input (always same symbol) */
+size_t FSE_buildCTable_rle(FSE_CTable *ct, BYTE symbolValue)
+{
+	void *ptr = ct;
+	U16 *tableU16 = ((U16 *)ptr) + 2;
+	void *FSCTptr = (U32 *)ptr + 2;
+	FSE_symbolCompressionTransform *symbolTT = (FSE_symbolCompressionTransform *)FSCTptr;
+
+	/* header */
+	tableU16[-2] = (U16)0;
+	tableU16[-1] = (U16)symbolValue;
+
+	/* Build table */
+	tableU16[0] = 0;
+	tableU16[1] = 0; /* just in case */
+
+	/* Build Symbol Transformation Table */
+	symbolTT[symbolValue].deltaNbBits = 0;
+	symbolTT[symbolValue].deltaFindState = 0;
+
+	return 0;
+}
+
+static size_t FSE_compress_usingCTable_generic(void *dst, size_t dstSize, const void *src, size_t srcSize, const FSE_CTable *ct, const unsigned fast)
+{
+	const BYTE *const istart = (const BYTE *)src;
+	const BYTE *const iend = istart + srcSize;
+	const BYTE *ip = iend;
+
+	BIT_CStream_t bitC;
+	FSE_CState_t CState1, CState2;
+
+	/* init */
+	if (srcSize <= 2)
+		return 0;
+	{
+		size_t const initError = BIT_initCStream(&bitC, dst, dstSize);
+		if (FSE_isError(initError))
+			return 0; /* not enough space available to write a bitstream */
+	}
+
+#define FSE_FLUSHBITS(s) (fast ? BIT_flushBitsFast(s) : BIT_flushBits(s))
+
+	if (srcSize & 1) {
+		FSE_initCState2(&CState1, ct, *--ip);
+		FSE_initCState2(&CState2, ct, *--ip);
+		FSE_encodeSymbol(&bitC, &CState1, *--ip);
+		FSE_FLUSHBITS(&bitC);
+	} else {
+		FSE_initCState2(&CState2, ct, *--ip);
+		FSE_initCState2(&CState1, ct, *--ip);
+	}
+
+	/* join to mod 4 */
+	srcSize -= 2;
+	if ((sizeof(bitC.bitContainer) * 8 > FSE_MAX_TABLELOG * 4 + 7) && (srcSize & 2)) { /* test bit 2 */
+		FSE_encodeSymbol(&bitC, &CState2, *--ip);
+		FSE_encodeSymbol(&bitC, &CState1, *--ip);
+		FSE_FLUSHBITS(&bitC);
+	}
+
+	/* 2 or 4 encoding per loop */
+	while (ip > istart) {
+
+		FSE_encodeSymbol(&bitC, &CState2, *--ip);
+
+		if (sizeof(bitC.bitContainer) * 8 < FSE_MAX_TABLELOG * 2 + 7) /* this test must be static */
+			FSE_FLUSHBITS(&bitC);
+
+		FSE_encodeSymbol(&bitC, &CState1, *--ip);
+
+		if (sizeof(bitC.bitContainer) * 8 > FSE_MAX_TABLELOG * 4 + 7) { /* this test must be static */
+			FSE_encodeSymbol(&bitC, &CState2, *--ip);
+			FSE_encodeSymbol(&bitC, &CState1, *--ip);
+		}
+
+		FSE_FLUSHBITS(&bitC);
+	}
+
+	FSE_flushCState(&bitC, &CState2);
+	FSE_flushCState(&bitC, &CState1);
+	return BIT_closeCStream(&bitC);
+}
+
+size_t FSE_compress_usingCTable(void *dst, size_t dstSize, const void *src, size_t srcSize, const FSE_CTable *ct)
+{
+	unsigned const fast = (dstSize >= FSE_BLOCKBOUND(srcSize));
+
+	if (fast)
+		return FSE_compress_usingCTable_generic(dst, dstSize, src, srcSize, ct, 1);
+	else
+		return FSE_compress_usingCTable_generic(dst, dstSize, src, srcSize, ct, 0);
+}
+
+size_t FSE_compressBound(size_t size) { return FSE_COMPRESSBOUND(size); }
diff -Naurp -x debian.hwe linux-4.10.x.ori/lib/zstd/fse_decompress.c linux-4.10.x/lib/zstd/fse_decompress.c
--- linux-4.10.x.ori/lib/zstd/fse_decompress.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-4.10.x/lib/zstd/fse_decompress.c	2017-10-30 10:05:19.610447000 +0100
@@ -0,0 +1,332 @@
+/*
+ * FSE : Finite State Entropy decoder
+ * Copyright (C) 2013-2015, Yann Collet.
+ *
+ * BSD 2-Clause License (http://www.opensource.org/licenses/bsd-license.php)
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ * notice, this list of conditions and the following disclaimer.
+ *   * Redistributions in binary form must reproduce the above
+ * copyright notice, this list of conditions and the following disclaimer
+ * in the documentation and/or other materials provided with the
+ * distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ * This program is free software; you can redistribute it and/or modify it under
+ * the terms of the GNU General Public License version 2 as published by the
+ * Free Software Foundation. This program is dual-licensed; you may select
+ * either version 2 of the GNU General Public License ("GPL") or BSD license
+ * ("BSD").
+ *
+ * You can contact the author at :
+ * - Source repository : https://github.com/Cyan4973/FiniteStateEntropy
+ */
+
+/* **************************************************************
+*  Compiler specifics
+****************************************************************/
+#define FORCE_INLINE static __always_inline
+
+/* **************************************************************
+*  Includes
+****************************************************************/
+#include "bitstream.h"
+#include "fse.h"
+#include <linux/compiler.h>
+#include <linux/kernel.h>
+#include <linux/string.h> /* memcpy, memset */
+
+/* **************************************************************
+*  Error Management
+****************************************************************/
+#define FSE_isError ERR_isError
+#define FSE_STATIC_ASSERT(c)                                   \
+	{                                                      \
+		enum { FSE_static_assert = 1 / (int)(!!(c)) }; \
+	} /* use only *after* variable declarations */
+
+/* check and forward error code */
+#define CHECK_F(f)                  \
+	{                           \
+		size_t const e = f; \
+		if (FSE_isError(e)) \
+			return e;   \
+	}
+
+/* **************************************************************
+*  Templates
+****************************************************************/
+/*
+  designed to be included
+  for type-specific functions (template emulation in C)
+  Objective is to write these functions only once, for improved maintenance
+*/
+
+/* safety checks */
+#ifndef FSE_FUNCTION_EXTENSION
+#error "FSE_FUNCTION_EXTENSION must be defined"
+#endif
+#ifndef FSE_FUNCTION_TYPE
+#error "FSE_FUNCTION_TYPE must be defined"
+#endif
+
+/* Function names */
+#define FSE_CAT(X, Y) X##Y
+#define FSE_FUNCTION_NAME(X, Y) FSE_CAT(X, Y)
+#define FSE_TYPE_NAME(X, Y) FSE_CAT(X, Y)
+
+/* Function templates */
+
+size_t FSE_buildDTable_wksp(FSE_DTable *dt, const short *normalizedCounter, unsigned maxSymbolValue, unsigned tableLog, void *workspace, size_t workspaceSize)
+{
+	void *const tdPtr = dt + 1; /* because *dt is unsigned, 32-bits aligned on 32-bits */
+	FSE_DECODE_TYPE *const tableDecode = (FSE_DECODE_TYPE *)(tdPtr);
+	U16 *symbolNext = (U16 *)workspace;
+
+	U32 const maxSV1 = maxSymbolValue + 1;
+	U32 const tableSize = 1 << tableLog;
+	U32 highThreshold = tableSize - 1;
+
+	/* Sanity Checks */
+	if (workspaceSize < sizeof(U16) * (FSE_MAX_SYMBOL_VALUE + 1))
+		return ERROR(tableLog_tooLarge);
+	if (maxSymbolValue > FSE_MAX_SYMBOL_VALUE)
+		return ERROR(maxSymbolValue_tooLarge);
+	if (tableLog > FSE_MAX_TABLELOG)
+		return ERROR(tableLog_tooLarge);
+
+	/* Init, lay down lowprob symbols */
+	{
+		FSE_DTableHeader DTableH;
+		DTableH.tableLog = (U16)tableLog;
+		DTableH.fastMode = 1;
+		{
+			S16 const largeLimit = (S16)(1 << (tableLog - 1));
+			U32 s;
+			for (s = 0; s < maxSV1; s++) {
+				if (normalizedCounter[s] == -1) {
+					tableDecode[highThreshold--].symbol = (FSE_FUNCTION_TYPE)s;
+					symbolNext[s] = 1;
+				} else {
+					if (normalizedCounter[s] >= largeLimit)
+						DTableH.fastMode = 0;
+					symbolNext[s] = normalizedCounter[s];
+				}
+			}
+		}
+		memcpy(dt, &DTableH, sizeof(DTableH));
+	}
+
+	/* Spread symbols */
+	{
+		U32 const tableMask = tableSize - 1;
+		U32 const step = FSE_TABLESTEP(tableSize);
+		U32 s, position = 0;
+		for (s = 0; s < maxSV1; s++) {
+			int i;
+			for (i = 0; i < normalizedCounter[s]; i++) {
+				tableDecode[position].symbol = (FSE_FUNCTION_TYPE)s;
+				position = (position + step) & tableMask;
+				while (position > highThreshold)
+					position = (position + step) & tableMask; /* lowprob area */
+			}
+		}
+		if (position != 0)
+			return ERROR(GENERIC); /* position must reach all cells once, otherwise normalizedCounter is incorrect */
+	}
+
+	/* Build Decoding table */
+	{
+		U32 u;
+		for (u = 0; u < tableSize; u++) {
+			FSE_FUNCTION_TYPE const symbol = (FSE_FUNCTION_TYPE)(tableDecode[u].symbol);
+			U16 nextState = symbolNext[symbol]++;
+			tableDecode[u].nbBits = (BYTE)(tableLog - BIT_highbit32((U32)nextState));
+			tableDecode[u].newState = (U16)((nextState << tableDecode[u].nbBits) - tableSize);
+		}
+	}
+
+	return 0;
+}
+
+/*-*******************************************************
+*  Decompression (Byte symbols)
+*********************************************************/
+size_t FSE_buildDTable_rle(FSE_DTable *dt, BYTE symbolValue)
+{
+	void *ptr = dt;
+	FSE_DTableHeader *const DTableH = (FSE_DTableHeader *)ptr;
+	void *dPtr = dt + 1;
+	FSE_decode_t *const cell = (FSE_decode_t *)dPtr;
+
+	DTableH->tableLog = 0;
+	DTableH->fastMode = 0;
+
+	cell->newState = 0;
+	cell->symbol = symbolValue;
+	cell->nbBits = 0;
+
+	return 0;
+}
+
+size_t FSE_buildDTable_raw(FSE_DTable *dt, unsigned nbBits)
+{
+	void *ptr = dt;
+	FSE_DTableHeader *const DTableH = (FSE_DTableHeader *)ptr;
+	void *dPtr = dt + 1;
+	FSE_decode_t *const dinfo = (FSE_decode_t *)dPtr;
+	const unsigned tableSize = 1 << nbBits;
+	const unsigned tableMask = tableSize - 1;
+	const unsigned maxSV1 = tableMask + 1;
+	unsigned s;
+
+	/* Sanity checks */
+	if (nbBits < 1)
+		return ERROR(GENERIC); /* min size */
+
+	/* Build Decoding Table */
+	DTableH->tableLog = (U16)nbBits;
+	DTableH->fastMode = 1;
+	for (s = 0; s < maxSV1; s++) {
+		dinfo[s].newState = 0;
+		dinfo[s].symbol = (BYTE)s;
+		dinfo[s].nbBits = (BYTE)nbBits;
+	}
+
+	return 0;
+}
+
+FORCE_INLINE size_t FSE_decompress_usingDTable_generic(void *dst, size_t maxDstSize, const void *cSrc, size_t cSrcSize, const FSE_DTable *dt,
+						       const unsigned fast)
+{
+	BYTE *const ostart = (BYTE *)dst;
+	BYTE *op = ostart;
+	BYTE *const omax = op + maxDstSize;
+	BYTE *const olimit = omax - 3;
+
+	BIT_DStream_t bitD;
+	FSE_DState_t state1;
+	FSE_DState_t state2;
+
+	/* Init */
+	CHECK_F(BIT_initDStream(&bitD, cSrc, cSrcSize));
+
+	FSE_initDState(&state1, &bitD, dt);
+	FSE_initDState(&state2, &bitD, dt);
+
+#define FSE_GETSYMBOL(statePtr) fast ? FSE_decodeSymbolFast(statePtr, &bitD) : FSE_decodeSymbol(statePtr, &bitD)
+
+	/* 4 symbols per loop */
+	for (; (BIT_reloadDStream(&bitD) == BIT_DStream_unfinished) & (op < olimit); op += 4) {
+		op[0] = FSE_GETSYMBOL(&state1);
+
+		if (FSE_MAX_TABLELOG * 2 + 7 > sizeof(bitD.bitContainer) * 8) /* This test must be static */
+			BIT_reloadDStream(&bitD);
+
+		op[1] = FSE_GETSYMBOL(&state2);
+
+		if (FSE_MAX_TABLELOG * 4 + 7 > sizeof(bitD.bitContainer) * 8) /* This test must be static */
+		{
+			if (BIT_reloadDStream(&bitD) > BIT_DStream_unfinished) {
+				op += 2;
+				break;
+			}
+		}
+
+		op[2] = FSE_GETSYMBOL(&state1);
+
+		if (FSE_MAX_TABLELOG * 2 + 7 > sizeof(bitD.bitContainer) * 8) /* This test must be static */
+			BIT_reloadDStream(&bitD);
+
+		op[3] = FSE_GETSYMBOL(&state2);
+	}
+
+	/* tail */
+	/* note : BIT_reloadDStream(&bitD) >= FSE_DStream_partiallyFilled; Ends at exactly BIT_DStream_completed */
+	while (1) {
+		if (op > (omax - 2))
+			return ERROR(dstSize_tooSmall);
+		*op++ = FSE_GETSYMBOL(&state1);
+		if (BIT_reloadDStream(&bitD) == BIT_DStream_overflow) {
+			*op++ = FSE_GETSYMBOL(&state2);
+			break;
+		}
+
+		if (op > (omax - 2))
+			return ERROR(dstSize_tooSmall);
+		*op++ = FSE_GETSYMBOL(&state2);
+		if (BIT_reloadDStream(&bitD) == BIT_DStream_overflow) {
+			*op++ = FSE_GETSYMBOL(&state1);
+			break;
+		}
+	}
+
+	return op - ostart;
+}
+
+size_t FSE_decompress_usingDTable(void *dst, size_t originalSize, const void *cSrc, size_t cSrcSize, const FSE_DTable *dt)
+{
+	const void *ptr = dt;
+	const FSE_DTableHeader *DTableH = (const FSE_DTableHeader *)ptr;
+	const U32 fastMode = DTableH->fastMode;
+
+	/* select fast mode (static) */
+	if (fastMode)
+		return FSE_decompress_usingDTable_generic(dst, originalSize, cSrc, cSrcSize, dt, 1);
+	return FSE_decompress_usingDTable_generic(dst, originalSize, cSrc, cSrcSize, dt, 0);
+}
+
+size_t FSE_decompress_wksp(void *dst, size_t dstCapacity, const void *cSrc, size_t cSrcSize, unsigned maxLog, void *workspace, size_t workspaceSize)
+{
+	const BYTE *const istart = (const BYTE *)cSrc;
+	const BYTE *ip = istart;
+	unsigned tableLog;
+	unsigned maxSymbolValue = FSE_MAX_SYMBOL_VALUE;
+	size_t NCountLength;
+
+	FSE_DTable *dt;
+	short *counting;
+	size_t spaceUsed32 = 0;
+
+	FSE_STATIC_ASSERT(sizeof(FSE_DTable) == sizeof(U32));
+
+	dt = (FSE_DTable *)((U32 *)workspace + spaceUsed32);
+	spaceUsed32 += FSE_DTABLE_SIZE_U32(maxLog);
+	counting = (short *)((U32 *)workspace + spaceUsed32);
+	spaceUsed32 += ALIGN(sizeof(short) * (FSE_MAX_SYMBOL_VALUE + 1), sizeof(U32)) >> 2;
+
+	if ((spaceUsed32 << 2) > workspaceSize)
+		return ERROR(tableLog_tooLarge);
+	workspace = (U32 *)workspace + spaceUsed32;
+	workspaceSize -= (spaceUsed32 << 2);
+
+	/* normal FSE decoding mode */
+	NCountLength = FSE_readNCount(counting, &maxSymbolValue, &tableLog, istart, cSrcSize);
+	if (FSE_isError(NCountLength))
+		return NCountLength;
+	// if (NCountLength >= cSrcSize) return ERROR(srcSize_wrong);   /* too small input size; supposed to be already checked in NCountLength, only remaining
+	// case : NCountLength==cSrcSize */
+	if (tableLog > maxLog)
+		return ERROR(tableLog_tooLarge);
+	ip += NCountLength;
+	cSrcSize -= NCountLength;
+
+	CHECK_F(FSE_buildDTable_wksp(dt, counting, maxSymbolValue, tableLog, workspace, workspaceSize));
+
+	return FSE_decompress_usingDTable(dst, dstCapacity, ip, cSrcSize, dt); /* always return, even if it is an error code */
+}
diff -Naurp -x debian.hwe linux-4.10.x.ori/lib/zstd/fse.h linux-4.10.x/lib/zstd/fse.h
--- linux-4.10.x.ori/lib/zstd/fse.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-4.10.x/lib/zstd/fse.h	2017-10-30 10:05:19.610447000 +0100
@@ -0,0 +1,575 @@
+/*
+ * FSE : Finite State Entropy codec
+ * Public Prototypes declaration
+ * Copyright (C) 2013-2016, Yann Collet.
+ *
+ * BSD 2-Clause License (http://www.opensource.org/licenses/bsd-license.php)
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ * notice, this list of conditions and the following disclaimer.
+ *   * Redistributions in binary form must reproduce the above
+ * copyright notice, this list of conditions and the following disclaimer
+ * in the documentation and/or other materials provided with the
+ * distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ * This program is free software; you can redistribute it and/or modify it under
+ * the terms of the GNU General Public License version 2 as published by the
+ * Free Software Foundation. This program is dual-licensed; you may select
+ * either version 2 of the GNU General Public License ("GPL") or BSD license
+ * ("BSD").
+ *
+ * You can contact the author at :
+ * - Source repository : https://github.com/Cyan4973/FiniteStateEntropy
+ */
+#ifndef FSE_H
+#define FSE_H
+
+/*-*****************************************
+*  Dependencies
+******************************************/
+#include <linux/types.h> /* size_t, ptrdiff_t */
+
+/*-*****************************************
+*  FSE_PUBLIC_API : control library symbols visibility
+******************************************/
+#define FSE_PUBLIC_API
+
+/*------   Version   ------*/
+#define FSE_VERSION_MAJOR 0
+#define FSE_VERSION_MINOR 9
+#define FSE_VERSION_RELEASE 0
+
+#define FSE_LIB_VERSION FSE_VERSION_MAJOR.FSE_VERSION_MINOR.FSE_VERSION_RELEASE
+#define FSE_QUOTE(str) #str
+#define FSE_EXPAND_AND_QUOTE(str) FSE_QUOTE(str)
+#define FSE_VERSION_STRING FSE_EXPAND_AND_QUOTE(FSE_LIB_VERSION)
+
+#define FSE_VERSION_NUMBER (FSE_VERSION_MAJOR * 100 * 100 + FSE_VERSION_MINOR * 100 + FSE_VERSION_RELEASE)
+FSE_PUBLIC_API unsigned FSE_versionNumber(void); /**< library version number; to be used when checking dll version */
+
+/*-*****************************************
+*  Tool functions
+******************************************/
+FSE_PUBLIC_API size_t FSE_compressBound(size_t size); /* maximum compressed size */
+
+/* Error Management */
+FSE_PUBLIC_API unsigned FSE_isError(size_t code); /* tells if a return value is an error code */
+
+/*-*****************************************
+*  FSE detailed API
+******************************************/
+/*!
+FSE_compress() does the following:
+1. count symbol occurrence from source[] into table count[]
+2. normalize counters so that sum(count[]) == Power_of_2 (2^tableLog)
+3. save normalized counters to memory buffer using writeNCount()
+4. build encoding table 'CTable' from normalized counters
+5. encode the data stream using encoding table 'CTable'
+
+FSE_decompress() does the following:
+1. read normalized counters with readNCount()
+2. build decoding table 'DTable' from normalized counters
+3. decode the data stream using decoding table 'DTable'
+
+The following API allows targeting specific sub-functions for advanced tasks.
+For example, it's possible to compress several blocks using the same 'CTable',
+or to save and provide normalized distribution using external method.
+*/
+
+/* *** COMPRESSION *** */
+/*! FSE_optimalTableLog():
+	dynamically downsize 'tableLog' when conditions are met.
+	It saves CPU time, by using smaller tables, while preserving or even improving compression ratio.
+	@return : recommended tableLog (necessarily <= 'maxTableLog') */
+FSE_PUBLIC_API unsigned FSE_optimalTableLog(unsigned maxTableLog, size_t srcSize, unsigned maxSymbolValue);
+
+/*! FSE_normalizeCount():
+	normalize counts so that sum(count[]) == Power_of_2 (2^tableLog)
+	'normalizedCounter' is a table of short, of minimum size (maxSymbolValue+1).
+	@return : tableLog,
+			  or an errorCode, which can be tested using FSE_isError() */
+FSE_PUBLIC_API size_t FSE_normalizeCount(short *normalizedCounter, unsigned tableLog, const unsigned *count, size_t srcSize, unsigned maxSymbolValue);
+
+/*! FSE_NCountWriteBound():
+	Provides the maximum possible size of an FSE normalized table, given 'maxSymbolValue' and 'tableLog'.
+	Typically useful for allocation purpose. */
+FSE_PUBLIC_API size_t FSE_NCountWriteBound(unsigned maxSymbolValue, unsigned tableLog);
+
+/*! FSE_writeNCount():
+	Compactly save 'normalizedCounter' into 'buffer'.
+	@return : size of the compressed table,
+			  or an errorCode, which can be tested using FSE_isError(). */
+FSE_PUBLIC_API size_t FSE_writeNCount(void *buffer, size_t bufferSize, const short *normalizedCounter, unsigned maxSymbolValue, unsigned tableLog);
+
+/*! Constructor and Destructor of FSE_CTable.
+	Note that FSE_CTable size depends on 'tableLog' and 'maxSymbolValue' */
+typedef unsigned FSE_CTable; /* don't allocate that. It's only meant to be more restrictive than void* */
+
+/*! FSE_compress_usingCTable():
+	Compress `src` using `ct` into `dst` which must be already allocated.
+	@return : size of compressed data (<= `dstCapacity`),
+			  or 0 if compressed data could not fit into `dst`,
+			  or an errorCode, which can be tested using FSE_isError() */
+FSE_PUBLIC_API size_t FSE_compress_usingCTable(void *dst, size_t dstCapacity, const void *src, size_t srcSize, const FSE_CTable *ct);
+
+/*!
+Tutorial :
+----------
+The first step is to count all symbols. FSE_count() does this job very fast.
+Result will be saved into 'count', a table of unsigned int, which must be already allocated, and have 'maxSymbolValuePtr[0]+1' cells.
+'src' is a table of bytes of size 'srcSize'. All values within 'src' MUST be <= maxSymbolValuePtr[0]
+maxSymbolValuePtr[0] will be updated, with its real value (necessarily <= original value)
+FSE_count() will return the number of occurrence of the most frequent symbol.
+This can be used to know if there is a single symbol within 'src', and to quickly evaluate its compressibility.
+If there is an error, the function will return an ErrorCode (which can be tested using FSE_isError()).
+
+The next step is to normalize the frequencies.
+FSE_normalizeCount() will ensure that sum of frequencies is == 2 ^'tableLog'.
+It also guarantees a minimum of 1 to any Symbol with frequency >= 1.
+You can use 'tableLog'==0 to mean "use default tableLog value".
+If you are unsure of which tableLog value to use, you can ask FSE_optimalTableLog(),
+which will provide the optimal valid tableLog given sourceSize, maxSymbolValue, and a user-defined maximum (0 means "default").
+
+The result of FSE_normalizeCount() will be saved into a table,
+called 'normalizedCounter', which is a table of signed short.
+'normalizedCounter' must be already allocated, and have at least 'maxSymbolValue+1' cells.
+The return value is tableLog if everything proceeded as expected.
+It is 0 if there is a single symbol within distribution.
+If there is an error (ex: invalid tableLog value), the function will return an ErrorCode (which can be tested using FSE_isError()).
+
+'normalizedCounter' can be saved in a compact manner to a memory area using FSE_writeNCount().
+'buffer' must be already allocated.
+For guaranteed success, buffer size must be at least FSE_headerBound().
+The result of the function is the number of bytes written into 'buffer'.
+If there is an error, the function will return an ErrorCode (which can be tested using FSE_isError(); ex : buffer size too small).
+
+'normalizedCounter' can then be used to create the compression table 'CTable'.
+The space required by 'CTable' must be already allocated, using FSE_createCTable().
+You can then use FSE_buildCTable() to fill 'CTable'.
+If there is an error, both functions will return an ErrorCode (which can be tested using FSE_isError()).
+
+'CTable' can then be used to compress 'src', with FSE_compress_usingCTable().
+Similar to FSE_count(), the convention is that 'src' is assumed to be a table of char of size 'srcSize'
+The function returns the size of compressed data (without header), necessarily <= `dstCapacity`.
+If it returns '0', compressed data could not fit into 'dst'.
+If there is an error, the function will return an ErrorCode (which can be tested using FSE_isError()).
+*/
+
+/* *** DECOMPRESSION *** */
+
+/*! FSE_readNCount():
+	Read compactly saved 'normalizedCounter' from 'rBuffer'.
+	@return : size read from 'rBuffer',
+			  or an errorCode, which can be tested using FSE_isError().
+			  maxSymbolValuePtr[0] and tableLogPtr[0] will also be updated with their respective values */
+FSE_PUBLIC_API size_t FSE_readNCount(short *normalizedCounter, unsigned *maxSymbolValuePtr, unsigned *tableLogPtr, const void *rBuffer, size_t rBuffSize);
+
+/*! Constructor and Destructor of FSE_DTable.
+	Note that its size depends on 'tableLog' */
+typedef unsigned FSE_DTable; /* don't allocate that. It's just a way to be more restrictive than void* */
+
+/*! FSE_buildDTable():
+	Builds 'dt', which must be already allocated, using FSE_createDTable().
+	return : 0, or an errorCode, which can be tested using FSE_isError() */
+FSE_PUBLIC_API size_t FSE_buildDTable_wksp(FSE_DTable *dt, const short *normalizedCounter, unsigned maxSymbolValue, unsigned tableLog, void *workspace, size_t workspaceSize);
+
+/*! FSE_decompress_usingDTable():
+	Decompress compressed source `cSrc` of size `cSrcSize` using `dt`
+	into `dst` which must be already allocated.
+	@return : size of regenerated data (necessarily <= `dstCapacity`),
+			  or an errorCode, which can be tested using FSE_isError() */
+FSE_PUBLIC_API size_t FSE_decompress_usingDTable(void *dst, size_t dstCapacity, const void *cSrc, size_t cSrcSize, const FSE_DTable *dt);
+
+/*!
+Tutorial :
+----------
+(Note : these functions only decompress FSE-compressed blocks.
+ If block is uncompressed, use memcpy() instead
+ If block is a single repeated byte, use memset() instead )
+
+The first step is to obtain the normalized frequencies of symbols.
+This can be performed by FSE_readNCount() if it was saved using FSE_writeNCount().
+'normalizedCounter' must be already allocated, and have at least 'maxSymbolValuePtr[0]+1' cells of signed short.
+In practice, that means it's necessary to know 'maxSymbolValue' beforehand,
+or size the table to handle worst case situations (typically 256).
+FSE_readNCount() will provide 'tableLog' and 'maxSymbolValue'.
+The result of FSE_readNCount() is the number of bytes read from 'rBuffer'.
+Note that 'rBufferSize' must be at least 4 bytes, even if useful information is less than that.
+If there is an error, the function will return an error code, which can be tested using FSE_isError().
+
+The next step is to build the decompression tables 'FSE_DTable' from 'normalizedCounter'.
+This is performed by the function FSE_buildDTable().
+The space required by 'FSE_DTable' must be already allocated using FSE_createDTable().
+If there is an error, the function will return an error code, which can be tested using FSE_isError().
+
+`FSE_DTable` can then be used to decompress `cSrc`, with FSE_decompress_usingDTable().
+`cSrcSize` must be strictly correct, otherwise decompression will fail.
+FSE_decompress_usingDTable() result will tell how many bytes were regenerated (<=`dstCapacity`).
+If there is an error, the function will return an error code, which can be tested using FSE_isError(). (ex: dst buffer too small)
+*/
+
+/* *** Dependency *** */
+#include "bitstream.h"
+
+/* *****************************************
+*  Static allocation
+*******************************************/
+/* FSE buffer bounds */
+#define FSE_NCOUNTBOUND 512
+#define FSE_BLOCKBOUND(size) (size + (size >> 7))
+#define FSE_COMPRESSBOUND(size) (FSE_NCOUNTBOUND + FSE_BLOCKBOUND(size)) /* Macro version, useful for static allocation */
+
+/* It is possible to statically allocate FSE CTable/DTable as a table of FSE_CTable/FSE_DTable using below macros */
+#define FSE_CTABLE_SIZE_U32(maxTableLog, maxSymbolValue) (1 + (1 << (maxTableLog - 1)) + ((maxSymbolValue + 1) * 2))
+#define FSE_DTABLE_SIZE_U32(maxTableLog) (1 + (1 << maxTableLog))
+
+/* *****************************************
+*  FSE advanced API
+*******************************************/
+/* FSE_count_wksp() :
+ * Same as FSE_count(), but using an externally provided scratch buffer.
+ * `workSpace` size must be table of >= `1024` unsigned
+ */
+size_t FSE_count_wksp(unsigned *count, unsigned *maxSymbolValuePtr, const void *source, size_t sourceSize, unsigned *workSpace);
+
+/* FSE_countFast_wksp() :
+ * Same as FSE_countFast(), but using an externally provided scratch buffer.
+ * `workSpace` must be a table of minimum `1024` unsigned
+ */
+size_t FSE_countFast_wksp(unsigned *count, unsigned *maxSymbolValuePtr, const void *src, size_t srcSize, unsigned *workSpace);
+
+/*! FSE_count_simple
+ * Same as FSE_countFast(), but does not use any additional memory (not even on stack).
+ * This function is unsafe, and will segfault if any value within `src` is `> *maxSymbolValuePtr` (presuming it's also the size of `count`).
+*/
+size_t FSE_count_simple(unsigned *count, unsigned *maxSymbolValuePtr, const void *src, size_t srcSize);
+
+unsigned FSE_optimalTableLog_internal(unsigned maxTableLog, size_t srcSize, unsigned maxSymbolValue, unsigned minus);
+/**< same as FSE_optimalTableLog(), which used `minus==2` */
+
+size_t FSE_buildCTable_raw(FSE_CTable *ct, unsigned nbBits);
+/**< build a fake FSE_CTable, designed for a flat distribution, where each symbol uses nbBits */
+
+size_t FSE_buildCTable_rle(FSE_CTable *ct, unsigned char symbolValue);
+/**< build a fake FSE_CTable, designed to compress always the same symbolValue */
+
+/* FSE_buildCTable_wksp() :
+ * Same as FSE_buildCTable(), but using an externally allocated scratch buffer (`workSpace`).
+ * `wkspSize` must be >= `(1<<tableLog)`.
+ */
+size_t FSE_buildCTable_wksp(FSE_CTable *ct, const short *normalizedCounter, unsigned maxSymbolValue, unsigned tableLog, void *workSpace, size_t wkspSize);
+
+size_t FSE_buildDTable_raw(FSE_DTable *dt, unsigned nbBits);
+/**< build a fake FSE_DTable, designed to read a flat distribution where each symbol uses nbBits */
+
+size_t FSE_buildDTable_rle(FSE_DTable *dt, unsigned char symbolValue);
+/**< build a fake FSE_DTable, designed to always generate the same symbolValue */
+
+size_t FSE_decompress_wksp(void *dst, size_t dstCapacity, const void *cSrc, size_t cSrcSize, unsigned maxLog, void *workspace, size_t workspaceSize);
+/**< same as FSE_decompress(), using an externally allocated `workSpace` produced with `FSE_DTABLE_SIZE_U32(maxLog)` */
+
+/* *****************************************
+*  FSE symbol compression API
+*******************************************/
+/*!
+   This API consists of small unitary functions, which highly benefit from being inlined.
+   Hence their body are included in next section.
+*/
+typedef struct {
+	ptrdiff_t value;
+	const void *stateTable;
+	const void *symbolTT;
+	unsigned stateLog;
+} FSE_CState_t;
+
+static void FSE_initCState(FSE_CState_t *CStatePtr, const FSE_CTable *ct);
+
+static void FSE_encodeSymbol(BIT_CStream_t *bitC, FSE_CState_t *CStatePtr, unsigned symbol);
+
+static void FSE_flushCState(BIT_CStream_t *bitC, const FSE_CState_t *CStatePtr);
+
+/**<
+These functions are inner components of FSE_compress_usingCTable().
+They allow the creation of custom streams, mixing multiple tables and bit sources.
+
+A key property to keep in mind is that encoding and decoding are done **in reverse direction**.
+So the first symbol you will encode is the last you will decode, like a LIFO stack.
+
+You will need a few variables to track your CStream. They are :
+
+FSE_CTable    ct;         // Provided by FSE_buildCTable()
+BIT_CStream_t bitStream;  // bitStream tracking structure
+FSE_CState_t  state;      // State tracking structure (can have several)
+
+
+The first thing to do is to init bitStream and state.
+	size_t errorCode = BIT_initCStream(&bitStream, dstBuffer, maxDstSize);
+	FSE_initCState(&state, ct);
+
+Note that BIT_initCStream() can produce an error code, so its result should be tested, using FSE_isError();
+You can then encode your input data, byte after byte.
+FSE_encodeSymbol() outputs a maximum of 'tableLog' bits at a time.
+Remember decoding will be done in reverse direction.
+	FSE_encodeByte(&bitStream, &state, symbol);
+
+At any time, you can also add any bit sequence.
+Note : maximum allowed nbBits is 25, for compatibility with 32-bits decoders
+	BIT_addBits(&bitStream, bitField, nbBits);
+
+The above methods don't commit data to memory, they just store it into local register, for speed.
+Local register size is 64-bits on 64-bits systems, 32-bits on 32-bits systems (size_t).
+Writing data to memory is a manual operation, performed by the flushBits function.
+	BIT_flushBits(&bitStream);
+
+Your last FSE encoding operation shall be to flush your last state value(s).
+	FSE_flushState(&bitStream, &state);
+
+Finally, you must close the bitStream.
+The function returns the size of CStream in bytes.
+If data couldn't fit into dstBuffer, it will return a 0 ( == not compressible)
+If there is an error, it returns an errorCode (which can be tested using FSE_isError()).
+	size_t size = BIT_closeCStream(&bitStream);
+*/
+
+/* *****************************************
+*  FSE symbol decompression API
+*******************************************/
+typedef struct {
+	size_t state;
+	const void *table; /* precise table may vary, depending on U16 */
+} FSE_DState_t;
+
+static void FSE_initDState(FSE_DState_t *DStatePtr, BIT_DStream_t *bitD, const FSE_DTable *dt);
+
+static unsigned char FSE_decodeSymbol(FSE_DState_t *DStatePtr, BIT_DStream_t *bitD);
+
+static unsigned FSE_endOfDState(const FSE_DState_t *DStatePtr);
+
+/**<
+Let's now decompose FSE_decompress_usingDTable() into its unitary components.
+You will decode FSE-encoded symbols from the bitStream,
+and also any other bitFields you put in, **in reverse order**.
+
+You will need a few variables to track your bitStream. They are :
+
+BIT_DStream_t DStream;    // Stream context
+FSE_DState_t  DState;     // State context. Multiple ones are possible
+FSE_DTable*   DTablePtr;  // Decoding table, provided by FSE_buildDTable()
+
+The first thing to do is to init the bitStream.
+	errorCode = BIT_initDStream(&DStream, srcBuffer, srcSize);
+
+You should then retrieve your initial state(s)
+(in reverse flushing order if you have several ones) :
+	errorCode = FSE_initDState(&DState, &DStream, DTablePtr);
+
+You can then decode your data, symbol after symbol.
+For information the maximum number of bits read by FSE_decodeSymbol() is 'tableLog'.
+Keep in mind that symbols are decoded in reverse order, like a LIFO stack (last in, first out).
+	unsigned char symbol = FSE_decodeSymbol(&DState, &DStream);
+
+You can retrieve any bitfield you eventually stored into the bitStream (in reverse order)
+Note : maximum allowed nbBits is 25, for 32-bits compatibility
+	size_t bitField = BIT_readBits(&DStream, nbBits);
+
+All above operations only read from local register (which size depends on size_t).
+Refueling the register from memory is manually performed by the reload method.
+	endSignal = FSE_reloadDStream(&DStream);
+
+BIT_reloadDStream() result tells if there is still some more data to read from DStream.
+BIT_DStream_unfinished : there is still some data left into the DStream.
+BIT_DStream_endOfBuffer : Dstream reached end of buffer. Its container may no longer be completely filled.
+BIT_DStream_completed : Dstream reached its exact end, corresponding in general to decompression completed.
+BIT_DStream_tooFar : Dstream went too far. Decompression result is corrupted.
+
+When reaching end of buffer (BIT_DStream_endOfBuffer), progress slowly, notably if you decode multiple symbols per loop,
+to properly detect the exact end of stream.
+After each decoded symbol, check if DStream is fully consumed using this simple test :
+	BIT_reloadDStream(&DStream) >= BIT_DStream_completed
+
+When it's done, verify decompression is fully completed, by checking both DStream and the relevant states.
+Checking if DStream has reached its end is performed by :
+	BIT_endOfDStream(&DStream);
+Check also the states. There might be some symbols left there, if some high probability ones (>50%) are possible.
+	FSE_endOfDState(&DState);
+*/
+
+/* *****************************************
+*  FSE unsafe API
+*******************************************/
+static unsigned char FSE_decodeSymbolFast(FSE_DState_t *DStatePtr, BIT_DStream_t *bitD);
+/* faster, but works only if nbBits is always >= 1 (otherwise, result will be corrupted) */
+
+/* *****************************************
+*  Implementation of inlined functions
+*******************************************/
+typedef struct {
+	int deltaFindState;
+	U32 deltaNbBits;
+} FSE_symbolCompressionTransform; /* total 8 bytes */
+
+ZSTD_STATIC void FSE_initCState(FSE_CState_t *statePtr, const FSE_CTable *ct)
+{
+	const void *ptr = ct;
+	const U16 *u16ptr = (const U16 *)ptr;
+	const U32 tableLog = ZSTD_read16(ptr);
+	statePtr->value = (ptrdiff_t)1 << tableLog;
+	statePtr->stateTable = u16ptr + 2;
+	statePtr->symbolTT = ((const U32 *)ct + 1 + (tableLog ? (1 << (tableLog - 1)) : 1));
+	statePtr->stateLog = tableLog;
+}
+
+/*! FSE_initCState2() :
+*   Same as FSE_initCState(), but the first symbol to include (which will be the last to be read)
+*   uses the smallest state value possible, saving the cost of this symbol */
+ZSTD_STATIC void FSE_initCState2(FSE_CState_t *statePtr, const FSE_CTable *ct, U32 symbol)
+{
+	FSE_initCState(statePtr, ct);
+	{
+		const FSE_symbolCompressionTransform symbolTT = ((const FSE_symbolCompressionTransform *)(statePtr->symbolTT))[symbol];
+		const U16 *stateTable = (const U16 *)(statePtr->stateTable);
+		U32 nbBitsOut = (U32)((symbolTT.deltaNbBits + (1 << 15)) >> 16);
+		statePtr->value = (nbBitsOut << 16) - symbolTT.deltaNbBits;
+		statePtr->value = stateTable[(statePtr->value >> nbBitsOut) + symbolTT.deltaFindState];
+	}
+}
+
+ZSTD_STATIC void FSE_encodeSymbol(BIT_CStream_t *bitC, FSE_CState_t *statePtr, U32 symbol)
+{
+	const FSE_symbolCompressionTransform symbolTT = ((const FSE_symbolCompressionTransform *)(statePtr->symbolTT))[symbol];
+	const U16 *const stateTable = (const U16 *)(statePtr->stateTable);
+	U32 nbBitsOut = (U32)((statePtr->value + symbolTT.deltaNbBits) >> 16);
+	BIT_addBits(bitC, statePtr->value, nbBitsOut);
+	statePtr->value = stateTable[(statePtr->value >> nbBitsOut) + symbolTT.deltaFindState];
+}
+
+ZSTD_STATIC void FSE_flushCState(BIT_CStream_t *bitC, const FSE_CState_t *statePtr)
+{
+	BIT_addBits(bitC, statePtr->value, statePtr->stateLog);
+	BIT_flushBits(bitC);
+}
+
+/* ======    Decompression    ====== */
+
+typedef struct {
+	U16 tableLog;
+	U16 fastMode;
+} FSE_DTableHeader; /* sizeof U32 */
+
+typedef struct {
+	unsigned short newState;
+	unsigned char symbol;
+	unsigned char nbBits;
+} FSE_decode_t; /* size == U32 */
+
+ZSTD_STATIC void FSE_initDState(FSE_DState_t *DStatePtr, BIT_DStream_t *bitD, const FSE_DTable *dt)
+{
+	const void *ptr = dt;
+	const FSE_DTableHeader *const DTableH = (const FSE_DTableHeader *)ptr;
+	DStatePtr->state = BIT_readBits(bitD, DTableH->tableLog);
+	BIT_reloadDStream(bitD);
+	DStatePtr->table = dt + 1;
+}
+
+ZSTD_STATIC BYTE FSE_peekSymbol(const FSE_DState_t *DStatePtr)
+{
+	FSE_decode_t const DInfo = ((const FSE_decode_t *)(DStatePtr->table))[DStatePtr->state];
+	return DInfo.symbol;
+}
+
+ZSTD_STATIC void FSE_updateState(FSE_DState_t *DStatePtr, BIT_DStream_t *bitD)
+{
+	FSE_decode_t const DInfo = ((const FSE_decode_t *)(DStatePtr->table))[DStatePtr->state];
+	U32 const nbBits = DInfo.nbBits;
+	size_t const lowBits = BIT_readBits(bitD, nbBits);
+	DStatePtr->state = DInfo.newState + lowBits;
+}
+
+ZSTD_STATIC BYTE FSE_decodeSymbol(FSE_DState_t *DStatePtr, BIT_DStream_t *bitD)
+{
+	FSE_decode_t const DInfo = ((const FSE_decode_t *)(DStatePtr->table))[DStatePtr->state];
+	U32 const nbBits = DInfo.nbBits;
+	BYTE const symbol = DInfo.symbol;
+	size_t const lowBits = BIT_readBits(bitD, nbBits);
+
+	DStatePtr->state = DInfo.newState + lowBits;
+	return symbol;
+}
+
+/*! FSE_decodeSymbolFast() :
+	unsafe, only works if no symbol has a probability > 50% */
+ZSTD_STATIC BYTE FSE_decodeSymbolFast(FSE_DState_t *DStatePtr, BIT_DStream_t *bitD)
+{
+	FSE_decode_t const DInfo = ((const FSE_decode_t *)(DStatePtr->table))[DStatePtr->state];
+	U32 const nbBits = DInfo.nbBits;
+	BYTE const symbol = DInfo.symbol;
+	size_t const lowBits = BIT_readBitsFast(bitD, nbBits);
+
+	DStatePtr->state = DInfo.newState + lowBits;
+	return symbol;
+}
+
+ZSTD_STATIC unsigned FSE_endOfDState(const FSE_DState_t *DStatePtr) { return DStatePtr->state == 0; }
+
+/* **************************************************************
+*  Tuning parameters
+****************************************************************/
+/*!MEMORY_USAGE :
+*  Memory usage formula : N->2^N Bytes (examples : 10 -> 1KB; 12 -> 4KB ; 16 -> 64KB; 20 -> 1MB; etc.)
+*  Increasing memory usage improves compression ratio
+*  Reduced memory usage can improve speed, due to cache effect
+*  Recommended max value is 14, for 16KB, which nicely fits into Intel x86 L1 cache */
+#ifndef FSE_MAX_MEMORY_USAGE
+#define FSE_MAX_MEMORY_USAGE 14
+#endif
+#ifndef FSE_DEFAULT_MEMORY_USAGE
+#define FSE_DEFAULT_MEMORY_USAGE 13
+#endif
+
+/*!FSE_MAX_SYMBOL_VALUE :
+*  Maximum symbol value authorized.
+*  Required for proper stack allocation */
+#ifndef FSE_MAX_SYMBOL_VALUE
+#define FSE_MAX_SYMBOL_VALUE 255
+#endif
+
+/* **************************************************************
+*  template functions type & suffix
+****************************************************************/
+#define FSE_FUNCTION_TYPE BYTE
+#define FSE_FUNCTION_EXTENSION
+#define FSE_DECODE_TYPE FSE_decode_t
+
+/* ***************************************************************
+*  Constants
+*****************************************************************/
+#define FSE_MAX_TABLELOG (FSE_MAX_MEMORY_USAGE - 2)
+#define FSE_MAX_TABLESIZE (1U << FSE_MAX_TABLELOG)
+#define FSE_MAXTABLESIZE_MASK (FSE_MAX_TABLESIZE - 1)
+#define FSE_DEFAULT_TABLELOG (FSE_DEFAULT_MEMORY_USAGE - 2)
+#define FSE_MIN_TABLELOG 5
+
+#define FSE_TABLELOG_ABSOLUTE_MAX 15
+#if FSE_MAX_TABLELOG > FSE_TABLELOG_ABSOLUTE_MAX
+#error "FSE_MAX_TABLELOG > FSE_TABLELOG_ABSOLUTE_MAX is not supported"
+#endif
+
+#define FSE_TABLESTEP(tableSize) ((tableSize >> 1) + (tableSize >> 3) + 3)
+
+#endif /* FSE_H */
diff -Naurp -x debian.hwe linux-4.10.x.ori/lib/zstd/huf_compress.c linux-4.10.x/lib/zstd/huf_compress.c
--- linux-4.10.x.ori/lib/zstd/huf_compress.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-4.10.x/lib/zstd/huf_compress.c	2017-10-30 10:05:19.610447000 +0100
@@ -0,0 +1,770 @@
+/*
+ * Huffman encoder, part of New Generation Entropy library
+ * Copyright (C) 2013-2016, Yann Collet.
+ *
+ * BSD 2-Clause License (http://www.opensource.org/licenses/bsd-license.php)
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ * notice, this list of conditions and the following disclaimer.
+ *   * Redistributions in binary form must reproduce the above
+ * copyright notice, this list of conditions and the following disclaimer
+ * in the documentation and/or other materials provided with the
+ * distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ * This program is free software; you can redistribute it and/or modify it under
+ * the terms of the GNU General Public License version 2 as published by the
+ * Free Software Foundation. This program is dual-licensed; you may select
+ * either version 2 of the GNU General Public License ("GPL") or BSD license
+ * ("BSD").
+ *
+ * You can contact the author at :
+ * - Source repository : https://github.com/Cyan4973/FiniteStateEntropy
+ */
+
+/* **************************************************************
+*  Includes
+****************************************************************/
+#include "bitstream.h"
+#include "fse.h" /* header compression */
+#include "huf.h"
+#include <linux/kernel.h>
+#include <linux/string.h> /* memcpy, memset */
+
+/* **************************************************************
+*  Error Management
+****************************************************************/
+#define HUF_STATIC_ASSERT(c)                                   \
+	{                                                      \
+		enum { HUF_static_assert = 1 / (int)(!!(c)) }; \
+	} /* use only *after* variable declarations */
+#define CHECK_V_F(e, f)     \
+	size_t const e = f; \
+	if (ERR_isError(e)) \
+	return f
+#define CHECK_F(f)                        \
+	{                                 \
+		CHECK_V_F(_var_err__, f); \
+	}
+
+/* **************************************************************
+*  Utils
+****************************************************************/
+unsigned HUF_optimalTableLog(unsigned maxTableLog, size_t srcSize, unsigned maxSymbolValue)
+{
+	return FSE_optimalTableLog_internal(maxTableLog, srcSize, maxSymbolValue, 1);
+}
+
+/* *******************************************************
+*  HUF : Huffman block compression
+*********************************************************/
+/* HUF_compressWeights() :
+ * Same as FSE_compress(), but dedicated to huff0's weights compression.
+ * The use case needs much less stack memory.
+ * Note : all elements within weightTable are supposed to be <= HUF_TABLELOG_MAX.
+ */
+#define MAX_FSE_TABLELOG_FOR_HUFF_HEADER 6
+size_t HUF_compressWeights_wksp(void *dst, size_t dstSize, const void *weightTable, size_t wtSize, void *workspace, size_t workspaceSize)
+{
+	BYTE *const ostart = (BYTE *)dst;
+	BYTE *op = ostart;
+	BYTE *const oend = ostart + dstSize;
+
+	U32 maxSymbolValue = HUF_TABLELOG_MAX;
+	U32 tableLog = MAX_FSE_TABLELOG_FOR_HUFF_HEADER;
+
+	FSE_CTable *CTable;
+	U32 *count;
+	S16 *norm;
+	size_t spaceUsed32 = 0;
+
+	HUF_STATIC_ASSERT(sizeof(FSE_CTable) == sizeof(U32));
+
+	CTable = (FSE_CTable *)((U32 *)workspace + spaceUsed32);
+	spaceUsed32 += FSE_CTABLE_SIZE_U32(MAX_FSE_TABLELOG_FOR_HUFF_HEADER, HUF_TABLELOG_MAX);
+	count = (U32 *)workspace + spaceUsed32;
+	spaceUsed32 += HUF_TABLELOG_MAX + 1;
+	norm = (S16 *)((U32 *)workspace + spaceUsed32);
+	spaceUsed32 += ALIGN(sizeof(S16) * (HUF_TABLELOG_MAX + 1), sizeof(U32)) >> 2;
+
+	if ((spaceUsed32 << 2) > workspaceSize)
+		return ERROR(tableLog_tooLarge);
+	workspace = (U32 *)workspace + spaceUsed32;
+	workspaceSize -= (spaceUsed32 << 2);
+
+	/* init conditions */
+	if (wtSize <= 1)
+		return 0; /* Not compressible */
+
+	/* Scan input and build symbol stats */
+	{
+		CHECK_V_F(maxCount, FSE_count_simple(count, &maxSymbolValue, weightTable, wtSize));
+		if (maxCount == wtSize)
+			return 1; /* only a single symbol in src : rle */
+		if (maxCount == 1)
+			return 0; /* each symbol present maximum once => not compressible */
+	}
+
+	tableLog = FSE_optimalTableLog(tableLog, wtSize, maxSymbolValue);
+	CHECK_F(FSE_normalizeCount(norm, tableLog, count, wtSize, maxSymbolValue));
+
+	/* Write table description header */
+	{
+		CHECK_V_F(hSize, FSE_writeNCount(op, oend - op, norm, maxSymbolValue, tableLog));
+		op += hSize;
+	}
+
+	/* Compress */
+	CHECK_F(FSE_buildCTable_wksp(CTable, norm, maxSymbolValue, tableLog, workspace, workspaceSize));
+	{
+		CHECK_V_F(cSize, FSE_compress_usingCTable(op, oend - op, weightTable, wtSize, CTable));
+		if (cSize == 0)
+			return 0; /* not enough space for compressed data */
+		op += cSize;
+	}
+
+	return op - ostart;
+}
+
+struct HUF_CElt_s {
+	U16 val;
+	BYTE nbBits;
+}; /* typedef'd to HUF_CElt within "huf.h" */
+
+/*! HUF_writeCTable_wksp() :
+	`CTable` : Huffman tree to save, using huf representation.
+	@return : size of saved CTable */
+size_t HUF_writeCTable_wksp(void *dst, size_t maxDstSize, const HUF_CElt *CTable, U32 maxSymbolValue, U32 huffLog, void *workspace, size_t workspaceSize)
+{
+	BYTE *op = (BYTE *)dst;
+	U32 n;
+
+	BYTE *bitsToWeight;
+	BYTE *huffWeight;
+	size_t spaceUsed32 = 0;
+
+	bitsToWeight = (BYTE *)((U32 *)workspace + spaceUsed32);
+	spaceUsed32 += ALIGN(HUF_TABLELOG_MAX + 1, sizeof(U32)) >> 2;
+	huffWeight = (BYTE *)((U32 *)workspace + spaceUsed32);
+	spaceUsed32 += ALIGN(HUF_SYMBOLVALUE_MAX, sizeof(U32)) >> 2;
+
+	if ((spaceUsed32 << 2) > workspaceSize)
+		return ERROR(tableLog_tooLarge);
+	workspace = (U32 *)workspace + spaceUsed32;
+	workspaceSize -= (spaceUsed32 << 2);
+
+	/* check conditions */
+	if (maxSymbolValue > HUF_SYMBOLVALUE_MAX)
+		return ERROR(maxSymbolValue_tooLarge);
+
+	/* convert to weight */
+	bitsToWeight[0] = 0;
+	for (n = 1; n < huffLog + 1; n++)
+		bitsToWeight[n] = (BYTE)(huffLog + 1 - n);
+	for (n = 0; n < maxSymbolValue; n++)
+		huffWeight[n] = bitsToWeight[CTable[n].nbBits];
+
+	/* attempt weights compression by FSE */
+	{
+		CHECK_V_F(hSize, HUF_compressWeights_wksp(op + 1, maxDstSize - 1, huffWeight, maxSymbolValue, workspace, workspaceSize));
+		if ((hSize > 1) & (hSize < maxSymbolValue / 2)) { /* FSE compressed */
+			op[0] = (BYTE)hSize;
+			return hSize + 1;
+		}
+	}
+
+	/* write raw values as 4-bits (max : 15) */
+	if (maxSymbolValue > (256 - 128))
+		return ERROR(GENERIC); /* should not happen : likely means source cannot be compressed */
+	if (((maxSymbolValue + 1) / 2) + 1 > maxDstSize)
+		return ERROR(dstSize_tooSmall); /* not enough space within dst buffer */
+	op[0] = (BYTE)(128 /*special case*/ + (maxSymbolValue - 1));
+	huffWeight[maxSymbolValue] = 0; /* to be sure it doesn't cause msan issue in final combination */
+	for (n = 0; n < maxSymbolValue; n += 2)
+		op[(n / 2) + 1] = (BYTE)((huffWeight[n] << 4) + huffWeight[n + 1]);
+	return ((maxSymbolValue + 1) / 2) + 1;
+}
+
+size_t HUF_readCTable_wksp(HUF_CElt *CTable, U32 maxSymbolValue, const void *src, size_t srcSize, void *workspace, size_t workspaceSize)
+{
+	U32 *rankVal;
+	BYTE *huffWeight;
+	U32 tableLog = 0;
+	U32 nbSymbols = 0;
+	size_t readSize;
+	size_t spaceUsed32 = 0;
+
+	rankVal = (U32 *)workspace + spaceUsed32;
+	spaceUsed32 += HUF_TABLELOG_ABSOLUTEMAX + 1;
+	huffWeight = (BYTE *)((U32 *)workspace + spaceUsed32);
+	spaceUsed32 += ALIGN(HUF_SYMBOLVALUE_MAX + 1, sizeof(U32)) >> 2;
+
+	if ((spaceUsed32 << 2) > workspaceSize)
+		return ERROR(tableLog_tooLarge);
+	workspace = (U32 *)workspace + spaceUsed32;
+	workspaceSize -= (spaceUsed32 << 2);
+
+	/* get symbol weights */
+	readSize = HUF_readStats_wksp(huffWeight, HUF_SYMBOLVALUE_MAX + 1, rankVal, &nbSymbols, &tableLog, src, srcSize, workspace, workspaceSize);
+	if (ERR_isError(readSize))
+		return readSize;
+
+	/* check result */
+	if (tableLog > HUF_TABLELOG_MAX)
+		return ERROR(tableLog_tooLarge);
+	if (nbSymbols > maxSymbolValue + 1)
+		return ERROR(maxSymbolValue_tooSmall);
+
+	/* Prepare base value per rank */
+	{
+		U32 n, nextRankStart = 0;
+		for (n = 1; n <= tableLog; n++) {
+			U32 curr = nextRankStart;
+			nextRankStart += (rankVal[n] << (n - 1));
+			rankVal[n] = curr;
+		}
+	}
+
+	/* fill nbBits */
+	{
+		U32 n;
+		for (n = 0; n < nbSymbols; n++) {
+			const U32 w = huffWeight[n];
+			CTable[n].nbBits = (BYTE)(tableLog + 1 - w);
+		}
+	}
+
+	/* fill val */
+	{
+		U16 nbPerRank[HUF_TABLELOG_MAX + 2] = {0}; /* support w=0=>n=tableLog+1 */
+		U16 valPerRank[HUF_TABLELOG_MAX + 2] = {0};
+		{
+			U32 n;
+			for (n = 0; n < nbSymbols; n++)
+				nbPerRank[CTable[n].nbBits]++;
+		}
+		/* determine stating value per rank */
+		valPerRank[tableLog + 1] = 0; /* for w==0 */
+		{
+			U16 min = 0;
+			U32 n;
+			for (n = tableLog; n > 0; n--) { /* start at n=tablelog <-> w=1 */
+				valPerRank[n] = min;     /* get starting value within each rank */
+				min += nbPerRank[n];
+				min >>= 1;
+			}
+		}
+		/* assign value within rank, symbol order */
+		{
+			U32 n;
+			for (n = 0; n <= maxSymbolValue; n++)
+				CTable[n].val = valPerRank[CTable[n].nbBits]++;
+		}
+	}
+
+	return readSize;
+}
+
+typedef struct nodeElt_s {
+	U32 count;
+	U16 parent;
+	BYTE byte;
+	BYTE nbBits;
+} nodeElt;
+
+static U32 HUF_setMaxHeight(nodeElt *huffNode, U32 lastNonNull, U32 maxNbBits)
+{
+	const U32 largestBits = huffNode[lastNonNull].nbBits;
+	if (largestBits <= maxNbBits)
+		return largestBits; /* early exit : no elt > maxNbBits */
+
+	/* there are several too large elements (at least >= 2) */
+	{
+		int totalCost = 0;
+		const U32 baseCost = 1 << (largestBits - maxNbBits);
+		U32 n = lastNonNull;
+
+		while (huffNode[n].nbBits > maxNbBits) {
+			totalCost += baseCost - (1 << (largestBits - huffNode[n].nbBits));
+			huffNode[n].nbBits = (BYTE)maxNbBits;
+			n--;
+		} /* n stops at huffNode[n].nbBits <= maxNbBits */
+		while (huffNode[n].nbBits == maxNbBits)
+			n--; /* n end at index of smallest symbol using < maxNbBits */
+
+		/* renorm totalCost */
+		totalCost >>= (largestBits - maxNbBits); /* note : totalCost is necessarily a multiple of baseCost */
+
+		/* repay normalized cost */
+		{
+			U32 const noSymbol = 0xF0F0F0F0;
+			U32 rankLast[HUF_TABLELOG_MAX + 2];
+			int pos;
+
+			/* Get pos of last (smallest) symbol per rank */
+			memset(rankLast, 0xF0, sizeof(rankLast));
+			{
+				U32 currNbBits = maxNbBits;
+				for (pos = n; pos >= 0; pos--) {
+					if (huffNode[pos].nbBits >= currNbBits)
+						continue;
+					currNbBits = huffNode[pos].nbBits; /* < maxNbBits */
+					rankLast[maxNbBits - currNbBits] = pos;
+				}
+			}
+
+			while (totalCost > 0) {
+				U32 nBitsToDecrease = BIT_highbit32(totalCost) + 1;
+				for (; nBitsToDecrease > 1; nBitsToDecrease--) {
+					U32 highPos = rankLast[nBitsToDecrease];
+					U32 lowPos = rankLast[nBitsToDecrease - 1];
+					if (highPos == noSymbol)
+						continue;
+					if (lowPos == noSymbol)
+						break;
+					{
+						U32 const highTotal = huffNode[highPos].count;
+						U32 const lowTotal = 2 * huffNode[lowPos].count;
+						if (highTotal <= lowTotal)
+							break;
+					}
+				}
+				/* only triggered when no more rank 1 symbol left => find closest one (note : there is necessarily at least one !) */
+				/* HUF_MAX_TABLELOG test just to please gcc 5+; but it should not be necessary */
+				while ((nBitsToDecrease <= HUF_TABLELOG_MAX) && (rankLast[nBitsToDecrease] == noSymbol))
+					nBitsToDecrease++;
+				totalCost -= 1 << (nBitsToDecrease - 1);
+				if (rankLast[nBitsToDecrease - 1] == noSymbol)
+					rankLast[nBitsToDecrease - 1] = rankLast[nBitsToDecrease]; /* this rank is no longer empty */
+				huffNode[rankLast[nBitsToDecrease]].nbBits++;
+				if (rankLast[nBitsToDecrease] == 0) /* special case, reached largest symbol */
+					rankLast[nBitsToDecrease] = noSymbol;
+				else {
+					rankLast[nBitsToDecrease]--;
+					if (huffNode[rankLast[nBitsToDecrease]].nbBits != maxNbBits - nBitsToDecrease)
+						rankLast[nBitsToDecrease] = noSymbol; /* this rank is now empty */
+				}
+			} /* while (totalCost > 0) */
+
+			while (totalCost < 0) {		       /* Sometimes, cost correction overshoot */
+				if (rankLast[1] == noSymbol) { /* special case : no rank 1 symbol (using maxNbBits-1); let's create one from largest rank 0
+								  (using maxNbBits) */
+					while (huffNode[n].nbBits == maxNbBits)
+						n--;
+					huffNode[n + 1].nbBits--;
+					rankLast[1] = n + 1;
+					totalCost++;
+					continue;
+				}
+				huffNode[rankLast[1] + 1].nbBits--;
+				rankLast[1]++;
+				totalCost++;
+			}
+		}
+	} /* there are several too large elements (at least >= 2) */
+
+	return maxNbBits;
+}
+
+typedef struct {
+	U32 base;
+	U32 curr;
+} rankPos;
+
+static void HUF_sort(nodeElt *huffNode, const U32 *count, U32 maxSymbolValue)
+{
+	rankPos rank[32];
+	U32 n;
+
+	memset(rank, 0, sizeof(rank));
+	for (n = 0; n <= maxSymbolValue; n++) {
+		U32 r = BIT_highbit32(count[n] + 1);
+		rank[r].base++;
+	}
+	for (n = 30; n > 0; n--)
+		rank[n - 1].base += rank[n].base;
+	for (n = 0; n < 32; n++)
+		rank[n].curr = rank[n].base;
+	for (n = 0; n <= maxSymbolValue; n++) {
+		U32 const c = count[n];
+		U32 const r = BIT_highbit32(c + 1) + 1;
+		U32 pos = rank[r].curr++;
+		while ((pos > rank[r].base) && (c > huffNode[pos - 1].count))
+			huffNode[pos] = huffNode[pos - 1], pos--;
+		huffNode[pos].count = c;
+		huffNode[pos].byte = (BYTE)n;
+	}
+}
+
+/** HUF_buildCTable_wksp() :
+ *  Same as HUF_buildCTable(), but using externally allocated scratch buffer.
+ *  `workSpace` must be aligned on 4-bytes boundaries, and be at least as large as a table of 1024 unsigned.
+ */
+#define STARTNODE (HUF_SYMBOLVALUE_MAX + 1)
+typedef nodeElt huffNodeTable[2 * HUF_SYMBOLVALUE_MAX + 1 + 1];
+size_t HUF_buildCTable_wksp(HUF_CElt *tree, const U32 *count, U32 maxSymbolValue, U32 maxNbBits, void *workSpace, size_t wkspSize)
+{
+	nodeElt *const huffNode0 = (nodeElt *)workSpace;
+	nodeElt *const huffNode = huffNode0 + 1;
+	U32 n, nonNullRank;
+	int lowS, lowN;
+	U16 nodeNb = STARTNODE;
+	U32 nodeRoot;
+
+	/* safety checks */
+	if (wkspSize < sizeof(huffNodeTable))
+		return ERROR(GENERIC); /* workSpace is not large enough */
+	if (maxNbBits == 0)
+		maxNbBits = HUF_TABLELOG_DEFAULT;
+	if (maxSymbolValue > HUF_SYMBOLVALUE_MAX)
+		return ERROR(GENERIC);
+	memset(huffNode0, 0, sizeof(huffNodeTable));
+
+	/* sort, decreasing order */
+	HUF_sort(huffNode, count, maxSymbolValue);
+
+	/* init for parents */
+	nonNullRank = maxSymbolValue;
+	while (huffNode[nonNullRank].count == 0)
+		nonNullRank--;
+	lowS = nonNullRank;
+	nodeRoot = nodeNb + lowS - 1;
+	lowN = nodeNb;
+	huffNode[nodeNb].count = huffNode[lowS].count + huffNode[lowS - 1].count;
+	huffNode[lowS].parent = huffNode[lowS - 1].parent = nodeNb;
+	nodeNb++;
+	lowS -= 2;
+	for (n = nodeNb; n <= nodeRoot; n++)
+		huffNode[n].count = (U32)(1U << 30);
+	huffNode0[0].count = (U32)(1U << 31); /* fake entry, strong barrier */
+
+	/* create parents */
+	while (nodeNb <= nodeRoot) {
+		U32 n1 = (huffNode[lowS].count < huffNode[lowN].count) ? lowS-- : lowN++;
+		U32 n2 = (huffNode[lowS].count < huffNode[lowN].count) ? lowS-- : lowN++;
+		huffNode[nodeNb].count = huffNode[n1].count + huffNode[n2].count;
+		huffNode[n1].parent = huffNode[n2].parent = nodeNb;
+		nodeNb++;
+	}
+
+	/* distribute weights (unlimited tree height) */
+	huffNode[nodeRoot].nbBits = 0;
+	for (n = nodeRoot - 1; n >= STARTNODE; n--)
+		huffNode[n].nbBits = huffNode[huffNode[n].parent].nbBits + 1;
+	for (n = 0; n <= nonNullRank; n++)
+		huffNode[n].nbBits = huffNode[huffNode[n].parent].nbBits + 1;
+
+	/* enforce maxTableLog */
+	maxNbBits = HUF_setMaxHeight(huffNode, nonNullRank, maxNbBits);
+
+	/* fill result into tree (val, nbBits) */
+	{
+		U16 nbPerRank[HUF_TABLELOG_MAX + 1] = {0};
+		U16 valPerRank[HUF_TABLELOG_MAX + 1] = {0};
+		if (maxNbBits > HUF_TABLELOG_MAX)
+			return ERROR(GENERIC); /* check fit into table */
+		for (n = 0; n <= nonNullRank; n++)
+			nbPerRank[huffNode[n].nbBits]++;
+		/* determine stating value per rank */
+		{
+			U16 min = 0;
+			for (n = maxNbBits; n > 0; n--) {
+				valPerRank[n] = min; /* get starting value within each rank */
+				min += nbPerRank[n];
+				min >>= 1;
+			}
+		}
+		for (n = 0; n <= maxSymbolValue; n++)
+			tree[huffNode[n].byte].nbBits = huffNode[n].nbBits; /* push nbBits per symbol, symbol order */
+		for (n = 0; n <= maxSymbolValue; n++)
+			tree[n].val = valPerRank[tree[n].nbBits]++; /* assign value within rank, symbol order */
+	}
+
+	return maxNbBits;
+}
+
+static size_t HUF_estimateCompressedSize(HUF_CElt *CTable, const unsigned *count, unsigned maxSymbolValue)
+{
+	size_t nbBits = 0;
+	int s;
+	for (s = 0; s <= (int)maxSymbolValue; ++s) {
+		nbBits += CTable[s].nbBits * count[s];
+	}
+	return nbBits >> 3;
+}
+
+static int HUF_validateCTable(const HUF_CElt *CTable, const unsigned *count, unsigned maxSymbolValue)
+{
+	int bad = 0;
+	int s;
+	for (s = 0; s <= (int)maxSymbolValue; ++s) {
+		bad |= (count[s] != 0) & (CTable[s].nbBits == 0);
+	}
+	return !bad;
+}
+
+static void HUF_encodeSymbol(BIT_CStream_t *bitCPtr, U32 symbol, const HUF_CElt *CTable)
+{
+	BIT_addBitsFast(bitCPtr, CTable[symbol].val, CTable[symbol].nbBits);
+}
+
+size_t HUF_compressBound(size_t size) { return HUF_COMPRESSBOUND(size); }
+
+#define HUF_FLUSHBITS(s)  BIT_flushBits(s)
+
+#define HUF_FLUSHBITS_1(stream)                                            \
+	if (sizeof((stream)->bitContainer) * 8 < HUF_TABLELOG_MAX * 2 + 7) \
+	HUF_FLUSHBITS(stream)
+
+#define HUF_FLUSHBITS_2(stream)                                            \
+	if (sizeof((stream)->bitContainer) * 8 < HUF_TABLELOG_MAX * 4 + 7) \
+	HUF_FLUSHBITS(stream)
+
+size_t HUF_compress1X_usingCTable(void *dst, size_t dstSize, const void *src, size_t srcSize, const HUF_CElt *CTable)
+{
+	const BYTE *ip = (const BYTE *)src;
+	BYTE *const ostart = (BYTE *)dst;
+	BYTE *const oend = ostart + dstSize;
+	BYTE *op = ostart;
+	size_t n;
+	BIT_CStream_t bitC;
+
+	/* init */
+	if (dstSize < 8)
+		return 0; /* not enough space to compress */
+	{
+		size_t const initErr = BIT_initCStream(&bitC, op, oend - op);
+		if (HUF_isError(initErr))
+			return 0;
+	}
+
+	n = srcSize & ~3; /* join to mod 4 */
+	switch (srcSize & 3) {
+	case 3: HUF_encodeSymbol(&bitC, ip[n + 2], CTable); HUF_FLUSHBITS_2(&bitC);
+	case 2: HUF_encodeSymbol(&bitC, ip[n + 1], CTable); HUF_FLUSHBITS_1(&bitC);
+	case 1: HUF_encodeSymbol(&bitC, ip[n + 0], CTable); HUF_FLUSHBITS(&bitC);
+	case 0:
+	default:;
+	}
+
+	for (; n > 0; n -= 4) { /* note : n&3==0 at this stage */
+		HUF_encodeSymbol(&bitC, ip[n - 1], CTable);
+		HUF_FLUSHBITS_1(&bitC);
+		HUF_encodeSymbol(&bitC, ip[n - 2], CTable);
+		HUF_FLUSHBITS_2(&bitC);
+		HUF_encodeSymbol(&bitC, ip[n - 3], CTable);
+		HUF_FLUSHBITS_1(&bitC);
+		HUF_encodeSymbol(&bitC, ip[n - 4], CTable);
+		HUF_FLUSHBITS(&bitC);
+	}
+
+	return BIT_closeCStream(&bitC);
+}
+
+size_t HUF_compress4X_usingCTable(void *dst, size_t dstSize, const void *src, size_t srcSize, const HUF_CElt *CTable)
+{
+	size_t const segmentSize = (srcSize + 3) / 4; /* first 3 segments */
+	const BYTE *ip = (const BYTE *)src;
+	const BYTE *const iend = ip + srcSize;
+	BYTE *const ostart = (BYTE *)dst;
+	BYTE *const oend = ostart + dstSize;
+	BYTE *op = ostart;
+
+	if (dstSize < 6 + 1 + 1 + 1 + 8)
+		return 0; /* minimum space to compress successfully */
+	if (srcSize < 12)
+		return 0; /* no saving possible : too small input */
+	op += 6;	  /* jumpTable */
+
+	{
+		CHECK_V_F(cSize, HUF_compress1X_usingCTable(op, oend - op, ip, segmentSize, CTable));
+		if (cSize == 0)
+			return 0;
+		ZSTD_writeLE16(ostart, (U16)cSize);
+		op += cSize;
+	}
+
+	ip += segmentSize;
+	{
+		CHECK_V_F(cSize, HUF_compress1X_usingCTable(op, oend - op, ip, segmentSize, CTable));
+		if (cSize == 0)
+			return 0;
+		ZSTD_writeLE16(ostart + 2, (U16)cSize);
+		op += cSize;
+	}
+
+	ip += segmentSize;
+	{
+		CHECK_V_F(cSize, HUF_compress1X_usingCTable(op, oend - op, ip, segmentSize, CTable));
+		if (cSize == 0)
+			return 0;
+		ZSTD_writeLE16(ostart + 4, (U16)cSize);
+		op += cSize;
+	}
+
+	ip += segmentSize;
+	{
+		CHECK_V_F(cSize, HUF_compress1X_usingCTable(op, oend - op, ip, iend - ip, CTable));
+		if (cSize == 0)
+			return 0;
+		op += cSize;
+	}
+
+	return op - ostart;
+}
+
+static size_t HUF_compressCTable_internal(BYTE *const ostart, BYTE *op, BYTE *const oend, const void *src, size_t srcSize, unsigned singleStream,
+					  const HUF_CElt *CTable)
+{
+	size_t const cSize =
+	    singleStream ? HUF_compress1X_usingCTable(op, oend - op, src, srcSize, CTable) : HUF_compress4X_usingCTable(op, oend - op, src, srcSize, CTable);
+	if (HUF_isError(cSize)) {
+		return cSize;
+	}
+	if (cSize == 0) {
+		return 0;
+	} /* uncompressible */
+	op += cSize;
+	/* check compressibility */
+	if ((size_t)(op - ostart) >= srcSize - 1) {
+		return 0;
+	}
+	return op - ostart;
+}
+
+/* `workSpace` must a table of at least 1024 unsigned */
+static size_t HUF_compress_internal(void *dst, size_t dstSize, const void *src, size_t srcSize, unsigned maxSymbolValue, unsigned huffLog,
+				    unsigned singleStream, void *workSpace, size_t wkspSize, HUF_CElt *oldHufTable, HUF_repeat *repeat, int preferRepeat)
+{
+	BYTE *const ostart = (BYTE *)dst;
+	BYTE *const oend = ostart + dstSize;
+	BYTE *op = ostart;
+
+	U32 *count;
+	size_t const countSize = sizeof(U32) * (HUF_SYMBOLVALUE_MAX + 1);
+	HUF_CElt *CTable;
+	size_t const CTableSize = sizeof(HUF_CElt) * (HUF_SYMBOLVALUE_MAX + 1);
+
+	/* checks & inits */
+	if (wkspSize < sizeof(huffNodeTable) + countSize + CTableSize)
+		return ERROR(GENERIC);
+	if (!srcSize)
+		return 0; /* Uncompressed (note : 1 means rle, so first byte must be correct) */
+	if (!dstSize)
+		return 0; /* cannot fit within dst budget */
+	if (srcSize > HUF_BLOCKSIZE_MAX)
+		return ERROR(srcSize_wrong); /* curr block size limit */
+	if (huffLog > HUF_TABLELOG_MAX)
+		return ERROR(tableLog_tooLarge);
+	if (!maxSymbolValue)
+		maxSymbolValue = HUF_SYMBOLVALUE_MAX;
+	if (!huffLog)
+		huffLog = HUF_TABLELOG_DEFAULT;
+
+	count = (U32 *)workSpace;
+	workSpace = (BYTE *)workSpace + countSize;
+	wkspSize -= countSize;
+	CTable = (HUF_CElt *)workSpace;
+	workSpace = (BYTE *)workSpace + CTableSize;
+	wkspSize -= CTableSize;
+
+	/* Heuristic : If we don't need to check the validity of the old table use the old table for small inputs */
+	if (preferRepeat && repeat && *repeat == HUF_repeat_valid) {
+		return HUF_compressCTable_internal(ostart, op, oend, src, srcSize, singleStream, oldHufTable);
+	}
+
+	/* Scan input and build symbol stats */
+	{
+		CHECK_V_F(largest, FSE_count_wksp(count, &maxSymbolValue, (const BYTE *)src, srcSize, (U32 *)workSpace));
+		if (largest == srcSize) {
+			*ostart = ((const BYTE *)src)[0];
+			return 1;
+		} /* single symbol, rle */
+		if (largest <= (srcSize >> 7) + 1)
+			return 0; /* Fast heuristic : not compressible enough */
+	}
+
+	/* Check validity of previous table */
+	if (repeat && *repeat == HUF_repeat_check && !HUF_validateCTable(oldHufTable, count, maxSymbolValue)) {
+		*repeat = HUF_repeat_none;
+	}
+	/* Heuristic : use existing table for small inputs */
+	if (preferRepeat && repeat && *repeat != HUF_repeat_none) {
+		return HUF_compressCTable_internal(ostart, op, oend, src, srcSize, singleStream, oldHufTable);
+	}
+
+	/* Build Huffman Tree */
+	huffLog = HUF_optimalTableLog(huffLog, srcSize, maxSymbolValue);
+	{
+		CHECK_V_F(maxBits, HUF_buildCTable_wksp(CTable, count, maxSymbolValue, huffLog, workSpace, wkspSize));
+		huffLog = (U32)maxBits;
+		/* Zero the unused symbols so we can check it for validity */
+		memset(CTable + maxSymbolValue + 1, 0, CTableSize - (maxSymbolValue + 1) * sizeof(HUF_CElt));
+	}
+
+	/* Write table description header */
+	{
+		CHECK_V_F(hSize, HUF_writeCTable_wksp(op, dstSize, CTable, maxSymbolValue, huffLog, workSpace, wkspSize));
+		/* Check if using the previous table will be beneficial */
+		if (repeat && *repeat != HUF_repeat_none) {
+			size_t const oldSize = HUF_estimateCompressedSize(oldHufTable, count, maxSymbolValue);
+			size_t const newSize = HUF_estimateCompressedSize(CTable, count, maxSymbolValue);
+			if (oldSize <= hSize + newSize || hSize + 12 >= srcSize) {
+				return HUF_compressCTable_internal(ostart, op, oend, src, srcSize, singleStream, oldHufTable);
+			}
+		}
+		/* Use the new table */
+		if (hSize + 12ul >= srcSize) {
+			return 0;
+		}
+		op += hSize;
+		if (repeat) {
+			*repeat = HUF_repeat_none;
+		}
+		if (oldHufTable) {
+			memcpy(oldHufTable, CTable, CTableSize);
+		} /* Save the new table */
+	}
+	return HUF_compressCTable_internal(ostart, op, oend, src, srcSize, singleStream, CTable);
+}
+
+size_t HUF_compress1X_wksp(void *dst, size_t dstSize, const void *src, size_t srcSize, unsigned maxSymbolValue, unsigned huffLog, void *workSpace,
+			   size_t wkspSize)
+{
+	return HUF_compress_internal(dst, dstSize, src, srcSize, maxSymbolValue, huffLog, 1 /* single stream */, workSpace, wkspSize, NULL, NULL, 0);
+}
+
+size_t HUF_compress1X_repeat(void *dst, size_t dstSize, const void *src, size_t srcSize, unsigned maxSymbolValue, unsigned huffLog, void *workSpace,
+			     size_t wkspSize, HUF_CElt *hufTable, HUF_repeat *repeat, int preferRepeat)
+{
+	return HUF_compress_internal(dst, dstSize, src, srcSize, maxSymbolValue, huffLog, 1 /* single stream */, workSpace, wkspSize, hufTable, repeat,
+				     preferRepeat);
+}
+
+size_t HUF_compress4X_wksp(void *dst, size_t dstSize, const void *src, size_t srcSize, unsigned maxSymbolValue, unsigned huffLog, void *workSpace,
+			   size_t wkspSize)
+{
+	return HUF_compress_internal(dst, dstSize, src, srcSize, maxSymbolValue, huffLog, 0 /* 4 streams */, workSpace, wkspSize, NULL, NULL, 0);
+}
+
+size_t HUF_compress4X_repeat(void *dst, size_t dstSize, const void *src, size_t srcSize, unsigned maxSymbolValue, unsigned huffLog, void *workSpace,
+			     size_t wkspSize, HUF_CElt *hufTable, HUF_repeat *repeat, int preferRepeat)
+{
+	return HUF_compress_internal(dst, dstSize, src, srcSize, maxSymbolValue, huffLog, 0 /* 4 streams */, workSpace, wkspSize, hufTable, repeat,
+				     preferRepeat);
+}
diff -Naurp -x debian.hwe linux-4.10.x.ori/lib/zstd/huf_decompress.c linux-4.10.x/lib/zstd/huf_decompress.c
--- linux-4.10.x.ori/lib/zstd/huf_decompress.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-4.10.x/lib/zstd/huf_decompress.c	2017-10-30 10:05:19.610447000 +0100
@@ -0,0 +1,960 @@
+/*
+ * Huffman decoder, part of New Generation Entropy library
+ * Copyright (C) 2013-2016, Yann Collet.
+ *
+ * BSD 2-Clause License (http://www.opensource.org/licenses/bsd-license.php)
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ * notice, this list of conditions and the following disclaimer.
+ *   * Redistributions in binary form must reproduce the above
+ * copyright notice, this list of conditions and the following disclaimer
+ * in the documentation and/or other materials provided with the
+ * distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ * This program is free software; you can redistribute it and/or modify it under
+ * the terms of the GNU General Public License version 2 as published by the
+ * Free Software Foundation. This program is dual-licensed; you may select
+ * either version 2 of the GNU General Public License ("GPL") or BSD license
+ * ("BSD").
+ *
+ * You can contact the author at :
+ * - Source repository : https://github.com/Cyan4973/FiniteStateEntropy
+ */
+
+/* **************************************************************
+*  Compiler specifics
+****************************************************************/
+#define FORCE_INLINE static __always_inline
+
+/* **************************************************************
+*  Dependencies
+****************************************************************/
+#include "bitstream.h" /* BIT_* */
+#include "fse.h"       /* header compression */
+#include "huf.h"
+#include <linux/compiler.h>
+#include <linux/kernel.h>
+#include <linux/string.h> /* memcpy, memset */
+
+/* **************************************************************
+*  Error Management
+****************************************************************/
+#define HUF_STATIC_ASSERT(c)                                   \
+	{                                                      \
+		enum { HUF_static_assert = 1 / (int)(!!(c)) }; \
+	} /* use only *after* variable declarations */
+
+/*-***************************/
+/*  generic DTableDesc       */
+/*-***************************/
+
+typedef struct {
+	BYTE maxTableLog;
+	BYTE tableType;
+	BYTE tableLog;
+	BYTE reserved;
+} DTableDesc;
+
+static DTableDesc HUF_getDTableDesc(const HUF_DTable *table)
+{
+	DTableDesc dtd;
+	memcpy(&dtd, table, sizeof(dtd));
+	return dtd;
+}
+
+/*-***************************/
+/*  single-symbol decoding   */
+/*-***************************/
+
+typedef struct {
+	BYTE byte;
+	BYTE nbBits;
+} HUF_DEltX2; /* single-symbol decoding */
+
+size_t HUF_readDTableX2_wksp(HUF_DTable *DTable, const void *src, size_t srcSize, void *workspace, size_t workspaceSize)
+{
+	U32 tableLog = 0;
+	U32 nbSymbols = 0;
+	size_t iSize;
+	void *const dtPtr = DTable + 1;
+	HUF_DEltX2 *const dt = (HUF_DEltX2 *)dtPtr;
+
+	U32 *rankVal;
+	BYTE *huffWeight;
+	size_t spaceUsed32 = 0;
+
+	rankVal = (U32 *)workspace + spaceUsed32;
+	spaceUsed32 += HUF_TABLELOG_ABSOLUTEMAX + 1;
+	huffWeight = (BYTE *)((U32 *)workspace + spaceUsed32);
+	spaceUsed32 += ALIGN(HUF_SYMBOLVALUE_MAX + 1, sizeof(U32)) >> 2;
+
+	if ((spaceUsed32 << 2) > workspaceSize)
+		return ERROR(tableLog_tooLarge);
+	workspace = (U32 *)workspace + spaceUsed32;
+	workspaceSize -= (spaceUsed32 << 2);
+
+	HUF_STATIC_ASSERT(sizeof(DTableDesc) == sizeof(HUF_DTable));
+	/* memset(huffWeight, 0, sizeof(huffWeight)); */ /* is not necessary, even though some analyzer complain ... */
+
+	iSize = HUF_readStats_wksp(huffWeight, HUF_SYMBOLVALUE_MAX + 1, rankVal, &nbSymbols, &tableLog, src, srcSize, workspace, workspaceSize);
+	if (HUF_isError(iSize))
+		return iSize;
+
+	/* Table header */
+	{
+		DTableDesc dtd = HUF_getDTableDesc(DTable);
+		if (tableLog > (U32)(dtd.maxTableLog + 1))
+			return ERROR(tableLog_tooLarge); /* DTable too small, Huffman tree cannot fit in */
+		dtd.tableType = 0;
+		dtd.tableLog = (BYTE)tableLog;
+		memcpy(DTable, &dtd, sizeof(dtd));
+	}
+
+	/* Calculate starting value for each rank */
+	{
+		U32 n, nextRankStart = 0;
+		for (n = 1; n < tableLog + 1; n++) {
+			U32 const curr = nextRankStart;
+			nextRankStart += (rankVal[n] << (n - 1));
+			rankVal[n] = curr;
+		}
+	}
+
+	/* fill DTable */
+	{
+		U32 n;
+		for (n = 0; n < nbSymbols; n++) {
+			U32 const w = huffWeight[n];
+			U32 const length = (1 << w) >> 1;
+			U32 u;
+			HUF_DEltX2 D;
+			D.byte = (BYTE)n;
+			D.nbBits = (BYTE)(tableLog + 1 - w);
+			for (u = rankVal[w]; u < rankVal[w] + length; u++)
+				dt[u] = D;
+			rankVal[w] += length;
+		}
+	}
+
+	return iSize;
+}
+
+static BYTE HUF_decodeSymbolX2(BIT_DStream_t *Dstream, const HUF_DEltX2 *dt, const U32 dtLog)
+{
+	size_t const val = BIT_lookBitsFast(Dstream, dtLog); /* note : dtLog >= 1 */
+	BYTE const c = dt[val].byte;
+	BIT_skipBits(Dstream, dt[val].nbBits);
+	return c;
+}
+
+#define HUF_DECODE_SYMBOLX2_0(ptr, DStreamPtr) *ptr++ = HUF_decodeSymbolX2(DStreamPtr, dt, dtLog)
+
+#define HUF_DECODE_SYMBOLX2_1(ptr, DStreamPtr)         \
+	if (ZSTD_64bits() || (HUF_TABLELOG_MAX <= 12)) \
+	HUF_DECODE_SYMBOLX2_0(ptr, DStreamPtr)
+
+#define HUF_DECODE_SYMBOLX2_2(ptr, DStreamPtr) \
+	if (ZSTD_64bits())                     \
+	HUF_DECODE_SYMBOLX2_0(ptr, DStreamPtr)
+
+FORCE_INLINE size_t HUF_decodeStreamX2(BYTE *p, BIT_DStream_t *const bitDPtr, BYTE *const pEnd, const HUF_DEltX2 *const dt, const U32 dtLog)
+{
+	BYTE *const pStart = p;
+
+	/* up to 4 symbols at a time */
+	while ((BIT_reloadDStream(bitDPtr) == BIT_DStream_unfinished) && (p <= pEnd - 4)) {
+		HUF_DECODE_SYMBOLX2_2(p, bitDPtr);
+		HUF_DECODE_SYMBOLX2_1(p, bitDPtr);
+		HUF_DECODE_SYMBOLX2_2(p, bitDPtr);
+		HUF_DECODE_SYMBOLX2_0(p, bitDPtr);
+	}
+
+	/* closer to the end */
+	while ((BIT_reloadDStream(bitDPtr) == BIT_DStream_unfinished) && (p < pEnd))
+		HUF_DECODE_SYMBOLX2_0(p, bitDPtr);
+
+	/* no more data to retrieve from bitstream, hence no need to reload */
+	while (p < pEnd)
+		HUF_DECODE_SYMBOLX2_0(p, bitDPtr);
+
+	return pEnd - pStart;
+}
+
+static size_t HUF_decompress1X2_usingDTable_internal(void *dst, size_t dstSize, const void *cSrc, size_t cSrcSize, const HUF_DTable *DTable)
+{
+	BYTE *op = (BYTE *)dst;
+	BYTE *const oend = op + dstSize;
+	const void *dtPtr = DTable + 1;
+	const HUF_DEltX2 *const dt = (const HUF_DEltX2 *)dtPtr;
+	BIT_DStream_t bitD;
+	DTableDesc const dtd = HUF_getDTableDesc(DTable);
+	U32 const dtLog = dtd.tableLog;
+
+	{
+		size_t const errorCode = BIT_initDStream(&bitD, cSrc, cSrcSize);
+		if (HUF_isError(errorCode))
+			return errorCode;
+	}
+
+	HUF_decodeStreamX2(op, &bitD, oend, dt, dtLog);
+
+	/* check */
+	if (!BIT_endOfDStream(&bitD))
+		return ERROR(corruption_detected);
+
+	return dstSize;
+}
+
+size_t HUF_decompress1X2_usingDTable(void *dst, size_t dstSize, const void *cSrc, size_t cSrcSize, const HUF_DTable *DTable)
+{
+	DTableDesc dtd = HUF_getDTableDesc(DTable);
+	if (dtd.tableType != 0)
+		return ERROR(GENERIC);
+	return HUF_decompress1X2_usingDTable_internal(dst, dstSize, cSrc, cSrcSize, DTable);
+}
+
+size_t HUF_decompress1X2_DCtx_wksp(HUF_DTable *DCtx, void *dst, size_t dstSize, const void *cSrc, size_t cSrcSize, void *workspace, size_t workspaceSize)
+{
+	const BYTE *ip = (const BYTE *)cSrc;
+
+	size_t const hSize = HUF_readDTableX2_wksp(DCtx, cSrc, cSrcSize, workspace, workspaceSize);
+	if (HUF_isError(hSize))
+		return hSize;
+	if (hSize >= cSrcSize)
+		return ERROR(srcSize_wrong);
+	ip += hSize;
+	cSrcSize -= hSize;
+
+	return HUF_decompress1X2_usingDTable_internal(dst, dstSize, ip, cSrcSize, DCtx);
+}
+
+static size_t HUF_decompress4X2_usingDTable_internal(void *dst, size_t dstSize, const void *cSrc, size_t cSrcSize, const HUF_DTable *DTable)
+{
+	/* Check */
+	if (cSrcSize < 10)
+		return ERROR(corruption_detected); /* strict minimum : jump table + 1 byte per stream */
+
+	{
+		const BYTE *const istart = (const BYTE *)cSrc;
+		BYTE *const ostart = (BYTE *)dst;
+		BYTE *const oend = ostart + dstSize;
+		const void *const dtPtr = DTable + 1;
+		const HUF_DEltX2 *const dt = (const HUF_DEltX2 *)dtPtr;
+
+		/* Init */
+		BIT_DStream_t bitD1;
+		BIT_DStream_t bitD2;
+		BIT_DStream_t bitD3;
+		BIT_DStream_t bitD4;
+		size_t const length1 = ZSTD_readLE16(istart);
+		size_t const length2 = ZSTD_readLE16(istart + 2);
+		size_t const length3 = ZSTD_readLE16(istart + 4);
+		size_t const length4 = cSrcSize - (length1 + length2 + length3 + 6);
+		const BYTE *const istart1 = istart + 6; /* jumpTable */
+		const BYTE *const istart2 = istart1 + length1;
+		const BYTE *const istart3 = istart2 + length2;
+		const BYTE *const istart4 = istart3 + length3;
+		const size_t segmentSize = (dstSize + 3) / 4;
+		BYTE *const opStart2 = ostart + segmentSize;
+		BYTE *const opStart3 = opStart2 + segmentSize;
+		BYTE *const opStart4 = opStart3 + segmentSize;
+		BYTE *op1 = ostart;
+		BYTE *op2 = opStart2;
+		BYTE *op3 = opStart3;
+		BYTE *op4 = opStart4;
+		U32 endSignal;
+		DTableDesc const dtd = HUF_getDTableDesc(DTable);
+		U32 const dtLog = dtd.tableLog;
+
+		if (length4 > cSrcSize)
+			return ERROR(corruption_detected); /* overflow */
+		{
+			size_t const errorCode = BIT_initDStream(&bitD1, istart1, length1);
+			if (HUF_isError(errorCode))
+				return errorCode;
+		}
+		{
+			size_t const errorCode = BIT_initDStream(&bitD2, istart2, length2);
+			if (HUF_isError(errorCode))
+				return errorCode;
+		}
+		{
+			size_t const errorCode = BIT_initDStream(&bitD3, istart3, length3);
+			if (HUF_isError(errorCode))
+				return errorCode;
+		}
+		{
+			size_t const errorCode = BIT_initDStream(&bitD4, istart4, length4);
+			if (HUF_isError(errorCode))
+				return errorCode;
+		}
+
+		/* 16-32 symbols per loop (4-8 symbols per stream) */
+		endSignal = BIT_reloadDStream(&bitD1) | BIT_reloadDStream(&bitD2) | BIT_reloadDStream(&bitD3) | BIT_reloadDStream(&bitD4);
+		for (; (endSignal == BIT_DStream_unfinished) && (op4 < (oend - 7));) {
+			HUF_DECODE_SYMBOLX2_2(op1, &bitD1);
+			HUF_DECODE_SYMBOLX2_2(op2, &bitD2);
+			HUF_DECODE_SYMBOLX2_2(op3, &bitD3);
+			HUF_DECODE_SYMBOLX2_2(op4, &bitD4);
+			HUF_DECODE_SYMBOLX2_1(op1, &bitD1);
+			HUF_DECODE_SYMBOLX2_1(op2, &bitD2);
+			HUF_DECODE_SYMBOLX2_1(op3, &bitD3);
+			HUF_DECODE_SYMBOLX2_1(op4, &bitD4);
+			HUF_DECODE_SYMBOLX2_2(op1, &bitD1);
+			HUF_DECODE_SYMBOLX2_2(op2, &bitD2);
+			HUF_DECODE_SYMBOLX2_2(op3, &bitD3);
+			HUF_DECODE_SYMBOLX2_2(op4, &bitD4);
+			HUF_DECODE_SYMBOLX2_0(op1, &bitD1);
+			HUF_DECODE_SYMBOLX2_0(op2, &bitD2);
+			HUF_DECODE_SYMBOLX2_0(op3, &bitD3);
+			HUF_DECODE_SYMBOLX2_0(op4, &bitD4);
+			endSignal = BIT_reloadDStream(&bitD1) | BIT_reloadDStream(&bitD2) | BIT_reloadDStream(&bitD3) | BIT_reloadDStream(&bitD4);
+		}
+
+		/* check corruption */
+		if (op1 > opStart2)
+			return ERROR(corruption_detected);
+		if (op2 > opStart3)
+			return ERROR(corruption_detected);
+		if (op3 > opStart4)
+			return ERROR(corruption_detected);
+		/* note : op4 supposed already verified within main loop */
+
+		/* finish bitStreams one by one */
+		HUF_decodeStreamX2(op1, &bitD1, opStart2, dt, dtLog);
+		HUF_decodeStreamX2(op2, &bitD2, opStart3, dt, dtLog);
+		HUF_decodeStreamX2(op3, &bitD3, opStart4, dt, dtLog);
+		HUF_decodeStreamX2(op4, &bitD4, oend, dt, dtLog);
+
+		/* check */
+		endSignal = BIT_endOfDStream(&bitD1) & BIT_endOfDStream(&bitD2) & BIT_endOfDStream(&bitD3) & BIT_endOfDStream(&bitD4);
+		if (!endSignal)
+			return ERROR(corruption_detected);
+
+		/* decoded size */
+		return dstSize;
+	}
+}
+
+size_t HUF_decompress4X2_usingDTable(void *dst, size_t dstSize, const void *cSrc, size_t cSrcSize, const HUF_DTable *DTable)
+{
+	DTableDesc dtd = HUF_getDTableDesc(DTable);
+	if (dtd.tableType != 0)
+		return ERROR(GENERIC);
+	return HUF_decompress4X2_usingDTable_internal(dst, dstSize, cSrc, cSrcSize, DTable);
+}
+
+size_t HUF_decompress4X2_DCtx_wksp(HUF_DTable *dctx, void *dst, size_t dstSize, const void *cSrc, size_t cSrcSize, void *workspace, size_t workspaceSize)
+{
+	const BYTE *ip = (const BYTE *)cSrc;
+
+	size_t const hSize = HUF_readDTableX2_wksp(dctx, cSrc, cSrcSize, workspace, workspaceSize);
+	if (HUF_isError(hSize))
+		return hSize;
+	if (hSize >= cSrcSize)
+		return ERROR(srcSize_wrong);
+	ip += hSize;
+	cSrcSize -= hSize;
+
+	return HUF_decompress4X2_usingDTable_internal(dst, dstSize, ip, cSrcSize, dctx);
+}
+
+/* *************************/
+/* double-symbols decoding */
+/* *************************/
+typedef struct {
+	U16 sequence;
+	BYTE nbBits;
+	BYTE length;
+} HUF_DEltX4; /* double-symbols decoding */
+
+typedef struct {
+	BYTE symbol;
+	BYTE weight;
+} sortedSymbol_t;
+
+/* HUF_fillDTableX4Level2() :
+ * `rankValOrigin` must be a table of at least (HUF_TABLELOG_MAX + 1) U32 */
+static void HUF_fillDTableX4Level2(HUF_DEltX4 *DTable, U32 sizeLog, const U32 consumed, const U32 *rankValOrigin, const int minWeight,
+				   const sortedSymbol_t *sortedSymbols, const U32 sortedListSize, U32 nbBitsBaseline, U16 baseSeq)
+{
+	HUF_DEltX4 DElt;
+	U32 rankVal[HUF_TABLELOG_MAX + 1];
+
+	/* get pre-calculated rankVal */
+	memcpy(rankVal, rankValOrigin, sizeof(rankVal));
+
+	/* fill skipped values */
+	if (minWeight > 1) {
+		U32 i, skipSize = rankVal[minWeight];
+		ZSTD_writeLE16(&(DElt.sequence), baseSeq);
+		DElt.nbBits = (BYTE)(consumed);
+		DElt.length = 1;
+		for (i = 0; i < skipSize; i++)
+			DTable[i] = DElt;
+	}
+
+	/* fill DTable */
+	{
+		U32 s;
+		for (s = 0; s < sortedListSize; s++) { /* note : sortedSymbols already skipped */
+			const U32 symbol = sortedSymbols[s].symbol;
+			const U32 weight = sortedSymbols[s].weight;
+			const U32 nbBits = nbBitsBaseline - weight;
+			const U32 length = 1 << (sizeLog - nbBits);
+			const U32 start = rankVal[weight];
+			U32 i = start;
+			const U32 end = start + length;
+
+			ZSTD_writeLE16(&(DElt.sequence), (U16)(baseSeq + (symbol << 8)));
+			DElt.nbBits = (BYTE)(nbBits + consumed);
+			DElt.length = 2;
+			do {
+				DTable[i++] = DElt;
+			} while (i < end); /* since length >= 1 */
+
+			rankVal[weight] += length;
+		}
+	}
+}
+
+typedef U32 rankVal_t[HUF_TABLELOG_MAX][HUF_TABLELOG_MAX + 1];
+typedef U32 rankValCol_t[HUF_TABLELOG_MAX + 1];
+
+static void HUF_fillDTableX4(HUF_DEltX4 *DTable, const U32 targetLog, const sortedSymbol_t *sortedList, const U32 sortedListSize, const U32 *rankStart,
+			     rankVal_t rankValOrigin, const U32 maxWeight, const U32 nbBitsBaseline)
+{
+	U32 rankVal[HUF_TABLELOG_MAX + 1];
+	const int scaleLog = nbBitsBaseline - targetLog; /* note : targetLog >= srcLog, hence scaleLog <= 1 */
+	const U32 minBits = nbBitsBaseline - maxWeight;
+	U32 s;
+
+	memcpy(rankVal, rankValOrigin, sizeof(rankVal));
+
+	/* fill DTable */
+	for (s = 0; s < sortedListSize; s++) {
+		const U16 symbol = sortedList[s].symbol;
+		const U32 weight = sortedList[s].weight;
+		const U32 nbBits = nbBitsBaseline - weight;
+		const U32 start = rankVal[weight];
+		const U32 length = 1 << (targetLog - nbBits);
+
+		if (targetLog - nbBits >= minBits) { /* enough room for a second symbol */
+			U32 sortedRank;
+			int minWeight = nbBits + scaleLog;
+			if (minWeight < 1)
+				minWeight = 1;
+			sortedRank = rankStart[minWeight];
+			HUF_fillDTableX4Level2(DTable + start, targetLog - nbBits, nbBits, rankValOrigin[nbBits], minWeight, sortedList + sortedRank,
+					       sortedListSize - sortedRank, nbBitsBaseline, symbol);
+		} else {
+			HUF_DEltX4 DElt;
+			ZSTD_writeLE16(&(DElt.sequence), symbol);
+			DElt.nbBits = (BYTE)(nbBits);
+			DElt.length = 1;
+			{
+				U32 const end = start + length;
+				U32 u;
+				for (u = start; u < end; u++)
+					DTable[u] = DElt;
+			}
+		}
+		rankVal[weight] += length;
+	}
+}
+
+size_t HUF_readDTableX4_wksp(HUF_DTable *DTable, const void *src, size_t srcSize, void *workspace, size_t workspaceSize)
+{
+	U32 tableLog, maxW, sizeOfSort, nbSymbols;
+	DTableDesc dtd = HUF_getDTableDesc(DTable);
+	U32 const maxTableLog = dtd.maxTableLog;
+	size_t iSize;
+	void *dtPtr = DTable + 1; /* force compiler to avoid strict-aliasing */
+	HUF_DEltX4 *const dt = (HUF_DEltX4 *)dtPtr;
+	U32 *rankStart;
+
+	rankValCol_t *rankVal;
+	U32 *rankStats;
+	U32 *rankStart0;
+	sortedSymbol_t *sortedSymbol;
+	BYTE *weightList;
+	size_t spaceUsed32 = 0;
+
+	HUF_STATIC_ASSERT((sizeof(rankValCol_t) & 3) == 0);
+
+	rankVal = (rankValCol_t *)((U32 *)workspace + spaceUsed32);
+	spaceUsed32 += (sizeof(rankValCol_t) * HUF_TABLELOG_MAX) >> 2;
+	rankStats = (U32 *)workspace + spaceUsed32;
+	spaceUsed32 += HUF_TABLELOG_MAX + 1;
+	rankStart0 = (U32 *)workspace + spaceUsed32;
+	spaceUsed32 += HUF_TABLELOG_MAX + 2;
+	sortedSymbol = (sortedSymbol_t *)((U32 *)workspace + spaceUsed32);
+	spaceUsed32 += ALIGN(sizeof(sortedSymbol_t) * (HUF_SYMBOLVALUE_MAX + 1), sizeof(U32)) >> 2;
+	weightList = (BYTE *)((U32 *)workspace + spaceUsed32);
+	spaceUsed32 += ALIGN(HUF_SYMBOLVALUE_MAX + 1, sizeof(U32)) >> 2;
+
+	if ((spaceUsed32 << 2) > workspaceSize)
+		return ERROR(tableLog_tooLarge);
+	workspace = (U32 *)workspace + spaceUsed32;
+	workspaceSize -= (spaceUsed32 << 2);
+
+	rankStart = rankStart0 + 1;
+	memset(rankStats, 0, sizeof(U32) * (2 * HUF_TABLELOG_MAX + 2 + 1));
+
+	HUF_STATIC_ASSERT(sizeof(HUF_DEltX4) == sizeof(HUF_DTable)); /* if compiler fails here, assertion is wrong */
+	if (maxTableLog > HUF_TABLELOG_MAX)
+		return ERROR(tableLog_tooLarge);
+	/* memset(weightList, 0, sizeof(weightList)); */ /* is not necessary, even though some analyzer complain ... */
+
+	iSize = HUF_readStats_wksp(weightList, HUF_SYMBOLVALUE_MAX + 1, rankStats, &nbSymbols, &tableLog, src, srcSize, workspace, workspaceSize);
+	if (HUF_isError(iSize))
+		return iSize;
+
+	/* check result */
+	if (tableLog > maxTableLog)
+		return ERROR(tableLog_tooLarge); /* DTable can't fit code depth */
+
+	/* find maxWeight */
+	for (maxW = tableLog; rankStats[maxW] == 0; maxW--) {
+	} /* necessarily finds a solution before 0 */
+
+	/* Get start index of each weight */
+	{
+		U32 w, nextRankStart = 0;
+		for (w = 1; w < maxW + 1; w++) {
+			U32 curr = nextRankStart;
+			nextRankStart += rankStats[w];
+			rankStart[w] = curr;
+		}
+		rankStart[0] = nextRankStart; /* put all 0w symbols at the end of sorted list*/
+		sizeOfSort = nextRankStart;
+	}
+
+	/* sort symbols by weight */
+	{
+		U32 s;
+		for (s = 0; s < nbSymbols; s++) {
+			U32 const w = weightList[s];
+			U32 const r = rankStart[w]++;
+			sortedSymbol[r].symbol = (BYTE)s;
+			sortedSymbol[r].weight = (BYTE)w;
+		}
+		rankStart[0] = 0; /* forget 0w symbols; this is beginning of weight(1) */
+	}
+
+	/* Build rankVal */
+	{
+		U32 *const rankVal0 = rankVal[0];
+		{
+			int const rescale = (maxTableLog - tableLog) - 1; /* tableLog <= maxTableLog */
+			U32 nextRankVal = 0;
+			U32 w;
+			for (w = 1; w < maxW + 1; w++) {
+				U32 curr = nextRankVal;
+				nextRankVal += rankStats[w] << (w + rescale);
+				rankVal0[w] = curr;
+			}
+		}
+		{
+			U32 const minBits = tableLog + 1 - maxW;
+			U32 consumed;
+			for (consumed = minBits; consumed < maxTableLog - minBits + 1; consumed++) {
+				U32 *const rankValPtr = rankVal[consumed];
+				U32 w;
+				for (w = 1; w < maxW + 1; w++) {
+					rankValPtr[w] = rankVal0[w] >> consumed;
+				}
+			}
+		}
+	}
+
+	HUF_fillDTableX4(dt, maxTableLog, sortedSymbol, sizeOfSort, rankStart0, rankVal, maxW, tableLog + 1);
+
+	dtd.tableLog = (BYTE)maxTableLog;
+	dtd.tableType = 1;
+	memcpy(DTable, &dtd, sizeof(dtd));
+	return iSize;
+}
+
+static U32 HUF_decodeSymbolX4(void *op, BIT_DStream_t *DStream, const HUF_DEltX4 *dt, const U32 dtLog)
+{
+	size_t const val = BIT_lookBitsFast(DStream, dtLog); /* note : dtLog >= 1 */
+	memcpy(op, dt + val, 2);
+	BIT_skipBits(DStream, dt[val].nbBits);
+	return dt[val].length;
+}
+
+static U32 HUF_decodeLastSymbolX4(void *op, BIT_DStream_t *DStream, const HUF_DEltX4 *dt, const U32 dtLog)
+{
+	size_t const val = BIT_lookBitsFast(DStream, dtLog); /* note : dtLog >= 1 */
+	memcpy(op, dt + val, 1);
+	if (dt[val].length == 1)
+		BIT_skipBits(DStream, dt[val].nbBits);
+	else {
+		if (DStream->bitsConsumed < (sizeof(DStream->bitContainer) * 8)) {
+			BIT_skipBits(DStream, dt[val].nbBits);
+			if (DStream->bitsConsumed > (sizeof(DStream->bitContainer) * 8))
+				/* ugly hack; works only because it's the last symbol. Note : can't easily extract nbBits from just this symbol */
+				DStream->bitsConsumed = (sizeof(DStream->bitContainer) * 8);
+		}
+	}
+	return 1;
+}
+
+#define HUF_DECODE_SYMBOLX4_0(ptr, DStreamPtr) ptr += HUF_decodeSymbolX4(ptr, DStreamPtr, dt, dtLog)
+
+#define HUF_DECODE_SYMBOLX4_1(ptr, DStreamPtr)         \
+	if (ZSTD_64bits() || (HUF_TABLELOG_MAX <= 12)) \
+	ptr += HUF_decodeSymbolX4(ptr, DStreamPtr, dt, dtLog)
+
+#define HUF_DECODE_SYMBOLX4_2(ptr, DStreamPtr) \
+	if (ZSTD_64bits())                     \
+	ptr += HUF_decodeSymbolX4(ptr, DStreamPtr, dt, dtLog)
+
+FORCE_INLINE size_t HUF_decodeStreamX4(BYTE *p, BIT_DStream_t *bitDPtr, BYTE *const pEnd, const HUF_DEltX4 *const dt, const U32 dtLog)
+{
+	BYTE *const pStart = p;
+
+	/* up to 8 symbols at a time */
+	while ((BIT_reloadDStream(bitDPtr) == BIT_DStream_unfinished) & (p < pEnd - (sizeof(bitDPtr->bitContainer) - 1))) {
+		HUF_DECODE_SYMBOLX4_2(p, bitDPtr);
+		HUF_DECODE_SYMBOLX4_1(p, bitDPtr);
+		HUF_DECODE_SYMBOLX4_2(p, bitDPtr);
+		HUF_DECODE_SYMBOLX4_0(p, bitDPtr);
+	}
+
+	/* closer to end : up to 2 symbols at a time */
+	while ((BIT_reloadDStream(bitDPtr) == BIT_DStream_unfinished) & (p <= pEnd - 2))
+		HUF_DECODE_SYMBOLX4_0(p, bitDPtr);
+
+	while (p <= pEnd - 2)
+		HUF_DECODE_SYMBOLX4_0(p, bitDPtr); /* no need to reload : reached the end of DStream */
+
+	if (p < pEnd)
+		p += HUF_decodeLastSymbolX4(p, bitDPtr, dt, dtLog);
+
+	return p - pStart;
+}
+
+static size_t HUF_decompress1X4_usingDTable_internal(void *dst, size_t dstSize, const void *cSrc, size_t cSrcSize, const HUF_DTable *DTable)
+{
+	BIT_DStream_t bitD;
+
+	/* Init */
+	{
+		size_t const errorCode = BIT_initDStream(&bitD, cSrc, cSrcSize);
+		if (HUF_isError(errorCode))
+			return errorCode;
+	}
+
+	/* decode */
+	{
+		BYTE *const ostart = (BYTE *)dst;
+		BYTE *const oend = ostart + dstSize;
+		const void *const dtPtr = DTable + 1; /* force compiler to not use strict-aliasing */
+		const HUF_DEltX4 *const dt = (const HUF_DEltX4 *)dtPtr;
+		DTableDesc const dtd = HUF_getDTableDesc(DTable);
+		HUF_decodeStreamX4(ostart, &bitD, oend, dt, dtd.tableLog);
+	}
+
+	/* check */
+	if (!BIT_endOfDStream(&bitD))
+		return ERROR(corruption_detected);
+
+	/* decoded size */
+	return dstSize;
+}
+
+size_t HUF_decompress1X4_usingDTable(void *dst, size_t dstSize, const void *cSrc, size_t cSrcSize, const HUF_DTable *DTable)
+{
+	DTableDesc dtd = HUF_getDTableDesc(DTable);
+	if (dtd.tableType != 1)
+		return ERROR(GENERIC);
+	return HUF_decompress1X4_usingDTable_internal(dst, dstSize, cSrc, cSrcSize, DTable);
+}
+
+size_t HUF_decompress1X4_DCtx_wksp(HUF_DTable *DCtx, void *dst, size_t dstSize, const void *cSrc, size_t cSrcSize, void *workspace, size_t workspaceSize)
+{
+	const BYTE *ip = (const BYTE *)cSrc;
+
+	size_t const hSize = HUF_readDTableX4_wksp(DCtx, cSrc, cSrcSize, workspace, workspaceSize);
+	if (HUF_isError(hSize))
+		return hSize;
+	if (hSize >= cSrcSize)
+		return ERROR(srcSize_wrong);
+	ip += hSize;
+	cSrcSize -= hSize;
+
+	return HUF_decompress1X4_usingDTable_internal(dst, dstSize, ip, cSrcSize, DCtx);
+}
+
+static size_t HUF_decompress4X4_usingDTable_internal(void *dst, size_t dstSize, const void *cSrc, size_t cSrcSize, const HUF_DTable *DTable)
+{
+	if (cSrcSize < 10)
+		return ERROR(corruption_detected); /* strict minimum : jump table + 1 byte per stream */
+
+	{
+		const BYTE *const istart = (const BYTE *)cSrc;
+		BYTE *const ostart = (BYTE *)dst;
+		BYTE *const oend = ostart + dstSize;
+		const void *const dtPtr = DTable + 1;
+		const HUF_DEltX4 *const dt = (const HUF_DEltX4 *)dtPtr;
+
+		/* Init */
+		BIT_DStream_t bitD1;
+		BIT_DStream_t bitD2;
+		BIT_DStream_t bitD3;
+		BIT_DStream_t bitD4;
+		size_t const length1 = ZSTD_readLE16(istart);
+		size_t const length2 = ZSTD_readLE16(istart + 2);
+		size_t const length3 = ZSTD_readLE16(istart + 4);
+		size_t const length4 = cSrcSize - (length1 + length2 + length3 + 6);
+		const BYTE *const istart1 = istart + 6; /* jumpTable */
+		const BYTE *const istart2 = istart1 + length1;
+		const BYTE *const istart3 = istart2 + length2;
+		const BYTE *const istart4 = istart3 + length3;
+		size_t const segmentSize = (dstSize + 3) / 4;
+		BYTE *const opStart2 = ostart + segmentSize;
+		BYTE *const opStart3 = opStart2 + segmentSize;
+		BYTE *const opStart4 = opStart3 + segmentSize;
+		BYTE *op1 = ostart;
+		BYTE *op2 = opStart2;
+		BYTE *op3 = opStart3;
+		BYTE *op4 = opStart4;
+		U32 endSignal;
+		DTableDesc const dtd = HUF_getDTableDesc(DTable);
+		U32 const dtLog = dtd.tableLog;
+
+		if (length4 > cSrcSize)
+			return ERROR(corruption_detected); /* overflow */
+		{
+			size_t const errorCode = BIT_initDStream(&bitD1, istart1, length1);
+			if (HUF_isError(errorCode))
+				return errorCode;
+		}
+		{
+			size_t const errorCode = BIT_initDStream(&bitD2, istart2, length2);
+			if (HUF_isError(errorCode))
+				return errorCode;
+		}
+		{
+			size_t const errorCode = BIT_initDStream(&bitD3, istart3, length3);
+			if (HUF_isError(errorCode))
+				return errorCode;
+		}
+		{
+			size_t const errorCode = BIT_initDStream(&bitD4, istart4, length4);
+			if (HUF_isError(errorCode))
+				return errorCode;
+		}
+
+		/* 16-32 symbols per loop (4-8 symbols per stream) */
+		endSignal = BIT_reloadDStream(&bitD1) | BIT_reloadDStream(&bitD2) | BIT_reloadDStream(&bitD3) | BIT_reloadDStream(&bitD4);
+		for (; (endSignal == BIT_DStream_unfinished) & (op4 < (oend - (sizeof(bitD4.bitContainer) - 1)));) {
+			HUF_DECODE_SYMBOLX4_2(op1, &bitD1);
+			HUF_DECODE_SYMBOLX4_2(op2, &bitD2);
+			HUF_DECODE_SYMBOLX4_2(op3, &bitD3);
+			HUF_DECODE_SYMBOLX4_2(op4, &bitD4);
+			HUF_DECODE_SYMBOLX4_1(op1, &bitD1);
+			HUF_DECODE_SYMBOLX4_1(op2, &bitD2);
+			HUF_DECODE_SYMBOLX4_1(op3, &bitD3);
+			HUF_DECODE_SYMBOLX4_1(op4, &bitD4);
+			HUF_DECODE_SYMBOLX4_2(op1, &bitD1);
+			HUF_DECODE_SYMBOLX4_2(op2, &bitD2);
+			HUF_DECODE_SYMBOLX4_2(op3, &bitD3);
+			HUF_DECODE_SYMBOLX4_2(op4, &bitD4);
+			HUF_DECODE_SYMBOLX4_0(op1, &bitD1);
+			HUF_DECODE_SYMBOLX4_0(op2, &bitD2);
+			HUF_DECODE_SYMBOLX4_0(op3, &bitD3);
+			HUF_DECODE_SYMBOLX4_0(op4, &bitD4);
+
+			endSignal = BIT_reloadDStream(&bitD1) | BIT_reloadDStream(&bitD2) | BIT_reloadDStream(&bitD3) | BIT_reloadDStream(&bitD4);
+		}
+
+		/* check corruption */
+		if (op1 > opStart2)
+			return ERROR(corruption_detected);
+		if (op2 > opStart3)
+			return ERROR(corruption_detected);
+		if (op3 > opStart4)
+			return ERROR(corruption_detected);
+		/* note : op4 already verified within main loop */
+
+		/* finish bitStreams one by one */
+		HUF_decodeStreamX4(op1, &bitD1, opStart2, dt, dtLog);
+		HUF_decodeStreamX4(op2, &bitD2, opStart3, dt, dtLog);
+		HUF_decodeStreamX4(op3, &bitD3, opStart4, dt, dtLog);
+		HUF_decodeStreamX4(op4, &bitD4, oend, dt, dtLog);
+
+		/* check */
+		{
+			U32 const endCheck = BIT_endOfDStream(&bitD1) & BIT_endOfDStream(&bitD2) & BIT_endOfDStream(&bitD3) & BIT_endOfDStream(&bitD4);
+			if (!endCheck)
+				return ERROR(corruption_detected);
+		}
+
+		/* decoded size */
+		return dstSize;
+	}
+}
+
+size_t HUF_decompress4X4_usingDTable(void *dst, size_t dstSize, const void *cSrc, size_t cSrcSize, const HUF_DTable *DTable)
+{
+	DTableDesc dtd = HUF_getDTableDesc(DTable);
+	if (dtd.tableType != 1)
+		return ERROR(GENERIC);
+	return HUF_decompress4X4_usingDTable_internal(dst, dstSize, cSrc, cSrcSize, DTable);
+}
+
+size_t HUF_decompress4X4_DCtx_wksp(HUF_DTable *dctx, void *dst, size_t dstSize, const void *cSrc, size_t cSrcSize, void *workspace, size_t workspaceSize)
+{
+	const BYTE *ip = (const BYTE *)cSrc;
+
+	size_t hSize = HUF_readDTableX4_wksp(dctx, cSrc, cSrcSize, workspace, workspaceSize);
+	if (HUF_isError(hSize))
+		return hSize;
+	if (hSize >= cSrcSize)
+		return ERROR(srcSize_wrong);
+	ip += hSize;
+	cSrcSize -= hSize;
+
+	return HUF_decompress4X4_usingDTable_internal(dst, dstSize, ip, cSrcSize, dctx);
+}
+
+/* ********************************/
+/* Generic decompression selector */
+/* ********************************/
+
+size_t HUF_decompress1X_usingDTable(void *dst, size_t maxDstSize, const void *cSrc, size_t cSrcSize, const HUF_DTable *DTable)
+{
+	DTableDesc const dtd = HUF_getDTableDesc(DTable);
+	return dtd.tableType ? HUF_decompress1X4_usingDTable_internal(dst, maxDstSize, cSrc, cSrcSize, DTable)
+			     : HUF_decompress1X2_usingDTable_internal(dst, maxDstSize, cSrc, cSrcSize, DTable);
+}
+
+size_t HUF_decompress4X_usingDTable(void *dst, size_t maxDstSize, const void *cSrc, size_t cSrcSize, const HUF_DTable *DTable)
+{
+	DTableDesc const dtd = HUF_getDTableDesc(DTable);
+	return dtd.tableType ? HUF_decompress4X4_usingDTable_internal(dst, maxDstSize, cSrc, cSrcSize, DTable)
+			     : HUF_decompress4X2_usingDTable_internal(dst, maxDstSize, cSrc, cSrcSize, DTable);
+}
+
+typedef struct {
+	U32 tableTime;
+	U32 decode256Time;
+} algo_time_t;
+static const algo_time_t algoTime[16 /* Quantization */][3 /* single, double, quad */] = {
+    /* single, double, quad */
+    {{0, 0}, {1, 1}, {2, 2}},		     /* Q==0 : impossible */
+    {{0, 0}, {1, 1}, {2, 2}},		     /* Q==1 : impossible */
+    {{38, 130}, {1313, 74}, {2151, 38}},     /* Q == 2 : 12-18% */
+    {{448, 128}, {1353, 74}, {2238, 41}},    /* Q == 3 : 18-25% */
+    {{556, 128}, {1353, 74}, {2238, 47}},    /* Q == 4 : 25-32% */
+    {{714, 128}, {1418, 74}, {2436, 53}},    /* Q == 5 : 32-38% */
+    {{883, 128}, {1437, 74}, {2464, 61}},    /* Q == 6 : 38-44% */
+    {{897, 128}, {1515, 75}, {2622, 68}},    /* Q == 7 : 44-50% */
+    {{926, 128}, {1613, 75}, {2730, 75}},    /* Q == 8 : 50-56% */
+    {{947, 128}, {1729, 77}, {3359, 77}},    /* Q == 9 : 56-62% */
+    {{1107, 128}, {2083, 81}, {4006, 84}},   /* Q ==10 : 62-69% */
+    {{1177, 128}, {2379, 87}, {4785, 88}},   /* Q ==11 : 69-75% */
+    {{1242, 128}, {2415, 93}, {5155, 84}},   /* Q ==12 : 75-81% */
+    {{1349, 128}, {2644, 106}, {5260, 106}}, /* Q ==13 : 81-87% */
+    {{1455, 128}, {2422, 124}, {4174, 124}}, /* Q ==14 : 87-93% */
+    {{722, 128}, {1891, 145}, {1936, 146}},  /* Q ==15 : 93-99% */
+};
+
+/** HUF_selectDecoder() :
+*   Tells which decoder is likely to decode faster,
+*   based on a set of pre-determined metrics.
+*   @return : 0==HUF_decompress4X2, 1==HUF_decompress4X4 .
+*   Assumption : 0 < cSrcSize < dstSize <= 128 KB */
+U32 HUF_selectDecoder(size_t dstSize, size_t cSrcSize)
+{
+	/* decoder timing evaluation */
+	U32 const Q = (U32)(cSrcSize * 16 / dstSize); /* Q < 16 since dstSize > cSrcSize */
+	U32 const D256 = (U32)(dstSize >> 8);
+	U32 const DTime0 = algoTime[Q][0].tableTime + (algoTime[Q][0].decode256Time * D256);
+	U32 DTime1 = algoTime[Q][1].tableTime + (algoTime[Q][1].decode256Time * D256);
+	DTime1 += DTime1 >> 3; /* advantage to algorithm using less memory, for cache eviction */
+
+	return DTime1 < DTime0;
+}
+
+typedef size_t (*decompressionAlgo)(void *dst, size_t dstSize, const void *cSrc, size_t cSrcSize);
+
+size_t HUF_decompress4X_DCtx_wksp(HUF_DTable *dctx, void *dst, size_t dstSize, const void *cSrc, size_t cSrcSize, void *workspace, size_t workspaceSize)
+{
+	/* validation checks */
+	if (dstSize == 0)
+		return ERROR(dstSize_tooSmall);
+	if (cSrcSize > dstSize)
+		return ERROR(corruption_detected); /* invalid */
+	if (cSrcSize == dstSize) {
+		memcpy(dst, cSrc, dstSize);
+		return dstSize;
+	} /* not compressed */
+	if (cSrcSize == 1) {
+		memset(dst, *(const BYTE *)cSrc, dstSize);
+		return dstSize;
+	} /* RLE */
+
+	{
+		U32 const algoNb = HUF_selectDecoder(dstSize, cSrcSize);
+		return algoNb ? HUF_decompress4X4_DCtx_wksp(dctx, dst, dstSize, cSrc, cSrcSize, workspace, workspaceSize)
+			      : HUF_decompress4X2_DCtx_wksp(dctx, dst, dstSize, cSrc, cSrcSize, workspace, workspaceSize);
+	}
+}
+
+size_t HUF_decompress4X_hufOnly_wksp(HUF_DTable *dctx, void *dst, size_t dstSize, const void *cSrc, size_t cSrcSize, void *workspace, size_t workspaceSize)
+{
+	/* validation checks */
+	if (dstSize == 0)
+		return ERROR(dstSize_tooSmall);
+	if ((cSrcSize >= dstSize) || (cSrcSize <= 1))
+		return ERROR(corruption_detected); /* invalid */
+
+	{
+		U32 const algoNb = HUF_selectDecoder(dstSize, cSrcSize);
+		return algoNb ? HUF_decompress4X4_DCtx_wksp(dctx, dst, dstSize, cSrc, cSrcSize, workspace, workspaceSize)
+			      : HUF_decompress4X2_DCtx_wksp(dctx, dst, dstSize, cSrc, cSrcSize, workspace, workspaceSize);
+	}
+}
+
+size_t HUF_decompress1X_DCtx_wksp(HUF_DTable *dctx, void *dst, size_t dstSize, const void *cSrc, size_t cSrcSize, void *workspace, size_t workspaceSize)
+{
+	/* validation checks */
+	if (dstSize == 0)
+		return ERROR(dstSize_tooSmall);
+	if (cSrcSize > dstSize)
+		return ERROR(corruption_detected); /* invalid */
+	if (cSrcSize == dstSize) {
+		memcpy(dst, cSrc, dstSize);
+		return dstSize;
+	} /* not compressed */
+	if (cSrcSize == 1) {
+		memset(dst, *(const BYTE *)cSrc, dstSize);
+		return dstSize;
+	} /* RLE */
+
+	{
+		U32 const algoNb = HUF_selectDecoder(dstSize, cSrcSize);
+		return algoNb ? HUF_decompress1X4_DCtx_wksp(dctx, dst, dstSize, cSrc, cSrcSize, workspace, workspaceSize)
+			      : HUF_decompress1X2_DCtx_wksp(dctx, dst, dstSize, cSrc, cSrcSize, workspace, workspaceSize);
+	}
+}
diff -Naurp -x debian.hwe linux-4.10.x.ori/lib/zstd/huf.h linux-4.10.x/lib/zstd/huf.h
--- linux-4.10.x.ori/lib/zstd/huf.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-4.10.x/lib/zstd/huf.h	2017-10-30 10:05:19.610447000 +0100
@@ -0,0 +1,212 @@
+/*
+ * Huffman coder, part of New Generation Entropy library
+ * header file
+ * Copyright (C) 2013-2016, Yann Collet.
+ *
+ * BSD 2-Clause License (http://www.opensource.org/licenses/bsd-license.php)
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ * notice, this list of conditions and the following disclaimer.
+ *   * Redistributions in binary form must reproduce the above
+ * copyright notice, this list of conditions and the following disclaimer
+ * in the documentation and/or other materials provided with the
+ * distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ * This program is free software; you can redistribute it and/or modify it under
+ * the terms of the GNU General Public License version 2 as published by the
+ * Free Software Foundation. This program is dual-licensed; you may select
+ * either version 2 of the GNU General Public License ("GPL") or BSD license
+ * ("BSD").
+ *
+ * You can contact the author at :
+ * - Source repository : https://github.com/Cyan4973/FiniteStateEntropy
+ */
+#ifndef HUF_H_298734234
+#define HUF_H_298734234
+
+/* *** Dependencies *** */
+#include <linux/types.h> /* size_t */
+
+/* ***   Tool functions *** */
+#define HUF_BLOCKSIZE_MAX (128 * 1024) /**< maximum input size for a single block compressed with HUF_compress */
+size_t HUF_compressBound(size_t size); /**< maximum compressed size (worst case) */
+
+/* Error Management */
+unsigned HUF_isError(size_t code); /**< tells if a return value is an error code */
+
+/* ***   Advanced function   *** */
+
+/** HUF_compress4X_wksp() :
+*   Same as HUF_compress2(), but uses externally allocated `workSpace`, which must be a table of >= 1024 unsigned */
+size_t HUF_compress4X_wksp(void *dst, size_t dstSize, const void *src, size_t srcSize, unsigned maxSymbolValue, unsigned tableLog, void *workSpace,
+			   size_t wkspSize); /**< `workSpace` must be a table of at least HUF_COMPRESS_WORKSPACE_SIZE_U32 unsigned */
+
+/* *** Dependencies *** */
+#include "mem.h" /* U32 */
+
+/* *** Constants *** */
+#define HUF_TABLELOG_MAX 12     /* max configured tableLog (for static allocation); can be modified up to HUF_ABSOLUTEMAX_TABLELOG */
+#define HUF_TABLELOG_DEFAULT 11 /* tableLog by default, when not specified */
+#define HUF_SYMBOLVALUE_MAX 255
+
+#define HUF_TABLELOG_ABSOLUTEMAX 15 /* absolute limit of HUF_MAX_TABLELOG. Beyond that value, code does not work */
+#if (HUF_TABLELOG_MAX > HUF_TABLELOG_ABSOLUTEMAX)
+#error "HUF_TABLELOG_MAX is too large !"
+#endif
+
+/* ****************************************
+*  Static allocation
+******************************************/
+/* HUF buffer bounds */
+#define HUF_CTABLEBOUND 129
+#define HUF_BLOCKBOUND(size) (size + (size >> 8) + 8)			 /* only true if incompressible pre-filtered with fast heuristic */
+#define HUF_COMPRESSBOUND(size) (HUF_CTABLEBOUND + HUF_BLOCKBOUND(size)) /* Macro version, useful for static allocation */
+
+/* static allocation of HUF's Compression Table */
+#define HUF_CREATE_STATIC_CTABLE(name, maxSymbolValue) \
+	U32 name##hb[maxSymbolValue + 1];              \
+	void *name##hv = &(name##hb);                  \
+	HUF_CElt *name = (HUF_CElt *)(name##hv) /* no final ; */
+
+/* static allocation of HUF's DTable */
+typedef U32 HUF_DTable;
+#define HUF_DTABLE_SIZE(maxTableLog) (1 + (1 << (maxTableLog)))
+#define HUF_CREATE_STATIC_DTABLEX2(DTable, maxTableLog) HUF_DTable DTable[HUF_DTABLE_SIZE((maxTableLog)-1)] = {((U32)((maxTableLog)-1) * 0x01000001)}
+#define HUF_CREATE_STATIC_DTABLEX4(DTable, maxTableLog) HUF_DTable DTable[HUF_DTABLE_SIZE(maxTableLog)] = {((U32)(maxTableLog)*0x01000001)}
+
+/* The workspace must have alignment at least 4 and be at least this large */
+#define HUF_COMPRESS_WORKSPACE_SIZE (6 << 10)
+#define HUF_COMPRESS_WORKSPACE_SIZE_U32 (HUF_COMPRESS_WORKSPACE_SIZE / sizeof(U32))
+
+/* The workspace must have alignment at least 4 and be at least this large */
+#define HUF_DECOMPRESS_WORKSPACE_SIZE (3 << 10)
+#define HUF_DECOMPRESS_WORKSPACE_SIZE_U32 (HUF_DECOMPRESS_WORKSPACE_SIZE / sizeof(U32))
+
+/* ****************************************
+*  Advanced decompression functions
+******************************************/
+size_t HUF_decompress4X_DCtx_wksp(HUF_DTable *dctx, void *dst, size_t dstSize, const void *cSrc, size_t cSrcSize, void *workspace, size_t workspaceSize); /**< decodes RLE and uncompressed */
+size_t HUF_decompress4X_hufOnly_wksp(HUF_DTable *dctx, void *dst, size_t dstSize, const void *cSrc, size_t cSrcSize, void *workspace,
+				size_t workspaceSize);							       /**< considers RLE and uncompressed as errors */
+size_t HUF_decompress4X2_DCtx_wksp(HUF_DTable *dctx, void *dst, size_t dstSize, const void *cSrc, size_t cSrcSize, void *workspace,
+				   size_t workspaceSize); /**< single-symbol decoder */
+size_t HUF_decompress4X4_DCtx_wksp(HUF_DTable *dctx, void *dst, size_t dstSize, const void *cSrc, size_t cSrcSize, void *workspace,
+				   size_t workspaceSize); /**< double-symbols decoder */
+
+/* ****************************************
+*  HUF detailed API
+******************************************/
+/*!
+HUF_compress() does the following:
+1. count symbol occurrence from source[] into table count[] using FSE_count()
+2. (optional) refine tableLog using HUF_optimalTableLog()
+3. build Huffman table from count using HUF_buildCTable()
+4. save Huffman table to memory buffer using HUF_writeCTable_wksp()
+5. encode the data stream using HUF_compress4X_usingCTable()
+
+The following API allows targeting specific sub-functions for advanced tasks.
+For example, it's possible to compress several blocks using the same 'CTable',
+or to save and regenerate 'CTable' using external methods.
+*/
+/* FSE_count() : find it within "fse.h" */
+unsigned HUF_optimalTableLog(unsigned maxTableLog, size_t srcSize, unsigned maxSymbolValue);
+typedef struct HUF_CElt_s HUF_CElt; /* incomplete type */
+size_t HUF_writeCTable_wksp(void *dst, size_t maxDstSize, const HUF_CElt *CTable, unsigned maxSymbolValue, unsigned huffLog, void *workspace, size_t workspaceSize);
+size_t HUF_compress4X_usingCTable(void *dst, size_t dstSize, const void *src, size_t srcSize, const HUF_CElt *CTable);
+
+typedef enum {
+	HUF_repeat_none,  /**< Cannot use the previous table */
+	HUF_repeat_check, /**< Can use the previous table but it must be checked. Note : The previous table must have been constructed by HUF_compress{1,
+			     4}X_repeat */
+	HUF_repeat_valid  /**< Can use the previous table and it is asumed to be valid */
+} HUF_repeat;
+/** HUF_compress4X_repeat() :
+*   Same as HUF_compress4X_wksp(), but considers using hufTable if *repeat != HUF_repeat_none.
+*   If it uses hufTable it does not modify hufTable or repeat.
+*   If it doesn't, it sets *repeat = HUF_repeat_none, and it sets hufTable to the table used.
+*   If preferRepeat then the old table will always be used if valid. */
+size_t HUF_compress4X_repeat(void *dst, size_t dstSize, const void *src, size_t srcSize, unsigned maxSymbolValue, unsigned tableLog, void *workSpace,
+			     size_t wkspSize, HUF_CElt *hufTable, HUF_repeat *repeat,
+			     int preferRepeat); /**< `workSpace` must be a table of at least HUF_COMPRESS_WORKSPACE_SIZE_U32 unsigned */
+
+/** HUF_buildCTable_wksp() :
+ *  Same as HUF_buildCTable(), but using externally allocated scratch buffer.
+ *  `workSpace` must be aligned on 4-bytes boundaries, and be at least as large as a table of 1024 unsigned.
+ */
+size_t HUF_buildCTable_wksp(HUF_CElt *tree, const U32 *count, U32 maxSymbolValue, U32 maxNbBits, void *workSpace, size_t wkspSize);
+
+/*! HUF_readStats() :
+	Read compact Huffman tree, saved by HUF_writeCTable().
+	`huffWeight` is destination buffer.
+	@return : size read from `src` , or an error Code .
+	Note : Needed by HUF_readCTable() and HUF_readDTableXn() . */
+size_t HUF_readStats_wksp(BYTE *huffWeight, size_t hwSize, U32 *rankStats, U32 *nbSymbolsPtr, U32 *tableLogPtr, const void *src, size_t srcSize,
+			  void *workspace, size_t workspaceSize);
+
+/** HUF_readCTable() :
+*   Loading a CTable saved with HUF_writeCTable() */
+size_t HUF_readCTable_wksp(HUF_CElt *CTable, unsigned maxSymbolValue, const void *src, size_t srcSize, void *workspace, size_t workspaceSize);
+
+/*
+HUF_decompress() does the following:
+1. select the decompression algorithm (X2, X4) based on pre-computed heuristics
+2. build Huffman table from save, using HUF_readDTableXn()
+3. decode 1 or 4 segments in parallel using HUF_decompressSXn_usingDTable
+*/
+
+/** HUF_selectDecoder() :
+*   Tells which decoder is likely to decode faster,
+*   based on a set of pre-determined metrics.
+*   @return : 0==HUF_decompress4X2, 1==HUF_decompress4X4 .
+*   Assumption : 0 < cSrcSize < dstSize <= 128 KB */
+U32 HUF_selectDecoder(size_t dstSize, size_t cSrcSize);
+
+size_t HUF_readDTableX2_wksp(HUF_DTable *DTable, const void *src, size_t srcSize, void *workspace, size_t workspaceSize);
+size_t HUF_readDTableX4_wksp(HUF_DTable *DTable, const void *src, size_t srcSize, void *workspace, size_t workspaceSize);
+
+size_t HUF_decompress4X_usingDTable(void *dst, size_t maxDstSize, const void *cSrc, size_t cSrcSize, const HUF_DTable *DTable);
+size_t HUF_decompress4X2_usingDTable(void *dst, size_t maxDstSize, const void *cSrc, size_t cSrcSize, const HUF_DTable *DTable);
+size_t HUF_decompress4X4_usingDTable(void *dst, size_t maxDstSize, const void *cSrc, size_t cSrcSize, const HUF_DTable *DTable);
+
+/* single stream variants */
+
+size_t HUF_compress1X_wksp(void *dst, size_t dstSize, const void *src, size_t srcSize, unsigned maxSymbolValue, unsigned tableLog, void *workSpace,
+			   size_t wkspSize); /**< `workSpace` must be a table of at least HUF_COMPRESS_WORKSPACE_SIZE_U32 unsigned */
+size_t HUF_compress1X_usingCTable(void *dst, size_t dstSize, const void *src, size_t srcSize, const HUF_CElt *CTable);
+/** HUF_compress1X_repeat() :
+*   Same as HUF_compress1X_wksp(), but considers using hufTable if *repeat != HUF_repeat_none.
+*   If it uses hufTable it does not modify hufTable or repeat.
+*   If it doesn't, it sets *repeat = HUF_repeat_none, and it sets hufTable to the table used.
+*   If preferRepeat then the old table will always be used if valid. */
+size_t HUF_compress1X_repeat(void *dst, size_t dstSize, const void *src, size_t srcSize, unsigned maxSymbolValue, unsigned tableLog, void *workSpace,
+			     size_t wkspSize, HUF_CElt *hufTable, HUF_repeat *repeat,
+			     int preferRepeat); /**< `workSpace` must be a table of at least HUF_COMPRESS_WORKSPACE_SIZE_U32 unsigned */
+
+size_t HUF_decompress1X_DCtx_wksp(HUF_DTable *dctx, void *dst, size_t dstSize, const void *cSrc, size_t cSrcSize, void *workspace, size_t workspaceSize);
+size_t HUF_decompress1X2_DCtx_wksp(HUF_DTable *dctx, void *dst, size_t dstSize, const void *cSrc, size_t cSrcSize, void *workspace,
+				   size_t workspaceSize); /**< single-symbol decoder */
+size_t HUF_decompress1X4_DCtx_wksp(HUF_DTable *dctx, void *dst, size_t dstSize, const void *cSrc, size_t cSrcSize, void *workspace,
+				   size_t workspaceSize); /**< double-symbols decoder */
+
+size_t HUF_decompress1X_usingDTable(void *dst, size_t maxDstSize, const void *cSrc, size_t cSrcSize,
+				    const HUF_DTable *DTable); /**< automatic selection of sing or double symbol decoder, based on DTable */
+size_t HUF_decompress1X2_usingDTable(void *dst, size_t maxDstSize, const void *cSrc, size_t cSrcSize, const HUF_DTable *DTable);
+size_t HUF_decompress1X4_usingDTable(void *dst, size_t maxDstSize, const void *cSrc, size_t cSrcSize, const HUF_DTable *DTable);
+
+#endif /* HUF_H_298734234 */
diff -Naurp -x debian.hwe linux-4.10.x.ori/lib/zstd/Makefile linux-4.10.x/lib/zstd/Makefile
--- linux-4.10.x.ori/lib/zstd/Makefile	1970-01-01 01:00:00.000000000 +0100
+++ linux-4.10.x/lib/zstd/Makefile	2017-10-30 10:05:19.610447000 +0100
@@ -0,0 +1,18 @@
+obj-$(CONFIG_ZSTD_COMPRESS) += zstd_compress.o
+obj-$(CONFIG_ZSTD_DECOMPRESS) += zstd_decompress.o
+
+ccflags-y += -O3
+
+# Object files unique to zstd_compress and zstd_decompress
+zstd_compress-y := fse_compress.o huf_compress.o compress.o
+zstd_decompress-y := huf_decompress.o decompress.o
+
+# These object files are shared between the modules.
+# Always add them to zstd_compress.
+# Unless both zstd_compress and zstd_decompress are built in
+# then also add them to zstd_decompress.
+zstd_compress-y += entropy_common.o fse_decompress.o zstd_common.o
+
+ifneq ($(CONFIG_ZSTD_COMPRESS)$(CONFIG_ZSTD_DECOMPRESS),yy)
+	zstd_decompress-y += entropy_common.o fse_decompress.o zstd_common.o
+endif
diff -Naurp -x debian.hwe linux-4.10.x.ori/lib/zstd/mem.h linux-4.10.x/lib/zstd/mem.h
--- linux-4.10.x.ori/lib/zstd/mem.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-4.10.x/lib/zstd/mem.h	2017-10-30 10:05:19.610447000 +0100
@@ -0,0 +1,149 @@
+/**
+ * Copyright (c) 2016-present, Yann Collet, Facebook, Inc.
+ * All rights reserved.
+ *
+ * This source code is licensed under the BSD-style license found in the
+ * LICENSE file in the root directory of https://github.com/facebook/zstd.
+ *
+ * This program is free software; you can redistribute it and/or modify it under
+ * the terms of the GNU General Public License version 2 as published by the
+ * Free Software Foundation. This program is dual-licensed; you may select
+ * either version 2 of the GNU General Public License ("GPL") or BSD license
+ * ("BSD").
+ */
+
+#ifndef MEM_H_MODULE
+#define MEM_H_MODULE
+
+/*-****************************************
+*  Dependencies
+******************************************/
+#include <asm/unaligned.h>
+#include <linux/string.h> /* memcpy */
+#include <linux/types.h>  /* size_t, ptrdiff_t */
+
+/*-****************************************
+*  Compiler specifics
+******************************************/
+#define ZSTD_STATIC static __inline __attribute__((unused))
+
+/*-**************************************************************
+*  Basic Types
+*****************************************************************/
+typedef uint8_t BYTE;
+typedef uint16_t U16;
+typedef int16_t S16;
+typedef uint32_t U32;
+typedef int32_t S32;
+typedef uint64_t U64;
+typedef int64_t S64;
+typedef ptrdiff_t iPtrDiff;
+typedef uintptr_t uPtrDiff;
+
+/*-**************************************************************
+*  Memory I/O
+*****************************************************************/
+ZSTD_STATIC unsigned ZSTD_32bits(void) { return sizeof(size_t) == 4; }
+ZSTD_STATIC unsigned ZSTD_64bits(void) { return sizeof(size_t) == 8; }
+
+#if defined(__LITTLE_ENDIAN)
+#define ZSTD_LITTLE_ENDIAN 1
+#else
+#define ZSTD_LITTLE_ENDIAN 0
+#endif
+
+ZSTD_STATIC unsigned ZSTD_isLittleEndian(void) { return ZSTD_LITTLE_ENDIAN; }
+
+ZSTD_STATIC U16 ZSTD_read16(const void *memPtr) { return get_unaligned((const U16 *)memPtr); }
+
+ZSTD_STATIC U32 ZSTD_read32(const void *memPtr) { return get_unaligned((const U32 *)memPtr); }
+
+ZSTD_STATIC U64 ZSTD_read64(const void *memPtr) { return get_unaligned((const U64 *)memPtr); }
+
+ZSTD_STATIC size_t ZSTD_readST(const void *memPtr) { return get_unaligned((const size_t *)memPtr); }
+
+ZSTD_STATIC void ZSTD_write16(void *memPtr, U16 value) { put_unaligned(value, (U16 *)memPtr); }
+
+ZSTD_STATIC void ZSTD_write32(void *memPtr, U32 value) { put_unaligned(value, (U32 *)memPtr); }
+
+ZSTD_STATIC void ZSTD_write64(void *memPtr, U64 value) { put_unaligned(value, (U64 *)memPtr); }
+
+/*=== Little endian r/w ===*/
+
+ZSTD_STATIC U16 ZSTD_readLE16(const void *memPtr) { return get_unaligned_le16(memPtr); }
+
+ZSTD_STATIC void ZSTD_writeLE16(void *memPtr, U16 val) { put_unaligned_le16(val, memPtr); }
+
+ZSTD_STATIC U32 ZSTD_readLE24(const void *memPtr) { return ZSTD_readLE16(memPtr) + (((const BYTE *)memPtr)[2] << 16); }
+
+ZSTD_STATIC void ZSTD_writeLE24(void *memPtr, U32 val)
+{
+	ZSTD_writeLE16(memPtr, (U16)val);
+	((BYTE *)memPtr)[2] = (BYTE)(val >> 16);
+}
+
+ZSTD_STATIC U32 ZSTD_readLE32(const void *memPtr) { return get_unaligned_le32(memPtr); }
+
+ZSTD_STATIC void ZSTD_writeLE32(void *memPtr, U32 val32) { put_unaligned_le32(val32, memPtr); }
+
+ZSTD_STATIC U64 ZSTD_readLE64(const void *memPtr) { return get_unaligned_le64(memPtr); }
+
+ZSTD_STATIC void ZSTD_writeLE64(void *memPtr, U64 val64) { put_unaligned_le64(val64, memPtr); }
+
+ZSTD_STATIC size_t ZSTD_readLEST(const void *memPtr)
+{
+	if (ZSTD_32bits())
+		return (size_t)ZSTD_readLE32(memPtr);
+	else
+		return (size_t)ZSTD_readLE64(memPtr);
+}
+
+ZSTD_STATIC void ZSTD_writeLEST(void *memPtr, size_t val)
+{
+	if (ZSTD_32bits())
+		ZSTD_writeLE32(memPtr, (U32)val);
+	else
+		ZSTD_writeLE64(memPtr, (U64)val);
+}
+
+/*=== Big endian r/w ===*/
+
+ZSTD_STATIC U32 ZSTD_readBE32(const void *memPtr) { return get_unaligned_be32(memPtr); }
+
+ZSTD_STATIC void ZSTD_writeBE32(void *memPtr, U32 val32) { put_unaligned_be32(val32, memPtr); }
+
+ZSTD_STATIC U64 ZSTD_readBE64(const void *memPtr) { return get_unaligned_be64(memPtr); }
+
+ZSTD_STATIC void ZSTD_writeBE64(void *memPtr, U64 val64) { put_unaligned_be64(val64, memPtr); }
+
+ZSTD_STATIC size_t ZSTD_readBEST(const void *memPtr)
+{
+	if (ZSTD_32bits())
+		return (size_t)ZSTD_readBE32(memPtr);
+	else
+		return (size_t)ZSTD_readBE64(memPtr);
+}
+
+ZSTD_STATIC void ZSTD_writeBEST(void *memPtr, size_t val)
+{
+	if (ZSTD_32bits())
+		ZSTD_writeBE32(memPtr, (U32)val);
+	else
+		ZSTD_writeBE64(memPtr, (U64)val);
+}
+
+/* function safe only for comparisons */
+ZSTD_STATIC U32 ZSTD_readMINMATCH(const void *memPtr, U32 length)
+{
+	switch (length) {
+	default:
+	case 4: return ZSTD_read32(memPtr);
+	case 3:
+		if (ZSTD_isLittleEndian())
+			return ZSTD_read32(memPtr) << 8;
+		else
+			return ZSTD_read32(memPtr) >> 8;
+	}
+}
+
+#endif /* MEM_H_MODULE */
diff -Naurp -x debian.hwe linux-4.10.x.ori/lib/zstd/zstd_common.c linux-4.10.x/lib/zstd/zstd_common.c
--- linux-4.10.x.ori/lib/zstd/zstd_common.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-4.10.x/lib/zstd/zstd_common.c	2017-10-30 10:05:19.610447000 +0100
@@ -0,0 +1,73 @@
+/**
+ * Copyright (c) 2016-present, Yann Collet, Facebook, Inc.
+ * All rights reserved.
+ *
+ * This source code is licensed under the BSD-style license found in the
+ * LICENSE file in the root directory of https://github.com/facebook/zstd.
+ *
+ * This program is free software; you can redistribute it and/or modify it under
+ * the terms of the GNU General Public License version 2 as published by the
+ * Free Software Foundation. This program is dual-licensed; you may select
+ * either version 2 of the GNU General Public License ("GPL") or BSD license
+ * ("BSD").
+ */
+
+/*-*************************************
+*  Dependencies
+***************************************/
+#include "error_private.h"
+#include "zstd_internal.h" /* declaration of ZSTD_isError, ZSTD_getErrorName, ZSTD_getErrorCode, ZSTD_getErrorString, ZSTD_versionNumber */
+#include <linux/kernel.h>
+
+/*=**************************************************************
+*  Custom allocator
+****************************************************************/
+
+#define stack_push(stack, size)                                 \
+	({                                                      \
+		void *const ptr = ZSTD_PTR_ALIGN((stack)->ptr); \
+		(stack)->ptr = (char *)ptr + (size);            \
+		(stack)->ptr <= (stack)->end ? ptr : NULL;      \
+	})
+
+ZSTD_customMem ZSTD_initStack(void *workspace, size_t workspaceSize)
+{
+	ZSTD_customMem stackMem = {ZSTD_stackAlloc, ZSTD_stackFree, workspace};
+	ZSTD_stack *stack = (ZSTD_stack *)workspace;
+	/* Verify preconditions */
+	if (!workspace || workspaceSize < sizeof(ZSTD_stack) || workspace != ZSTD_PTR_ALIGN(workspace)) {
+		ZSTD_customMem error = {NULL, NULL, NULL};
+		return error;
+	}
+	/* Initialize the stack */
+	stack->ptr = workspace;
+	stack->end = (char *)workspace + workspaceSize;
+	stack_push(stack, sizeof(ZSTD_stack));
+	return stackMem;
+}
+
+void *ZSTD_stackAllocAll(void *opaque, size_t *size)
+{
+	ZSTD_stack *stack = (ZSTD_stack *)opaque;
+	*size = (BYTE const *)stack->end - (BYTE *)ZSTD_PTR_ALIGN(stack->ptr);
+	return stack_push(stack, *size);
+}
+
+void *ZSTD_stackAlloc(void *opaque, size_t size)
+{
+	ZSTD_stack *stack = (ZSTD_stack *)opaque;
+	return stack_push(stack, size);
+}
+void ZSTD_stackFree(void *opaque, void *address)
+{
+	(void)opaque;
+	(void)address;
+}
+
+void *ZSTD_malloc(size_t size, ZSTD_customMem customMem) { return customMem.customAlloc(customMem.opaque, size); }
+
+void ZSTD_free(void *ptr, ZSTD_customMem customMem)
+{
+	if (ptr != NULL)
+		customMem.customFree(customMem.opaque, ptr);
+}
diff -Naurp -x debian.hwe linux-4.10.x.ori/lib/zstd/zstd_internal.h linux-4.10.x/lib/zstd/zstd_internal.h
--- linux-4.10.x.ori/lib/zstd/zstd_internal.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-4.10.x/lib/zstd/zstd_internal.h	2017-10-30 10:05:19.610447000 +0100
@@ -0,0 +1,279 @@
+/**
+ * Copyright (c) 2016-present, Yann Collet, Facebook, Inc.
+ * All rights reserved.
+ *
+ * This source code is licensed under the BSD-style license found in the
+ * LICENSE file in the root directory of https://github.com/facebook/zstd.
+ *
+ * This program is free software; you can redistribute it and/or modify it under
+ * the terms of the GNU General Public License version 2 as published by the
+ * Free Software Foundation. This program is dual-licensed; you may select
+ * either version 2 of the GNU General Public License ("GPL") or BSD license
+ * ("BSD").
+ */
+
+#ifndef ZSTD_CCOMMON_H_MODULE
+#define ZSTD_CCOMMON_H_MODULE
+
+/*-*******************************************************
+*  Compiler specifics
+*********************************************************/
+#define FORCE_INLINE static __always_inline
+#define FORCE_NOINLINE static noinline
+
+/*-*************************************
+*  Dependencies
+***************************************/
+#include "error_private.h"
+#include "mem.h"
+#include <linux/compiler.h>
+#include <linux/kernel.h>
+#include <linux/xxhash.h>
+#include <linux/zstd.h>
+
+/* Undef any of these macros coming from string_32.h. */
+#undef memcpy
+#undef memset
+#undef memcmp
+
+void *memcpy(void *dst, const void *src, size_t len);
+void *memset(void *dst, int c, size_t len);
+int memcmp(const void *s1, const void *s2, size_t len);
+
+/*
+ * Access builtin version by default. If one needs to use optimized version,
+ * do "undef memcpy" in .c file and link against right string.c
+ */
+#define memcpy(d,s,l) __builtin_memcpy(d,s,l)
+#define memset(d,c,l) __builtin_memset(d,c,l)
+#define memcmp  __builtin_memcmp
+
+
+/*-*************************************
+*  shared macros
+***************************************/
+#define MIN(a, b) ((a) < (b) ? (a) : (b))
+#define MAX(a, b) ((a) > (b) ? (a) : (b))
+#define CHECK_F(f)                       \
+	{                                \
+		size_t const errcod = f; \
+		if (ERR_isError(errcod)) \
+			return errcod;   \
+	} /* check and Forward error code */
+#define CHECK_E(f, e)                    \
+	{                                \
+		size_t const errcod = f; \
+		if (ERR_isError(errcod)) \
+			return ERROR(e); \
+	} /* check and send Error code */
+#define ZSTD_STATIC_ASSERT(c)                                   \
+	{                                                       \
+		enum { ZSTD_static_assert = 1 / (int)(!!(c)) }; \
+	}
+
+/*-*************************************
+*  Common constants
+***************************************/
+#define ZSTD_OPT_NUM (1 << 12)
+#define ZSTD_DICT_MAGIC 0xEC30A437 /* v0.7+ */
+
+#define ZSTD_REP_NUM 3		      /* number of repcodes */
+#define ZSTD_REP_CHECK (ZSTD_REP_NUM) /* number of repcodes to check by the optimal parser */
+#define ZSTD_REP_MOVE (ZSTD_REP_NUM - 1)
+#define ZSTD_REP_MOVE_OPT (ZSTD_REP_NUM)
+static const U32 repStartValue[ZSTD_REP_NUM] = {1, 4, 8};
+
+#define KB *(1 << 10)
+#define MB *(1 << 20)
+#define GB *(1U << 30)
+
+#define BIT7 128
+#define BIT6 64
+#define BIT5 32
+#define BIT4 16
+#define BIT1 2
+#define BIT0 1
+
+#define ZSTD_WINDOWLOG_ABSOLUTEMIN 10
+static const size_t ZSTD_fcs_fieldSize[4] = {0, 2, 4, 8};
+static const size_t ZSTD_did_fieldSize[4] = {0, 1, 2, 4};
+
+#define ZSTD_BLOCKHEADERSIZE 3 /* C standard doesn't allow `static const` variable to be init using another `static const` variable */
+static const size_t ZSTD_blockHeaderSize = ZSTD_BLOCKHEADERSIZE;
+typedef enum { bt_raw, bt_rle, bt_compressed, bt_reserved } blockType_e;
+
+#define MIN_SEQUENCES_SIZE 1									  /* nbSeq==0 */
+#define MIN_CBLOCK_SIZE (1 /*litCSize*/ + 1 /* RLE or RAW */ + MIN_SEQUENCES_SIZE /* nbSeq==0 */) /* for a non-null block */
+
+#define HufLog 12
+typedef enum { set_basic, set_rle, set_compressed, set_repeat } symbolEncodingType_e;
+
+#define LONGNBSEQ 0x7F00
+
+#define MINMATCH 3
+#define EQUAL_READ32 4
+
+#define Litbits 8
+#define MaxLit ((1 << Litbits) - 1)
+#define MaxML 52
+#define MaxLL 35
+#define MaxOff 28
+#define MaxSeq MAX(MaxLL, MaxML) /* Assumption : MaxOff < MaxLL,MaxML */
+#define MLFSELog 9
+#define LLFSELog 9
+#define OffFSELog 8
+
+static const U32 LL_bits[MaxLL + 1] = {0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 3, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16};
+static const S16 LL_defaultNorm[MaxLL + 1] = {4, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 1, 1, 1, 1, 1, -1, -1, -1, -1};
+#define LL_DEFAULTNORMLOG 6 /* for static allocation */
+static const U32 LL_defaultNormLog = LL_DEFAULTNORMLOG;
+
+static const U32 ML_bits[MaxML + 1] = {0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,  0,  0,  0,  0,  0,  0, 0,
+				       0, 0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 3, 3, 4, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16};
+static const S16 ML_defaultNorm[MaxML + 1] = {1, 4, 3, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,  1,  1,  1,  1,  1,  1, 1,
+					      1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, -1, -1, -1, -1, -1};
+#define ML_DEFAULTNORMLOG 6 /* for static allocation */
+static const U32 ML_defaultNormLog = ML_DEFAULTNORMLOG;
+
+static const S16 OF_defaultNorm[MaxOff + 1] = {1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, -1, -1, -1};
+#define OF_DEFAULTNORMLOG 5 /* for static allocation */
+static const U32 OF_defaultNormLog = OF_DEFAULTNORMLOG;
+
+/*-*******************************************
+*  Shared functions to include for inlining
+*********************************************/
+ZSTD_STATIC void ZSTD_copy8(void *dst, const void *src) {
+	memcpy(dst, src, 8);
+}
+/*! ZSTD_wildcopy() :
+*   custom version of memcpy(), can copy up to 7 bytes too many (8 bytes if length==0) */
+#define WILDCOPY_OVERLENGTH 8
+ZSTD_STATIC void ZSTD_wildcopy(void *dst, const void *src, ptrdiff_t length)
+{
+	const BYTE* ip = (const BYTE*)src;
+	BYTE* op = (BYTE*)dst;
+	BYTE* const oend = op + length;
+	/* Work around https://gcc.gnu.org/bugzilla/show_bug.cgi?id=81388.
+	 * Avoid the bad case where the loop only runs once by handling the
+	 * special case separately. This doesn't trigger the bug because it
+	 * doesn't involve pointer/integer overflow.
+	 */
+	if (length <= 8)
+		return ZSTD_copy8(dst, src);
+	do {
+		ZSTD_copy8(op, ip);
+		op += 8;
+		ip += 8;
+	} while (op < oend);
+}
+
+/*-*******************************************
+*  Private interfaces
+*********************************************/
+typedef struct ZSTD_stats_s ZSTD_stats_t;
+
+typedef struct {
+	U32 off;
+	U32 len;
+} ZSTD_match_t;
+
+typedef struct {
+	U32 price;
+	U32 off;
+	U32 mlen;
+	U32 litlen;
+	U32 rep[ZSTD_REP_NUM];
+} ZSTD_optimal_t;
+
+typedef struct seqDef_s {
+	U32 offset;
+	U16 litLength;
+	U16 matchLength;
+} seqDef;
+
+typedef struct {
+	seqDef *sequencesStart;
+	seqDef *sequences;
+	BYTE *litStart;
+	BYTE *lit;
+	BYTE *llCode;
+	BYTE *mlCode;
+	BYTE *ofCode;
+	U32 longLengthID; /* 0 == no longLength; 1 == Lit.longLength; 2 == Match.longLength; */
+	U32 longLengthPos;
+	/* opt */
+	ZSTD_optimal_t *priceTable;
+	ZSTD_match_t *matchTable;
+	U32 *matchLengthFreq;
+	U32 *litLengthFreq;
+	U32 *litFreq;
+	U32 *offCodeFreq;
+	U32 matchLengthSum;
+	U32 matchSum;
+	U32 litLengthSum;
+	U32 litSum;
+	U32 offCodeSum;
+	U32 log2matchLengthSum;
+	U32 log2matchSum;
+	U32 log2litLengthSum;
+	U32 log2litSum;
+	U32 log2offCodeSum;
+	U32 factor;
+	U32 staticPrices;
+	U32 cachedPrice;
+	U32 cachedLitLength;
+	const BYTE *cachedLiterals;
+} seqStore_t;
+
+const seqStore_t *ZSTD_getSeqStore(const ZSTD_CCtx *ctx);
+void ZSTD_seqToCodes(const seqStore_t *seqStorePtr);
+int ZSTD_isSkipFrame(ZSTD_DCtx *dctx);
+
+/*= Custom memory allocation functions */
+typedef void *(*ZSTD_allocFunction)(void *opaque, size_t size);
+typedef void (*ZSTD_freeFunction)(void *opaque, void *address);
+typedef struct {
+	ZSTD_allocFunction customAlloc;
+	ZSTD_freeFunction customFree;
+	void *opaque;
+} ZSTD_customMem;
+
+void *ZSTD_malloc(size_t size, ZSTD_customMem customMem);
+void ZSTD_free(void *ptr, ZSTD_customMem customMem);
+
+/*====== stack allocation  ======*/
+
+typedef struct {
+	void *ptr;
+	const void *end;
+} ZSTD_stack;
+
+#define ZSTD_ALIGN(x) ALIGN(x, sizeof(size_t))
+#define ZSTD_PTR_ALIGN(p) PTR_ALIGN(p, sizeof(size_t))
+
+ZSTD_customMem ZSTD_initStack(void *workspace, size_t workspaceSize);
+
+void *ZSTD_stackAllocAll(void *opaque, size_t *size);
+void *ZSTD_stackAlloc(void *opaque, size_t size);
+void ZSTD_stackFree(void *opaque, void *address);
+
+/*======  common function  ======*/
+
+ZSTD_STATIC U32 ZSTD_highbit32(U32 val) { return 31 - __builtin_clz(val); }
+
+/* hidden functions */
+
+/* ZSTD_invalidateRepCodes() :
+ * ensures next compression will not use repcodes from previous block.
+ * Note : only works with regular variant;
+ *        do not use with extDict variant ! */
+void ZSTD_invalidateRepCodes(ZSTD_CCtx *cctx);
+
+size_t ZSTD_freeCCtx(ZSTD_CCtx *cctx);
+size_t ZSTD_freeDCtx(ZSTD_DCtx *dctx);
+size_t ZSTD_freeCDict(ZSTD_CDict *cdict);
+size_t ZSTD_freeDDict(ZSTD_DDict *cdict);
+size_t ZSTD_freeCStream(ZSTD_CStream *zcs);
+size_t ZSTD_freeDStream(ZSTD_DStream *zds);
+
+#endif /* ZSTD_CCOMMON_H_MODULE */
diff -Naurp -x debian.hwe linux-4.10.x.ori/lib/zstd/zstd_opt.h linux-4.10.x/lib/zstd/zstd_opt.h
--- linux-4.10.x.ori/lib/zstd/zstd_opt.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-4.10.x/lib/zstd/zstd_opt.h	2017-10-30 10:05:19.610447000 +0100
@@ -0,0 +1,1012 @@
+/**
+ * Copyright (c) 2016-present, Przemyslaw Skibinski, Yann Collet, Facebook, Inc.
+ * All rights reserved.
+ *
+ * This source code is licensed under the BSD-style license found in the
+ * LICENSE file in the root directory of https://github.com/facebook/zstd.
+ *
+ * This program is free software; you can redistribute it and/or modify it under
+ * the terms of the GNU General Public License version 2 as published by the
+ * Free Software Foundation. This program is dual-licensed; you may select
+ * either version 2 of the GNU General Public License ("GPL") or BSD license
+ * ("BSD").
+ */
+
+/* Note : this file is intended to be included within zstd_compress.c */
+
+#ifndef ZSTD_OPT_H_91842398743
+#define ZSTD_OPT_H_91842398743
+
+#define ZSTD_LITFREQ_ADD 2
+#define ZSTD_FREQ_DIV 4
+#define ZSTD_MAX_PRICE (1 << 30)
+
+/*-*************************************
+*  Price functions for optimal parser
+***************************************/
+FORCE_INLINE void ZSTD_setLog2Prices(seqStore_t *ssPtr)
+{
+	ssPtr->log2matchLengthSum = ZSTD_highbit32(ssPtr->matchLengthSum + 1);
+	ssPtr->log2litLengthSum = ZSTD_highbit32(ssPtr->litLengthSum + 1);
+	ssPtr->log2litSum = ZSTD_highbit32(ssPtr->litSum + 1);
+	ssPtr->log2offCodeSum = ZSTD_highbit32(ssPtr->offCodeSum + 1);
+	ssPtr->factor = 1 + ((ssPtr->litSum >> 5) / ssPtr->litLengthSum) + ((ssPtr->litSum << 1) / (ssPtr->litSum + ssPtr->matchSum));
+}
+
+ZSTD_STATIC void ZSTD_rescaleFreqs(seqStore_t *ssPtr, const BYTE *src, size_t srcSize)
+{
+	unsigned u;
+
+	ssPtr->cachedLiterals = NULL;
+	ssPtr->cachedPrice = ssPtr->cachedLitLength = 0;
+	ssPtr->staticPrices = 0;
+
+	if (ssPtr->litLengthSum == 0) {
+		if (srcSize <= 1024)
+			ssPtr->staticPrices = 1;
+
+		for (u = 0; u <= MaxLit; u++)
+			ssPtr->litFreq[u] = 0;
+		for (u = 0; u < srcSize; u++)
+			ssPtr->litFreq[src[u]]++;
+
+		ssPtr->litSum = 0;
+		ssPtr->litLengthSum = MaxLL + 1;
+		ssPtr->matchLengthSum = MaxML + 1;
+		ssPtr->offCodeSum = (MaxOff + 1);
+		ssPtr->matchSum = (ZSTD_LITFREQ_ADD << Litbits);
+
+		for (u = 0; u <= MaxLit; u++) {
+			ssPtr->litFreq[u] = 1 + (ssPtr->litFreq[u] >> ZSTD_FREQ_DIV);
+			ssPtr->litSum += ssPtr->litFreq[u];
+		}
+		for (u = 0; u <= MaxLL; u++)
+			ssPtr->litLengthFreq[u] = 1;
+		for (u = 0; u <= MaxML; u++)
+			ssPtr->matchLengthFreq[u] = 1;
+		for (u = 0; u <= MaxOff; u++)
+			ssPtr->offCodeFreq[u] = 1;
+	} else {
+		ssPtr->matchLengthSum = 0;
+		ssPtr->litLengthSum = 0;
+		ssPtr->offCodeSum = 0;
+		ssPtr->matchSum = 0;
+		ssPtr->litSum = 0;
+
+		for (u = 0; u <= MaxLit; u++) {
+			ssPtr->litFreq[u] = 1 + (ssPtr->litFreq[u] >> (ZSTD_FREQ_DIV + 1));
+			ssPtr->litSum += ssPtr->litFreq[u];
+		}
+		for (u = 0; u <= MaxLL; u++) {
+			ssPtr->litLengthFreq[u] = 1 + (ssPtr->litLengthFreq[u] >> (ZSTD_FREQ_DIV + 1));
+			ssPtr->litLengthSum += ssPtr->litLengthFreq[u];
+		}
+		for (u = 0; u <= MaxML; u++) {
+			ssPtr->matchLengthFreq[u] = 1 + (ssPtr->matchLengthFreq[u] >> ZSTD_FREQ_DIV);
+			ssPtr->matchLengthSum += ssPtr->matchLengthFreq[u];
+			ssPtr->matchSum += ssPtr->matchLengthFreq[u] * (u + 3);
+		}
+		ssPtr->matchSum *= ZSTD_LITFREQ_ADD;
+		for (u = 0; u <= MaxOff; u++) {
+			ssPtr->offCodeFreq[u] = 1 + (ssPtr->offCodeFreq[u] >> ZSTD_FREQ_DIV);
+			ssPtr->offCodeSum += ssPtr->offCodeFreq[u];
+		}
+	}
+
+	ZSTD_setLog2Prices(ssPtr);
+}
+
+FORCE_INLINE U32 ZSTD_getLiteralPrice(seqStore_t *ssPtr, U32 litLength, const BYTE *literals)
+{
+	U32 price, u;
+
+	if (ssPtr->staticPrices)
+		return ZSTD_highbit32((U32)litLength + 1) + (litLength * 6);
+
+	if (litLength == 0)
+		return ssPtr->log2litLengthSum - ZSTD_highbit32(ssPtr->litLengthFreq[0] + 1);
+
+	/* literals */
+	if (ssPtr->cachedLiterals == literals) {
+		U32 const additional = litLength - ssPtr->cachedLitLength;
+		const BYTE *literals2 = ssPtr->cachedLiterals + ssPtr->cachedLitLength;
+		price = ssPtr->cachedPrice + additional * ssPtr->log2litSum;
+		for (u = 0; u < additional; u++)
+			price -= ZSTD_highbit32(ssPtr->litFreq[literals2[u]] + 1);
+		ssPtr->cachedPrice = price;
+		ssPtr->cachedLitLength = litLength;
+	} else {
+		price = litLength * ssPtr->log2litSum;
+		for (u = 0; u < litLength; u++)
+			price -= ZSTD_highbit32(ssPtr->litFreq[literals[u]] + 1);
+
+		if (litLength >= 12) {
+			ssPtr->cachedLiterals = literals;
+			ssPtr->cachedPrice = price;
+			ssPtr->cachedLitLength = litLength;
+		}
+	}
+
+	/* literal Length */
+	{
+		const BYTE LL_deltaCode = 19;
+		const BYTE llCode = (litLength > 63) ? (BYTE)ZSTD_highbit32(litLength) + LL_deltaCode : LL_Code[litLength];
+		price += LL_bits[llCode] + ssPtr->log2litLengthSum - ZSTD_highbit32(ssPtr->litLengthFreq[llCode] + 1);
+	}
+
+	return price;
+}
+
+FORCE_INLINE U32 ZSTD_getPrice(seqStore_t *seqStorePtr, U32 litLength, const BYTE *literals, U32 offset, U32 matchLength, const int ultra)
+{
+	/* offset */
+	U32 price;
+	BYTE const offCode = (BYTE)ZSTD_highbit32(offset + 1);
+
+	if (seqStorePtr->staticPrices)
+		return ZSTD_getLiteralPrice(seqStorePtr, litLength, literals) + ZSTD_highbit32((U32)matchLength + 1) + 16 + offCode;
+
+	price = offCode + seqStorePtr->log2offCodeSum - ZSTD_highbit32(seqStorePtr->offCodeFreq[offCode] + 1);
+	if (!ultra && offCode >= 20)
+		price += (offCode - 19) * 2;
+
+	/* match Length */
+	{
+		const BYTE ML_deltaCode = 36;
+		const BYTE mlCode = (matchLength > 127) ? (BYTE)ZSTD_highbit32(matchLength) + ML_deltaCode : ML_Code[matchLength];
+		price += ML_bits[mlCode] + seqStorePtr->log2matchLengthSum - ZSTD_highbit32(seqStorePtr->matchLengthFreq[mlCode] + 1);
+	}
+
+	return price + ZSTD_getLiteralPrice(seqStorePtr, litLength, literals) + seqStorePtr->factor;
+}
+
+ZSTD_STATIC void ZSTD_updatePrice(seqStore_t *seqStorePtr, U32 litLength, const BYTE *literals, U32 offset, U32 matchLength)
+{
+	U32 u;
+
+	/* literals */
+	seqStorePtr->litSum += litLength * ZSTD_LITFREQ_ADD;
+	for (u = 0; u < litLength; u++)
+		seqStorePtr->litFreq[literals[u]] += ZSTD_LITFREQ_ADD;
+
+	/* literal Length */
+	{
+		const BYTE LL_deltaCode = 19;
+		const BYTE llCode = (litLength > 63) ? (BYTE)ZSTD_highbit32(litLength) + LL_deltaCode : LL_Code[litLength];
+		seqStorePtr->litLengthFreq[llCode]++;
+		seqStorePtr->litLengthSum++;
+	}
+
+	/* match offset */
+	{
+		BYTE const offCode = (BYTE)ZSTD_highbit32(offset + 1);
+		seqStorePtr->offCodeSum++;
+		seqStorePtr->offCodeFreq[offCode]++;
+	}
+
+	/* match Length */
+	{
+		const BYTE ML_deltaCode = 36;
+		const BYTE mlCode = (matchLength > 127) ? (BYTE)ZSTD_highbit32(matchLength) + ML_deltaCode : ML_Code[matchLength];
+		seqStorePtr->matchLengthFreq[mlCode]++;
+		seqStorePtr->matchLengthSum++;
+	}
+
+	ZSTD_setLog2Prices(seqStorePtr);
+}
+
+#define SET_PRICE(pos, mlen_, offset_, litlen_, price_)           \
+	{                                                         \
+		while (last_pos < pos) {                          \
+			opt[last_pos + 1].price = ZSTD_MAX_PRICE; \
+			last_pos++;                               \
+		}                                                 \
+		opt[pos].mlen = mlen_;                            \
+		opt[pos].off = offset_;                           \
+		opt[pos].litlen = litlen_;                        \
+		opt[pos].price = price_;                          \
+	}
+
+/* Update hashTable3 up to ip (excluded)
+   Assumption : always within prefix (i.e. not within extDict) */
+FORCE_INLINE
+U32 ZSTD_insertAndFindFirstIndexHash3(ZSTD_CCtx *zc, const BYTE *ip)
+{
+	U32 *const hashTable3 = zc->hashTable3;
+	U32 const hashLog3 = zc->hashLog3;
+	const BYTE *const base = zc->base;
+	U32 idx = zc->nextToUpdate3;
+	const U32 target = zc->nextToUpdate3 = (U32)(ip - base);
+	const size_t hash3 = ZSTD_hash3Ptr(ip, hashLog3);
+
+	while (idx < target) {
+		hashTable3[ZSTD_hash3Ptr(base + idx, hashLog3)] = idx;
+		idx++;
+	}
+
+	return hashTable3[hash3];
+}
+
+/*-*************************************
+*  Binary Tree search
+***************************************/
+static U32 ZSTD_insertBtAndGetAllMatches(ZSTD_CCtx *zc, const BYTE *const ip, const BYTE *const iLimit, U32 nbCompares, const U32 mls, U32 extDict,
+					 ZSTD_match_t *matches, const U32 minMatchLen)
+{
+	const BYTE *const base = zc->base;
+	const U32 curr = (U32)(ip - base);
+	const U32 hashLog = zc->params.cParams.hashLog;
+	const size_t h = ZSTD_hashPtr(ip, hashLog, mls);
+	U32 *const hashTable = zc->hashTable;
+	U32 matchIndex = hashTable[h];
+	U32 *const bt = zc->chainTable;
+	const U32 btLog = zc->params.cParams.chainLog - 1;
+	const U32 btMask = (1U << btLog) - 1;
+	size_t commonLengthSmaller = 0, commonLengthLarger = 0;
+	const BYTE *const dictBase = zc->dictBase;
+	const U32 dictLimit = zc->dictLimit;
+	const BYTE *const dictEnd = dictBase + dictLimit;
+	const BYTE *const prefixStart = base + dictLimit;
+	const U32 btLow = btMask >= curr ? 0 : curr - btMask;
+	const U32 windowLow = zc->lowLimit;
+	U32 *smallerPtr = bt + 2 * (curr & btMask);
+	U32 *largerPtr = bt + 2 * (curr & btMask) + 1;
+	U32 matchEndIdx = curr + 8;
+	U32 dummy32; /* to be nullified at the end */
+	U32 mnum = 0;
+
+	const U32 minMatch = (mls == 3) ? 3 : 4;
+	size_t bestLength = minMatchLen - 1;
+
+	if (minMatch == 3) { /* HC3 match finder */
+		U32 const matchIndex3 = ZSTD_insertAndFindFirstIndexHash3(zc, ip);
+		if (matchIndex3 > windowLow && (curr - matchIndex3 < (1 << 18))) {
+			const BYTE *match;
+			size_t currMl = 0;
+			if ((!extDict) || matchIndex3 >= dictLimit) {
+				match = base + matchIndex3;
+				if (match[bestLength] == ip[bestLength])
+					currMl = ZSTD_count(ip, match, iLimit);
+			} else {
+				match = dictBase + matchIndex3;
+				if (ZSTD_readMINMATCH(match, MINMATCH) ==
+				    ZSTD_readMINMATCH(ip, MINMATCH)) /* assumption : matchIndex3 <= dictLimit-4 (by table construction) */
+					currMl = ZSTD_count_2segments(ip + MINMATCH, match + MINMATCH, iLimit, dictEnd, prefixStart) + MINMATCH;
+			}
+
+			/* save best solution */
+			if (currMl > bestLength) {
+				bestLength = currMl;
+				matches[mnum].off = ZSTD_REP_MOVE_OPT + curr - matchIndex3;
+				matches[mnum].len = (U32)currMl;
+				mnum++;
+				if (currMl > ZSTD_OPT_NUM)
+					goto update;
+				if (ip + currMl == iLimit)
+					goto update; /* best possible, and avoid read overflow*/
+			}
+		}
+	}
+
+	hashTable[h] = curr; /* Update Hash Table */
+
+	while (nbCompares-- && (matchIndex > windowLow)) {
+		U32 *nextPtr = bt + 2 * (matchIndex & btMask);
+		size_t matchLength = MIN(commonLengthSmaller, commonLengthLarger); /* guaranteed minimum nb of common bytes */
+		const BYTE *match;
+
+		if ((!extDict) || (matchIndex + matchLength >= dictLimit)) {
+			match = base + matchIndex;
+			if (match[matchLength] == ip[matchLength]) {
+				matchLength += ZSTD_count(ip + matchLength + 1, match + matchLength + 1, iLimit) + 1;
+			}
+		} else {
+			match = dictBase + matchIndex;
+			matchLength += ZSTD_count_2segments(ip + matchLength, match + matchLength, iLimit, dictEnd, prefixStart);
+			if (matchIndex + matchLength >= dictLimit)
+				match = base + matchIndex; /* to prepare for next usage of match[matchLength] */
+		}
+
+		if (matchLength > bestLength) {
+			if (matchLength > matchEndIdx - matchIndex)
+				matchEndIdx = matchIndex + (U32)matchLength;
+			bestLength = matchLength;
+			matches[mnum].off = ZSTD_REP_MOVE_OPT + curr - matchIndex;
+			matches[mnum].len = (U32)matchLength;
+			mnum++;
+			if (matchLength > ZSTD_OPT_NUM)
+				break;
+			if (ip + matchLength == iLimit) /* equal : no way to know if inf or sup */
+				break;			/* drop, to guarantee consistency (miss a little bit of compression) */
+		}
+
+		if (match[matchLength] < ip[matchLength]) {
+			/* match is smaller than curr */
+			*smallerPtr = matchIndex;	  /* update smaller idx */
+			commonLengthSmaller = matchLength; /* all smaller will now have at least this guaranteed common length */
+			if (matchIndex <= btLow) {
+				smallerPtr = &dummy32;
+				break;
+			}			  /* beyond tree size, stop the search */
+			smallerPtr = nextPtr + 1; /* new "smaller" => larger of match */
+			matchIndex = nextPtr[1];  /* new matchIndex larger than previous (closer to curr) */
+		} else {
+			/* match is larger than curr */
+			*largerPtr = matchIndex;
+			commonLengthLarger = matchLength;
+			if (matchIndex <= btLow) {
+				largerPtr = &dummy32;
+				break;
+			} /* beyond tree size, stop the search */
+			largerPtr = nextPtr;
+			matchIndex = nextPtr[0];
+		}
+	}
+
+	*smallerPtr = *largerPtr = 0;
+
+update:
+	zc->nextToUpdate = (matchEndIdx > curr + 8) ? matchEndIdx - 8 : curr + 1;
+	return mnum;
+}
+
+/** Tree updater, providing best match */
+static U32 ZSTD_BtGetAllMatches(ZSTD_CCtx *zc, const BYTE *const ip, const BYTE *const iLimit, const U32 maxNbAttempts, const U32 mls, ZSTD_match_t *matches,
+				const U32 minMatchLen)
+{
+	if (ip < zc->base + zc->nextToUpdate)
+		return 0; /* skipped area */
+	ZSTD_updateTree(zc, ip, iLimit, maxNbAttempts, mls);
+	return ZSTD_insertBtAndGetAllMatches(zc, ip, iLimit, maxNbAttempts, mls, 0, matches, minMatchLen);
+}
+
+static U32 ZSTD_BtGetAllMatches_selectMLS(ZSTD_CCtx *zc, /* Index table will be updated */
+					  const BYTE *ip, const BYTE *const iHighLimit, const U32 maxNbAttempts, const U32 matchLengthSearch,
+					  ZSTD_match_t *matches, const U32 minMatchLen)
+{
+	switch (matchLengthSearch) {
+	case 3: return ZSTD_BtGetAllMatches(zc, ip, iHighLimit, maxNbAttempts, 3, matches, minMatchLen);
+	default:
+	case 4: return ZSTD_BtGetAllMatches(zc, ip, iHighLimit, maxNbAttempts, 4, matches, minMatchLen);
+	case 5: return ZSTD_BtGetAllMatches(zc, ip, iHighLimit, maxNbAttempts, 5, matches, minMatchLen);
+	case 7:
+	case 6: return ZSTD_BtGetAllMatches(zc, ip, iHighLimit, maxNbAttempts, 6, matches, minMatchLen);
+	}
+}
+
+/** Tree updater, providing best match */
+static U32 ZSTD_BtGetAllMatches_extDict(ZSTD_CCtx *zc, const BYTE *const ip, const BYTE *const iLimit, const U32 maxNbAttempts, const U32 mls,
+					ZSTD_match_t *matches, const U32 minMatchLen)
+{
+	if (ip < zc->base + zc->nextToUpdate)
+		return 0; /* skipped area */
+	ZSTD_updateTree_extDict(zc, ip, iLimit, maxNbAttempts, mls);
+	return ZSTD_insertBtAndGetAllMatches(zc, ip, iLimit, maxNbAttempts, mls, 1, matches, minMatchLen);
+}
+
+static U32 ZSTD_BtGetAllMatches_selectMLS_extDict(ZSTD_CCtx *zc, /* Index table will be updated */
+						  const BYTE *ip, const BYTE *const iHighLimit, const U32 maxNbAttempts, const U32 matchLengthSearch,
+						  ZSTD_match_t *matches, const U32 minMatchLen)
+{
+	switch (matchLengthSearch) {
+	case 3: return ZSTD_BtGetAllMatches_extDict(zc, ip, iHighLimit, maxNbAttempts, 3, matches, minMatchLen);
+	default:
+	case 4: return ZSTD_BtGetAllMatches_extDict(zc, ip, iHighLimit, maxNbAttempts, 4, matches, minMatchLen);
+	case 5: return ZSTD_BtGetAllMatches_extDict(zc, ip, iHighLimit, maxNbAttempts, 5, matches, minMatchLen);
+	case 7:
+	case 6: return ZSTD_BtGetAllMatches_extDict(zc, ip, iHighLimit, maxNbAttempts, 6, matches, minMatchLen);
+	}
+}
+
+/*-*******************************
+*  Optimal parser
+*********************************/
+FORCE_INLINE
+void ZSTD_compressBlock_opt_generic(ZSTD_CCtx *ctx, const void *src, size_t srcSize, const int ultra)
+{
+	seqStore_t *seqStorePtr = &(ctx->seqStore);
+	const BYTE *const istart = (const BYTE *)src;
+	const BYTE *ip = istart;
+	const BYTE *anchor = istart;
+	const BYTE *const iend = istart + srcSize;
+	const BYTE *const ilimit = iend - 8;
+	const BYTE *const base = ctx->base;
+	const BYTE *const prefixStart = base + ctx->dictLimit;
+
+	const U32 maxSearches = 1U << ctx->params.cParams.searchLog;
+	const U32 sufficient_len = ctx->params.cParams.targetLength;
+	const U32 mls = ctx->params.cParams.searchLength;
+	const U32 minMatch = (ctx->params.cParams.searchLength == 3) ? 3 : 4;
+
+	ZSTD_optimal_t *opt = seqStorePtr->priceTable;
+	ZSTD_match_t *matches = seqStorePtr->matchTable;
+	const BYTE *inr;
+	U32 offset, rep[ZSTD_REP_NUM];
+
+	/* init */
+	ctx->nextToUpdate3 = ctx->nextToUpdate;
+	ZSTD_rescaleFreqs(seqStorePtr, (const BYTE *)src, srcSize);
+	ip += (ip == prefixStart);
+	{
+		U32 i;
+		for (i = 0; i < ZSTD_REP_NUM; i++)
+			rep[i] = ctx->rep[i];
+	}
+
+	/* Match Loop */
+	while (ip < ilimit) {
+		U32 cur, match_num, last_pos, litlen, price;
+		U32 u, mlen, best_mlen, best_off, litLength;
+		memset(opt, 0, sizeof(ZSTD_optimal_t));
+		last_pos = 0;
+		litlen = (U32)(ip - anchor);
+
+		/* check repCode */
+		{
+			U32 i, last_i = ZSTD_REP_CHECK + (ip == anchor);
+			for (i = (ip == anchor); i < last_i; i++) {
+				const S32 repCur = (i == ZSTD_REP_MOVE_OPT) ? (rep[0] - 1) : rep[i];
+				if ((repCur > 0) && (repCur < (S32)(ip - prefixStart)) &&
+				    (ZSTD_readMINMATCH(ip, minMatch) == ZSTD_readMINMATCH(ip - repCur, minMatch))) {
+					mlen = (U32)ZSTD_count(ip + minMatch, ip + minMatch - repCur, iend) + minMatch;
+					if (mlen > sufficient_len || mlen >= ZSTD_OPT_NUM) {
+						best_mlen = mlen;
+						best_off = i;
+						cur = 0;
+						last_pos = 1;
+						goto _storeSequence;
+					}
+					best_off = i - (ip == anchor);
+					do {
+						price = ZSTD_getPrice(seqStorePtr, litlen, anchor, best_off, mlen - MINMATCH, ultra);
+						if (mlen > last_pos || price < opt[mlen].price)
+							SET_PRICE(mlen, mlen, i, litlen, price); /* note : macro modifies last_pos */
+						mlen--;
+					} while (mlen >= minMatch);
+				}
+			}
+		}
+
+		match_num = ZSTD_BtGetAllMatches_selectMLS(ctx, ip, iend, maxSearches, mls, matches, minMatch);
+
+		if (!last_pos && !match_num) {
+			ip++;
+			continue;
+		}
+
+		if (match_num && (matches[match_num - 1].len > sufficient_len || matches[match_num - 1].len >= ZSTD_OPT_NUM)) {
+			best_mlen = matches[match_num - 1].len;
+			best_off = matches[match_num - 1].off;
+			cur = 0;
+			last_pos = 1;
+			goto _storeSequence;
+		}
+
+		/* set prices using matches at position = 0 */
+		best_mlen = (last_pos) ? last_pos : minMatch;
+		for (u = 0; u < match_num; u++) {
+			mlen = (u > 0) ? matches[u - 1].len + 1 : best_mlen;
+			best_mlen = matches[u].len;
+			while (mlen <= best_mlen) {
+				price = ZSTD_getPrice(seqStorePtr, litlen, anchor, matches[u].off - 1, mlen - MINMATCH, ultra);
+				if (mlen > last_pos || price < opt[mlen].price)
+					SET_PRICE(mlen, mlen, matches[u].off, litlen, price); /* note : macro modifies last_pos */
+				mlen++;
+			}
+		}
+
+		if (last_pos < minMatch) {
+			ip++;
+			continue;
+		}
+
+		/* initialize opt[0] */
+		{
+			U32 i;
+			for (i = 0; i < ZSTD_REP_NUM; i++)
+				opt[0].rep[i] = rep[i];
+		}
+		opt[0].mlen = 1;
+		opt[0].litlen = litlen;
+
+		/* check further positions */
+		for (cur = 1; cur <= last_pos; cur++) {
+			inr = ip + cur;
+
+			if (opt[cur - 1].mlen == 1) {
+				litlen = opt[cur - 1].litlen + 1;
+				if (cur > litlen) {
+					price = opt[cur - litlen].price + ZSTD_getLiteralPrice(seqStorePtr, litlen, inr - litlen);
+				} else
+					price = ZSTD_getLiteralPrice(seqStorePtr, litlen, anchor);
+			} else {
+				litlen = 1;
+				price = opt[cur - 1].price + ZSTD_getLiteralPrice(seqStorePtr, litlen, inr - 1);
+			}
+
+			if (cur > last_pos || price <= opt[cur].price)
+				SET_PRICE(cur, 1, 0, litlen, price);
+
+			if (cur == last_pos)
+				break;
+
+			if (inr > ilimit) /* last match must start at a minimum distance of 8 from oend */
+				continue;
+
+			mlen = opt[cur].mlen;
+			if (opt[cur].off > ZSTD_REP_MOVE_OPT) {
+				opt[cur].rep[2] = opt[cur - mlen].rep[1];
+				opt[cur].rep[1] = opt[cur - mlen].rep[0];
+				opt[cur].rep[0] = opt[cur].off - ZSTD_REP_MOVE_OPT;
+			} else {
+				opt[cur].rep[2] = (opt[cur].off > 1) ? opt[cur - mlen].rep[1] : opt[cur - mlen].rep[2];
+				opt[cur].rep[1] = (opt[cur].off > 0) ? opt[cur - mlen].rep[0] : opt[cur - mlen].rep[1];
+				opt[cur].rep[0] =
+				    ((opt[cur].off == ZSTD_REP_MOVE_OPT) && (mlen != 1)) ? (opt[cur - mlen].rep[0] - 1) : (opt[cur - mlen].rep[opt[cur].off]);
+			}
+
+			best_mlen = minMatch;
+			{
+				U32 i, last_i = ZSTD_REP_CHECK + (mlen != 1);
+				for (i = (opt[cur].mlen != 1); i < last_i; i++) { /* check rep */
+					const S32 repCur = (i == ZSTD_REP_MOVE_OPT) ? (opt[cur].rep[0] - 1) : opt[cur].rep[i];
+					if ((repCur > 0) && (repCur < (S32)(inr - prefixStart)) &&
+					    (ZSTD_readMINMATCH(inr, minMatch) == ZSTD_readMINMATCH(inr - repCur, minMatch))) {
+						mlen = (U32)ZSTD_count(inr + minMatch, inr + minMatch - repCur, iend) + minMatch;
+
+						if (mlen > sufficient_len || cur + mlen >= ZSTD_OPT_NUM) {
+							best_mlen = mlen;
+							best_off = i;
+							last_pos = cur + 1;
+							goto _storeSequence;
+						}
+
+						best_off = i - (opt[cur].mlen != 1);
+						if (mlen > best_mlen)
+							best_mlen = mlen;
+
+						do {
+							if (opt[cur].mlen == 1) {
+								litlen = opt[cur].litlen;
+								if (cur > litlen) {
+									price = opt[cur - litlen].price + ZSTD_getPrice(seqStorePtr, litlen, inr - litlen,
+															best_off, mlen - MINMATCH, ultra);
+								} else
+									price = ZSTD_getPrice(seqStorePtr, litlen, anchor, best_off, mlen - MINMATCH, ultra);
+							} else {
+								litlen = 0;
+								price = opt[cur].price + ZSTD_getPrice(seqStorePtr, 0, NULL, best_off, mlen - MINMATCH, ultra);
+							}
+
+							if (cur + mlen > last_pos || price <= opt[cur + mlen].price)
+								SET_PRICE(cur + mlen, mlen, i, litlen, price);
+							mlen--;
+						} while (mlen >= minMatch);
+					}
+				}
+			}
+
+			match_num = ZSTD_BtGetAllMatches_selectMLS(ctx, inr, iend, maxSearches, mls, matches, best_mlen);
+
+			if (match_num > 0 && (matches[match_num - 1].len > sufficient_len || cur + matches[match_num - 1].len >= ZSTD_OPT_NUM)) {
+				best_mlen = matches[match_num - 1].len;
+				best_off = matches[match_num - 1].off;
+				last_pos = cur + 1;
+				goto _storeSequence;
+			}
+
+			/* set prices using matches at position = cur */
+			for (u = 0; u < match_num; u++) {
+				mlen = (u > 0) ? matches[u - 1].len + 1 : best_mlen;
+				best_mlen = matches[u].len;
+
+				while (mlen <= best_mlen) {
+					if (opt[cur].mlen == 1) {
+						litlen = opt[cur].litlen;
+						if (cur > litlen)
+							price = opt[cur - litlen].price + ZSTD_getPrice(seqStorePtr, litlen, ip + cur - litlen,
+													matches[u].off - 1, mlen - MINMATCH, ultra);
+						else
+							price = ZSTD_getPrice(seqStorePtr, litlen, anchor, matches[u].off - 1, mlen - MINMATCH, ultra);
+					} else {
+						litlen = 0;
+						price = opt[cur].price + ZSTD_getPrice(seqStorePtr, 0, NULL, matches[u].off - 1, mlen - MINMATCH, ultra);
+					}
+
+					if (cur + mlen > last_pos || (price < opt[cur + mlen].price))
+						SET_PRICE(cur + mlen, mlen, matches[u].off, litlen, price);
+
+					mlen++;
+				}
+			}
+		}
+
+		best_mlen = opt[last_pos].mlen;
+		best_off = opt[last_pos].off;
+		cur = last_pos - best_mlen;
+
+	/* store sequence */
+_storeSequence: /* cur, last_pos, best_mlen, best_off have to be set */
+		opt[0].mlen = 1;
+
+		while (1) {
+			mlen = opt[cur].mlen;
+			offset = opt[cur].off;
+			opt[cur].mlen = best_mlen;
+			opt[cur].off = best_off;
+			best_mlen = mlen;
+			best_off = offset;
+			if (mlen > cur)
+				break;
+			cur -= mlen;
+		}
+
+		for (u = 0; u <= last_pos;) {
+			u += opt[u].mlen;
+		}
+
+		for (cur = 0; cur < last_pos;) {
+			mlen = opt[cur].mlen;
+			if (mlen == 1) {
+				ip++;
+				cur++;
+				continue;
+			}
+			offset = opt[cur].off;
+			cur += mlen;
+			litLength = (U32)(ip - anchor);
+
+			if (offset > ZSTD_REP_MOVE_OPT) {
+				rep[2] = rep[1];
+				rep[1] = rep[0];
+				rep[0] = offset - ZSTD_REP_MOVE_OPT;
+				offset--;
+			} else {
+				if (offset != 0) {
+					best_off = (offset == ZSTD_REP_MOVE_OPT) ? (rep[0] - 1) : (rep[offset]);
+					if (offset != 1)
+						rep[2] = rep[1];
+					rep[1] = rep[0];
+					rep[0] = best_off;
+				}
+				if (litLength == 0)
+					offset--;
+			}
+
+			ZSTD_updatePrice(seqStorePtr, litLength, anchor, offset, mlen - MINMATCH);
+			ZSTD_storeSeq(seqStorePtr, litLength, anchor, offset, mlen - MINMATCH);
+			anchor = ip = ip + mlen;
+		}
+	} /* for (cur=0; cur < last_pos; ) */
+
+	/* Save reps for next block */
+	{
+		int i;
+		for (i = 0; i < ZSTD_REP_NUM; i++)
+			ctx->repToConfirm[i] = rep[i];
+	}
+
+	/* Last Literals */
+	{
+		size_t const lastLLSize = iend - anchor;
+		memcpy(seqStorePtr->lit, anchor, lastLLSize);
+		seqStorePtr->lit += lastLLSize;
+	}
+}
+
+FORCE_INLINE
+void ZSTD_compressBlock_opt_extDict_generic(ZSTD_CCtx *ctx, const void *src, size_t srcSize, const int ultra)
+{
+	seqStore_t *seqStorePtr = &(ctx->seqStore);
+	const BYTE *const istart = (const BYTE *)src;
+	const BYTE *ip = istart;
+	const BYTE *anchor = istart;
+	const BYTE *const iend = istart + srcSize;
+	const BYTE *const ilimit = iend - 8;
+	const BYTE *const base = ctx->base;
+	const U32 lowestIndex = ctx->lowLimit;
+	const U32 dictLimit = ctx->dictLimit;
+	const BYTE *const prefixStart = base + dictLimit;
+	const BYTE *const dictBase = ctx->dictBase;
+	const BYTE *const dictEnd = dictBase + dictLimit;
+
+	const U32 maxSearches = 1U << ctx->params.cParams.searchLog;
+	const U32 sufficient_len = ctx->params.cParams.targetLength;
+	const U32 mls = ctx->params.cParams.searchLength;
+	const U32 minMatch = (ctx->params.cParams.searchLength == 3) ? 3 : 4;
+
+	ZSTD_optimal_t *opt = seqStorePtr->priceTable;
+	ZSTD_match_t *matches = seqStorePtr->matchTable;
+	const BYTE *inr;
+
+	/* init */
+	U32 offset, rep[ZSTD_REP_NUM];
+	{
+		U32 i;
+		for (i = 0; i < ZSTD_REP_NUM; i++)
+			rep[i] = ctx->rep[i];
+	}
+
+	ctx->nextToUpdate3 = ctx->nextToUpdate;
+	ZSTD_rescaleFreqs(seqStorePtr, (const BYTE *)src, srcSize);
+	ip += (ip == prefixStart);
+
+	/* Match Loop */
+	while (ip < ilimit) {
+		U32 cur, match_num, last_pos, litlen, price;
+		U32 u, mlen, best_mlen, best_off, litLength;
+		U32 curr = (U32)(ip - base);
+		memset(opt, 0, sizeof(ZSTD_optimal_t));
+		last_pos = 0;
+		opt[0].litlen = (U32)(ip - anchor);
+
+		/* check repCode */
+		{
+			U32 i, last_i = ZSTD_REP_CHECK + (ip == anchor);
+			for (i = (ip == anchor); i < last_i; i++) {
+				const S32 repCur = (i == ZSTD_REP_MOVE_OPT) ? (rep[0] - 1) : rep[i];
+				const U32 repIndex = (U32)(curr - repCur);
+				const BYTE *const repBase = repIndex < dictLimit ? dictBase : base;
+				const BYTE *const repMatch = repBase + repIndex;
+				if ((repCur > 0 && repCur <= (S32)curr) &&
+				    (((U32)((dictLimit - 1) - repIndex) >= 3) & (repIndex > lowestIndex)) /* intentional overflow */
+				    && (ZSTD_readMINMATCH(ip, minMatch) == ZSTD_readMINMATCH(repMatch, minMatch))) {
+					/* repcode detected we should take it */
+					const BYTE *const repEnd = repIndex < dictLimit ? dictEnd : iend;
+					mlen = (U32)ZSTD_count_2segments(ip + minMatch, repMatch + minMatch, iend, repEnd, prefixStart) + minMatch;
+
+					if (mlen > sufficient_len || mlen >= ZSTD_OPT_NUM) {
+						best_mlen = mlen;
+						best_off = i;
+						cur = 0;
+						last_pos = 1;
+						goto _storeSequence;
+					}
+
+					best_off = i - (ip == anchor);
+					litlen = opt[0].litlen;
+					do {
+						price = ZSTD_getPrice(seqStorePtr, litlen, anchor, best_off, mlen - MINMATCH, ultra);
+						if (mlen > last_pos || price < opt[mlen].price)
+							SET_PRICE(mlen, mlen, i, litlen, price); /* note : macro modifies last_pos */
+						mlen--;
+					} while (mlen >= minMatch);
+				}
+			}
+		}
+
+		match_num = ZSTD_BtGetAllMatches_selectMLS_extDict(ctx, ip, iend, maxSearches, mls, matches, minMatch); /* first search (depth 0) */
+
+		if (!last_pos && !match_num) {
+			ip++;
+			continue;
+		}
+
+		{
+			U32 i;
+			for (i = 0; i < ZSTD_REP_NUM; i++)
+				opt[0].rep[i] = rep[i];
+		}
+		opt[0].mlen = 1;
+
+		if (match_num && (matches[match_num - 1].len > sufficient_len || matches[match_num - 1].len >= ZSTD_OPT_NUM)) {
+			best_mlen = matches[match_num - 1].len;
+			best_off = matches[match_num - 1].off;
+			cur = 0;
+			last_pos = 1;
+			goto _storeSequence;
+		}
+
+		best_mlen = (last_pos) ? last_pos : minMatch;
+
+		/* set prices using matches at position = 0 */
+		for (u = 0; u < match_num; u++) {
+			mlen = (u > 0) ? matches[u - 1].len + 1 : best_mlen;
+			best_mlen = matches[u].len;
+			litlen = opt[0].litlen;
+			while (mlen <= best_mlen) {
+				price = ZSTD_getPrice(seqStorePtr, litlen, anchor, matches[u].off - 1, mlen - MINMATCH, ultra);
+				if (mlen > last_pos || price < opt[mlen].price)
+					SET_PRICE(mlen, mlen, matches[u].off, litlen, price);
+				mlen++;
+			}
+		}
+
+		if (last_pos < minMatch) {
+			ip++;
+			continue;
+		}
+
+		/* check further positions */
+		for (cur = 1; cur <= last_pos; cur++) {
+			inr = ip + cur;
+
+			if (opt[cur - 1].mlen == 1) {
+				litlen = opt[cur - 1].litlen + 1;
+				if (cur > litlen) {
+					price = opt[cur - litlen].price + ZSTD_getLiteralPrice(seqStorePtr, litlen, inr - litlen);
+				} else
+					price = ZSTD_getLiteralPrice(seqStorePtr, litlen, anchor);
+			} else {
+				litlen = 1;
+				price = opt[cur - 1].price + ZSTD_getLiteralPrice(seqStorePtr, litlen, inr - 1);
+			}
+
+			if (cur > last_pos || price <= opt[cur].price)
+				SET_PRICE(cur, 1, 0, litlen, price);
+
+			if (cur == last_pos)
+				break;
+
+			if (inr > ilimit) /* last match must start at a minimum distance of 8 from oend */
+				continue;
+
+			mlen = opt[cur].mlen;
+			if (opt[cur].off > ZSTD_REP_MOVE_OPT) {
+				opt[cur].rep[2] = opt[cur - mlen].rep[1];
+				opt[cur].rep[1] = opt[cur - mlen].rep[0];
+				opt[cur].rep[0] = opt[cur].off - ZSTD_REP_MOVE_OPT;
+			} else {
+				opt[cur].rep[2] = (opt[cur].off > 1) ? opt[cur - mlen].rep[1] : opt[cur - mlen].rep[2];
+				opt[cur].rep[1] = (opt[cur].off > 0) ? opt[cur - mlen].rep[0] : opt[cur - mlen].rep[1];
+				opt[cur].rep[0] =
+				    ((opt[cur].off == ZSTD_REP_MOVE_OPT) && (mlen != 1)) ? (opt[cur - mlen].rep[0] - 1) : (opt[cur - mlen].rep[opt[cur].off]);
+			}
+
+			best_mlen = minMatch;
+			{
+				U32 i, last_i = ZSTD_REP_CHECK + (mlen != 1);
+				for (i = (mlen != 1); i < last_i; i++) {
+					const S32 repCur = (i == ZSTD_REP_MOVE_OPT) ? (opt[cur].rep[0] - 1) : opt[cur].rep[i];
+					const U32 repIndex = (U32)(curr + cur - repCur);
+					const BYTE *const repBase = repIndex < dictLimit ? dictBase : base;
+					const BYTE *const repMatch = repBase + repIndex;
+					if ((repCur > 0 && repCur <= (S32)(curr + cur)) &&
+					    (((U32)((dictLimit - 1) - repIndex) >= 3) & (repIndex > lowestIndex)) /* intentional overflow */
+					    && (ZSTD_readMINMATCH(inr, minMatch) == ZSTD_readMINMATCH(repMatch, minMatch))) {
+						/* repcode detected */
+						const BYTE *const repEnd = repIndex < dictLimit ? dictEnd : iend;
+						mlen = (U32)ZSTD_count_2segments(inr + minMatch, repMatch + minMatch, iend, repEnd, prefixStart) + minMatch;
+
+						if (mlen > sufficient_len || cur + mlen >= ZSTD_OPT_NUM) {
+							best_mlen = mlen;
+							best_off = i;
+							last_pos = cur + 1;
+							goto _storeSequence;
+						}
+
+						best_off = i - (opt[cur].mlen != 1);
+						if (mlen > best_mlen)
+							best_mlen = mlen;
+
+						do {
+							if (opt[cur].mlen == 1) {
+								litlen = opt[cur].litlen;
+								if (cur > litlen) {
+									price = opt[cur - litlen].price + ZSTD_getPrice(seqStorePtr, litlen, inr - litlen,
+															best_off, mlen - MINMATCH, ultra);
+								} else
+									price = ZSTD_getPrice(seqStorePtr, litlen, anchor, best_off, mlen - MINMATCH, ultra);
+							} else {
+								litlen = 0;
+								price = opt[cur].price + ZSTD_getPrice(seqStorePtr, 0, NULL, best_off, mlen - MINMATCH, ultra);
+							}
+
+							if (cur + mlen > last_pos || price <= opt[cur + mlen].price)
+								SET_PRICE(cur + mlen, mlen, i, litlen, price);
+							mlen--;
+						} while (mlen >= minMatch);
+					}
+				}
+			}
+
+			match_num = ZSTD_BtGetAllMatches_selectMLS_extDict(ctx, inr, iend, maxSearches, mls, matches, minMatch);
+
+			if (match_num > 0 && (matches[match_num - 1].len > sufficient_len || cur + matches[match_num - 1].len >= ZSTD_OPT_NUM)) {
+				best_mlen = matches[match_num - 1].len;
+				best_off = matches[match_num - 1].off;
+				last_pos = cur + 1;
+				goto _storeSequence;
+			}
+
+			/* set prices using matches at position = cur */
+			for (u = 0; u < match_num; u++) {
+				mlen = (u > 0) ? matches[u - 1].len + 1 : best_mlen;
+				best_mlen = matches[u].len;
+
+				while (mlen <= best_mlen) {
+					if (opt[cur].mlen == 1) {
+						litlen = opt[cur].litlen;
+						if (cur > litlen)
+							price = opt[cur - litlen].price + ZSTD_getPrice(seqStorePtr, litlen, ip + cur - litlen,
+													matches[u].off - 1, mlen - MINMATCH, ultra);
+						else
+							price = ZSTD_getPrice(seqStorePtr, litlen, anchor, matches[u].off - 1, mlen - MINMATCH, ultra);
+					} else {
+						litlen = 0;
+						price = opt[cur].price + ZSTD_getPrice(seqStorePtr, 0, NULL, matches[u].off - 1, mlen - MINMATCH, ultra);
+					}
+
+					if (cur + mlen > last_pos || (price < opt[cur + mlen].price))
+						SET_PRICE(cur + mlen, mlen, matches[u].off, litlen, price);
+
+					mlen++;
+				}
+			}
+		} /* for (cur = 1; cur <= last_pos; cur++) */
+
+		best_mlen = opt[last_pos].mlen;
+		best_off = opt[last_pos].off;
+		cur = last_pos - best_mlen;
+
+	/* store sequence */
+_storeSequence: /* cur, last_pos, best_mlen, best_off have to be set */
+		opt[0].mlen = 1;
+
+		while (1) {
+			mlen = opt[cur].mlen;
+			offset = opt[cur].off;
+			opt[cur].mlen = best_mlen;
+			opt[cur].off = best_off;
+			best_mlen = mlen;
+			best_off = offset;
+			if (mlen > cur)
+				break;
+			cur -= mlen;
+		}
+
+		for (u = 0; u <= last_pos;) {
+			u += opt[u].mlen;
+		}
+
+		for (cur = 0; cur < last_pos;) {
+			mlen = opt[cur].mlen;
+			if (mlen == 1) {
+				ip++;
+				cur++;
+				continue;
+			}
+			offset = opt[cur].off;
+			cur += mlen;
+			litLength = (U32)(ip - anchor);
+
+			if (offset > ZSTD_REP_MOVE_OPT) {
+				rep[2] = rep[1];
+				rep[1] = rep[0];
+				rep[0] = offset - ZSTD_REP_MOVE_OPT;
+				offset--;
+			} else {
+				if (offset != 0) {
+					best_off = (offset == ZSTD_REP_MOVE_OPT) ? (rep[0] - 1) : (rep[offset]);
+					if (offset != 1)
+						rep[2] = rep[1];
+					rep[1] = rep[0];
+					rep[0] = best_off;
+				}
+
+				if (litLength == 0)
+					offset--;
+			}
+
+			ZSTD_updatePrice(seqStorePtr, litLength, anchor, offset, mlen - MINMATCH);
+			ZSTD_storeSeq(seqStorePtr, litLength, anchor, offset, mlen - MINMATCH);
+			anchor = ip = ip + mlen;
+		}
+	} /* for (cur=0; cur < last_pos; ) */
+
+	/* Save reps for next block */
+	{
+		int i;
+		for (i = 0; i < ZSTD_REP_NUM; i++)
+			ctx->repToConfirm[i] = rep[i];
+	}
+
+	/* Last Literals */
+	{
+		size_t lastLLSize = iend - anchor;
+		memcpy(seqStorePtr->lit, anchor, lastLLSize);
+		seqStorePtr->lit += lastLLSize;
+	}
+}
+
+#endif /* ZSTD_OPT_H_91842398743 */
diff -Naurp -x debian.hwe linux-4.10.x.ori/net/core/ethtool.c linux-4.10.x/net/core/ethtool.c
--- linux-4.10.x.ori/net/core/ethtool.c	2017-07-11 13:26:26.551117000 +0200
+++ linux-4.10.x/net/core/ethtool.c	2017-07-11 13:26:26.551117000 +0200
@@ -2581,6 +2581,10 @@ int dev_ethtool(struct net *net, struct
 		if (!ns_capable(net->user_ns, CAP_NET_ADMIN))
 			return -EPERM;
 	}
+	
+	if (!dev->ethtool_ops) {
+		return -EOPNOTSUPP;
+	}
 
 	if (dev->ethtool_ops->begin) {
 		rc = dev->ethtool_ops->begin(dev);
diff -Naurp -x debian.hwe linux-4.10.x.ori/net/rfkill/rfkill-gpio.c linux-4.10.x/net/rfkill/rfkill-gpio.c
--- linux-4.10.x.ori/net/rfkill/rfkill-gpio.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/net/rfkill/rfkill-gpio.c	2017-10-09 08:43:16.840263000 +0200
@@ -161,6 +161,7 @@ static int rfkill_gpio_remove(struct pla
 
 #ifdef CONFIG_ACPI
 static const struct acpi_device_id rfkill_acpi_match[] = {
+	{ "OBDA8723", RFKILL_TYPE_BLUETOOTH },
 	{ "BCM4752", RFKILL_TYPE_GPS },
 	{ "LNV4752", RFKILL_TYPE_GPS },
 	{ },
diff -Naurp -x debian.hwe linux-4.10.x.ori/scripts/mkcompile_h linux-4.10.x/scripts/mkcompile_h
--- linux-4.10.x.ori/scripts/mkcompile_h	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/scripts/mkcompile_h	2017-04-10 11:27:25.836919000 +0200
@@ -37,18 +37,20 @@ else
 	VERSION=$KBUILD_BUILD_VERSION
 fi
 
+# lang@igel.de: use shorter timestamps, use IGEL as build user 
+# and ITGA as build host
 if [ -z "$KBUILD_BUILD_TIMESTAMP" ]; then
-	TIMESTAMP=`date`
+	TIMESTAMP=`date -u +"%F %R %Z"`
 else
 	TIMESTAMP=$KBUILD_BUILD_TIMESTAMP
 fi
 if test -z "$KBUILD_BUILD_USER"; then
-	LINUX_COMPILE_BY=$(whoami | sed 's/\\/\\\\/')
+	LINUX_COMPILE_BY="IGEL"
 else
 	LINUX_COMPILE_BY=$KBUILD_BUILD_USER
 fi
 if test -z "$KBUILD_BUILD_HOST"; then
-	LINUX_COMPILE_HOST=`hostname`
+	LINUX_COMPILE_HOST="ITGA"
 else
 	LINUX_COMPILE_HOST=$KBUILD_BUILD_HOST
 fi
diff -Naurp -x debian.hwe linux-4.10.x.ori/scripts/setlocalversion linux-4.10.x/scripts/setlocalversion
--- linux-4.10.x.ori/scripts/setlocalversion	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/scripts/setlocalversion	2017-04-10 11:27:25.836919000 +0200
@@ -157,18 +157,19 @@ fi
 res="${res}${CONFIG_LOCALVERSION}${LOCALVERSION}"
 
 # scm version string if not at a tagged commit
-if test "$CONFIG_LOCALVERSION_AUTO" = "y"; then
-	# full scm version string
-	res="$res$(scm_version)"
-else
+# lang@igel.de: do not change the version string
+#if test "$CONFIG_LOCALVERSION_AUTO" = "y"; then
+#	# full scm version string
+#	res="$res$(scm_version)"
+#else
 	# append a plus sign if the repository is not in a clean
 	# annotated or signed tagged state (as git describe only
 	# looks at signed or annotated tags - git tag -a/-s) and
 	# LOCALVERSION= is not specified
-	if test "${LOCALVERSION+set}" != "set"; then
-		scm=$(scm_version --short)
-		res="$res${scm:++}"
-	fi
-fi
+#	if test "${LOCALVERSION+set}" != "set"; then
+#		scm=$(scm_version --short)
+#		res="$res${scm:++}"
+#	fi
+#fi
 
 echo "$res"
diff -Naurp -x debian.hwe linux-4.10.x.ori/sound/core/jack.c linux-4.10.x/sound/core/jack.c
--- linux-4.10.x.ori/sound/core/jack.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/sound/core/jack.c	2017-04-10 11:27:25.836919000 +0200
@@ -26,11 +26,15 @@
 #include <sound/core.h>
 #include <sound/control.h>
 
+/* gottwald@igel.com moved to include/sound/jack.h because struct is also
+ * needed by sound/pci/hda/patch_realtek.c */
+#if 0
 struct snd_jack_kctl {
 	struct snd_kcontrol *kctl;
 	struct list_head list;  /* list of controls belong to the same jack */
 	unsigned int mask_bits; /* only masked status bits are reported via kctl */
 };
+#endif
 
 #ifdef CONFIG_SND_JACK_INPUT_DEV
 static int jack_switch_types[SND_JACK_SWITCH_TYPES] = {
diff -Naurp -x debian.hwe linux-4.10.x.ori/sound/Kconfig linux-4.10.x/sound/Kconfig
--- linux-4.10.x.ori/sound/Kconfig	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/sound/Kconfig	2017-04-21 17:01:32.706015000 +0200
@@ -108,6 +108,8 @@ source "sound/parisc/Kconfig"
 
 source "sound/soc/Kconfig"
 
+source "sound/x86/Kconfig"
+
 endif # SND
 
 menuconfig SOUND_PRIME
diff -Naurp -x debian.hwe linux-4.10.x.ori/sound/Makefile linux-4.10.x/sound/Makefile
--- linux-4.10.x.ori/sound/Makefile	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/sound/Makefile	2017-04-21 17:01:32.706015000 +0200
@@ -5,7 +5,7 @@ obj-$(CONFIG_SOUND) += soundcore.o
 obj-$(CONFIG_SOUND_PRIME) += oss/
 obj-$(CONFIG_DMASOUND) += oss/
 obj-$(CONFIG_SND) += core/ i2c/ drivers/ isa/ pci/ ppc/ arm/ sh/ synth/ usb/ \
-	firewire/ sparc/ spi/ parisc/ pcmcia/ mips/ soc/ atmel/ hda/
+	firewire/ sparc/ spi/ parisc/ pcmcia/ mips/ soc/ atmel/ hda/ x86/
 obj-$(CONFIG_SND_AOA) += aoa/
 
 # This one must be compilable even if sound is configured out
diff -Naurp -x debian.hwe linux-4.10.x.ori/sound/pci/hda/patch_realtek.c linux-4.10.x/sound/pci/hda/patch_realtek.c
--- linux-4.10.x.ori/sound/pci/hda/patch_realtek.c	2017-05-03 11:18:05.164927000 +0200
+++ linux-4.10.x/sound/pci/hda/patch_realtek.c	2017-10-10 16:54:55.906531000 +0200
@@ -337,6 +337,7 @@ static void alc_fill_eapd_coef(struct hd
 	case 0x10ec0288:
 	case 0x10ec0295:
 	case 0x10ec0298:
+	case 0x10ec0299:
 		alc_update_coef_idx(codec, 0x10, 1<<9, 0);
 		break;
 	case 0x10ec0285:
@@ -912,6 +913,7 @@ static struct alc_codec_rename_pci_table
 	{ 0x10ec0256, 0x1028, 0, "ALC3246" },
 	{ 0x10ec0225, 0x1028, 0, "ALC3253" },
 	{ 0x10ec0295, 0x1028, 0, "ALC3254" },
+	{ 0x10ec0299, 0x1028, 0, "ALC3271" },
 	{ 0x10ec0670, 0x1025, 0, "ALC669X" },
 	{ 0x10ec0676, 0x1025, 0, "ALC679X" },
 	{ 0x10ec0282, 0x1043, 0, "ALC3229" },
@@ -3717,6 +3719,7 @@ static void alc_headset_mode_unplugged(s
 		break;
 	case 0x10ec0225:
 	case 0x10ec0295:
+	case 0x10ec0299:
 		alc_process_coef_fw(codec, coef0225);
 		break;
 	case 0x10ec0867:
@@ -3824,6 +3827,7 @@ static void alc_headset_mode_mic_in(stru
 		break;
 	case 0x10ec0225:
 	case 0x10ec0295:
+	case 0x10ec0299:
 		alc_update_coef_idx(codec, 0x45, 0x3f<<10, 0x31<<10);
 		snd_hda_set_pin_ctl_cache(codec, hp_pin, 0);
 		alc_process_coef_fw(codec, coef0225);
@@ -3882,6 +3886,7 @@ static void alc_headset_mode_default(str
 	switch (codec->core.vendor_id) {
 	case 0x10ec0225:
 	case 0x10ec0295:
+	case 0x10ec0299:
 		alc_process_coef_fw(codec, coef0225);
 		break;
 	case 0x10ec0255:
@@ -3997,6 +4002,7 @@ static void alc_headset_mode_ctia(struct
 		break;
 	case 0x10ec0225:
 	case 0x10ec0295:
+	case 0x10ec0299:
 		alc_process_coef_fw(codec, coef0225);
 		break;
 	case 0x10ec0867:
@@ -4090,6 +4096,7 @@ static void alc_headset_mode_omtp(struct
 		break;
 	case 0x10ec0225:
 	case 0x10ec0295:
+	case 0x10ec0299:
 		alc_process_coef_fw(codec, coef0225);
 		break;
 	}
@@ -4174,6 +4181,7 @@ static void alc_determine_headset_type(s
 		break;
 	case 0x10ec0225:
 	case 0x10ec0295:
+	case 0x10ec0299:
 		alc_process_coef_fw(codec, coef0225);
 		msleep(800);
 		val = alc_read_coef_idx(codec, 0x46);
@@ -4755,6 +4763,49 @@ static void alc280_fixup_hp_9480m(struct
 	}
 }
 
+static void alc_rename_ctl(struct hda_codec *codec, unsigned int nid, 
+		const char *name, const char *new_name)
+{
+	int i;
+	struct hda_nid_item *items = codec->mixers.list;
+
+	for (i = 0; i < codec->mixers.used; i++) {
+		if (items[i].nid == nid && !strcmp(items[i].kctl->id.name, name)) {
+			strcpy(items[i].kctl->id.name, new_name);
+			break;
+		}
+	}	
+}	
+
+static void alc_rename_jack(struct hda_codec *codec, unsigned int nid, 
+		const char *name, const char *new_name)
+{
+	struct hda_jack_tbl *j;
+	struct snd_jack_kctl *jack_kctl, *tmp_jack_kctl;
+
+	j = snd_hda_jack_tbl_get(codec, nid);
+	if (NULL != j && NULL != j->jack) {
+		list_for_each_entry_safe(jack_kctl, 
+				tmp_jack_kctl, &(j->jack->kctl_list), list) 
+		{
+			if (!strcmp(jack_kctl->kctl->id.name, name)) {
+				strcpy(jack_kctl->kctl->id.name, new_name);
+			}
+		}
+	}
+}
+
+/* hamburg@igel.com */
+static void alc233_fixup_lenovo_m600(struct hda_codec *codec, 
+		const struct hda_fixup *fix, int action)
+{
+	if (HDA_FIXUP_ACT_BUILD == action) {
+		/* rename double */
+		alc_rename_jack(codec, 0x19, 
+				"Mic Jack", "Headset Mic Jack");
+	}
+}	
+
 /* for hda_fixup_thinkpad_acpi() */
 #include "thinkpad_helper.c"
 
@@ -4858,6 +4909,7 @@ enum {
 	ALC292_FIXUP_TPT460,
 	ALC298_FIXUP_SPK_VOLUME,
 	ALC256_FIXUP_DELL_INSPIRON_7559_SUBWOOFER,
+	ALC233_FIXUP_LENOVO_M600,
 };
 
 static const struct hda_fixup alc269_fixups[] = {
@@ -5539,6 +5591,11 @@ static const struct hda_fixup alc269_fix
 		.chained = true,
 		.chain_id = ALC255_FIXUP_DELL1_MIC_NO_PRESENCE
 	},
+	/* hamburg@igel.com */
+	[ALC233_FIXUP_LENOVO_M600] = {
+		.type = HDA_FIXUP_FUNC,
+		.v.func = alc233_fixup_lenovo_m600
+	},
 };
 
 static const struct snd_pci_quirk alc269_fixup_tbl[] = {
@@ -5801,6 +5858,7 @@ static const struct hda_model_fixup alc2
 	{.id = ALC292_FIXUP_TPT440_DOCK, .name = "tpt440-dock"},
 	{.id = ALC292_FIXUP_TPT440, .name = "tpt440"},
 	{.id = ALC292_FIXUP_TPT460, .name = "tpt460"},
+	{.id = ALC233_FIXUP_LENOVO_M600, .name = "lenovo-m600"},
 	{}
 };
 #define ALC225_STANDARD_PINS \
@@ -6232,6 +6290,7 @@ static int patch_alc269(struct hda_codec
 		break;
 	case 0x10ec0225:
 	case 0x10ec0295:
+	case 0x10ec0299:
 		spec->codec_variant = ALC269_TYPE_ALC225;
 		break;
 	case 0x10ec0234:
@@ -6638,6 +6697,101 @@ static void alc668_restore_default_value
 	alc_process_coef_fw(codec, alc668_coefs);
 }
 
+static void alc662_fixup_limit_mic_boost(struct hda_codec *codec,
+					     const struct hda_fixup *fix,
+					     int action)
+{
+		if (action != HDA_FIXUP_ACT_PROBE)
+		return;
+
+	/* The mic boosts on level 2 and 3 are too noisy
+	   on the internal mic input. Therefore limit the boost to 0 or 1. */
+	snd_hda_override_amp_caps(codec, 0x18, HDA_INPUT, 
+			(0x00 << AC_AMPCAP_OFFSET_SHIFT) | 
+			(0x01 << AC_AMPCAP_NUM_STEPS_SHIFT) | 
+			(0x2f << AC_AMPCAP_STEP_SIZE_SHIFT) | 
+			(0 << AC_AMPCAP_MUTE_SHIFT));
+
+	/* limit Mic Playback Volume to avoid noise in sound output */
+	snd_hda_override_amp_caps(codec, 0x0b, HDA_INPUT, 
+			(0x00 << AC_AMPCAP_OFFSET_SHIFT) | 
+			(0x14 << AC_AMPCAP_NUM_STEPS_SHIFT) | 
+			(0x02 << AC_AMPCAP_STEP_SIZE_SHIFT) | 
+			(0 << AC_AMPCAP_MUTE_SHIFT));
+}
+
+static void alc_fixup_igel_m340c_ctl(struct hda_codec *codec,
+		const struct hda_fixup *fix, int action)
+{
+	struct snd_kcontrol *kctl;
+	
+	if (action == HDA_FIXUP_ACT_BUILD) {
+		kctl = snd_hda_find_mixer_ctl(codec, "Speaker Playback Volume");
+		if (kctl) {
+			strcpy(kctl->id.name, "Alt Speaker Playback Volume");
+		}
+		kctl = snd_hda_find_mixer_ctl(codec, "Speaker Playback Switch");
+		if (kctl) {
+			strcpy(kctl->id.name, "Alt Speaker Playback Switch");
+		}
+
+		kctl = snd_hda_find_mixer_ctl(codec, "Headphone Playback Volume");
+		if (kctl) {
+			strcpy(kctl->id.name, "Speaker Playback Volume");
+		}
+		kctl = snd_hda_find_mixer_ctl(codec, "Headphone Playback Switch");
+		if (kctl) {
+			strcpy(kctl->id.name, "Speaker Playback Switch");
+		}
+	}	
+}	
+	
+/* hamburg@igel.com: rename speaker control */
+static void alc_fixup_igel_ud9_ctl(struct hda_codec *codec,
+		const struct hda_fixup *fix, int action)
+{
+	struct snd_kcontrol *kctl;
+
+	if (action == HDA_FIXUP_ACT_BUILD) {
+		/* ud9 with the new BIOS */
+		kctl = snd_hda_find_mixer_ctl(codec, "Front Playback Volume");
+		if (kctl) {
+			strcpy(kctl->id.name, "Speaker Playback Volume");
+		}
+		kctl = snd_hda_find_mixer_ctl(codec, "Front Playback Switch");
+		if (kctl) {
+			strcpy(kctl->id.name, "Speaker Playback Switch");
+		}
+
+		/* ud9 with the old BIOS */
+		kctl = snd_hda_find_mixer_ctl(codec, "Master Playback Volume");
+		if (kctl) {
+			strcpy(kctl->id.name, "PCM Playback Volume");
+		}	
+		kctl = snd_hda_find_mixer_ctl(codec, "Master Playback Switch");
+		if (kctl) {
+			strcpy(kctl->id.name, "PCM Playback Switch");
+		} 
+		alc_rename_ctl(codec, 0x09, "Capture Volume", "Alt Capture Volume");
+		alc_rename_ctl(codec, 0x09, "Capture Switch", "Alt Capture Switch");
+	}
+}
+	
+/* hamburg@igel.com */
+static void alc_fixup_igel_h830(struct hda_codec *codec,
+		const struct hda_fixup *fix, int action)
+{
+	if (HDA_FIXUP_ACT_BUILD == action) {
+		/* rename mixer control element for the line out on the rear side */
+		alc_rename_ctl(codec, 0x03, 
+				"PCM Playback Volume", "Headphone Playback Volume");
+		alc_rename_ctl(codec, 0x1b, 
+				"PCM Playback Switch", "Headphone Playback Switch");
+		alc_rename_jack(codec, 0x1b, 
+				"Line Out Jack", "Headphone Jack");
+	}
+}
+
 enum {
 	ALC662_FIXUP_ASPIRE,
 	ALC662_FIXUP_LED_GPIO1,
@@ -6676,6 +6830,11 @@ enum {
 	ALC892_FIXUP_ASROCK_MOBO,
 	ALC662_FIXUP_USI_FUNC,
 	ALC662_FIXUP_USI_HEADSET_MODE,
+	ALC662_FIXUP_IGEL_UD9,
+	ALC662_FIXUP_IGEL_UD9_CTL,
+	ALC662_FIXUP_LIMIT_MIC_BOOST,
+	ALC662_FIXUP_IGEL_H830,
+	ALC662_FIXUP_IGEL_M340C,
 };
 
 static const struct hda_fixup alc662_fixups[] = {
@@ -6974,6 +7133,40 @@ static const struct hda_fixup alc662_fix
 		.chained = true,
 		.chain_id = ALC662_FIXUP_USI_FUNC
 	},
+	/* hamburg@igel.com : fix line out in H830 */
+	[ALC662_FIXUP_IGEL_H830] = {
+		.type = HDA_FIXUP_FUNC,
+		.v.func = alc_fixup_igel_h830,
+		.chained = true,
+		.chain_id = ALC662_FIXUP_LIMIT_MIC_BOOST
+	},
+	/* hamburg@igel.com : fix EAPD in UD9 devices */
+	[ALC662_FIXUP_IGEL_UD9] = {
+		.type = HDA_FIXUP_VERBS,
+		.v.verbs = (const struct hda_verb[]) {
+			{0x14, AC_VERB_SET_EAPD_BTLENABLE, 0},
+			{}
+		},
+		.chained = true,
+		.chain_id = ALC662_FIXUP_IGEL_UD9_CTL
+	},
+	/* hamburg@igel.com : rename playback control: "Front" into "Speaker" 
+	 * in UD9 devices */
+	[ALC662_FIXUP_IGEL_UD9_CTL] = {
+		.type = HDA_FIXUP_FUNC,
+		.v.func = alc_fixup_igel_ud9_ctl,
+		.chained = true,
+		.chain_id = ALC662_FIXUP_LIMIT_MIC_BOOST
+	},
+	/* hamburg@igel.com : limit Mic Boost */
+	[ALC662_FIXUP_LIMIT_MIC_BOOST] = {
+		.type = HDA_FIXUP_FUNC,
+		.v.func = alc662_fixup_limit_mic_boost,
+	},	
+	[ALC662_FIXUP_IGEL_M340C] = {
+		.type = HDA_FIXUP_FUNC,
+		.v.func = alc_fixup_igel_m340c_ctl,
+	}
 };
 
 static const struct snd_pci_quirk alc662_fixup_tbl[] = {
@@ -7017,6 +7210,9 @@ static const struct snd_pci_quirk alc662
 	SND_PCI_QUIRK(0x19da, 0xa130, "Zotac Z68", ALC662_FIXUP_ZOTAC_Z68),
 	SND_PCI_QUIRK(0x1b0a, 0x01b8, "ACER Veriton", ALC662_FIXUP_ACER_VERITON),
 	SND_PCI_QUIRK(0x1b35, 0x2206, "CZC P10T", ALC662_FIXUP_CZC_P10T),
+	/* hamburg@igel.com: activate ALC662 fixes */
+	SND_PCI_QUIRK(0x8086, 0x27d8, "IGEL-UD9", ALC662_FIXUP_IGEL_UD9),
+	SND_PCI_QUIRK(0x8086, 0x7270, "IGEL-H830", ALC662_FIXUP_IGEL_H830),
 
 #if 0
 	/* Below is a quirk table taken from the old code.
@@ -7090,6 +7286,8 @@ static const struct hda_model_fixup alc6
 	{.id = ALC662_FIXUP_ASUS_MODE8, .name = "asus-mode8"},
 	{.id = ALC662_FIXUP_INV_DMIC, .name = "inv-dmic"},
 	{.id = ALC668_FIXUP_DELL_MIC_NO_PRESENCE, .name = "dell-headset-multi"},
+	{.id = ALC662_FIXUP_IGEL_UD9, .name = "igel-ud9"},
+	{.id = ALC662_FIXUP_IGEL_M340C, .name = "igel-m340c"},
 	{}
 };
 
@@ -7270,6 +7468,7 @@ static const struct hda_device_id snd_hd
 	HDA_CODEC_ENTRY(0x10ec0294, "ALC294", patch_alc269),
 	HDA_CODEC_ENTRY(0x10ec0295, "ALC295", patch_alc269),
 	HDA_CODEC_ENTRY(0x10ec0298, "ALC298", patch_alc269),
+	HDA_CODEC_ENTRY(0x10ec0299, "ALC299", patch_alc269),
 	HDA_CODEC_REV_ENTRY(0x10ec0861, 0x100340, "ALC660", patch_alc861),
 	HDA_CODEC_ENTRY(0x10ec0660, "ALC660-VD", patch_alc861vd),
 	HDA_CODEC_ENTRY(0x10ec0861, "ALC861", patch_alc861),
diff -Naurp -x debian.hwe linux-4.10.x.ori/sound/soc/intel/atom/sst/sst_acpi.c linux-4.10.x/sound/soc/intel/atom/sst/sst_acpi.c
--- linux-4.10.x.ori/sound/soc/intel/atom/sst/sst_acpi.c	2017-05-03 11:18:05.164927000 +0200
+++ linux-4.10.x/sound/soc/intel/atom/sst/sst_acpi.c	2017-06-30 12:01:40.556581000 +0200
@@ -420,9 +420,23 @@ static const struct dmi_system_id byt_ta
 		.callback = byt_thinkpad10_quirk_cb,
 		.matches = {
 			DMI_MATCH(DMI_SYS_VENDOR, "LENOVO"),
-			DMI_MATCH(DMI_PRODUCT_NAME, "20C3001VHH"),
+			DMI_MATCH(DMI_PRODUCT_VERSION, "ThinkPad 10"),
 		},
 	},
+        {
+                .callback = byt_thinkpad10_quirk_cb,
+                .matches = {
+                        DMI_MATCH(DMI_SYS_VENDOR, "LENOVO"),
+			DMI_MATCH(DMI_PRODUCT_VERSION, "ThinkPad Tablet B"),
+                },
+        },
+        {
+                .callback = byt_thinkpad10_quirk_cb,
+                .matches = {
+                        DMI_MATCH(DMI_SYS_VENDOR, "LENOVO"),
+			DMI_MATCH(DMI_PRODUCT_VERSION, "Lenovo Miix 2 10"),
+                },
+        },
 	{ }
 };
 
diff -Naurp -x debian.hwe linux-4.10.x.ori/sound/sound_core.c linux-4.10.x/sound/sound_core.c
--- linux-4.10.x.ori/sound/sound_core.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/sound/sound_core.c	2017-04-10 11:27:25.836919000 +0200
@@ -266,7 +266,13 @@ retry:
 	
 	if (r < 0)
 		goto fail;
-	else if (r < SOUND_STEP)
+	/* lang@igel: for the oss devices dsp/audio/mixer we want 
+	   a number "0" at the end of the device name, because we create 
+	   a device node link dsp -> dsp0 */
+	else if (r < SOUND_STEP &&
+		 strncmp(name, "dsp", 3) != 0 &&
+		 strncmp(name, "audio", 5) != 0 &&
+		 strncmp(name, "mixer", 5) != 0)
 		sprintf(s->name, "sound/%s", name);
 	else
 		sprintf(s->name, "sound/%s%d", name, r / SOUND_STEP);
diff -Naurp -x debian.hwe linux-4.10.x.ori/sound/usb/mixer.c linux-4.10.x/sound/usb/mixer.c
--- linux-4.10.x.ori/sound/usb/mixer.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/sound/usb/mixer.c	2017-04-10 11:27:25.836919000 +0200
@@ -1295,6 +1295,11 @@ static void build_feature_ctl(struct mix
 	if (!len && nameid)
 		len = snd_usb_copy_string_desc(state, nameid,
 				kctl->id.name, sizeof(kctl->id.name));
+	/* hamburg@igel.com fixed Sennheiser DW Pro2 headset: renamed control 
+	 * elements in FEATURE_UNIT of sidetone chain */
+	if (!len) {
+		len = snd_usb_mixer_control_name_apply_quirk(state->mixer, unitid, kctl);
+	}
 
 	switch (control) {
 	case UAC_FU_MUTE:
diff -Naurp -x debian.hwe linux-4.10.x.ori/sound/usb/mixer_quirks.c linux-4.10.x/sound/usb/mixer_quirks.c
--- linux-4.10.x.ori/sound/usb/mixer_quirks.c	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/sound/usb/mixer_quirks.c	2017-04-10 11:27:25.836919000 +0200
@@ -1876,3 +1876,23 @@ void snd_usb_mixer_fu_apply_quirk(struct
 	}
 }
 
+/* hamburg@igel.com fixed Sennheiser DW Pro2 headset: renamed control 
+ * elements in FEATURE_UNIT of sidetone chain */
+
+size_t snd_usb_mixer_control_name_apply_quirk(struct usb_mixer_interface *mixer, 
+		int unitid, struct snd_kcontrol *kctl)
+{
+	size_t len;
+
+	len = 0;
+
+	switch (mixer->chip->usb_id) {
+	case USB_ID(0x1395, 0x740a): /* Sennheiser DW Pro2 */
+		if (unitid == 6) {
+			len = strlcpy(kctl->id.name, "Sidetone", sizeof(kctl->id.name));
+		}
+		break;
+	}
+
+	return (len);
+}
diff -Naurp -x debian.hwe linux-4.10.x.ori/sound/usb/mixer_quirks.h linux-4.10.x/sound/usb/mixer_quirks.h
--- linux-4.10.x.ori/sound/usb/mixer_quirks.h	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/sound/usb/mixer_quirks.h	2017-04-10 11:27:25.836919000 +0200
@@ -13,5 +13,9 @@ void snd_usb_mixer_fu_apply_quirk(struct
 				  struct usb_mixer_elem_info *cval, int unitid,
 				  struct snd_kcontrol *kctl);
 
+/* hamburg@igel.com fixed Sennheiser DW Pro2 headset: renamed control 
+ * elements in FEATURE_UNIT of sidetone chain */
+size_t snd_usb_mixer_control_name_apply_quirk(struct usb_mixer_interface *mixer, 
+		int unitid, struct snd_kcontrol *kctl);
 #endif /* SND_USB_MIXER_QUIRKS_H */
 
diff -Naurp -x debian.hwe linux-4.10.x.ori/sound/x86/intel_hdmi_audio.c linux-4.10.x/sound/x86/intel_hdmi_audio.c
--- linux-4.10.x.ori/sound/x86/intel_hdmi_audio.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-4.10.x/sound/x86/intel_hdmi_audio.c	2017-04-21 17:01:32.706015000 +0200
@@ -0,0 +1,1932 @@
+/*
+ *   intel_hdmi_audio.c - Intel HDMI audio driver
+ *
+ *  Copyright (C) 2016 Intel Corp
+ *  Authors:	Sailaja Bandarupalli <sailaja.bandarupalli@intel.com>
+ *		Ramesh Babu K V	<ramesh.babu@intel.com>
+ *		Vaibhav Agarwal <vaibhav.agarwal@intel.com>
+ *		Jerome Anand <jerome.anand@intel.com>
+ *  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+ *
+ *  This program is free software; you can redistribute it and/or modify
+ *  it under the terms of the GNU General Public License as published by
+ *  the Free Software Foundation; version 2 of the License.
+ *
+ *  This program is distributed in the hope that it will be useful, but
+ *  WITHOUT ANY WARRANTY; without even the implied warranty of
+ *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ *  General Public License for more details.
+ *
+ * ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+ * ALSA driver for Intel HDMI audio
+ */
+
+#define pr_fmt(fmt)	"had: " fmt
+
+#include <linux/platform_device.h>
+#include <linux/io.h>
+#include <linux/slab.h>
+#include <linux/module.h>
+#include <linux/acpi.h>
+#include <asm/cacheflush.h>
+#include <sound/pcm.h>
+#include <sound/core.h>
+#include <sound/pcm_params.h>
+#include <sound/initval.h>
+#include <sound/control.h>
+#include <sound/initval.h>
+#include "intel_hdmi_audio.h"
+
+static DEFINE_MUTEX(had_mutex);
+
+/*standard module options for ALSA. This module supports only one card*/
+static int hdmi_card_index = SNDRV_DEFAULT_IDX1;
+static char *hdmi_card_id = SNDRV_DEFAULT_STR1;
+static struct snd_intelhad *had_data;
+static int underrun_count;
+
+module_param_named(index, hdmi_card_index, int, 0444);
+MODULE_PARM_DESC(index,
+		"Index value for INTEL Intel HDMI Audio controller.");
+module_param_named(id, hdmi_card_id, charp, 0444);
+MODULE_PARM_DESC(id,
+		"ID string for INTEL Intel HDMI Audio controller.");
+
+/*
+ * ELD SA bits in the CEA Speaker Allocation data block
+*/
+static int eld_speaker_allocation_bits[] = {
+	[0] = FL | FR,
+	[1] = LFE,
+	[2] = FC,
+	[3] = RL | RR,
+	[4] = RC,
+	[5] = FLC | FRC,
+	[6] = RLC | RRC,
+	/* the following are not defined in ELD yet */
+	[7] = 0,
+};
+
+/*
+ * This is an ordered list!
+ *
+ * The preceding ones have better chances to be selected by
+ * hdmi_channel_allocation().
+ */
+static struct cea_channel_speaker_allocation channel_allocations[] = {
+/*                        channel:   7     6    5    4    3     2    1    0  */
+{ .ca_index = 0x00,  .speakers = {   0,    0,   0,   0,   0,    0,  FR,  FL } },
+				/* 2.1 */
+{ .ca_index = 0x01,  .speakers = {   0,    0,   0,   0,   0,  LFE,  FR,  FL } },
+				/* Dolby Surround */
+{ .ca_index = 0x02,  .speakers = {   0,    0,   0,   0,  FC,    0,  FR,  FL } },
+				/* surround40 */
+{ .ca_index = 0x08,  .speakers = {   0,    0,  RR,  RL,   0,    0,  FR,  FL } },
+				/* surround41 */
+{ .ca_index = 0x09,  .speakers = {   0,    0,  RR,  RL,   0,  LFE,  FR,  FL } },
+				/* surround50 */
+{ .ca_index = 0x0a,  .speakers = {   0,    0,  RR,  RL,  FC,    0,  FR,  FL } },
+				/* surround51 */
+{ .ca_index = 0x0b,  .speakers = {   0,    0,  RR,  RL,  FC,  LFE,  FR,  FL } },
+				/* 6.1 */
+{ .ca_index = 0x0f,  .speakers = {   0,   RC,  RR,  RL,  FC,  LFE,  FR,  FL } },
+				/* surround71 */
+{ .ca_index = 0x13,  .speakers = { RRC,  RLC,  RR,  RL,  FC,  LFE,  FR,  FL } },
+
+{ .ca_index = 0x03,  .speakers = {   0,    0,   0,   0,  FC,  LFE,  FR,  FL } },
+{ .ca_index = 0x04,  .speakers = {   0,    0,   0,  RC,   0,    0,  FR,  FL } },
+{ .ca_index = 0x05,  .speakers = {   0,    0,   0,  RC,   0,  LFE,  FR,  FL } },
+{ .ca_index = 0x06,  .speakers = {   0,    0,   0,  RC,  FC,    0,  FR,  FL } },
+{ .ca_index = 0x07,  .speakers = {   0,    0,   0,  RC,  FC,  LFE,  FR,  FL } },
+{ .ca_index = 0x0c,  .speakers = {   0,   RC,  RR,  RL,   0,    0,  FR,  FL } },
+{ .ca_index = 0x0d,  .speakers = {   0,   RC,  RR,  RL,   0,  LFE,  FR,  FL } },
+{ .ca_index = 0x0e,  .speakers = {   0,   RC,  RR,  RL,  FC,    0,  FR,  FL } },
+{ .ca_index = 0x10,  .speakers = { RRC,  RLC,  RR,  RL,   0,    0,  FR,  FL } },
+{ .ca_index = 0x11,  .speakers = { RRC,  RLC,  RR,  RL,   0,  LFE,  FR,  FL } },
+{ .ca_index = 0x12,  .speakers = { RRC,  RLC,  RR,  RL,  FC,    0,  FR,  FL } },
+{ .ca_index = 0x14,  .speakers = { FRC,  FLC,   0,   0,   0,    0,  FR,  FL } },
+{ .ca_index = 0x15,  .speakers = { FRC,  FLC,   0,   0,   0,  LFE,  FR,  FL } },
+{ .ca_index = 0x16,  .speakers = { FRC,  FLC,   0,   0,  FC,    0,  FR,  FL } },
+{ .ca_index = 0x17,  .speakers = { FRC,  FLC,   0,   0,  FC,  LFE,  FR,  FL } },
+{ .ca_index = 0x18,  .speakers = { FRC,  FLC,   0,  RC,   0,    0,  FR,  FL } },
+{ .ca_index = 0x19,  .speakers = { FRC,  FLC,   0,  RC,   0,  LFE,  FR,  FL } },
+{ .ca_index = 0x1a,  .speakers = { FRC,  FLC,   0,  RC,  FC,    0,  FR,  FL } },
+{ .ca_index = 0x1b,  .speakers = { FRC,  FLC,   0,  RC,  FC,  LFE,  FR,  FL } },
+{ .ca_index = 0x1c,  .speakers = { FRC,  FLC,  RR,  RL,   0,    0,  FR,  FL } },
+{ .ca_index = 0x1d,  .speakers = { FRC,  FLC,  RR,  RL,   0,  LFE,  FR,  FL } },
+{ .ca_index = 0x1e,  .speakers = { FRC,  FLC,  RR,  RL,  FC,    0,  FR,  FL } },
+{ .ca_index = 0x1f,  .speakers = { FRC,  FLC,  RR,  RL,  FC,  LFE,  FR,  FL } },
+};
+
+static struct channel_map_table map_tables[] = {
+	{ SNDRV_CHMAP_FL,       0x00,   FL },
+	{ SNDRV_CHMAP_FR,       0x01,   FR },
+	{ SNDRV_CHMAP_RL,       0x04,   RL },
+	{ SNDRV_CHMAP_RR,       0x05,   RR },
+	{ SNDRV_CHMAP_LFE,      0x02,   LFE },
+	{ SNDRV_CHMAP_FC,       0x03,   FC },
+	{ SNDRV_CHMAP_RLC,      0x06,   RLC },
+	{ SNDRV_CHMAP_RRC,      0x07,   RRC },
+	{} /* terminator */
+};
+
+/* hardware capability structure */
+static const struct snd_pcm_hardware snd_intel_hadstream = {
+	.info =	(SNDRV_PCM_INFO_INTERLEAVED |
+		SNDRV_PCM_INFO_DOUBLE |
+		SNDRV_PCM_INFO_MMAP|
+		SNDRV_PCM_INFO_MMAP_VALID |
+		SNDRV_PCM_INFO_BATCH),
+	.formats = (SNDRV_PCM_FMTBIT_S24 |
+		SNDRV_PCM_FMTBIT_U24),
+	.rates = SNDRV_PCM_RATE_32000 |
+		SNDRV_PCM_RATE_44100 |
+		SNDRV_PCM_RATE_48000 |
+		SNDRV_PCM_RATE_88200 |
+		SNDRV_PCM_RATE_96000 |
+		SNDRV_PCM_RATE_176400 |
+		SNDRV_PCM_RATE_192000,
+	.rate_min = HAD_MIN_RATE,
+	.rate_max = HAD_MAX_RATE,
+	.channels_min = HAD_MIN_CHANNEL,
+	.channels_max = HAD_MAX_CHANNEL,
+	.buffer_bytes_max = HAD_MAX_BUFFER,
+	.period_bytes_min = HAD_MIN_PERIOD_BYTES,
+	.period_bytes_max = HAD_MAX_PERIOD_BYTES,
+	.periods_min = HAD_MIN_PERIODS,
+	.periods_max = HAD_MAX_PERIODS,
+	.fifo_size = HAD_FIFO_SIZE,
+};
+
+/* Register access functions */
+
+inline int had_get_hwstate(struct snd_intelhad *intelhaddata)
+{
+	/* Check for device presence -SW state */
+	if (intelhaddata->drv_status == HAD_DRV_DISCONNECTED) {
+		pr_debug("%s:Device not connected:%d\n", __func__,
+				intelhaddata->drv_status);
+		return -ENODEV;
+	}
+
+	return 0;
+}
+
+inline int had_get_caps(enum had_caps_list query, void *caps)
+{
+	int retval;
+	struct snd_intelhad *intelhaddata = had_data;
+
+	retval = had_get_hwstate(intelhaddata);
+	if (!retval)
+		retval = intelhaddata->query_ops.hdmi_audio_get_caps(query,
+				caps);
+
+	return retval;
+}
+
+inline int had_set_caps(enum had_caps_list set_element, void *caps)
+{
+	int retval;
+	struct snd_intelhad *intelhaddata = had_data;
+
+	retval = had_get_hwstate(intelhaddata);
+	if (!retval)
+		retval = intelhaddata->query_ops.hdmi_audio_set_caps(
+				set_element, caps);
+
+	return retval;
+}
+
+inline int had_read_register(uint32_t offset, uint32_t *data)
+{
+	int retval;
+	struct snd_intelhad *intelhaddata = had_data;
+
+	retval = had_get_hwstate(intelhaddata);
+	if (!retval)
+		retval = intelhaddata->reg_ops.hdmi_audio_read_register(
+				offset + intelhaddata->audio_cfg_offset, data);
+
+	return retval;
+}
+
+inline int had_write_register(uint32_t offset, uint32_t data)
+{
+	int retval;
+	struct snd_intelhad *intelhaddata = had_data;
+
+	retval = had_get_hwstate(intelhaddata);
+	if (!retval)
+		retval = intelhaddata->reg_ops.hdmi_audio_write_register(
+				offset + intelhaddata->audio_cfg_offset, data);
+
+	return retval;
+}
+
+inline int had_read_modify(uint32_t offset, uint32_t data, uint32_t mask)
+{
+	int retval;
+	struct snd_intelhad *intelhaddata = had_data;
+
+	retval = had_get_hwstate(intelhaddata);
+	if (!retval)
+		retval = intelhaddata->reg_ops.hdmi_audio_read_modify(
+				offset + intelhaddata->audio_cfg_offset,
+				data, mask);
+
+	return retval;
+}
+/**
+ * had_read_modify_aud_config_v2 - Specific function to read-modify
+ * AUD_CONFIG register on VLV2.The had_read_modify() function should not
+ * directly be used on VLV2 for updating AUD_CONFIG register.
+ * This is because:
+ * Bit6 of AUD_CONFIG register is writeonly due to a silicon bug on VLV2
+ * HDMI IP. As a result a read-modify of AUD_CONFIG regiter will always
+ * clear bit6. AUD_CONFIG[6:4] represents the "channels" field of the
+ * register. This field should be 1xy binary for configuration with 6 or
+ * more channels. Read-modify of AUD_CONFIG (Eg. for enabling audio)
+ * causes the "channels" field to be updated as 0xy binary resulting in
+ * bad audio. The fix is to always write the AUD_CONFIG[6:4] with
+ * appropriate value when doing read-modify of AUD_CONFIG register.
+ *
+ * @substream: the current substream or NULL if no active substream
+ * @data : data to be written
+ * @mask : mask
+ *
+ */
+inline int had_read_modify_aud_config_v2(struct snd_pcm_substream *substream,
+					uint32_t data, uint32_t mask)
+{
+	union aud_cfg cfg_val = {.cfg_regval = 0};
+	u8 channels;
+
+	/*
+	 * If substream is NULL, there is no active stream.
+	 * In this case just set channels to 2
+	 */
+	if (substream)
+		channels = substream->runtime->channels;
+	else
+		channels = 2;
+	cfg_val.cfg_regx_v2.num_ch = channels - 2;
+
+	data = data | cfg_val.cfg_regval;
+	mask = mask | AUD_CONFIG_CH_MASK_V2;
+
+	pr_debug("%s : data = %x, mask =%x\n", __func__, data, mask);
+
+	return had_read_modify(AUD_CONFIG, data, mask);
+}
+
+/**
+ * snd_intelhad_enable_audio_v1 - to enable audio
+ *
+ * @substream: Current substream or NULL if no active substream.
+ * @enable: 1 if audio is to be enabled; 0 if audio is to be disabled.
+ *
+ */
+static void snd_intelhad_enable_audio_v1(struct snd_pcm_substream *substream,
+					u8 enable)
+{
+	had_read_modify(AUD_CONFIG, enable, BIT(0));
+}
+
+/**
+ * snd_intelhad_enable_audio_v2 - to enable audio
+ *
+ * @substream: Current substream or NULL if no active substream.
+ * @enable: 1 if audio is to be enabled; 0 if audio is to be disabled.
+ */
+static void snd_intelhad_enable_audio_v2(struct snd_pcm_substream *substream,
+					u8 enable)
+{
+	had_read_modify_aud_config_v2(substream, enable, BIT(0));
+}
+
+/**
+ * snd_intelhad_reset_audio_v1 - to reset audio subsystem
+ *
+ * @reset: 1 to reset audio; 0 to bring audio out of reset.
+ *
+ */
+static void snd_intelhad_reset_audio_v1(u8 reset)
+{
+	had_write_register(AUD_HDMI_STATUS, reset);
+}
+
+/**
+ * snd_intelhad_reset_audio_v2 - to reset audio subsystem
+ *
+ * @reset: 1 to reset audio; 0 to bring audio out of reset.
+ *
+ */
+static void snd_intelhad_reset_audio_v2(u8 reset)
+{
+	had_write_register(AUD_HDMI_STATUS_v2, reset);
+}
+
+/**
+ * had_prog_status_reg - to initialize audio channel status registers
+ *
+ * @substream:substream for which the prepare function is called
+ * @intelhaddata:substream private data
+ *
+ * This function is called in the prepare callback
+ */
+static int had_prog_status_reg(struct snd_pcm_substream *substream,
+			struct snd_intelhad *intelhaddata)
+{
+	union aud_cfg cfg_val = {.cfg_regval = 0};
+	union aud_ch_status_0 ch_stat0 = {.status_0_regval = 0};
+	union aud_ch_status_1 ch_stat1 = {.status_1_regval = 0};
+	int format;
+
+	pr_debug("Entry %s\n", __func__);
+
+	ch_stat0.status_0_regx.lpcm_id = (intelhaddata->aes_bits &
+						IEC958_AES0_NONAUDIO)>>1;
+	ch_stat0.status_0_regx.clk_acc = (intelhaddata->aes_bits &
+						IEC958_AES3_CON_CLOCK)>>4;
+	cfg_val.cfg_regx.val_bit = ch_stat0.status_0_regx.lpcm_id;
+
+	switch (substream->runtime->rate) {
+	case AUD_SAMPLE_RATE_32:
+		ch_stat0.status_0_regx.samp_freq = CH_STATUS_MAP_32KHZ;
+		break;
+
+	case AUD_SAMPLE_RATE_44_1:
+		ch_stat0.status_0_regx.samp_freq = CH_STATUS_MAP_44KHZ;
+		break;
+	case AUD_SAMPLE_RATE_48:
+		ch_stat0.status_0_regx.samp_freq = CH_STATUS_MAP_48KHZ;
+		break;
+	case AUD_SAMPLE_RATE_88_2:
+		ch_stat0.status_0_regx.samp_freq = CH_STATUS_MAP_88KHZ;
+		break;
+	case AUD_SAMPLE_RATE_96:
+		ch_stat0.status_0_regx.samp_freq = CH_STATUS_MAP_96KHZ;
+		break;
+	case AUD_SAMPLE_RATE_176_4:
+		ch_stat0.status_0_regx.samp_freq = CH_STATUS_MAP_176KHZ;
+		break;
+	case AUD_SAMPLE_RATE_192:
+		ch_stat0.status_0_regx.samp_freq = CH_STATUS_MAP_192KHZ;
+		break;
+
+	default:
+		/* control should never come here */
+		return -EINVAL;
+	break;
+
+	}
+	had_write_register(AUD_CH_STATUS_0, ch_stat0.status_0_regval);
+
+	format = substream->runtime->format;
+
+	if (format == SNDRV_PCM_FORMAT_S16_LE) {
+		ch_stat1.status_1_regx.max_wrd_len = MAX_SMPL_WIDTH_20;
+		ch_stat1.status_1_regx.wrd_len = SMPL_WIDTH_16BITS;
+	} else if (format == SNDRV_PCM_FORMAT_S24_LE) {
+		ch_stat1.status_1_regx.max_wrd_len = MAX_SMPL_WIDTH_24;
+		ch_stat1.status_1_regx.wrd_len = SMPL_WIDTH_24BITS;
+	} else {
+		ch_stat1.status_1_regx.max_wrd_len = 0;
+		ch_stat1.status_1_regx.wrd_len = 0;
+	}
+	had_write_register(AUD_CH_STATUS_1, ch_stat1.status_1_regval);
+	return 0;
+}
+
+/**
+ * snd_intelhad_prog_audio_ctrl_v2 - to initialize audio
+ * registers and buffer confgiuration registers
+ *
+ * @substream:substream for which the prepare function is called
+ * @intelhaddata:substream private data
+ *
+ * This function is called in the prepare callback
+ */
+int snd_intelhad_prog_audio_ctrl_v2(struct snd_pcm_substream *substream,
+					struct snd_intelhad *intelhaddata)
+{
+	union aud_cfg cfg_val = {.cfg_regval = 0};
+	union aud_buf_config buf_cfg = {.buf_cfgval = 0};
+	u8 channels;
+
+	had_prog_status_reg(substream, intelhaddata);
+
+	buf_cfg.buf_cfg_regx_v2.audio_fifo_watermark = FIFO_THRESHOLD;
+	buf_cfg.buf_cfg_regx_v2.dma_fifo_watermark = DMA_FIFO_THRESHOLD;
+	buf_cfg.buf_cfg_regx_v2.aud_delay = 0;
+	had_write_register(AUD_BUF_CONFIG, buf_cfg.buf_cfgval);
+
+	channels = substream->runtime->channels;
+	cfg_val.cfg_regx_v2.num_ch = channels - 2;
+	if (channels <= 2)
+		cfg_val.cfg_regx_v2.layout = LAYOUT0;
+	else
+		cfg_val.cfg_regx_v2.layout = LAYOUT1;
+
+	had_write_register(AUD_CONFIG, cfg_val.cfg_regval);
+	return 0;
+}
+
+/**
+ * snd_intelhad_prog_audio_ctrl_v1 - to initialize audio
+ * registers and buffer confgiuration registers
+ *
+ * @substream:substream for which the prepare function is called
+ * @intelhaddata:substream private data
+ *
+ * This function is called in the prepare callback
+ */
+int snd_intelhad_prog_audio_ctrl_v1(struct snd_pcm_substream *substream,
+					struct snd_intelhad *intelhaddata)
+{
+	union aud_cfg cfg_val = {.cfg_regval = 0};
+	union aud_buf_config buf_cfg = {.buf_cfgval = 0};
+	u8 channels;
+
+	had_prog_status_reg(substream, intelhaddata);
+
+	buf_cfg.buf_cfg_regx.fifo_width = FIFO_THRESHOLD;
+	buf_cfg.buf_cfg_regx.aud_delay = 0;
+	had_write_register(AUD_BUF_CONFIG, buf_cfg.buf_cfgval);
+
+	channels = substream->runtime->channels;
+
+	switch (channels) {
+	case 1:
+	case 2:
+		cfg_val.cfg_regx.num_ch = CH_STEREO;
+		cfg_val.cfg_regx.layout = LAYOUT0;
+	break;
+
+	case 3:
+	case 4:
+		cfg_val.cfg_regx.num_ch = CH_THREE_FOUR;
+		cfg_val.cfg_regx.layout = LAYOUT1;
+	break;
+
+	case 5:
+	case 6:
+		cfg_val.cfg_regx.num_ch = CH_FIVE_SIX;
+		cfg_val.cfg_regx.layout = LAYOUT1;
+	break;
+
+	case 7:
+	case 8:
+		cfg_val.cfg_regx.num_ch = CH_SEVEN_EIGHT;
+		cfg_val.cfg_regx.layout = LAYOUT1;
+	break;
+
+	}
+
+	had_write_register(AUD_CONFIG, cfg_val.cfg_regval);
+	return 0;
+}
+/*
+ * Compute derived values in channel_allocations[].
+ */
+static void init_channel_allocations(void)
+{
+	int i, j;
+	struct cea_channel_speaker_allocation *p;
+
+	pr_debug("%s: Enter\n", __func__);
+
+	for (i = 0; i < ARRAY_SIZE(channel_allocations); i++) {
+		p = channel_allocations + i;
+		p->channels = 0;
+		p->spk_mask = 0;
+		for (j = 0; j < ARRAY_SIZE(p->speakers); j++)
+			if (p->speakers[j]) {
+				p->channels++;
+				p->spk_mask |= p->speakers[j];
+			}
+	}
+}
+
+/*
+ * The transformation takes two steps:
+ *
+ *      eld->spk_alloc => (eld_speaker_allocation_bits[]) => spk_mask
+ *            spk_mask => (channel_allocations[])         => ai->CA
+ *
+ * TODO: it could select the wrong CA from multiple candidates.
+*/
+static int snd_intelhad_channel_allocation(struct snd_intelhad *intelhaddata,
+					int channels)
+{
+	int i;
+	int ca = 0;
+	int spk_mask = 0;
+
+	/*
+	* CA defaults to 0 for basic stereo audio
+	*/
+	if (channels <= 2)
+		return 0;
+
+	/*
+	* expand ELD's speaker allocation mask
+	*
+	* ELD tells the speaker mask in a compact(paired) form,
+	* expand ELD's notions to match the ones used by Audio InfoFrame.
+	*/
+
+	for (i = 0; i < ARRAY_SIZE(eld_speaker_allocation_bits); i++) {
+		if (intelhaddata->eeld.speaker_allocation_block & (1 << i))
+			spk_mask |= eld_speaker_allocation_bits[i];
+	}
+
+	/* search for the first working match in the CA table */
+	for (i = 0; i < ARRAY_SIZE(channel_allocations); i++) {
+		if (channels == channel_allocations[i].channels &&
+		(spk_mask & channel_allocations[i].spk_mask) ==
+				channel_allocations[i].spk_mask) {
+			ca = channel_allocations[i].ca_index;
+			break;
+		}
+	}
+
+	pr_debug("HDMI: select CA 0x%x for %d\n", ca, channels);
+
+	return ca;
+}
+
+/* from speaker bit mask to ALSA API channel position */
+static int spk_to_chmap(int spk)
+{
+	struct channel_map_table *t = map_tables;
+
+	for (; t->map; t++) {
+		if (t->spk_mask == spk)
+			return t->map;
+	}
+	return 0;
+}
+
+void had_build_channel_allocation_map(struct snd_intelhad *intelhaddata)
+{
+	int i = 0, c = 0;
+	int spk_mask = 0;
+	struct snd_pcm_chmap_elem *chmap;
+	uint8_t eld_high, eld_high_mask = 0xF0;
+	uint8_t high_msb;
+
+	chmap = kzalloc(sizeof(*chmap), GFP_KERNEL);
+	if (chmap == NULL) {
+		intelhaddata->chmap->chmap = NULL;
+		return;
+	}
+
+	had_get_caps(HAD_GET_ELD, &intelhaddata->eeld);
+
+	pr_debug("eeld.speaker_allocation_block = %x\n",
+			intelhaddata->eeld.speaker_allocation_block);
+
+	/* WA: Fix the max channel supported to 8 */
+
+	/*
+	 * Sink may support more than 8 channels, if eld_high has more than
+	 * one bit set. SOC supports max 8 channels.
+	 * Refer eld_speaker_allocation_bits, for sink speaker allocation
+	 */
+
+	/* if 0x2F < eld < 0x4F fall back to 0x2f, else fall back to 0x4F */
+	eld_high = intelhaddata->eeld.speaker_allocation_block & eld_high_mask;
+	if ((eld_high & (eld_high-1)) && (eld_high > 0x1F)) {
+		/* eld_high & (eld_high-1): if more than 1 bit set */
+		/* 0x1F: 7 channels */
+		for (i = 1; i < 4; i++) {
+			high_msb = eld_high & (0x80 >> i);
+			if (high_msb) {
+				intelhaddata->eeld.speaker_allocation_block &=
+					high_msb | 0xF;
+				break;
+			}
+		}
+	}
+
+	for (i = 0; i < ARRAY_SIZE(eld_speaker_allocation_bits); i++) {
+		if (intelhaddata->eeld.speaker_allocation_block & (1 << i))
+			spk_mask |= eld_speaker_allocation_bits[i];
+	}
+
+	for (i = 0; i < ARRAY_SIZE(channel_allocations); i++) {
+		if (spk_mask == channel_allocations[i].spk_mask) {
+			for (c = 0; c < channel_allocations[i].channels; c++) {
+				chmap->map[c] = spk_to_chmap(
+					channel_allocations[i].speakers[
+						(MAX_SPEAKERS - 1)-c]);
+			}
+			chmap->channels = channel_allocations[i].channels;
+			intelhaddata->chmap->chmap = chmap;
+			break;
+		}
+	}
+	if (i >= ARRAY_SIZE(channel_allocations)) {
+		intelhaddata->chmap->chmap = NULL;
+		kfree(chmap);
+	}
+}
+
+/*
+ ** ALSA API channel-map control callbacks
+ **/
+static int had_chmap_ctl_info(struct snd_kcontrol *kcontrol,
+				struct snd_ctl_elem_info *uinfo)
+{
+	struct snd_pcm_chmap *info = snd_kcontrol_chip(kcontrol);
+	struct snd_intelhad *intelhaddata = info->private_data;
+
+	if (intelhaddata->drv_status == HAD_DRV_DISCONNECTED)
+		return -ENODEV;
+	uinfo->type = SNDRV_CTL_ELEM_TYPE_INTEGER;
+	uinfo->count = HAD_MAX_CHANNEL;
+	uinfo->value.integer.min = 0;
+	uinfo->value.integer.max = SNDRV_CHMAP_LAST;
+	return 0;
+}
+
+#ifndef USE_ALSA_DEFAULT_TLV
+static int had_chmap_ctl_tlv(struct snd_kcontrol *kcontrol, int op_flag,
+				unsigned int size, unsigned int __user *tlv)
+{
+	struct snd_pcm_chmap *info = snd_kcontrol_chip(kcontrol);
+	struct snd_intelhad *intelhaddata = info->private_data;
+
+	if (intelhaddata->drv_status == HAD_DRV_DISCONNECTED)
+		return -ENODEV;
+
+	/* TODO: Fix for query channel map */
+	return -EPERM;
+}
+#endif
+
+static int had_chmap_ctl_get(struct snd_kcontrol *kcontrol,
+				struct snd_ctl_elem_value *ucontrol)
+{
+	struct snd_pcm_chmap *info = snd_kcontrol_chip(kcontrol);
+	struct snd_intelhad *intelhaddata = info->private_data;
+	int i = 0;
+	const struct snd_pcm_chmap_elem *chmap;
+
+	if (intelhaddata->drv_status == HAD_DRV_DISCONNECTED)
+		return -ENODEV;
+	if (intelhaddata->chmap->chmap ==  NULL)
+		return -ENODATA;
+	chmap = intelhaddata->chmap->chmap;
+	for (i = 0; i < chmap->channels; i++) {
+		ucontrol->value.integer.value[i] = chmap->map[i];
+		pr_debug("chmap->map[%d] = %d\n", i, chmap->map[i]);
+	}
+
+	return 0;
+}
+
+static int had_chmap_ctl_put(struct snd_kcontrol *kcontrol,
+				struct snd_ctl_elem_value *ucontrol)
+{
+	/* TODO: Get channel map and set swap register */
+	return -EPERM;
+}
+
+static int had_register_chmap_ctls(struct snd_intelhad *intelhaddata,
+						struct snd_pcm *pcm)
+{
+	int err = 0;
+
+	err = snd_pcm_add_chmap_ctls(pcm, SNDRV_PCM_STREAM_PLAYBACK,
+			NULL, 0, (unsigned long)intelhaddata,
+			&intelhaddata->chmap);
+	if (err < 0)
+		return err;
+
+	intelhaddata->chmap->private_data = intelhaddata;
+	intelhaddata->kctl = intelhaddata->chmap->kctl;
+	intelhaddata->kctl->info = had_chmap_ctl_info;
+	intelhaddata->kctl->get = had_chmap_ctl_get;
+	intelhaddata->kctl->put = had_chmap_ctl_put;
+#ifndef USE_ALSA_DEFAULT_TLV
+	intelhaddata->kctl->tlv.c = had_chmap_ctl_tlv;
+#endif
+	intelhaddata->chmap->chmap = NULL;
+	return 0;
+}
+
+/**
+ * snd_intelhad_prog_dip_v1 - to initialize Data Island Packets registers
+ *
+ * @substream:substream for which the prepare function is called
+ * @intelhaddata:substream private data
+ *
+ * This function is called in the prepare callback
+ */
+static void snd_intelhad_prog_dip_v1(struct snd_pcm_substream *substream,
+				struct snd_intelhad *intelhaddata)
+{
+	int i;
+	union aud_ctrl_st ctrl_state = {.ctrl_val = 0};
+	union aud_info_frame2 frame2 = {.fr2_val = 0};
+	union aud_info_frame3 frame3 = {.fr3_val = 0};
+	u8 checksum = 0;
+	int channels;
+
+	channels = substream->runtime->channels;
+
+	had_write_register(AUD_CNTL_ST, ctrl_state.ctrl_val);
+
+	frame2.fr2_regx.chnl_cnt = substream->runtime->channels - 1;
+
+	frame3.fr3_regx.chnl_alloc = snd_intelhad_channel_allocation(
+					intelhaddata, channels);
+
+	/*Calculte the byte wide checksum for all valid DIP words*/
+	for (i = 0; i < BYTES_PER_WORD; i++)
+		checksum += (INFO_FRAME_WORD1 >> i*BITS_PER_BYTE) & MASK_BYTE0;
+	for (i = 0; i < BYTES_PER_WORD; i++)
+		checksum += (frame2.fr2_val >> i*BITS_PER_BYTE) & MASK_BYTE0;
+	for (i = 0; i < BYTES_PER_WORD; i++)
+		checksum += (frame3.fr3_val >> i*BITS_PER_BYTE) & MASK_BYTE0;
+
+	frame2.fr2_regx.chksum = -(checksum);
+
+	had_write_register(AUD_HDMIW_INFOFR, INFO_FRAME_WORD1);
+	had_write_register(AUD_HDMIW_INFOFR, frame2.fr2_val);
+	had_write_register(AUD_HDMIW_INFOFR, frame3.fr3_val);
+
+	/* program remaining DIP words with zero */
+	for (i = 0; i < HAD_MAX_DIP_WORDS-VALID_DIP_WORDS; i++)
+		had_write_register(AUD_HDMIW_INFOFR, 0x0);
+
+	ctrl_state.ctrl_regx.dip_freq = 1;
+	ctrl_state.ctrl_regx.dip_en_sta = 1;
+	had_write_register(AUD_CNTL_ST, ctrl_state.ctrl_val);
+}
+
+/**
+ * snd_intelhad_prog_dip_v2 - to initialize Data Island Packets registers
+ *
+ * @substream:substream for which the prepare function is called
+ * @intelhaddata:substream private data
+ *
+ * This function is called in the prepare callback
+ */
+static void snd_intelhad_prog_dip_v2(struct snd_pcm_substream *substream,
+				struct snd_intelhad *intelhaddata)
+{
+	int i;
+	union aud_ctrl_st ctrl_state = {.ctrl_val = 0};
+	union aud_info_frame2 frame2 = {.fr2_val = 0};
+	union aud_info_frame3 frame3 = {.fr3_val = 0};
+	u8 checksum = 0;
+	int channels;
+
+	channels = substream->runtime->channels;
+
+	had_write_register(AUD_CNTL_ST, ctrl_state.ctrl_val);
+
+	frame2.fr2_regx.chnl_cnt = substream->runtime->channels - 1;
+
+	frame3.fr3_regx.chnl_alloc = snd_intelhad_channel_allocation(
+					intelhaddata, channels);
+
+	/*Calculte the byte wide checksum for all valid DIP words*/
+	for (i = 0; i < BYTES_PER_WORD; i++)
+		checksum += (INFO_FRAME_WORD1 >> i*BITS_PER_BYTE) & MASK_BYTE0;
+	for (i = 0; i < BYTES_PER_WORD; i++)
+		checksum += (frame2.fr2_val >> i*BITS_PER_BYTE) & MASK_BYTE0;
+	for (i = 0; i < BYTES_PER_WORD; i++)
+		checksum += (frame3.fr3_val >> i*BITS_PER_BYTE) & MASK_BYTE0;
+
+	frame2.fr2_regx.chksum = -(checksum);
+
+	had_write_register(AUD_HDMIW_INFOFR_v2, INFO_FRAME_WORD1);
+	had_write_register(AUD_HDMIW_INFOFR_v2, frame2.fr2_val);
+	had_write_register(AUD_HDMIW_INFOFR_v2, frame3.fr3_val);
+
+	/* program remaining DIP words with zero */
+	for (i = 0; i < HAD_MAX_DIP_WORDS-VALID_DIP_WORDS; i++)
+		had_write_register(AUD_HDMIW_INFOFR_v2, 0x0);
+
+	ctrl_state.ctrl_regx.dip_freq = 1;
+	ctrl_state.ctrl_regx.dip_en_sta = 1;
+	had_write_register(AUD_CNTL_ST, ctrl_state.ctrl_val);
+}
+
+/**
+ * snd_intelhad_prog_buffer - programs buffer
+ * address and length registers
+ *
+ * @substream:substream for which the prepare function is called
+ * @intelhaddata:substream private data
+ *
+ * This function programs ring buffer address and length into registers.
+ */
+int snd_intelhad_prog_buffer(struct snd_intelhad *intelhaddata,
+					int start, int end)
+{
+	u32 ring_buf_addr, ring_buf_size, period_bytes;
+	u8 i, num_periods;
+	struct snd_pcm_substream *substream;
+
+	substream = intelhaddata->stream_info.had_substream;
+	if (!substream) {
+		pr_err("substream is NULL\n");
+		dump_stack();
+		return 0;
+	}
+
+	ring_buf_addr = substream->runtime->dma_addr;
+	ring_buf_size = snd_pcm_lib_buffer_bytes(substream);
+	intelhaddata->stream_info.ring_buf_size = ring_buf_size;
+	period_bytes = frames_to_bytes(substream->runtime,
+				substream->runtime->period_size);
+	num_periods = substream->runtime->periods;
+
+	/*
+	 * buffer addr should  be 64 byte aligned, period bytes
+	 * will be used to calculate addr offset
+	 */
+	period_bytes &= ~0x3F;
+
+	/* Hardware supports MAX_PERIODS buffers */
+	if (end >= HAD_MAX_PERIODS)
+		return -EINVAL;
+
+	for (i = start; i <= end; i++) {
+		/* Program the buf registers with addr and len */
+		intelhaddata->buf_info[i].buf_addr = ring_buf_addr +
+							 (i * period_bytes);
+		if (i < num_periods-1)
+			intelhaddata->buf_info[i].buf_size = period_bytes;
+		else
+			intelhaddata->buf_info[i].buf_size = ring_buf_size -
+							(period_bytes*i);
+
+		had_write_register(AUD_BUF_A_ADDR + (i * HAD_REG_WIDTH),
+					intelhaddata->buf_info[i].buf_addr |
+					BIT(0) | BIT(1));
+		had_write_register(AUD_BUF_A_LENGTH + (i * HAD_REG_WIDTH),
+					period_bytes);
+		intelhaddata->buf_info[i].is_valid = true;
+	}
+	pr_debug("%s:buf[%d-%d] addr=%#x  and size=%d\n", __func__, start, end,
+			intelhaddata->buf_info[start].buf_addr,
+			intelhaddata->buf_info[start].buf_size);
+	intelhaddata->valid_buf_cnt = num_periods;
+	return 0;
+}
+
+inline int snd_intelhad_read_len(struct snd_intelhad *intelhaddata)
+{
+	int i, retval = 0;
+	u32 len[4];
+
+	for (i = 0; i < 4 ; i++) {
+		had_read_register(AUD_BUF_A_LENGTH + (i * HAD_REG_WIDTH),
+					&len[i]);
+		if (!len[i])
+			retval++;
+	}
+	if (retval != 1) {
+		for (i = 0; i < 4 ; i++)
+			pr_debug("buf[%d] size=%d\n", i, len[i]);
+	}
+
+	return retval;
+}
+
+/**
+ * snd_intelhad_prog_cts_v1 - Program HDMI audio CTS value
+ *
+ * @aud_samp_freq: sampling frequency of audio data
+ * @tmds: sampling frequency of the display data
+ * @n_param: N value, depends on aud_samp_freq
+ * @intelhaddata:substream private data
+ *
+ * Program CTS register based on the audio and display sampling frequency
+ */
+static void snd_intelhad_prog_cts_v1(u32 aud_samp_freq, u32 tmds, u32 n_param,
+				struct snd_intelhad *intelhaddata)
+{
+	u32 cts_val;
+	u64 dividend, divisor;
+
+	/* Calculate CTS according to HDMI 1.3a spec*/
+	dividend = (u64)tmds * n_param*1000;
+	divisor = 128 * aud_samp_freq;
+	cts_val = div64_u64(dividend, divisor);
+	pr_debug("TMDS value=%d, N value=%d, CTS Value=%d\n",
+			tmds, n_param, cts_val);
+	had_write_register(AUD_HDMI_CTS, (BIT(20) | cts_val));
+}
+
+/**
+ * snd_intelhad_prog_cts_v2 - Program HDMI audio CTS value
+ *
+ * @aud_samp_freq: sampling frequency of audio data
+ * @tmds: sampling frequency of the display data
+ * @n_param: N value, depends on aud_samp_freq
+ * @intelhaddata:substream private data
+ *
+ * Program CTS register based on the audio and display sampling frequency
+ */
+static void snd_intelhad_prog_cts_v2(u32 aud_samp_freq, u32 tmds, u32 n_param,
+				struct snd_intelhad *intelhaddata)
+{
+	u32 cts_val;
+	u64 dividend, divisor;
+
+	/* Calculate CTS according to HDMI 1.3a spec*/
+	dividend = (u64)tmds * n_param*1000;
+	divisor = 128 * aud_samp_freq;
+	cts_val = div64_u64(dividend, divisor);
+	pr_debug("TMDS value=%d, N value=%d, CTS Value=%d\n",
+			tmds, n_param, cts_val);
+	had_write_register(AUD_HDMI_CTS, (BIT(24) | cts_val));
+}
+
+static int had_calculate_n_value(u32 aud_samp_freq)
+{
+	s32 n_val;
+
+	/* Select N according to HDMI 1.3a spec*/
+	switch (aud_samp_freq) {
+	case AUD_SAMPLE_RATE_32:
+		n_val = 4096;
+	break;
+
+	case AUD_SAMPLE_RATE_44_1:
+		n_val = 6272;
+	break;
+
+	case AUD_SAMPLE_RATE_48:
+		n_val = 6144;
+	break;
+
+	case AUD_SAMPLE_RATE_88_2:
+		n_val = 12544;
+	break;
+
+	case AUD_SAMPLE_RATE_96:
+		n_val = 12288;
+	break;
+
+	case AUD_SAMPLE_RATE_176_4:
+		n_val = 25088;
+	break;
+
+	case HAD_MAX_RATE:
+		n_val = 24576;
+	break;
+
+	default:
+		n_val = -EINVAL;
+	break;
+	}
+	return n_val;
+}
+
+/**
+ * snd_intelhad_prog_n_v1 - Program HDMI audio N value
+ *
+ * @aud_samp_freq: sampling frequency of audio data
+ * @n_param: N value, depends on aud_samp_freq
+ * @intelhaddata:substream private data
+ *
+ * This function is called in the prepare callback.
+ * It programs based on the audio and display sampling frequency
+ */
+static int snd_intelhad_prog_n_v1(u32 aud_samp_freq, u32 *n_param,
+				struct snd_intelhad *intelhaddata)
+{
+	s32 n_val;
+
+	n_val =	had_calculate_n_value(aud_samp_freq);
+
+	if (n_val < 0)
+		return n_val;
+
+	had_write_register(AUD_N_ENABLE, (BIT(20) | n_val));
+	*n_param = n_val;
+	return 0;
+}
+
+/**
+ * snd_intelhad_prog_n_v2 - Program HDMI audio N value
+ *
+ * @aud_samp_freq: sampling frequency of audio data
+ * @n_param: N value, depends on aud_samp_freq
+ * @intelhaddata:substream private data
+ *
+ * This function is called in the prepare callback.
+ * It programs based on the audio and display sampling frequency
+ */
+static int snd_intelhad_prog_n_v2(u32 aud_samp_freq, u32 *n_param,
+				struct snd_intelhad *intelhaddata)
+{
+	s32 n_val;
+
+	n_val =	had_calculate_n_value(aud_samp_freq);
+
+	if (n_val < 0)
+		return n_val;
+
+	had_write_register(AUD_N_ENABLE, (BIT(24) | n_val));
+	*n_param = n_val;
+	return 0;
+}
+
+static void had_clear_underrun_intr_v1(struct snd_intelhad *intelhaddata)
+{
+	u32 hdmi_status, i = 0;
+
+	/* Handle Underrun interrupt within Audio Unit */
+	had_write_register(AUD_CONFIG, 0);
+	/* Reset buffer pointers */
+	had_write_register(AUD_HDMI_STATUS, 1);
+	had_write_register(AUD_HDMI_STATUS, 0);
+	/**
+	 * The interrupt status 'sticky' bits might not be cleared by
+	 * setting '1' to that bit once...
+	 */
+	do { /* clear bit30, 31 AUD_HDMI_STATUS */
+		had_read_register(AUD_HDMI_STATUS, &hdmi_status);
+		pr_debug("HDMI status =0x%x\n", hdmi_status);
+		if (hdmi_status & AUD_CONFIG_MASK_UNDERRUN) {
+			i++;
+			hdmi_status &= (AUD_CONFIG_MASK_SRDBG |
+					AUD_CONFIG_MASK_FUNCRST);
+			hdmi_status |= ~AUD_CONFIG_MASK_UNDERRUN;
+			had_write_register(AUD_HDMI_STATUS, hdmi_status);
+		} else
+			break;
+	} while (i < MAX_CNT);
+	if (i >= MAX_CNT)
+		pr_err("Unable to clear UNDERRUN bits\n");
+}
+
+static void had_clear_underrun_intr_v2(struct snd_intelhad *intelhaddata)
+{
+	u32 hdmi_status, i = 0;
+
+	/* Handle Underrun interrupt within Audio Unit */
+	had_write_register(AUD_CONFIG, 0);
+	/* Reset buffer pointers */
+	had_write_register(AUD_HDMI_STATUS_v2, 1);
+	had_write_register(AUD_HDMI_STATUS_v2, 0);
+	/**
+	 * The interrupt status 'sticky' bits might not be cleared by
+	 * setting '1' to that bit once...
+	 */
+	do { /* clear bit30, 31 AUD_HDMI_STATUS */
+		had_read_register(AUD_HDMI_STATUS_v2, &hdmi_status);
+		pr_debug("HDMI status =0x%x\n", hdmi_status);
+		if (hdmi_status & AUD_CONFIG_MASK_UNDERRUN) {
+			i++;
+			had_write_register(AUD_HDMI_STATUS_v2, hdmi_status);
+		} else
+			break;
+	} while (i < MAX_CNT);
+	if (i >= MAX_CNT)
+		pr_err("Unable to clear UNDERRUN bits\n");
+}
+
+/**
+* snd_intelhad_open - stream initializations are done here
+* @substream:substream for which the stream function is called
+*
+* This function is called whenever a PCM stream is opened
+*/
+static int snd_intelhad_open(struct snd_pcm_substream *substream)
+{
+	struct snd_intelhad *intelhaddata;
+	struct snd_pcm_runtime *runtime;
+	struct had_stream_pvt *stream;
+	struct had_pvt_data *had_stream;
+	int retval;
+
+	pr_debug("snd_intelhad_open called\n");
+	intelhaddata = snd_pcm_substream_chip(substream);
+	had_stream = intelhaddata->private_data;
+	runtime = substream->runtime;
+	underrun_count = 0;
+
+	pm_runtime_get(intelhaddata->dev);
+
+	if (had_get_hwstate(intelhaddata)) {
+		pr_err("%s: HDMI cable plugged-out\n", __func__);
+		retval = -ENODEV;
+		goto exit_put_handle;
+	}
+
+	/* Check, if device already in use */
+	if (runtime->private_data) {
+		pr_err("Device already in use\n");
+		retval = -EBUSY;
+		goto exit_put_handle;
+	}
+
+	/* set the runtime hw parameter with local snd_pcm_hardware struct */
+	runtime->hw = snd_intel_hadstream;
+
+	stream = kzalloc(sizeof(*stream), GFP_KERNEL);
+	if (!stream) {
+		retval = -ENOMEM;
+		goto exit_put_handle;
+	}
+	stream->stream_status = STREAM_INIT;
+	runtime->private_data = stream;
+
+	retval = snd_pcm_hw_constraint_integer(runtime,
+			 SNDRV_PCM_HW_PARAM_PERIODS);
+	if (retval < 0)
+		goto exit_err;
+
+	/* Make sure, that the period size is always aligned
+	 * 64byte boundary
+	 */
+	retval = snd_pcm_hw_constraint_step(substream->runtime, 0,
+			SNDRV_PCM_HW_PARAM_PERIOD_BYTES, 64);
+	if (retval < 0) {
+		pr_err("%s:step_size=64 failed,err=%d\n", __func__, retval);
+		goto exit_err;
+	}
+
+	return retval;
+exit_err:
+	kfree(stream);
+exit_put_handle:
+	pm_runtime_put(intelhaddata->dev);
+	runtime->private_data = NULL;
+	return retval;
+}
+
+/**
+* had_period_elapsed - updates the hardware pointer status
+* @had_substream:substream for which the stream function is called
+*
+*/
+static void had_period_elapsed(void *had_substream)
+{
+	struct snd_pcm_substream *substream = had_substream;
+	struct had_stream_pvt *stream;
+
+	/* pr_debug("had_period_elapsed called\n"); */
+
+	if (!substream || !substream->runtime)
+		return;
+	stream = substream->runtime->private_data;
+	if (!stream)
+		return;
+
+	if (stream->stream_status != STREAM_RUNNING)
+		return;
+	snd_pcm_period_elapsed(substream);
+}
+
+/**
+* snd_intelhad_init_stream - internal function to initialize stream info
+* @substream:substream for which the stream function is called
+*
+*/
+static int snd_intelhad_init_stream(struct snd_pcm_substream *substream)
+{
+	struct snd_intelhad *intelhaddata = snd_pcm_substream_chip(substream);
+
+	pr_debug("snd_intelhad_init_stream called\n");
+
+	pr_debug("setting buffer ptr param\n");
+	intelhaddata->stream_info.period_elapsed = had_period_elapsed;
+	intelhaddata->stream_info.had_substream = substream;
+	intelhaddata->stream_info.buffer_ptr = 0;
+	intelhaddata->stream_info.buffer_rendered = 0;
+	intelhaddata->stream_info.sfreq = substream->runtime->rate;
+	return 0;
+}
+
+/**
+ * snd_intelhad_close- to free parameteres when stream is stopped
+ *
+ * @substream:  substream for which the function is called
+ *
+ * This function is called by ALSA framework when stream is stopped
+ */
+static int snd_intelhad_close(struct snd_pcm_substream *substream)
+{
+	struct snd_intelhad *intelhaddata;
+	struct snd_pcm_runtime *runtime;
+
+	pr_debug("snd_intelhad_close called\n");
+
+	intelhaddata = snd_pcm_substream_chip(substream);
+	runtime = substream->runtime;
+
+	if (!runtime->private_data) {
+		pr_debug("close() might have called after failed open");
+		return 0;
+	}
+
+	intelhaddata->stream_info.buffer_rendered = 0;
+	intelhaddata->stream_info.buffer_ptr = 0;
+	intelhaddata->stream_info.str_id = 0;
+	intelhaddata->stream_info.had_substream = NULL;
+
+	/* Check if following drv_status modification is required - VA */
+	if (intelhaddata->drv_status != HAD_DRV_DISCONNECTED) {
+		intelhaddata->drv_status = HAD_DRV_CONNECTED;
+		pr_debug("%s @ %d:DEBUG PLUG/UNPLUG : HAD_DRV_CONNECTED\n",
+			__func__, __LINE__);
+	}
+	kfree(runtime->private_data);
+	runtime->private_data = NULL;
+	pm_runtime_put(intelhaddata->dev);
+	return 0;
+}
+
+/**
+ * snd_intelhad_hw_params- to setup the hardware parameters
+ * like allocating the buffers
+ *
+ * @substream:  substream for which the function is called
+ * @hw_params: hardware parameters
+ *
+ * This function is called by ALSA framework when hardware params are set
+ */
+static int snd_intelhad_hw_params(struct snd_pcm_substream *substream,
+				    struct snd_pcm_hw_params *hw_params)
+{
+	unsigned long addr;
+	int pages, buf_size, retval;
+
+	pr_debug("snd_intelhad_hw_params called\n");
+
+	if (!hw_params)
+		return -EINVAL;
+
+	buf_size = params_buffer_bytes(hw_params);
+	retval = snd_pcm_lib_malloc_pages(substream, buf_size);
+	if (retval < 0)
+		return retval;
+	pr_debug("%s:allocated memory = %d\n", __func__, buf_size);
+	/* mark the pages as uncached region */
+	addr = (unsigned long) substream->runtime->dma_area;
+	pages = (substream->runtime->dma_bytes + PAGE_SIZE - 1) / PAGE_SIZE;
+	retval = set_memory_uc(addr, pages);
+	if (retval) {
+		pr_err("set_memory_uc failed.Error:%d\n", retval);
+		return retval;
+	}
+	memset(substream->runtime->dma_area, 0, buf_size);
+
+	return retval;
+}
+
+/**
+ * snd_intelhad_hw_free- to release the resources allocated during
+ * hardware params setup
+ *
+ * @substream:  substream for which the function is called
+ *
+ * This function is called by ALSA framework before close callback.
+ *
+ */
+static int snd_intelhad_hw_free(struct snd_pcm_substream *substream)
+{
+	unsigned long addr;
+	u32 pages;
+
+	pr_debug("snd_intelhad_hw_free called\n");
+
+	/* mark back the pages as cached/writeback region before the free */
+	if (substream->runtime->dma_area != NULL) {
+		addr = (unsigned long) substream->runtime->dma_area;
+		pages = (substream->runtime->dma_bytes + PAGE_SIZE - 1) /
+								PAGE_SIZE;
+		set_memory_wb(addr, pages);
+		return snd_pcm_lib_free_pages(substream);
+	}
+	return 0;
+}
+
+/**
+* snd_intelhad_pcm_trigger - stream activities are handled here
+* @substream:substream for which the stream function is called
+* @cmd:the stream commamd thats requested from upper layer
+* This function is called whenever an a stream activity is invoked
+*/
+static int snd_intelhad_pcm_trigger(struct snd_pcm_substream *substream,
+					int cmd)
+{
+	int caps, retval = 0;
+	unsigned long flag_irq;
+	struct snd_intelhad *intelhaddata;
+	struct had_stream_pvt *stream;
+	struct had_pvt_data *had_stream;
+
+	pr_debug("snd_intelhad_pcm_trigger called\n");
+
+	intelhaddata = snd_pcm_substream_chip(substream);
+	stream = substream->runtime->private_data;
+	had_stream = intelhaddata->private_data;
+
+	switch (cmd) {
+	case SNDRV_PCM_TRIGGER_START:
+		pr_debug("Trigger Start\n");
+
+		/* Disable local INTRs till register prgmng is done */
+		if (had_get_hwstate(intelhaddata)) {
+			pr_err("_START: HDMI cable plugged-out\n");
+			retval = -ENODEV;
+			break;
+		}
+		stream->stream_status = STREAM_RUNNING;
+
+		had_stream->stream_type = HAD_RUNNING_STREAM;
+
+		/* Enable Audio */
+		/*
+		 * ToDo: Need to enable UNDERRUN interrupts as well
+		 *   caps = HDMI_AUDIO_UNDERRUN | HDMI_AUDIO_BUFFER_DONE;
+		 */
+		caps = HDMI_AUDIO_BUFFER_DONE;
+		retval = had_set_caps(HAD_SET_ENABLE_AUDIO_INT, &caps);
+		retval = had_set_caps(HAD_SET_ENABLE_AUDIO, NULL);
+		intelhaddata->ops->enable_audio(substream, 1);
+
+		pr_debug("Processed _Start\n");
+
+		break;
+
+	case SNDRV_PCM_TRIGGER_STOP:
+		pr_debug("Trigger Stop\n");
+		spin_lock_irqsave(&intelhaddata->had_spinlock, flag_irq);
+		intelhaddata->stream_info.str_id = 0;
+		intelhaddata->curr_buf = 0;
+
+		/* Stop reporting BUFFER_DONE/UNDERRUN to above layers*/
+
+		had_stream->stream_type = HAD_INIT;
+		spin_unlock_irqrestore(&intelhaddata->had_spinlock, flag_irq);
+		/* Disable Audio */
+		/*
+		 * ToDo: Need to disable UNDERRUN interrupts as well
+		 *   caps = HDMI_AUDIO_UNDERRUN | HDMI_AUDIO_BUFFER_DONE;
+		 */
+		caps = HDMI_AUDIO_BUFFER_DONE;
+		had_set_caps(HAD_SET_DISABLE_AUDIO_INT, &caps);
+		intelhaddata->ops->enable_audio(substream, 0);
+		/* Reset buffer pointers */
+		intelhaddata->ops->reset_audio(1);
+		intelhaddata->ops->reset_audio(0);
+		stream->stream_status = STREAM_DROPPED;
+		had_set_caps(HAD_SET_DISABLE_AUDIO, NULL);
+		break;
+
+	default:
+		retval = -EINVAL;
+	}
+	return retval;
+}
+
+/**
+* snd_intelhad_pcm_prepare- internal preparation before starting a stream
+*
+* @substream:  substream for which the function is called
+*
+* This function is called when a stream is started for internal preparation.
+*/
+static int snd_intelhad_pcm_prepare(struct snd_pcm_substream *substream)
+{
+	int retval;
+	u32 disp_samp_freq, n_param;
+	struct snd_intelhad *intelhaddata;
+	struct snd_pcm_runtime *runtime;
+	struct had_pvt_data *had_stream;
+
+	pr_debug("snd_intelhad_pcm_prepare called\n");
+
+	intelhaddata = snd_pcm_substream_chip(substream);
+	runtime = substream->runtime;
+	had_stream = intelhaddata->private_data;
+
+	if (had_get_hwstate(intelhaddata)) {
+		pr_err("%s: HDMI cable plugged-out\n", __func__);
+		retval = -ENODEV;
+		goto prep_end;
+	}
+
+	pr_debug("period_size=%d\n",
+		(int)frames_to_bytes(runtime, runtime->period_size));
+	pr_debug("periods=%d\n", runtime->periods);
+	pr_debug("buffer_size=%d\n", (int)snd_pcm_lib_buffer_bytes(substream));
+	pr_debug("rate=%d\n", runtime->rate);
+	pr_debug("channels=%d\n", runtime->channels);
+
+	if (intelhaddata->stream_info.str_id) {
+		pr_debug("_prepare is called for existing str_id#%d\n",
+					intelhaddata->stream_info.str_id);
+		retval = snd_intelhad_pcm_trigger(substream,
+						SNDRV_PCM_TRIGGER_STOP);
+		return retval;
+	}
+
+	retval = snd_intelhad_init_stream(substream);
+	if (retval)
+		goto prep_end;
+
+
+	/* Get N value in KHz */
+	retval = had_get_caps(HAD_GET_DISPLAY_RATE, &disp_samp_freq);
+	if (retval) {
+		pr_err("querying display sampling freq failed %#x\n", retval);
+		goto prep_end;
+	}
+
+	had_get_caps(HAD_GET_ELD, &intelhaddata->eeld);
+
+	retval = intelhaddata->ops->prog_n(substream->runtime->rate, &n_param,
+								intelhaddata);
+	if (retval) {
+		pr_err("programming N value failed %#x\n", retval);
+		goto prep_end;
+	}
+	intelhaddata->ops->prog_cts(substream->runtime->rate,
+					disp_samp_freq, n_param, intelhaddata);
+
+	intelhaddata->ops->prog_dip(substream, intelhaddata);
+
+	retval = intelhaddata->ops->audio_ctrl(substream, intelhaddata);
+
+	/* Prog buffer address */
+	retval = snd_intelhad_prog_buffer(intelhaddata,
+			HAD_BUF_TYPE_A, HAD_BUF_TYPE_D);
+
+	/*
+	 * Program channel mapping in following order:
+	 * FL, FR, C, LFE, RL, RR
+	 */
+
+	had_write_register(AUD_BUF_CH_SWAP, SWAP_LFE_CENTER);
+
+prep_end:
+	return retval;
+}
+
+/**
+ * snd_intelhad_pcm_pointer- to send the current buffer pointerprocessed by hw
+ *
+ * @substream:  substream for which the function is called
+ *
+ * This function is called by ALSA framework to get the current hw buffer ptr
+ * when a period is elapsed
+ */
+static snd_pcm_uframes_t snd_intelhad_pcm_pointer(
+					struct snd_pcm_substream *substream)
+{
+	struct snd_intelhad *intelhaddata;
+	u32 bytes_rendered = 0;
+	u32 t;
+	int buf_id;
+
+	/* pr_debug("snd_intelhad_pcm_pointer called\n"); */
+
+	intelhaddata = snd_pcm_substream_chip(substream);
+
+	if (intelhaddata->flag_underrun) {
+		intelhaddata->flag_underrun = 0;
+		return SNDRV_PCM_POS_XRUN;
+	}
+
+	/* Use a hw register to calculate sub-period position reports.
+	 * This makes PulseAudio happier.
+	 */
+
+	buf_id = intelhaddata->curr_buf % 4;
+	had_read_register(AUD_BUF_A_LENGTH + (buf_id * HAD_REG_WIDTH), &t);
+
+	if ((t == 0) || (t == ((u32)-1L))) {
+		underrun_count++;
+		pr_debug("discovered buffer done for buf %d, count = %d\n",
+			buf_id, underrun_count);
+
+		if (underrun_count > (HAD_MIN_PERIODS/2)) {
+			pr_debug("assume audio_codec_reset, underrun = %d - do xrun\n",
+				underrun_count);
+			underrun_count = 0;
+			return SNDRV_PCM_POS_XRUN;
+		}
+	} else {
+		/* Reset Counter */
+		underrun_count = 0;
+	}
+
+	t = intelhaddata->buf_info[buf_id].buf_size - t;
+
+	if (intelhaddata->stream_info.buffer_rendered)
+		div_u64_rem(intelhaddata->stream_info.buffer_rendered,
+			intelhaddata->stream_info.ring_buf_size,
+			&(bytes_rendered));
+
+	intelhaddata->stream_info.buffer_ptr = bytes_to_frames(
+						substream->runtime,
+						bytes_rendered + t);
+	return intelhaddata->stream_info.buffer_ptr;
+}
+
+/**
+* snd_intelhad_pcm_mmap- mmaps a kernel buffer to user space for copying data
+*
+* @substream:  substream for which the function is called
+* @vma:		struct instance of memory VMM memory area
+*
+* This function is called by OS when a user space component
+* tries to get mmap memory from driver
+*/
+static int snd_intelhad_pcm_mmap(struct snd_pcm_substream *substream,
+	struct vm_area_struct *vma)
+{
+
+	pr_debug("snd_intelhad_pcm_mmap called\n");
+
+	pr_debug("entry with prot:%s\n", __func__);
+	vma->vm_page_prot = pgprot_noncached(vma->vm_page_prot);
+	return remap_pfn_range(vma, vma->vm_start,
+			substream->dma_buffer.addr >> PAGE_SHIFT,
+			vma->vm_end - vma->vm_start, vma->vm_page_prot);
+}
+
+int hdmi_audio_mode_change(struct snd_pcm_substream *substream)
+{
+	int retval = 0;
+	u32 disp_samp_freq, n_param;
+	struct snd_intelhad *intelhaddata;
+
+	intelhaddata = snd_pcm_substream_chip(substream);
+
+	/* Disable Audio */
+	intelhaddata->ops->enable_audio(substream, 0);
+
+	/* Update CTS value */
+	retval = had_get_caps(HAD_GET_DISPLAY_RATE, &disp_samp_freq);
+	if (retval) {
+		pr_err("querying display sampling freq failed %#x\n", retval);
+		goto out;
+	}
+
+	retval = intelhaddata->ops->prog_n(substream->runtime->rate, &n_param,
+								intelhaddata);
+	if (retval) {
+		pr_err("programming N value failed %#x\n", retval);
+		goto out;
+	}
+	intelhaddata->ops->prog_cts(substream->runtime->rate,
+					disp_samp_freq, n_param, intelhaddata);
+
+	/* Enable Audio */
+	intelhaddata->ops->enable_audio(substream, 1);
+
+out:
+	return retval;
+}
+
+/*PCM operations structure and the calls back for the same */
+struct snd_pcm_ops snd_intelhad_playback_ops = {
+	.open =		snd_intelhad_open,
+	.close =	snd_intelhad_close,
+	.ioctl =	snd_pcm_lib_ioctl,
+	.hw_params =	snd_intelhad_hw_params,
+	.hw_free =	snd_intelhad_hw_free,
+	.prepare =	snd_intelhad_pcm_prepare,
+	.trigger =	snd_intelhad_pcm_trigger,
+	.pointer =	snd_intelhad_pcm_pointer,
+	.mmap =	snd_intelhad_pcm_mmap,
+};
+
+/**
+ * snd_intelhad_create - to crete alsa card instance
+ *
+ * @intelhaddata: pointer to internal context
+ * @card: pointer to card
+ *
+ * This function is called when the hdmi cable is plugged in
+ */
+static int snd_intelhad_create(
+		struct snd_intelhad *intelhaddata,
+		struct snd_card *card)
+{
+	int retval;
+	static struct snd_device_ops ops = {
+	};
+
+	pr_debug("snd_intelhad_create called\n");
+
+	if (!intelhaddata)
+		return -EINVAL;
+
+	/* ALSA api to register the device */
+	retval = snd_device_new(card, SNDRV_DEV_LOWLEVEL, intelhaddata, &ops);
+	return retval;
+}
+/**
+ * snd_intelhad_pcm_free - to free the memory allocated
+ *
+ * @pcm: pointer to pcm instance
+ * This function is called when the device is removed
+ */
+static void snd_intelhad_pcm_free(struct snd_pcm *pcm)
+{
+	pr_debug("Freeing PCM preallocated pages\n");
+	snd_pcm_lib_preallocate_free_for_all(pcm);
+}
+
+static int had_iec958_info(struct snd_kcontrol *kcontrol,
+				struct snd_ctl_elem_info *uinfo)
+{
+	uinfo->type = SNDRV_CTL_ELEM_TYPE_IEC958;
+	uinfo->count = 1;
+	return 0;
+}
+
+static int had_iec958_get(struct snd_kcontrol *kcontrol,
+				struct snd_ctl_elem_value *ucontrol)
+{
+	struct snd_intelhad *intelhaddata = snd_kcontrol_chip(kcontrol);
+
+	ucontrol->value.iec958.status[0] = (intelhaddata->aes_bits >> 0) & 0xff;
+	ucontrol->value.iec958.status[1] = (intelhaddata->aes_bits >> 8) & 0xff;
+	ucontrol->value.iec958.status[2] =
+					(intelhaddata->aes_bits >> 16) & 0xff;
+	ucontrol->value.iec958.status[3] =
+					(intelhaddata->aes_bits >> 24) & 0xff;
+	return 0;
+}
+static int had_iec958_mask_get(struct snd_kcontrol *kcontrol,
+				struct snd_ctl_elem_value *ucontrol)
+{
+	ucontrol->value.iec958.status[0] = 0xff;
+	ucontrol->value.iec958.status[1] = 0xff;
+	ucontrol->value.iec958.status[2] = 0xff;
+	ucontrol->value.iec958.status[3] = 0xff;
+	return 0;
+}
+static int had_iec958_put(struct snd_kcontrol *kcontrol,
+				struct snd_ctl_elem_value *ucontrol)
+{
+	unsigned int val;
+	struct snd_intelhad *intelhaddata = snd_kcontrol_chip(kcontrol);
+
+	pr_debug("entered had_iec958_put\n");
+	val = (ucontrol->value.iec958.status[0] << 0) |
+		(ucontrol->value.iec958.status[1] << 8) |
+		(ucontrol->value.iec958.status[2] << 16) |
+		(ucontrol->value.iec958.status[3] << 24);
+	if (intelhaddata->aes_bits != val) {
+		intelhaddata->aes_bits = val;
+		return 1;
+	}
+	return 1;
+}
+
+static struct snd_kcontrol_new had_control_iec958_mask = {
+	.access =   SNDRV_CTL_ELEM_ACCESS_READ,
+	.iface =    SNDRV_CTL_ELEM_IFACE_PCM,
+	.name =     SNDRV_CTL_NAME_IEC958("", PLAYBACK, MASK),
+	.info =     had_iec958_info, /* shared */
+	.get =      had_iec958_mask_get,
+};
+
+static struct snd_kcontrol_new had_control_iec958 = {
+	.iface =    SNDRV_CTL_ELEM_IFACE_PCM,
+	.name =         SNDRV_CTL_NAME_IEC958("", PLAYBACK, DEFAULT),
+	.info =         had_iec958_info,
+	.get =          had_iec958_get,
+	.put =          had_iec958_put
+};
+
+static struct snd_intel_had_interface had_interface = {
+	.name =         "hdmi-audio",
+	.query =        hdmi_audio_query,
+	.suspend =      hdmi_audio_suspend,
+	.resume =       hdmi_audio_resume,
+};
+
+static struct had_ops had_ops_v1 = {
+	.enable_audio = snd_intelhad_enable_audio_v1,
+	.reset_audio = snd_intelhad_reset_audio_v1,
+	.prog_n =	snd_intelhad_prog_n_v1,
+	.prog_cts =	snd_intelhad_prog_cts_v1,
+	.audio_ctrl =	snd_intelhad_prog_audio_ctrl_v1,
+	.prog_dip =	snd_intelhad_prog_dip_v1,
+	.handle_underrun =  had_clear_underrun_intr_v1,
+};
+
+static struct had_ops had_ops_v2 = {
+	.enable_audio = snd_intelhad_enable_audio_v2,
+	.reset_audio = snd_intelhad_reset_audio_v2,
+	.prog_n =	snd_intelhad_prog_n_v2,
+	.prog_cts =	snd_intelhad_prog_cts_v2,
+	.audio_ctrl =	snd_intelhad_prog_audio_ctrl_v2,
+	.prog_dip =	snd_intelhad_prog_dip_v2,
+	.handle_underrun = had_clear_underrun_intr_v2,
+};
+/**
+ * hdmi_audio_probe - to create sound card instance for HDMI audio playabck
+ *
+ *@haddata: pointer to HAD private data
+ *@card_id: card for which probe is called
+ *
+ * This function is called when the hdmi cable is plugged in. This function
+ * creates and registers the sound card with ALSA
+ */
+int hdmi_audio_probe(void *deviceptr)
+{
+	int retval;
+	struct snd_pcm *pcm;
+	struct snd_card *card;
+	struct had_callback_ops ops_cb;
+	struct snd_intelhad *intelhaddata;
+	struct had_pvt_data *had_stream;
+	struct platform_device *devptr = deviceptr;
+
+	pr_debug("Enter %s\n", __func__);
+
+	pr_debug("hdmi_audio_probe dma_mask: %p\n", devptr->dev.dma_mask);
+
+	/* allocate memory for saving internal context and working */
+	intelhaddata = kzalloc(sizeof(*intelhaddata), GFP_KERNEL);
+	if (!intelhaddata)
+		return -ENOMEM;
+
+	had_stream = kzalloc(sizeof(*had_stream), GFP_KERNEL);
+	if (!had_stream) {
+		retval = -ENOMEM;
+		goto free_haddata;
+	}
+
+	had_data = intelhaddata;
+	ops_cb.intel_had_event_call_back = had_event_handler;
+
+	/* registering with display driver to get access to display APIs */
+
+	retval = mid_hdmi_audio_setup(
+			ops_cb.intel_had_event_call_back,
+			&(intelhaddata->reg_ops),
+			&(intelhaddata->query_ops));
+	if (retval) {
+		pr_err("querying display driver APIs failed %#x\n", retval);
+		goto free_hadstream;
+	}
+	mutex_lock(&had_mutex);
+	spin_lock_init(&intelhaddata->had_spinlock);
+	intelhaddata->drv_status = HAD_DRV_DISCONNECTED;
+	pr_debug("%s @ %d:DEBUG PLUG/UNPLUG : HAD_DRV_DISCONNECTED\n",
+			__func__, __LINE__);
+
+	/* create a card instance with ALSA framework */
+	retval = snd_card_new(&devptr->dev, hdmi_card_index, hdmi_card_id,
+				THIS_MODULE, 0, &card);
+
+	if (retval)
+		goto unlock_mutex;
+	intelhaddata->card = card;
+	intelhaddata->card_id = hdmi_card_id;
+	intelhaddata->card_index = card->number;
+	intelhaddata->private_data = had_stream;
+	intelhaddata->flag_underrun = 0;
+	intelhaddata->aes_bits = SNDRV_PCM_DEFAULT_CON_SPDIF;
+	strncpy(card->driver, INTEL_HAD, strlen(INTEL_HAD));
+	strncpy(card->shortname, INTEL_HAD, strlen(INTEL_HAD));
+
+	retval = snd_pcm_new(card, INTEL_HAD, PCM_INDEX, MAX_PB_STREAMS,
+						MAX_CAP_STREAMS, &pcm);
+	if (retval)
+		goto err;
+
+	/* setup private data which can be retrieved when required */
+	pcm->private_data = intelhaddata;
+	pcm->private_free = snd_intelhad_pcm_free;
+	pcm->info_flags = 0;
+	strncpy(pcm->name, card->shortname, strlen(card->shortname));
+	/* setup the ops for palyabck */
+	snd_pcm_set_ops(pcm, SNDRV_PCM_STREAM_PLAYBACK,
+			    &snd_intelhad_playback_ops);
+	/* allocate dma pages for ALSA stream operations
+	 * memory allocated is based on size, not max value
+	 * thus using same argument for max & size
+	 */
+	retval = snd_pcm_lib_preallocate_pages_for_all(pcm,
+			SNDRV_DMA_TYPE_DEV, NULL,
+			HAD_MAX_BUFFER, HAD_MAX_BUFFER);
+
+	if (card->dev == NULL)
+		pr_debug("card->dev is NULL!!!!! Should not be this case\n");
+	else if (card->dev->dma_mask == NULL)
+		pr_debug("hdmi_audio_probe dma_mask is NULL!!!!!\n");
+	else
+		pr_debug("hdmi_audio_probe dma_mask is : %p\n",
+				card->dev->dma_mask);
+
+	if (retval)
+		goto err;
+
+	/* internal function call to register device with ALSA */
+	retval = snd_intelhad_create(intelhaddata, card);
+	if (retval)
+		goto err;
+
+	card->private_data = &intelhaddata;
+	retval = snd_card_register(card);
+	if (retval)
+		goto err;
+
+	/* IEC958 controls */
+	retval = snd_ctl_add(card, snd_ctl_new1(&had_control_iec958_mask,
+						intelhaddata));
+	if (retval < 0)
+		goto err;
+	retval = snd_ctl_add(card, snd_ctl_new1(&had_control_iec958,
+						intelhaddata));
+	if (retval < 0)
+		goto err;
+
+	init_channel_allocations();
+
+	/* Register channel map controls */
+	retval = had_register_chmap_ctls(intelhaddata, pcm);
+	if (retval < 0)
+		goto err;
+
+	intelhaddata->dev = &devptr->dev;
+	pm_runtime_set_active(intelhaddata->dev);
+	pm_runtime_enable(intelhaddata->dev);
+
+	mutex_unlock(&had_mutex);
+	retval = mid_hdmi_audio_register(&had_interface, intelhaddata);
+	if (retval) {
+		pr_err("registering with display driver failed %#x\n", retval);
+		snd_card_free(card);
+		goto free_hadstream;
+	}
+
+	intelhaddata->hw_silence = 1;
+	had_ops_v1 = had_ops_v1;	/* unused */
+	intelhaddata->ops = &had_ops_v2;
+
+	return retval;
+err:
+	snd_card_free(card);
+unlock_mutex:
+	mutex_unlock(&had_mutex);
+free_hadstream:
+	kfree(had_stream);
+	pm_runtime_disable(intelhaddata->dev);
+	intelhaddata->dev = NULL;
+free_haddata:
+	kfree(intelhaddata);
+	intelhaddata = NULL;
+	pr_err("Error returned from %s api %#x\n", __func__, retval);
+	return retval;
+}
+
+/**
+ * hdmi_audio_remove - removes the alsa card
+ *
+ *@haddata: pointer to HAD private data
+ *
+ * This function is called when the hdmi cable is un-plugged. This function
+ * free the sound card.
+ */
+int hdmi_audio_remove(void *pdevptr)
+{
+	struct snd_intelhad *intelhaddata = had_data;
+	int caps;
+
+	pr_debug("Enter %s\n", __func__);
+
+	if (!intelhaddata)
+		return 0;
+
+	if (intelhaddata->drv_status != HAD_DRV_DISCONNECTED) {
+		caps = HDMI_AUDIO_UNDERRUN | HDMI_AUDIO_BUFFER_DONE;
+		had_set_caps(HAD_SET_DISABLE_AUDIO_INT, &caps);
+		had_set_caps(HAD_SET_DISABLE_AUDIO, NULL);
+	}
+	snd_card_free(intelhaddata->card);
+	kfree(intelhaddata->private_data);
+	kfree(intelhaddata);
+	return 0;
+}
+
+MODULE_AUTHOR("Sailaja Bandarupalli <sailaja.bandarupalli@intel.com>");
+MODULE_AUTHOR("Ramesh Babu K V <ramesh.babu@intel.com>");
+MODULE_AUTHOR("Vaibhav Agarwal <vaibhav.agarwal@intel.com>");
+MODULE_AUTHOR("Jerome Anand <jerome.anand@intel.com>");
+MODULE_DESCRIPTION("Intel HDMI Audio driver");
+MODULE_LICENSE("GPL v2");
+MODULE_SUPPORTED_DEVICE("{Intel,Intel_HAD}");
diff -Naurp -x debian.hwe linux-4.10.x.ori/sound/x86/intel_hdmi_audio.h linux-4.10.x/sound/x86/intel_hdmi_audio.h
--- linux-4.10.x.ori/sound/x86/intel_hdmi_audio.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-4.10.x/sound/x86/intel_hdmi_audio.h	2017-04-21 17:01:32.706015000 +0200
@@ -0,0 +1,201 @@
+/*
+ * Copyright (C) 2016 Intel Corporation
+ *  Authors:	Sailaja Bandarupalli <sailaja.bandarupalli@intel.com>
+ *		Ramesh Babu K V	<ramesh.babu@intel.com>
+ *		Vaibhav Agarwal <vaibhav.agarwal@intel.com>
+ *		Jerome Anand <jerome.anand@intel.com>
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining
+ * a copy of this software and associated documentation files
+ * (the "Software"), to deal in the Software without restriction,
+ * including without limitation the rights to use, copy, modify, merge,
+ * publish, distribute, sublicense, and/or sell copies of the Software,
+ * and to permit persons to whom the Software is furnished to do so,
+ * subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the
+ * next paragraph) shall be included in all copies or substantial
+ * portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT.  IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#ifndef _INTEL_HDMI_AUDIO_H_
+#define _INTEL_HDMI_AUDIO_H_
+
+#include <linux/types.h>
+#include <sound/initval.h>
+#include <linux/version.h>
+#include <linux/pm_runtime.h>
+#include <sound/asoundef.h>
+#include <sound/control.h>
+#include <sound/pcm.h>
+#include "intel_hdmi_lpe_audio.h"
+
+#define PCM_INDEX		0
+#define MAX_PB_STREAMS		1
+#define MAX_CAP_STREAMS		0
+#define HDMI_AUDIO_DRIVER	"hdmi-audio"
+
+#define INFO_FRAME_WORD1	0x000a0184
+#define FIFO_THRESHOLD		0xFE
+#define DMA_FIFO_THRESHOLD	0x7
+#define BYTES_PER_WORD		0x4
+
+/* Sampling rate as per IEC60958 Ver 3 */
+#define CH_STATUS_MAP_32KHZ	0x3
+#define CH_STATUS_MAP_44KHZ	0x0
+#define CH_STATUS_MAP_48KHZ	0x2
+#define CH_STATUS_MAP_88KHZ	0x8
+#define CH_STATUS_MAP_96KHZ	0xA
+#define CH_STATUS_MAP_176KHZ	0xC
+#define CH_STATUS_MAP_192KHZ	0xE
+
+#define MAX_SMPL_WIDTH_20	0x0
+#define MAX_SMPL_WIDTH_24	0x1
+#define SMPL_WIDTH_16BITS	0x1
+#define SMPL_WIDTH_24BITS	0x5
+#define CHANNEL_ALLOCATION	0x1F
+#define MASK_BYTE0		0x000000FF
+#define VALID_DIP_WORDS		3
+#define LAYOUT0			0
+#define LAYOUT1			1
+#define SWAP_LFE_CENTER		0x00fac4c8
+#define AUD_CONFIG_CH_MASK_V2	0x70
+
+struct pcm_stream_info {
+	int		str_id;
+	void	*had_substream;
+	void	(*period_elapsed)(void *had_substream);
+	u32		buffer_ptr;
+	u64		buffer_rendered;
+	u32		ring_buf_size;
+	int		sfreq;
+};
+
+struct ring_buf_info {
+	uint32_t	buf_addr;
+	uint32_t	buf_size;
+	uint8_t		is_valid;
+};
+
+struct had_stream_pvt {
+	enum had_stream_status		stream_status;
+	int				stream_ops;
+	ssize_t				dbg_cum_bytes;
+};
+
+struct had_pvt_data {
+	enum had_status_stream		stream_type;
+};
+
+struct had_callback_ops {
+	had_event_call_back intel_had_event_call_back;
+};
+
+/**
+ * struct snd_intelhad - intelhad driver structure
+ *
+ * @card: ptr to hold card details
+ * @card_index: sound card index
+ * @card_id: detected sound card id
+ * @reg_ops: register operations to program registers
+ * @query_ops: caps call backs for get/set operations
+ * @drv_status: driver status
+ * @buf_info: ring buffer info
+ * @stream_info: stream information
+ * @eeld: holds EELD info
+ * @curr_buf: pointer to hold current active ring buf
+ * @valid_buf_cnt: ring buffer count for stream
+ * @had_spinlock: driver lock
+ * @aes_bits: IEC958 status bits
+ * @buff_done: id of current buffer done intr
+ * @dev: platoform device handle
+ * @kctl: holds kctl ptrs used for channel map
+ * @chmap: holds channel map info
+ * @audio_reg_base: hdmi audio register base offset
+ * @hw_silence: flag indicates SoC support for HW silence/Keep alive
+ * @ops: holds ops functions based on platform
+ */
+struct snd_intelhad {
+	struct snd_card	*card;
+	int		card_index;
+	char		*card_id;
+	struct hdmi_audio_registers_ops	reg_ops;
+	struct hdmi_audio_query_set_ops	query_ops;
+	enum had_drv_status	drv_status;
+	struct		ring_buf_info buf_info[HAD_NUM_OF_RING_BUFS];
+	struct		pcm_stream_info stream_info;
+	union otm_hdmi_eld_t	eeld;
+	enum		intel_had_aud_buf_type curr_buf;
+	int		valid_buf_cnt;
+	unsigned int	aes_bits;
+	int flag_underrun;
+	struct had_pvt_data *private_data;
+	spinlock_t had_spinlock;
+	enum		intel_had_aud_buf_type buff_done;
+	struct device *dev;
+	struct snd_kcontrol *kctl;
+	struct snd_pcm_chmap *chmap;
+	unsigned int	*audio_reg_base;
+	unsigned int	audio_cfg_offset;
+	bool		hw_silence;
+	struct had_ops	*ops;
+};
+
+struct had_ops {
+	void (*enable_audio)(struct snd_pcm_substream *substream,
+			u8 enable);
+	void (*reset_audio)(u8 reset);
+	int (*prog_n)(u32 aud_samp_freq, u32 *n_param,
+			struct snd_intelhad *intelhaddata);
+	void (*prog_cts)(u32 aud_samp_freq, u32 tmds, u32 n_param,
+			struct snd_intelhad *intelhaddata);
+	int (*audio_ctrl)(struct snd_pcm_substream *substream,
+				struct snd_intelhad *intelhaddata);
+	void (*prog_dip)(struct snd_pcm_substream *substream,
+				struct snd_intelhad *intelhaddata);
+	void (*handle_underrun)(struct snd_intelhad *intelhaddata);
+};
+
+
+int had_event_handler(enum had_event_type event_type, void *data);
+
+int hdmi_audio_query(void *drv_data, struct hdmi_audio_event event);
+int hdmi_audio_suspend(void *drv_data, struct hdmi_audio_event event);
+int hdmi_audio_resume(void *drv_data);
+int hdmi_audio_mode_change(struct snd_pcm_substream *substream);
+extern struct snd_pcm_ops snd_intelhad_playback_ops;
+
+int snd_intelhad_init_audio_ctrl(struct snd_pcm_substream *substream,
+					struct snd_intelhad *intelhaddata,
+					int flag_silence);
+int snd_intelhad_prog_buffer(struct snd_intelhad *intelhaddata,
+					int start, int end);
+int snd_intelhad_invd_buffer(int start, int end);
+inline int snd_intelhad_read_len(struct snd_intelhad *intelhaddata);
+void had_build_channel_allocation_map(struct snd_intelhad *intelhaddata);
+
+/* Register access functions */
+inline int had_get_hwstate(struct snd_intelhad *intelhaddata);
+inline int had_get_caps(enum had_caps_list query_element,
+						void *capabilties);
+inline int had_set_caps(enum had_caps_list set_element,
+						void *capabilties);
+inline int had_read_register(uint32_t reg_addr, uint32_t *data);
+inline int had_write_register(uint32_t reg_addr, uint32_t data);
+inline int had_read_modify(uint32_t reg_addr, uint32_t data,
+							uint32_t mask);
+
+/**/
+int hdmi_audio_probe(void *devptr);
+int hdmi_audio_remove(void *pdev);
+
+#endif /* _INTEL_HDMI_AUDIO_ */
diff -Naurp -x debian.hwe linux-4.10.x.ori/sound/x86/intel_hdmi_audio_if.c linux-4.10.x/sound/x86/intel_hdmi_audio_if.c
--- linux-4.10.x.ori/sound/x86/intel_hdmi_audio_if.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-4.10.x/sound/x86/intel_hdmi_audio_if.c	2017-04-21 17:01:32.706015000 +0200
@@ -0,0 +1,551 @@
+/*
+ *   intel_hdmi_audio_if.c - Intel HDMI audio driver for MID
+ *
+ *  Copyright (C) 2016 Intel Corp
+ *  Authors:	Sailaja Bandarupalli <sailaja.bandarupalli@intel.com>
+ *		Ramesh Babu K V <ramesh.babu@intel.com>
+ *		Vaibhav Agarwal <vaibhav.agarwal@intel.com>
+ *		Jerome Anand <jerome.anand@intel.com>
+ *  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+ *
+ *  This program is free software; you can redistribute it and/or modify
+ *  it under the terms of the GNU General Public License as published by
+ *  the Free Software Foundation; version 2 of the License.
+ *
+ *  This program is distributed in the hope that it will be useful, but
+ *  WITHOUT ANY WARRANTY; without even the implied warranty of
+ *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ *  General Public License for more details.
+ *
+ * ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+ * ALSA driver for Intel MID HDMI audio controller.  This file contains
+ * interface functions exposed to HDMI Display driver and code to register
+ * with ALSA framework..
+ */
+
+#define pr_fmt(fmt)		"had: " fmt
+
+#include <linux/io.h>
+#include <linux/jiffies.h>
+#include <linux/slab.h>
+#include <sound/pcm.h>
+#include <sound/core.h>
+#include "intel_hdmi_audio.h"
+#include "intel_hdmi_lpe_audio.h"
+
+/**
+ * hdmi_audio_query - hdmi audio query function
+ *
+ *@haddata: pointer to HAD private data
+ *@event: audio event for which this method is invoked
+ *
+ * This function is called by client driver to query the
+ * hdmi audio.
+ */
+int hdmi_audio_query(void *haddata, struct hdmi_audio_event event)
+{
+	struct snd_pcm_substream *substream = NULL;
+	struct had_pvt_data *had_stream;
+	unsigned long flag_irqs;
+	struct snd_intelhad *intelhaddata = (struct snd_intelhad *)haddata;
+
+	if (intelhaddata->stream_info.had_substream)
+		substream = intelhaddata->stream_info.had_substream;
+	had_stream = intelhaddata->private_data;
+	switch (event.type) {
+	case HAD_EVENT_QUERY_IS_AUDIO_BUSY:
+		spin_lock_irqsave(&intelhaddata->had_spinlock, flag_irqs);
+
+		if ((had_stream->stream_type == HAD_RUNNING_STREAM) ||
+			substream) {
+			spin_unlock_irqrestore(&intelhaddata->had_spinlock,
+						flag_irqs);
+			pr_debug("Audio stream active\n");
+			return -EBUSY;
+		}
+		spin_unlock_irqrestore(&intelhaddata->had_spinlock, flag_irqs);
+	break;
+
+	case HAD_EVENT_QUERY_IS_AUDIO_SUSPENDED:
+		spin_lock_irqsave(&intelhaddata->had_spinlock, flag_irqs);
+		if (intelhaddata->drv_status == HAD_DRV_SUSPENDED) {
+			spin_unlock_irqrestore(&intelhaddata->had_spinlock,
+						flag_irqs);
+			pr_debug("Audio is suspended\n");
+			return 1;
+		}
+		spin_unlock_irqrestore(&intelhaddata->had_spinlock, flag_irqs);
+	break;
+
+	default:
+		pr_debug("error un-handled event !!\n");
+		return -EINVAL;
+	break;
+
+	}
+
+	return 0;
+}
+
+/**
+ * hdmi_audio_suspend - power management suspend function
+ *
+ *@haddata: pointer to HAD private data
+ *@event: pm event for which this method is invoked
+ *
+ * This function is called by client driver to suspend the
+ * hdmi audio.
+ */
+int hdmi_audio_suspend(void *haddata, struct hdmi_audio_event event)
+{
+	int caps, retval = 0;
+	struct had_pvt_data *had_stream;
+	unsigned long flag_irqs;
+	struct snd_pcm_substream *substream;
+	struct snd_intelhad *intelhaddata = (struct snd_intelhad *)haddata;
+
+	pr_debug("Enter:%s\n", __func__);
+
+	had_stream = intelhaddata->private_data;
+	substream = intelhaddata->stream_info.had_substream;
+
+	if (intelhaddata->dev->power.runtime_status != RPM_SUSPENDED) {
+		pr_err("audio stream is active\n");
+		return -EAGAIN;
+	}
+
+
+	spin_lock_irqsave(&intelhaddata->had_spinlock, flag_irqs);
+	if (intelhaddata->drv_status == HAD_DRV_DISCONNECTED) {
+		spin_unlock_irqrestore(&intelhaddata->had_spinlock, flag_irqs);
+		pr_debug("had not connected\n");
+		return retval;
+	}
+
+	if (intelhaddata->drv_status == HAD_DRV_SUSPENDED) {
+		spin_unlock_irqrestore(&intelhaddata->had_spinlock, flag_irqs);
+		pr_debug("had already suspended\n");
+		return retval;
+	}
+
+	intelhaddata->drv_status = HAD_DRV_SUSPENDED;
+	pr_debug("%s @ %d:DEBUG PLUG/UNPLUG : HAD_DRV_SUSPENDED\n",
+			__func__, __LINE__);
+
+	spin_unlock_irqrestore(&intelhaddata->had_spinlock, flag_irqs);
+	/*
+	 * ToDo: Need to disable UNDERRUN interrupts as well
+	 *  caps = HDMI_AUDIO_UNDERRUN | HDMI_AUDIO_BUFFER_DONE;
+	 */
+	caps = HDMI_AUDIO_BUFFER_DONE;
+	had_set_caps(HAD_SET_DISABLE_AUDIO_INT, &caps);
+	had_set_caps(HAD_SET_DISABLE_AUDIO, NULL);
+	pr_debug("Exit:%s", __func__);
+	return retval;
+}
+
+/**
+ * hdmi_audio_resume - power management resume function
+ *
+ *@haddata: pointer to HAD private data
+ *
+ * This function is called by client driver to resume the
+ * hdmi audio.
+ */
+int hdmi_audio_resume(void *haddata)
+{
+	int caps, retval = 0;
+	struct snd_intelhad *intelhaddata = (struct snd_intelhad *)haddata;
+	unsigned long flag_irqs;
+
+	pr_debug("Enter:%s\n", __func__);
+
+	spin_lock_irqsave(&intelhaddata->had_spinlock, flag_irqs);
+	if (intelhaddata->drv_status == HAD_DRV_DISCONNECTED) {
+		spin_unlock_irqrestore(&intelhaddata->had_spinlock, flag_irqs);
+		pr_debug("had not connected\n");
+		return 0;
+	}
+
+	if (intelhaddata->drv_status != HAD_DRV_SUSPENDED) {
+		spin_unlock_irqrestore(&intelhaddata->had_spinlock, flag_irqs);
+		pr_err("had is not in suspended state\n");
+		return 0;
+	}
+
+	if (had_get_hwstate(intelhaddata)) {
+		spin_unlock_irqrestore(&intelhaddata->had_spinlock, flag_irqs);
+		pr_err("Failed to resume. Device not accessible\n");
+		return -ENODEV;
+	}
+
+	intelhaddata->drv_status = HAD_DRV_CONNECTED;
+	pr_debug("%s @ %d:DEBUG PLUG/UNPLUG : HAD_DRV_DISCONNECTED\n",
+			__func__, __LINE__);
+	spin_unlock_irqrestore(&intelhaddata->had_spinlock, flag_irqs);
+	/*
+	 * ToDo: Need to enable UNDERRUN interrupts as well
+	 * caps = HDMI_AUDIO_UNDERRUN | HDMI_AUDIO_BUFFER_DONE;
+	 */
+	caps = HDMI_AUDIO_BUFFER_DONE;
+	retval = had_set_caps(HAD_SET_ENABLE_AUDIO_INT, &caps);
+	retval = had_set_caps(HAD_SET_ENABLE_AUDIO, NULL);
+	pr_debug("Exit:%s", __func__);
+	return retval;
+}
+
+static inline int had_chk_intrmiss(struct snd_intelhad *intelhaddata,
+		enum intel_had_aud_buf_type buf_id)
+{
+	int i, intr_count = 0;
+	enum intel_had_aud_buf_type buff_done;
+	u32 buf_size, buf_addr;
+	struct had_pvt_data *had_stream;
+	unsigned long flag_irqs;
+
+	had_stream = intelhaddata->private_data;
+
+	buff_done = buf_id;
+
+	intr_count = snd_intelhad_read_len(intelhaddata);
+	if (intr_count > 1) {
+		/* In case of active playback */
+		pr_err("Driver detected %d missed buffer done interrupt(s)!!!!\n",
+				(intr_count - 1));
+		if (intr_count > 3)
+			return intr_count;
+
+		buf_id += (intr_count - 1);
+		/* Reprogram registers*/
+		for (i = buff_done; i < buf_id; i++) {
+			int j = i % 4;
+
+			buf_size = intelhaddata->buf_info[j].buf_size;
+			buf_addr = intelhaddata->buf_info[j].buf_addr;
+			had_write_register(AUD_BUF_A_LENGTH +
+					(j * HAD_REG_WIDTH), buf_size);
+			had_write_register(
+					AUD_BUF_A_ADDR+(j * HAD_REG_WIDTH),
+					(buf_addr | BIT(0) | BIT(1)));
+		}
+		buf_id = buf_id % 4;
+		spin_lock_irqsave(&intelhaddata->had_spinlock, flag_irqs);
+		intelhaddata->buff_done = buf_id;
+		spin_unlock_irqrestore(&intelhaddata->had_spinlock, flag_irqs);
+	}
+
+	return intr_count;
+}
+
+int had_process_buffer_done(struct snd_intelhad *intelhaddata)
+{
+	int retval = 0;
+	u32 len = 1;
+	enum intel_had_aud_buf_type buf_id;
+	enum intel_had_aud_buf_type buff_done;
+	struct pcm_stream_info *stream;
+	u32 buf_size;
+	struct had_pvt_data *had_stream;
+	int intr_count;
+	enum had_status_stream		stream_type;
+	unsigned long flag_irqs;
+
+	had_stream = intelhaddata->private_data;
+	stream = &intelhaddata->stream_info;
+	intr_count = 1;
+
+	spin_lock_irqsave(&intelhaddata->had_spinlock, flag_irqs);
+	if (intelhaddata->drv_status == HAD_DRV_DISCONNECTED) {
+		spin_unlock_irqrestore(&intelhaddata->had_spinlock, flag_irqs);
+		pr_err("%s:Device already disconnected\n", __func__);
+		return retval;
+	}
+	buf_id = intelhaddata->curr_buf;
+	intelhaddata->buff_done = buf_id;
+	buff_done = intelhaddata->buff_done;
+	buf_size = intelhaddata->buf_info[buf_id].buf_size;
+	stream_type = had_stream->stream_type;
+
+	pr_debug("Enter:%s buf_id=%d\n", __func__, buf_id);
+
+	/* Every debug statement has an implication
+	 * of ~5msec. Thus, avoid having >3 debug statements
+	 * for each buffer_done handling.
+	 */
+
+	/* Check for any intr_miss in case of active playback */
+	if (had_stream->stream_type == HAD_RUNNING_STREAM) {
+		spin_unlock_irqrestore(&intelhaddata->had_spinlock, flag_irqs);
+		intr_count = had_chk_intrmiss(intelhaddata, buf_id);
+		if (!intr_count || (intr_count > 3)) {
+			pr_err("HAD SW state in non-recoverable!!! mode\n");
+			pr_err("Already played stale data\n");
+			return retval;
+		}
+		buf_id += (intr_count - 1);
+		buf_id = buf_id % 4;
+		spin_lock_irqsave(&intelhaddata->had_spinlock, flag_irqs);
+	}
+
+	intelhaddata->buf_info[buf_id].is_valid = true;
+	if (intelhaddata->valid_buf_cnt-1 == buf_id) {
+		if (had_stream->stream_type >= HAD_RUNNING_STREAM)
+			intelhaddata->curr_buf = HAD_BUF_TYPE_A;
+	} else
+		intelhaddata->curr_buf = buf_id + 1;
+
+	spin_unlock_irqrestore(&intelhaddata->had_spinlock, flag_irqs);
+
+	if (had_get_hwstate(intelhaddata)) {
+		pr_err("HDMI cable plugged-out\n");
+		return retval;
+	}
+
+	/*Reprogram the registers with addr and length*/
+	had_write_register(AUD_BUF_A_LENGTH +
+			(buf_id * HAD_REG_WIDTH), buf_size);
+	had_write_register(AUD_BUF_A_ADDR+(buf_id * HAD_REG_WIDTH),
+			intelhaddata->buf_info[buf_id].buf_addr|
+			BIT(0) | BIT(1));
+
+	had_read_register(AUD_BUF_A_LENGTH + (buf_id * HAD_REG_WIDTH),
+					&len);
+	pr_debug("%s:Enabled buf[%d]\n", __func__, buf_id);
+
+	/* In case of actual data,
+	 * report buffer_done to above ALSA layer
+	 */
+	buf_size =  intelhaddata->buf_info[buf_id].buf_size;
+	if (stream_type >= HAD_RUNNING_STREAM) {
+		intelhaddata->stream_info.buffer_rendered +=
+			(intr_count * buf_size);
+		stream->period_elapsed(stream->had_substream);
+	}
+
+	return retval;
+}
+
+int had_process_buffer_underrun(struct snd_intelhad *intelhaddata)
+{
+	int retval = 0;
+	enum intel_had_aud_buf_type buf_id;
+	struct pcm_stream_info *stream;
+	struct had_pvt_data *had_stream;
+	enum had_status_stream stream_type;
+	unsigned long flag_irqs;
+	int drv_status;
+
+	had_stream = intelhaddata->private_data;
+	stream = &intelhaddata->stream_info;
+
+	spin_lock_irqsave(&intelhaddata->had_spinlock, flag_irqs);
+	buf_id = intelhaddata->curr_buf;
+	stream_type = had_stream->stream_type;
+	intelhaddata->buff_done = buf_id;
+	drv_status = intelhaddata->drv_status;
+	if (stream_type == HAD_RUNNING_STREAM)
+		intelhaddata->curr_buf = HAD_BUF_TYPE_A;
+
+	spin_unlock_irqrestore(&intelhaddata->had_spinlock, flag_irqs);
+
+	pr_debug("Enter:%s buf_id=%d, stream_type=%d\n",
+			__func__, buf_id, stream_type);
+
+	intelhaddata->ops->handle_underrun(intelhaddata);
+
+	if (drv_status == HAD_DRV_DISCONNECTED) {
+		pr_err("%s:Device already disconnected\n", __func__);
+		return retval;
+	}
+
+	if (stream_type == HAD_RUNNING_STREAM) {
+		/* Report UNDERRUN error to above layers */
+		intelhaddata->flag_underrun = 1;
+		stream->period_elapsed(stream->had_substream);
+	}
+
+	return retval;
+}
+
+int had_process_hot_plug(struct snd_intelhad *intelhaddata)
+{
+	int retval = 0;
+	enum intel_had_aud_buf_type buf_id;
+	struct snd_pcm_substream *substream;
+	struct had_pvt_data *had_stream;
+	unsigned long flag_irqs;
+
+	pr_debug("Enter:%s\n", __func__);
+
+	substream = intelhaddata->stream_info.had_substream;
+	had_stream = intelhaddata->private_data;
+
+	spin_lock_irqsave(&intelhaddata->had_spinlock, flag_irqs);
+	if (intelhaddata->drv_status == HAD_DRV_CONNECTED) {
+		pr_debug("Device already connected\n");
+		spin_unlock_irqrestore(&intelhaddata->had_spinlock, flag_irqs);
+		return retval;
+	}
+	buf_id = intelhaddata->curr_buf;
+	intelhaddata->buff_done = buf_id;
+	intelhaddata->drv_status = HAD_DRV_CONNECTED;
+	pr_debug("%s @ %d:DEBUG PLUG/UNPLUG : HAD_DRV_CONNECTED\n",
+			__func__, __LINE__);
+	spin_unlock_irqrestore(&intelhaddata->had_spinlock, flag_irqs);
+
+	pr_debug("Processing HOT_PLUG, buf_id = %d\n", buf_id);
+
+	 /* Query display driver for audio register base */
+	if (intelhaddata->reg_ops.hdmi_audio_get_register_base(
+		&intelhaddata->audio_reg_base,
+		&intelhaddata->audio_cfg_offset)) {
+		pr_err("Unable to get audio reg base from Display driver\n");
+		goto err;
+	}
+
+	if (intelhaddata->audio_reg_base == NULL) {
+		pr_err("audio reg base value is NULL\n");
+		goto err;
+	}
+
+	pr_debug("%s audio_reg_base = 0x%p\n", __func__,
+			intelhaddata->audio_reg_base);
+
+	/* Safety check */
+	if (substream) {
+		pr_debug("There should not be active PB from ALSA\n");
+		pr_debug("Signifies, cable is plugged-in even before\n");
+		pr_debug("processing snd_pcm_disconnect\n");
+		/* Set runtime->state to hw_params done */
+		snd_pcm_stop(substream, SNDRV_PCM_STATE_SETUP);
+	}
+
+	had_build_channel_allocation_map(intelhaddata);
+
+	return retval;
+
+err:
+	pm_runtime_disable(intelhaddata->dev);
+	intelhaddata->dev = NULL;
+	return retval;
+}
+
+int had_process_hot_unplug(struct snd_intelhad *intelhaddata)
+{
+	int caps, retval = 0;
+	enum intel_had_aud_buf_type buf_id;
+	struct had_pvt_data *had_stream;
+	unsigned long flag_irqs;
+
+	pr_debug("Enter:%s\n", __func__);
+
+	had_stream = intelhaddata->private_data;
+	buf_id = intelhaddata->curr_buf;
+
+	spin_lock_irqsave(&intelhaddata->had_spinlock, flag_irqs);
+
+	if (intelhaddata->drv_status == HAD_DRV_DISCONNECTED) {
+		pr_debug("Device already disconnected\n");
+		spin_unlock_irqrestore(&intelhaddata->had_spinlock, flag_irqs);
+		return retval;
+
+	} else {
+		/* Disable Audio */
+		caps = HDMI_AUDIO_BUFFER_DONE;
+		retval = had_set_caps(HAD_SET_DISABLE_AUDIO_INT, &caps);
+		retval = had_set_caps(HAD_SET_DISABLE_AUDIO, NULL);
+		intelhaddata->ops->enable_audio(
+			intelhaddata->stream_info.had_substream, 0);
+	}
+
+	intelhaddata->drv_status = HAD_DRV_DISCONNECTED;
+	pr_debug("%s @ %d:DEBUG PLUG/UNPLUG : HAD_DRV_DISCONNECTED\n",
+			__func__, __LINE__);
+
+	/* Report to above ALSA layer */
+	if (intelhaddata->stream_info.had_substream != NULL) {
+		spin_unlock_irqrestore(&intelhaddata->had_spinlock, flag_irqs);
+		pr_debug("%s: unlock -> sending pcm_stop -> lock\n", __func__);
+		snd_pcm_stop(intelhaddata->stream_info.had_substream,
+				SNDRV_PCM_STATE_DISCONNECTED);
+		spin_lock_irqsave(&intelhaddata->had_spinlock, flag_irqs);
+	}
+
+	had_stream->stream_type = HAD_INIT;
+	spin_unlock_irqrestore(&intelhaddata->had_spinlock, flag_irqs);
+	kfree(intelhaddata->chmap->chmap);
+	intelhaddata->chmap->chmap = NULL;
+	intelhaddata->audio_reg_base = NULL;
+	pr_debug("%s: unlocked -> returned\n", __func__);
+
+	return retval;
+}
+
+/**
+ * had_event_handler - Call back function to handle events
+ *
+ * @event_type: Event type to handle
+ * @data: data related to the event_type
+ *
+ * This function is invoked to handle HDMI events from client driver.
+ */
+int had_event_handler(enum had_event_type event_type, void *data)
+{
+	int retval = 0;
+	struct snd_intelhad *intelhaddata = data;
+	enum intel_had_aud_buf_type buf_id;
+	struct snd_pcm_substream *substream;
+	struct had_pvt_data *had_stream;
+	unsigned long flag_irqs;
+
+	buf_id = intelhaddata->curr_buf;
+	had_stream = intelhaddata->private_data;
+
+	/* Switching to a function can drop atomicity even in INTR context.
+	 * Thus, a big lock is acquired to maintain atomicity.
+	 * This can be optimized later.
+	 * Currently, only buffer_done/_underrun executes in INTR context.
+	 * Also, locking is implemented separately to avoid real contention
+	 * of data(struct intelhaddata) between IRQ/SOFT_IRQ/PROCESS context.
+	 */
+	substream = intelhaddata->stream_info.had_substream;
+	switch (event_type) {
+	case HAD_EVENT_AUDIO_BUFFER_DONE:
+		retval = had_process_buffer_done(intelhaddata);
+	break;
+
+	case HAD_EVENT_AUDIO_BUFFER_UNDERRUN:
+		retval = had_process_buffer_underrun(intelhaddata);
+	break;
+
+	case HAD_EVENT_HOT_PLUG:
+		retval = had_process_hot_plug(intelhaddata);
+	break;
+
+	case HAD_EVENT_HOT_UNPLUG:
+		retval = had_process_hot_unplug(intelhaddata);
+	break;
+
+	case HAD_EVENT_MODE_CHANGING:
+		pr_debug(" called _event_handler with _MODE_CHANGE event\n");
+		/* Process only if stream is active & cable Plugged-in */
+		spin_lock_irqsave(&intelhaddata->had_spinlock, flag_irqs);
+		if (intelhaddata->drv_status >= HAD_DRV_DISCONNECTED) {
+			spin_unlock_irqrestore(&intelhaddata->had_spinlock,
+					flag_irqs);
+			break;
+		}
+		spin_unlock_irqrestore(&intelhaddata->had_spinlock, flag_irqs);
+		if ((had_stream->stream_type == HAD_RUNNING_STREAM)
+				&& substream)
+			retval = hdmi_audio_mode_change(substream);
+	break;
+
+	default:
+		pr_debug("error un-handled event !!\n");
+		retval = -EINVAL;
+	break;
+
+	}
+	return retval;
+}
diff -Naurp -x debian.hwe linux-4.10.x.ori/sound/x86/intel_hdmi_lpe_audio.c linux-4.10.x/sound/x86/intel_hdmi_lpe_audio.c
--- linux-4.10.x.ori/sound/x86/intel_hdmi_lpe_audio.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-4.10.x/sound/x86/intel_hdmi_lpe_audio.c	2017-04-21 17:01:32.706015000 +0200
@@ -0,0 +1,617 @@
+/*
+ *  intel_hdmi_lpe_audio.c - Intel HDMI LPE audio driver for Atom platforms
+ *
+ *  Copyright (C) 2016 Intel Corp
+ *  Authors:
+ *		Jerome Anand <jerome.anand@intel.com>
+ *		Aravind Siddappaji <aravindx.siddappaji@intel.com>
+ *  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+ *
+ *  This program is free software; you can redistribute it and/or modify
+ *  it under the terms of the GNU General Public License as published by
+ *  the Free Software Foundation; version 2 of the License.
+ *
+ *  This program is distributed in the hope that it will be useful, but
+ *  WITHOUT ANY WARRANTY; without even the implied warranty of
+ *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ *  General Public License for more details.
+ *
+ * ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+ */
+
+#include <linux/platform_device.h>
+#include <linux/irqreturn.h>
+#include <linux/interrupt.h>
+#include <linux/io.h>
+#include <linux/slab.h>
+#include <linux/module.h>
+#include <linux/pci.h>
+#include <sound/pcm.h>
+#include <sound/core.h>
+#include <sound/pcm_params.h>
+#include <sound/initval.h>
+#include <sound/control.h>
+#include <sound/initval.h>
+#include <drm/intel_lpe_audio.h>
+#include "intel_hdmi_lpe_audio.h"
+#include "intel_hdmi_audio.h"
+
+/* globals*/
+struct platform_device *hlpe_pdev;
+int hlpe_state;
+union otm_hdmi_eld_t hlpe_eld;
+
+struct hdmi_lpe_audio_ctx {
+	int irq;
+	void __iomem *mmio_start;
+	had_event_call_back had_event_callbacks;
+	struct snd_intel_had_interface *had_interface;
+	void *had_pvt_data;
+	int tmds_clock_speed;
+	unsigned int had_config_offset;
+	int hdmi_audio_interrupt_mask;
+	struct work_struct hdmi_audio_wq;
+};
+
+static inline void hdmi_set_eld(void *eld)
+{
+	int size;
+
+	BUILD_BUG_ON(sizeof(hlpe_eld) > HDMI_MAX_ELD_BYTES);
+
+	size = sizeof(hlpe_eld);
+	memcpy((void *)&hlpe_eld, eld, size);
+}
+
+static inline int hdmi_get_eld(void *eld)
+{
+	uint8_t *eld_data = (uint8_t *)&hlpe_eld;
+
+	memcpy(eld, (void *)&hlpe_eld, sizeof(hlpe_eld));
+
+	print_hex_dump_bytes("eld: ", DUMP_PREFIX_NONE, eld_data,
+			sizeof(hlpe_eld));
+	return 0;
+}
+
+
+static inline struct hdmi_lpe_audio_ctx *get_hdmi_context(void)
+{
+	struct hdmi_lpe_audio_ctx *ctx;
+
+	ctx = platform_get_drvdata(hlpe_pdev);
+	return ctx;
+}
+
+/*
+ * return whether HDMI audio device is busy.
+ */
+bool mid_hdmi_audio_is_busy(void *ddev)
+{
+	struct hdmi_lpe_audio_ctx *ctx;
+	int hdmi_audio_busy = 0;
+	struct hdmi_audio_event hdmi_audio_event;
+
+	dev_dbg(&hlpe_pdev->dev, "%s: Enter",  __func__);
+
+	ctx = platform_get_drvdata(hlpe_pdev);
+
+	if (hlpe_state == hdmi_connector_status_disconnected) {
+		/* HDMI is not connected, assuming audio device is idle. */
+		return false;
+	}
+
+	if (ctx->had_interface) {
+		hdmi_audio_event.type = HAD_EVENT_QUERY_IS_AUDIO_BUSY;
+		hdmi_audio_busy = ctx->had_interface->query(
+				ctx->had_pvt_data,
+				hdmi_audio_event);
+		return hdmi_audio_busy != 0;
+	}
+	return false;
+}
+
+/*
+ * return whether HDMI audio device is suspended.
+ */
+bool mid_hdmi_audio_suspend(void *ddev)
+{
+	struct hdmi_lpe_audio_ctx *ctx;
+	struct hdmi_audio_event hdmi_audio_event;
+	int ret = 0;
+
+	ctx = platform_get_drvdata(hlpe_pdev);
+
+	if (hlpe_state == hdmi_connector_status_disconnected) {
+		/* HDMI is not connected, assuming audio device
+		 * is suspended already.
+		 */
+		return true;
+	}
+
+	dev_dbg(&hlpe_pdev->dev, "%s: hlpe_state %d",  __func__,
+			hlpe_state);
+
+	if (ctx->had_interface) {
+		hdmi_audio_event.type = 0;
+		ret = ctx->had_interface->suspend(ctx->had_pvt_data,
+				hdmi_audio_event);
+		return (ret == 0) ? true : false;
+	}
+	return true;
+}
+
+void mid_hdmi_audio_resume(void *ddev)
+{
+	struct hdmi_lpe_audio_ctx *ctx;
+
+	ctx = platform_get_drvdata(hlpe_pdev);
+
+	if (hlpe_state == hdmi_connector_status_disconnected) {
+		/* HDMI is not connected, there is no need
+		 * to resume audio device.
+		 */
+		return;
+	}
+
+	dev_dbg(&hlpe_pdev->dev, "%s: hlpe_state %d",  __func__, hlpe_state);
+
+	if (ctx->had_interface)
+		ctx->had_interface->resume(ctx->had_pvt_data);
+}
+
+void mid_hdmi_audio_signal_event(enum had_event_type event)
+{
+	struct hdmi_lpe_audio_ctx *ctx;
+
+	dev_dbg(&hlpe_pdev->dev, "%s: Enter\n", __func__);
+
+	ctx = platform_get_drvdata(hlpe_pdev);
+
+	if (ctx->had_event_callbacks)
+		(*ctx->had_event_callbacks)(event,
+			ctx->had_pvt_data);
+}
+
+/**
+ * hdmi_audio_write:
+ * used to write into display controller HDMI audio registers.
+ *
+ */
+static int hdmi_audio_write(uint32_t reg, uint32_t val)
+{
+	struct hdmi_lpe_audio_ctx *ctx;
+
+	ctx = platform_get_drvdata(hlpe_pdev);
+
+	dev_dbg(&hlpe_pdev->dev, "%s: reg[0x%x] = 0x%x\n", __func__, reg, val);
+
+	iowrite32(val, (ctx->mmio_start+reg));
+
+	return 0;
+}
+
+/**
+ * hdmi_audio_read:
+ * used to get the register value read from
+ * display controller HDMI audio registers.
+ */
+static int hdmi_audio_read(uint32_t reg, uint32_t *val)
+{
+	struct hdmi_lpe_audio_ctx *ctx;
+
+	ctx = platform_get_drvdata(hlpe_pdev);
+	*val = ioread32(ctx->mmio_start+reg);
+	dev_dbg(&hlpe_pdev->dev, "%s: reg[0x%x] = 0x%x\n", __func__, reg, *val);
+	return 0;
+}
+
+/**
+ * hdmi_audio_rmw:
+ * used to update the masked bits in display controller HDMI
+ * audio registers.
+ */
+static int hdmi_audio_rmw(uint32_t reg, uint32_t val, uint32_t mask)
+{
+	struct hdmi_lpe_audio_ctx *ctx;
+	uint32_t val_tmp = 0;
+
+	ctx = platform_get_drvdata(hlpe_pdev);
+
+	val_tmp = (val & mask) |
+			((ioread32(ctx->mmio_start + reg)) & ~mask);
+
+	iowrite32(val_tmp, (ctx->mmio_start+reg));
+	dev_dbg(&hlpe_pdev->dev, "%s: reg[0x%x] = 0x%x\n", __func__, reg, val_tmp);
+
+	return 0;
+}
+
+/**
+ * hdmi_audio_get_caps:
+ * used to return the HDMI audio capabilities.
+ * e.g. resolution, frame rate.
+ */
+static int hdmi_audio_get_caps(enum had_caps_list get_element,
+			void *capabilities)
+{
+	struct hdmi_lpe_audio_ctx *ctx;
+	int ret = 0;
+
+	ctx = get_hdmi_context();
+
+	dev_dbg(&hlpe_pdev->dev, "%s: Enter\n", __func__);
+
+	switch (get_element) {
+	case HAD_GET_ELD:
+		ret = hdmi_get_eld(capabilities);
+		break;
+	case HAD_GET_DISPLAY_RATE:
+		/* ToDo: Verify if sampling freq logic is correct */
+		memcpy(capabilities, &(ctx->tmds_clock_speed),
+			sizeof(uint32_t));
+		dev_dbg(&hlpe_pdev->dev, "%s: tmds_clock_speed = 0x%x\n", __func__,
+				ctx->tmds_clock_speed);
+		break;
+	default:
+		break;
+	}
+
+	return ret;
+}
+
+/**
+ * hdmi_audio_get_register_base
+ * used to get the current hdmi base address
+ */
+int hdmi_audio_get_register_base(uint32_t **reg_base,
+		uint32_t *config_offset)
+{
+	struct hdmi_lpe_audio_ctx *ctx;
+
+	ctx = platform_get_drvdata(hlpe_pdev);
+	*reg_base = (uint32_t *)(ctx->mmio_start);
+	*config_offset = ctx->had_config_offset;
+	dev_dbg(&hlpe_pdev->dev, "%s: reg_base = 0x%p, cfg_off = 0x%x\n", __func__,
+			*reg_base, *config_offset);
+	return 0;
+}
+
+/**
+ * hdmi_audio_set_caps:
+ * used to set the HDMI audio capabilities.
+ * e.g. Audio INT.
+ */
+int hdmi_audio_set_caps(enum had_caps_list set_element,
+			void *capabilties)
+{
+	struct hdmi_lpe_audio_ctx *ctx;
+
+	ctx = platform_get_drvdata(hlpe_pdev);
+
+	dev_dbg(&hlpe_pdev->dev, "%s: cap_id = 0x%x\n", __func__, set_element);
+
+	switch (set_element) {
+	case HAD_SET_ENABLE_AUDIO_INT:
+		{
+			uint32_t status_reg;
+
+			hdmi_audio_read(AUD_HDMI_STATUS_v2 +
+				ctx->had_config_offset, &status_reg);
+			status_reg |=
+				HDMI_AUDIO_BUFFER_DONE | HDMI_AUDIO_UNDERRUN;
+			hdmi_audio_write(AUD_HDMI_STATUS_v2 +
+				ctx->had_config_offset, status_reg);
+			hdmi_audio_read(AUD_HDMI_STATUS_v2 +
+				ctx->had_config_offset, &status_reg);
+
+		}
+		break;
+	default:
+		break;
+	}
+
+	return 0;
+}
+
+static struct  hdmi_audio_registers_ops hdmi_audio_reg_ops = {
+	.hdmi_audio_get_register_base = hdmi_audio_get_register_base,
+	.hdmi_audio_read_register = hdmi_audio_read,
+	.hdmi_audio_write_register = hdmi_audio_write,
+	.hdmi_audio_read_modify = hdmi_audio_rmw,
+};
+
+static struct hdmi_audio_query_set_ops hdmi_audio_get_set_ops = {
+	.hdmi_audio_get_caps = hdmi_audio_get_caps,
+	.hdmi_audio_set_caps = hdmi_audio_set_caps,
+};
+
+int mid_hdmi_audio_setup(
+		had_event_call_back audio_callbacks,
+		struct hdmi_audio_registers_ops *reg_ops,
+		struct hdmi_audio_query_set_ops *query_ops)
+{
+	struct hdmi_lpe_audio_ctx *ctx;
+
+	ctx = platform_get_drvdata(hlpe_pdev);
+
+	dev_dbg(&hlpe_pdev->dev, "%s: called\n",  __func__);
+
+	reg_ops->hdmi_audio_get_register_base =
+		(hdmi_audio_reg_ops.hdmi_audio_get_register_base);
+	reg_ops->hdmi_audio_read_register =
+		(hdmi_audio_reg_ops.hdmi_audio_read_register);
+	reg_ops->hdmi_audio_write_register =
+		(hdmi_audio_reg_ops.hdmi_audio_write_register);
+	reg_ops->hdmi_audio_read_modify =
+		(hdmi_audio_reg_ops.hdmi_audio_read_modify);
+	query_ops->hdmi_audio_get_caps =
+		hdmi_audio_get_set_ops.hdmi_audio_get_caps;
+	query_ops->hdmi_audio_set_caps =
+		hdmi_audio_get_set_ops.hdmi_audio_set_caps;
+
+	ctx->had_event_callbacks = audio_callbacks;
+
+	return 0;
+}
+
+void _had_wq(struct work_struct *work)
+{
+	mid_hdmi_audio_signal_event(HAD_EVENT_HOT_PLUG);
+}
+
+int mid_hdmi_audio_register(struct snd_intel_had_interface *driver,
+				void *had_data)
+{
+	struct hdmi_lpe_audio_ctx *ctx;
+
+	ctx = platform_get_drvdata(hlpe_pdev);
+
+	dev_dbg(&hlpe_pdev->dev, "%s: called\n", __func__);
+
+	ctx->had_pvt_data = had_data;
+	ctx->had_interface = driver;
+
+	/* The Audio driver is loading now and we need to notify
+	 * it if there is an HDMI device attached
+	 */
+	INIT_WORK(&ctx->hdmi_audio_wq, _had_wq);
+	dev_dbg(&hlpe_pdev->dev, "%s: Scheduling HDMI audio work queue\n", __func__);
+	schedule_work(&ctx->hdmi_audio_wq);
+
+	return 0;
+}
+
+static irqreturn_t display_pipe_interrupt_handler(int irq, void *dev_id)
+{
+	u32 audio_stat, audio_reg;
+
+	struct hdmi_lpe_audio_ctx *ctx;
+
+	dev_dbg(&hlpe_pdev->dev, "%s: Enter\n", __func__);
+
+	ctx = platform_get_drvdata(hlpe_pdev);
+
+	audio_reg = ctx->had_config_offset + AUD_HDMI_STATUS_v2;
+	hdmi_audio_read(audio_reg, &audio_stat);
+
+	if (audio_stat & HDMI_AUDIO_UNDERRUN) {
+		hdmi_audio_write(audio_reg, HDMI_AUDIO_UNDERRUN);
+		mid_hdmi_audio_signal_event(
+				HAD_EVENT_AUDIO_BUFFER_UNDERRUN);
+	}
+
+	if (audio_stat & HDMI_AUDIO_BUFFER_DONE) {
+		hdmi_audio_write(audio_reg, HDMI_AUDIO_BUFFER_DONE);
+		mid_hdmi_audio_signal_event(
+				HAD_EVENT_AUDIO_BUFFER_DONE);
+	}
+
+	return IRQ_HANDLED;
+}
+
+static void notify_audio_lpe(void *audio_ptr)
+{
+	struct hdmi_lpe_audio_ctx *ctx = get_hdmi_context();
+	struct intel_hdmi_lpe_audio_pdata *pdata = hlpe_pdev->dev.platform_data;
+	struct intel_hdmi_lpe_audio_eld *eld = audio_ptr;
+
+	if (pdata->hdmi_connected != true) {
+
+		dev_dbg(&hlpe_pdev->dev, "%s: Event: HAD_NOTIFY_HOT_UNPLUG\n",
+			__func__);
+
+		if (hlpe_state == hdmi_connector_status_connected) {
+
+			hlpe_state =
+				hdmi_connector_status_disconnected;
+
+			mid_hdmi_audio_signal_event(
+				HAD_EVENT_HOT_UNPLUG);
+		} else
+			dev_dbg(&hlpe_pdev->dev, "%s: Already Unplugged!\n", __func__);
+
+	} else if (eld != NULL) {
+
+		hdmi_set_eld(eld->eld_data);
+
+		mid_hdmi_audio_signal_event(HAD_EVENT_HOT_PLUG);
+
+		hlpe_state = hdmi_connector_status_connected;
+
+		dev_dbg(&hlpe_pdev->dev, "%s: HAD_NOTIFY_ELD : port = %d, tmds = %d\n",
+			__func__, eld->port_id,
+			pdata->tmds_clock_speed);
+
+		if (pdata->tmds_clock_speed) {
+			ctx->tmds_clock_speed = pdata->tmds_clock_speed;
+			mid_hdmi_audio_signal_event(HAD_EVENT_MODE_CHANGING);
+		}
+	} else
+		dev_dbg(&hlpe_pdev->dev, "%s: Event: NULL EDID!!\n", __func__);
+}
+
+/**
+ * hdmi_lpe_audio_probe - start bridge with i915
+ *
+ * This function is called when the i915 driver creates the
+ * hdmi-lpe-audio platform device. Card creation is deferred until a
+ * hot plug event is received
+ */
+static int hdmi_lpe_audio_probe(struct platform_device *pdev)
+{
+	struct hdmi_lpe_audio_ctx *ctx;
+	struct intel_hdmi_lpe_audio_pdata *pdata;
+	int irq;
+	struct resource *res_mmio;
+	void __iomem *mmio_start;
+	int ret = 0;
+	unsigned long flag_irq;
+	static const struct pci_device_id cherryview_ids[] = {
+		{PCI_DEVICE(0x8086, 0x22b0)},
+		{PCI_DEVICE(0x8086, 0x22b1)},
+		{PCI_DEVICE(0x8086, 0x22b2)},
+		{PCI_DEVICE(0x8086, 0x22b3)},
+		{}
+	};
+
+	dev_dbg(&hlpe_pdev->dev, "Enter %s\n", __func__);
+
+	/*TBD:remove globals*/
+	hlpe_pdev = pdev;
+	hlpe_state = hdmi_connector_status_disconnected;
+
+	/* get resources */
+	irq = platform_get_irq(pdev, 0);
+	if (irq < 0) {
+		dev_err(&hlpe_pdev->dev, "Could not get irq resource\n");
+		return -ENODEV;
+	}
+
+	res_mmio = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	if (!res_mmio) {
+		dev_err(&hlpe_pdev->dev, "Could not get IO_MEM resources\n");
+		return -ENXIO;
+	}
+
+	dev_dbg(&hlpe_pdev->dev, "%s: mmio_start = 0x%x, mmio_end = 0x%x\n", __func__,
+		(unsigned int)res_mmio->start, (unsigned int)res_mmio->end);
+
+	mmio_start = ioremap_nocache(res_mmio->start,
+				(size_t)((res_mmio->end -
+					res_mmio->start) + 1));
+	if (!mmio_start) {
+		dev_err(&hlpe_pdev->dev, "Could not get ioremap\n");
+		return -EACCES;
+	}
+
+	/* setup interrupt handler */
+	ret = request_irq(irq, display_pipe_interrupt_handler,
+			0,
+			pdev->name,
+			NULL);
+	if (ret < 0) {
+		dev_err(&hlpe_pdev->dev, "request_irq failed\n");
+		iounmap(mmio_start);
+		return -ENODEV;
+	}
+
+	/* alloc and save context */
+	ctx = kzalloc(sizeof(*ctx), GFP_KERNEL);
+	if (ctx == NULL) {
+		free_irq(irq, NULL);
+		iounmap(mmio_start);
+		return -ENOMEM;
+	}
+
+	ctx->irq = irq;
+	dev_dbg(&hlpe_pdev->dev, "hdmi lpe audio: irq num = %d\n", irq);
+	ctx->mmio_start = mmio_start;
+	ctx->tmds_clock_speed = DIS_SAMPLE_RATE_148_5;
+
+	if (pci_dev_present(cherryview_ids)) {
+		dev_dbg(&hlpe_pdev->dev, "%s: Cherrytrail LPE - Detected\n", __func__);
+		ctx->had_config_offset = AUDIO_HDMI_CONFIG_C;
+	} else {
+		dev_dbg(&hlpe_pdev->dev, "%s: Baytrail LPE - Assume\n", __func__);
+		ctx->had_config_offset = AUDIO_HDMI_CONFIG_A;
+	}
+
+	pdata = pdev->dev.platform_data;
+
+	if (pdata == NULL) {
+		dev_err(&hlpe_pdev->dev, "%s: quit: pdata not allocated by i915!!\n", __func__);
+		kfree(ctx);
+		free_irq(irq, NULL);
+		iounmap(mmio_start);
+		return -ENOMEM;
+	}
+
+	platform_set_drvdata(pdev, ctx);
+
+	ret = hdmi_audio_probe((void *)pdev);
+	dev_dbg(&hlpe_pdev->dev, "hdmi lpe audio: setting pin eld notify callback\n");
+
+	spin_lock_irqsave(&pdata->lpe_audio_slock, flag_irq);
+	pdata->notify_audio_lpe = notify_audio_lpe;
+	if (pdata->notify_pending) {
+
+		dev_dbg(&hlpe_pdev->dev, "%s: handle pending notification\n", __func__);
+		notify_audio_lpe(&pdata->eld);
+		pdata->notify_pending = false;
+	}
+	spin_unlock_irqrestore(&pdata->lpe_audio_slock, flag_irq);
+
+	return ret;
+}
+
+/**
+ * hdmi_lpe_audio_remove - stop bridge with i915
+ *
+ * This function is called when the platform device is destroyed. The sound
+ * card should have been removed on hot plug event.
+ */
+static int hdmi_lpe_audio_remove(struct platform_device *pdev)
+{
+	struct hdmi_lpe_audio_ctx *ctx;
+
+	dev_dbg(&hlpe_pdev->dev, "Enter %s\n", __func__);
+
+	hdmi_audio_remove(pdev);
+
+	/* get context, release resources */
+	ctx = platform_get_drvdata(pdev);
+	iounmap(ctx->mmio_start);
+	free_irq(ctx->irq, NULL);
+	kfree(ctx);
+	return 0;
+}
+
+static int hdmi_lpe_audio_suspend(struct platform_device *pt_dev,
+				pm_message_t state)
+{
+	dev_dbg(&hlpe_pdev->dev, "Enter %s\n", __func__);
+	mid_hdmi_audio_suspend(NULL);
+	return 0;
+}
+
+static int hdmi_lpe_audio_resume(struct platform_device *pt_dev)
+{
+	dev_dbg(&hlpe_pdev->dev, "Enter %s\n", __func__);
+	mid_hdmi_audio_resume(NULL);
+	return 0;
+}
+
+static struct platform_driver hdmi_lpe_audio_driver = {
+	.driver		= {
+		.name  = "hdmi-lpe-audio",
+	},
+	.probe          = hdmi_lpe_audio_probe,
+	.remove		= hdmi_lpe_audio_remove,
+	.suspend	= hdmi_lpe_audio_suspend,
+	.resume		= hdmi_lpe_audio_resume
+};
+
+module_platform_driver(hdmi_lpe_audio_driver);
+MODULE_LICENSE("GPL v2");
+MODULE_ALIAS("platform:hdmi_lpe_audio");
diff -Naurp -x debian.hwe linux-4.10.x.ori/sound/x86/intel_hdmi_lpe_audio.h linux-4.10.x/sound/x86/intel_hdmi_lpe_audio.h
--- linux-4.10.x.ori/sound/x86/intel_hdmi_lpe_audio.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-4.10.x/sound/x86/intel_hdmi_lpe_audio.h	2017-04-21 17:01:32.706015000 +0200
@@ -0,0 +1,685 @@
+/*
+ *   intel_hdmi_lpe_audio.h - Intel HDMI LPE audio driver
+ *
+ *  Copyright (C) 2016 Intel Corp
+ *  Authors:	Sailaja Bandarupalli <sailaja.bandarupalli@intel.com>
+ *		Ramesh Babu K V <ramesh.babu@intel.com>
+ *		Vaibhav Agarwal <vaibhav.agarwal@intel.com>
+ *		Jerome Anand <jerome.anand@intel.com>
+ *		Aravind Siddappaji <aravindx.siddappaji@intel.com>
+ *  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+ *
+ *  This program is free software; you can redistribute it and/or modify
+ *  it under the terms of the GNU General Public License as published by
+ *  the Free Software Foundation; version 2 of the License.
+ *
+ *  This program is distributed in the hope that it will be useful, but
+ *  WITHOUT ANY WARRANTY; without even the implied warranty of
+ *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ *  General Public License for more details.
+ *
+ * ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+ */
+#ifndef __INTEL_HDMI_LPE_AUDIO_H
+#define __INTEL_HDMI_LPE_AUDIO_H
+
+#include <linux/types.h>
+#include <sound/initval.h>
+#include <linux/version.h>
+#include <linux/pm_runtime.h>
+#include <sound/asoundef.h>
+#include <sound/control.h>
+#include <sound/pcm.h>
+
+#define HMDI_LPE_AUDIO_DRIVER_NAME		"intel-hdmi-lpe-audio"
+#define HAD_MAX_DEVICES		1
+#define HAD_MIN_CHANNEL		2
+#define HAD_MAX_CHANNEL		8
+#define HAD_NUM_OF_RING_BUFS	4
+
+/* Assume 192KHz, 8channel, 25msec period */
+#define HAD_MAX_BUFFER		(600*1024)
+#define HAD_MIN_BUFFER		(32*1024)
+#define HAD_MAX_PERIODS		4
+#define HAD_MIN_PERIODS		4
+#define HAD_MAX_PERIOD_BYTES	(HAD_MAX_BUFFER/HAD_MIN_PERIODS)
+#define HAD_MIN_PERIOD_BYTES	256
+#define HAD_FIFO_SIZE		0 /* fifo not being used */
+#define MAX_SPEAKERS		8
+/* TODO: Add own tlv when channel map is ported for user space */
+#define USE_ALSA_DEFAULT_TLV
+
+#define AUD_SAMPLE_RATE_32	32000
+#define AUD_SAMPLE_RATE_44_1	44100
+#define AUD_SAMPLE_RATE_48	48000
+#define AUD_SAMPLE_RATE_88_2	88200
+#define AUD_SAMPLE_RATE_96	96000
+#define AUD_SAMPLE_RATE_176_4	176400
+#define AUD_SAMPLE_RATE_192	192000
+
+#define HAD_MIN_RATE		AUD_SAMPLE_RATE_32
+#define HAD_MAX_RATE		AUD_SAMPLE_RATE_192
+
+#define DIS_SAMPLE_RATE_25_2	25200
+#define DIS_SAMPLE_RATE_27	27000
+#define DIS_SAMPLE_RATE_54	54000
+#define DIS_SAMPLE_RATE_74_25	74250
+#define DIS_SAMPLE_RATE_148_5	148500
+#define HAD_REG_WIDTH		0x08
+#define HAD_MAX_HW_BUFS		0x04
+#define HAD_MAX_DIP_WORDS		16
+#define INTEL_HAD		"IntelHdmiLpeAudio"
+
+/* _AUD_CONFIG register MASK */
+#define AUD_CONFIG_MASK_UNDERRUN	0xC0000000
+#define AUD_CONFIG_MASK_SRDBG		0x00000002
+#define AUD_CONFIG_MASK_FUNCRST		0x00000001
+
+#define MAX_CNT			0xFF
+#define HAD_SUSPEND_DELAY	1000
+
+#define OTM_HDMI_ELD_SIZE 128
+
+union otm_hdmi_eld_t {
+	unsigned char eld_data[OTM_HDMI_ELD_SIZE];
+	struct {
+		/* Byte[0] = ELD Version Number */
+		union {
+			unsigned char   byte0;
+			struct {
+				unsigned char reserved:3; /* Reserf */
+				unsigned char eld_ver:5; /* ELD Version Number */
+				/* 00000b - reserved
+				 * 00001b - first rev, obsoleted
+				 * 00010b - version 2, supporting CEA version
+				 *			861D or below
+				 * 00011b:11111b - reserved
+				 * for future
+				 */
+			};
+		};
+
+		/* Byte[1] = Vendor Version Field */
+		union {
+			unsigned char vendor_version;
+			struct {
+				unsigned char reserved1:3;
+				unsigned char veld_ver:5; /* Version number of the ELD
+						     * extension. This value is
+						     * provisioned and unique to
+						     * each vendor.
+						     */
+			};
+		};
+
+		/* Byte[2] = Baseline Length field */
+		unsigned char baseline_eld_length; /* Length of the Baseline structure
+					      *	divided by Four.
+					      */
+
+		/* Byte [3] = Reserved for future use */
+		unsigned char byte3;
+
+		/* Starting of the BaseLine EELD structure
+		 * Byte[4] = Monitor Name Length
+		 */
+		union {
+			unsigned char byte4;
+			struct {
+				unsigned char mnl:5;
+				unsigned char cea_edid_rev_id:3;
+			};
+		};
+
+		/* Byte[5] = Capabilities */
+		union {
+			unsigned char capabilities;
+			struct {
+				unsigned char hdcp:1; /* HDCP support */
+				unsigned char ai_support:1;   /* AI support */
+				unsigned char connection_type:2; /* Connection type
+							    * 00 - HDMI
+							    * 01 - DP
+							    * 10 -11  Reserved
+							    * for future
+							    * connection types
+							    */
+				unsigned char sadc:4; /* Indicates number of 3 bytes
+						 * Short Audio Descriptors.
+						 */
+			};
+		};
+
+		/* Byte[6] = Audio Synch Delay */
+		unsigned char audio_synch_delay; /* Amount of time reported by the
+					    * sink that the video trails audio
+					    * in milliseconds.
+					    */
+
+		/* Byte[7] = Speaker Allocation Block */
+		union {
+			unsigned char speaker_allocation_block;
+			struct {
+				unsigned char flr:1; /*Front Left and Right channels*/
+				unsigned char lfe:1; /*Low Frequency Effect channel*/
+				unsigned char fc:1;  /*Center transmission channel*/
+				unsigned char rlr:1; /*Rear Left and Right channels*/
+				unsigned char rc:1; /*Rear Center channel*/
+				unsigned char flrc:1; /*Front left and Right of Center
+						 *transmission channels
+						 */
+				unsigned char rlrc:1; /*Rear left and Right of Center
+						 *transmission channels
+						 */
+				unsigned char reserved3:1; /* Reserved */
+			};
+		};
+
+		/* Byte[8 - 15] - 8 Byte port identification value */
+		unsigned char port_id_value[8];
+
+		/* Byte[16 - 17] - 2 Byte Manufacturer ID */
+		unsigned char manufacturer_id[2];
+
+		/* Byte[18 - 19] - 2 Byte Product ID */
+		unsigned char product_id[2];
+
+		/* Byte [20-83] - 64 Bytes of BaseLine Data */
+		unsigned char mn_sand_sads[64]; /* This will include
+					   * - ASCII string of Monitor name
+					   * - List of 3 byte SADs
+					   * - Zero padding
+					   */
+
+		/* Vendor ELD Block should continue here!
+		 * No Vendor ELD block defined as of now.
+		 */
+	} __packed;
+};
+
+/**
+ * enum had_status - Audio stream states
+ *
+ * @STREAM_INIT: Stream initialized
+ * @STREAM_RUNNING: Stream running
+ * @STREAM_PAUSED: Stream paused
+ * @STREAM_DROPPED: Stream dropped
+ */
+enum had_stream_status {
+	STREAM_INIT = 0,
+	STREAM_RUNNING = 1,
+	STREAM_PAUSED = 2,
+	STREAM_DROPPED = 3
+};
+
+/**
+ * enum had_status_stream - HAD stream states
+ */
+enum had_status_stream {
+	HAD_INIT = 0,
+	HAD_RUNNING_STREAM,
+};
+
+enum had_drv_status {
+	HAD_DRV_CONNECTED,
+	HAD_DRV_RUNNING,
+	HAD_DRV_DISCONNECTED,
+	HAD_DRV_SUSPENDED,
+	HAD_DRV_ERR,
+};
+
+/* enum intel_had_aud_buf_type - HDMI controller ring buffer types */
+enum intel_had_aud_buf_type {
+	HAD_BUF_TYPE_A = 0,
+	HAD_BUF_TYPE_B = 1,
+	HAD_BUF_TYPE_C = 2,
+	HAD_BUF_TYPE_D = 3,
+};
+
+enum num_aud_ch {
+	CH_STEREO = 0,
+	CH_THREE_FOUR = 1,
+	CH_FIVE_SIX = 2,
+	CH_SEVEN_EIGHT = 3
+};
+
+/* HDMI Controller register offsets - audio domain common */
+/* Base address for below regs = 0x65000 */
+enum hdmi_ctrl_reg_offset_common {
+	AUDIO_HDMI_CONFIG_A	= 0x000,
+	AUDIO_HDMI_CONFIG_B = 0x800,
+	AUDIO_HDMI_CONFIG_C = 0x900,
+};
+/* HDMI controller register offsets */
+enum hdmi_ctrl_reg_offset_v1 {
+	AUD_CONFIG		= 0x0,
+	AUD_CH_STATUS_0		= 0x08,
+	AUD_CH_STATUS_1		= 0x0C,
+	AUD_HDMI_CTS		= 0x10,
+	AUD_N_ENABLE		= 0x14,
+	AUD_SAMPLE_RATE		= 0x18,
+	AUD_BUF_CONFIG		= 0x20,
+	AUD_BUF_CH_SWAP		= 0x24,
+	AUD_BUF_A_ADDR		= 0x40,
+	AUD_BUF_A_LENGTH	= 0x44,
+	AUD_BUF_B_ADDR		= 0x48,
+	AUD_BUF_B_LENGTH	= 0x4c,
+	AUD_BUF_C_ADDR		= 0x50,
+	AUD_BUF_C_LENGTH	= 0x54,
+	AUD_BUF_D_ADDR		= 0x58,
+	AUD_BUF_D_LENGTH	= 0x5c,
+	AUD_CNTL_ST		= 0x60,
+	AUD_HDMI_STATUS		= 0x68,
+	AUD_HDMIW_INFOFR	= 0x114,
+};
+
+/*
+ * Delta changes in HDMI controller register offsets
+ * compare to v1 version
+ */
+
+enum hdmi_ctrl_reg_offset_v2 {
+	AUD_HDMI_STATUS_v2	= 0x64,
+	AUD_HDMIW_INFOFR_v2	= 0x68,
+};
+
+/*
+ *	CEA speaker placement:
+ *
+ *	FL  FLC   FC   FRC   FR
+ *
+ *						LFE
+ *
+ *	RL  RLC   RC   RRC   RR
+ *
+ *	The Left/Right Surround channel _notions_ LS/RS in SMPTE 320M
+ *	corresponds to CEA RL/RR; The SMPTE channel _assignment_ C/LFE is
+ *	swapped to CEA LFE/FC.
+ */
+enum cea_speaker_placement {
+	FL  = (1 <<  0),        /* Front Left           */
+	FC  = (1 <<  1),        /* Front Center         */
+	FR  = (1 <<  2),        /* Front Right          */
+	FLC = (1 <<  3),        /* Front Left Center    */
+	FRC = (1 <<  4),        /* Front Right Center   */
+	RL  = (1 <<  5),        /* Rear Left            */
+	RC  = (1 <<  6),        /* Rear Center          */
+	RR  = (1 <<  7),        /* Rear Right           */
+	RLC = (1 <<  8),        /* Rear Left Center     */
+	RRC = (1 <<  9),        /* Rear Right Center    */
+	LFE = (1 << 10),        /* Low Frequency Effect */
+};
+
+struct cea_channel_speaker_allocation {
+	int ca_index;
+	int speakers[8];
+
+	/* derived values, just for convenience */
+	int channels;
+	int spk_mask;
+};
+
+struct channel_map_table {
+	unsigned char map;              /* ALSA API channel map position */
+	unsigned char cea_slot;         /* CEA slot value */
+	int spk_mask;                   /* speaker position bit mask */
+};
+
+/**
+ * union aud_cfg - Audio configuration
+ *
+ * @cfg_regx: individual register bits
+ * @cfg_regval: full register value
+ *
+ */
+union aud_cfg {
+	struct {
+		u32 aud_en:1;
+		u32 layout:1;
+		u32 fmt:2;
+		u32 num_ch:2;
+		u32 rsvd0:1;
+		u32 set:1;
+		u32 flat:1;
+		u32 val_bit:1;
+		u32 user_bit:1;
+		u32 underrun:1;
+		u32 rsvd1:20;
+	} cfg_regx;
+	struct {
+		u32 aud_en:1;
+		u32 layout:1;
+		u32 fmt:2;
+		u32 num_ch:3;
+		u32 set:1;
+		u32 flat:1;
+		u32 val_bit:1;
+		u32 user_bit:1;
+		u32 underrun:1;
+		u32 packet_mode:1;
+		u32 left_align:1;
+		u32 bogus_sample:1;
+		u32 dp_modei:1;
+		u32 rsvd:16;
+	} cfg_regx_v2;
+	u32 cfg_regval;
+};
+
+/**
+ * union aud_ch_status_0 - Audio Channel Status 0 Attributes
+ *
+ * @status_0_regx:individual register bits
+ * @status_0_regval:full register value
+ *
+ */
+union aud_ch_status_0 {
+	struct {
+		u32 ch_status:1;
+		u32 lpcm_id:1;
+		u32 cp_info:1;
+		u32 format:3;
+		u32 mode:2;
+		u32 ctg_code:8;
+		u32 src_num:4;
+		u32 ch_num:4;
+		u32 samp_freq:4;
+		u32 clk_acc:2;
+		u32 rsvd:2;
+	} status_0_regx;
+	u32 status_0_regval;
+};
+
+/**
+ * union aud_ch_status_1 - Audio Channel Status 1 Attributes
+ *
+ * @status_1_regx: individual register bits
+ * @status_1_regval: full register value
+ *
+ */
+union aud_ch_status_1 {
+	struct {
+		u32 max_wrd_len:1;
+		u32 wrd_len:3;
+		u32 rsvd:28;
+		} status_1_regx;
+	u32 status_1_regval;
+};
+
+/**
+ * union aud_hdmi_cts - CTS register
+ *
+ * @cts_regx: individual register bits
+ * @cts_regval: full register value
+ *
+ */
+union aud_hdmi_cts {
+	struct {
+		u32 cts_val:20;
+		u32 en_cts_prog:1;
+		u32 rsvd:11;
+	} cts_regx;
+	struct {
+		u32 cts_val:24;
+		u32 en_cts_prog:1;
+		u32 rsvd:7;
+	} cts_regx_v2;
+	u32 cts_regval;
+};
+
+/**
+ * union aud_hdmi_n_enable - N register
+ *
+ * @n_regx: individual register bits
+ * @n_regval: full register value
+ *
+ */
+union aud_hdmi_n_enable {
+	struct {
+		u32 n_val:20;
+		u32 en_n_prog:1;
+		u32 rsvd:11;
+	} n_regx;
+	struct {
+		u32 n_val:24;
+		u32 en_n_prog:1;
+		u32 rsvd:7;
+	} n_regx_v2;
+	u32 n_regval;
+};
+
+/**
+ * union aud_buf_config -  Audio Buffer configurations
+ *
+ * @buf_cfg_regx: individual register bits
+ * @buf_cfgval: full register value
+ *
+ */
+union aud_buf_config {
+	struct {
+		u32 fifo_width:8;
+		u32 rsvd0:8;
+		u32 aud_delay:8;
+		u32 rsvd1:8;
+	} buf_cfg_regx;
+	struct {
+		u32 audio_fifo_watermark:8;
+		u32 dma_fifo_watermark:3;
+		u32 rsvd0:5;
+		u32 aud_delay:8;
+		u32 rsvd1:8;
+	} buf_cfg_regx_v2;
+	u32 buf_cfgval;
+};
+
+/**
+ * union aud_buf_ch_swap - Audio Sample Swapping offset
+ *
+ * @buf_ch_swap_regx: individual register bits
+ * @buf_ch_swap_val: full register value
+ *
+ */
+union aud_buf_ch_swap {
+	struct {
+		u32 first_0:3;
+		u32 second_0:3;
+		u32 first_1:3;
+		u32 second_1:3;
+		u32 first_2:3;
+		u32 second_2:3;
+		u32 first_3:3;
+		u32 second_3:3;
+		u32 rsvd:8;
+	} buf_ch_swap_regx;
+	u32 buf_ch_swap_val;
+};
+
+/**
+ * union aud_buf_addr - Address for Audio Buffer
+ *
+ * @buf_addr_regx: individual register bits
+ * @buf_addr_val: full register value
+ *
+ */
+union aud_buf_addr {
+	struct {
+		u32 valid:1;
+		u32 intr_en:1;
+		u32 rsvd:4;
+		u32 addr:26;
+	} buf_addr_regx;
+	u32 buf_addr_val;
+};
+
+/**
+ * union aud_buf_len - Length of Audio Buffer
+ *
+ * @buf_len_regx: individual register bits
+ * @buf_len_val: full register value
+ *
+ */
+union aud_buf_len {
+	struct {
+		u32 buf_len:20;
+		u32 rsvd:12;
+	} buf_len_regx;
+	u32 buf_len_val;
+};
+
+/**
+ * union aud_ctrl_st - Audio Control State Register offset
+ *
+ * @ctrl_regx: individual register bits
+ * @ctrl_val: full register value
+ *
+ */
+union aud_ctrl_st {
+	struct {
+		u32 ram_addr:4;
+		u32 eld_ack:1;
+		u32 eld_addr:4;
+		u32 eld_buf_size:5;
+		u32 eld_valid:1;
+		u32 cp_ready:1;
+		u32 dip_freq:2;
+		u32 dip_idx:3;
+		u32 dip_en_sta:4;
+		u32 rsvd:7;
+	} ctrl_regx;
+	u32 ctrl_val;
+};
+
+/**
+ * union aud_info_frame1 - Audio HDMI Widget Data Island Packet offset
+ *
+ * @fr1_regx: individual register bits
+ * @fr1_val: full register value
+ *
+ */
+union aud_info_frame1 {
+	struct {
+		u32 pkt_type:8;
+		u32 ver_num:8;
+		u32 len:5;
+		u32 rsvd:11;
+	} fr1_regx;
+	u32 fr1_val;
+};
+
+/**
+ * union aud_info_frame2 - DIP frame 2
+ *
+ * @fr2_regx: individual register bits
+ * @fr2_val: full register value
+ *
+ */
+union aud_info_frame2 {
+	struct {
+		u32 chksum:8;
+		u32 chnl_cnt:3;
+		u32 rsvd0:1;
+		u32 coding_type:4;
+		u32 smpl_size:2;
+		u32 smpl_freq:3;
+		u32 rsvd1:3;
+		u32 format:8;
+	} fr2_regx;
+	u32 fr2_val;
+};
+
+/**
+ * union aud_info_frame3 - DIP frame 3
+ *
+ * @fr3_regx: individual register bits
+ * @fr3_val: full register value
+ *
+ */
+union aud_info_frame3 {
+	struct {
+		u32 chnl_alloc:8;
+		u32 rsvd0:3;
+		u32 lsv:4;
+		u32 dm_inh:1;
+		u32 rsvd1:16;
+	} fr3_regx;
+	u32 fr3_val;
+};
+
+enum hdmi_connector_status {
+	hdmi_connector_status_connected = 1,
+	hdmi_connector_status_disconnected = 2,
+	hdmi_connector_status_unknown = 3,
+};
+
+#define HDMI_AUDIO_UNDERRUN     (1UL<<31)
+#define HDMI_AUDIO_BUFFER_DONE  (1UL<<29)
+
+
+#define PORT_ENABLE			(1 << 31)
+#define SDVO_AUDIO_ENABLE	(1 << 6)
+
+enum had_caps_list {
+	HAD_GET_ELD = 1,
+	HAD_GET_DISPLAY_RATE,
+	HAD_SET_ENABLE_AUDIO,
+	HAD_SET_DISABLE_AUDIO,
+	HAD_SET_ENABLE_AUDIO_INT,
+	HAD_SET_DISABLE_AUDIO_INT,
+};
+
+enum had_event_type {
+	HAD_EVENT_HOT_PLUG = 1,
+	HAD_EVENT_HOT_UNPLUG,
+	HAD_EVENT_MODE_CHANGING,
+	HAD_EVENT_AUDIO_BUFFER_DONE,
+	HAD_EVENT_AUDIO_BUFFER_UNDERRUN,
+	HAD_EVENT_QUERY_IS_AUDIO_BUSY,
+	HAD_EVENT_QUERY_IS_AUDIO_SUSPENDED,
+};
+
+/*
+ * HDMI Display Controller Audio Interface
+ *
+ */
+typedef int (*had_event_call_back) (enum had_event_type event_type,
+		void *ctxt_info);
+
+struct hdmi_audio_registers_ops {
+	int (*hdmi_audio_get_register_base)(uint32_t **reg_base,
+			uint32_t *config_offset);
+	int (*hdmi_audio_read_register)(uint32_t reg_addr, uint32_t *data);
+	int (*hdmi_audio_write_register)(uint32_t reg_addr, uint32_t data);
+	int (*hdmi_audio_read_modify)(uint32_t reg_addr, uint32_t data,
+			uint32_t mask);
+};
+
+struct hdmi_audio_query_set_ops {
+	int (*hdmi_audio_get_caps)(enum had_caps_list query_element,
+			void *capabilties);
+	int (*hdmi_audio_set_caps)(enum had_caps_list set_element,
+			void *capabilties);
+};
+
+struct hdmi_audio_event {
+	int type;
+};
+
+struct snd_intel_had_interface {
+	const char *name;
+	int (*query)(void *had_data, struct hdmi_audio_event event);
+	int (*suspend)(void *had_data, struct hdmi_audio_event event);
+	int (*resume)(void *had_data);
+};
+
+bool mid_hdmi_audio_is_busy(void *dev);
+bool mid_hdmi_audio_suspend(void *dev);
+void mid_hdmi_audio_resume(void *dev);
+void mid_hdmi_audio_signal_event(enum had_event_type event);
+int mid_hdmi_audio_setup(
+	had_event_call_back audio_callbacks,
+	struct hdmi_audio_registers_ops *reg_ops,
+	struct hdmi_audio_query_set_ops *query_ops);
+int mid_hdmi_audio_register(
+	struct snd_intel_had_interface *driver,
+	void *had_data);
+
+#endif
diff -Naurp -x debian.hwe linux-4.10.x.ori/sound/x86/Kconfig linux-4.10.x/sound/x86/Kconfig
--- linux-4.10.x.ori/sound/x86/Kconfig	1970-01-01 01:00:00.000000000 +0100
+++ linux-4.10.x/sound/x86/Kconfig	2017-04-21 17:01:32.706015000 +0200
@@ -0,0 +1,16 @@
+menuconfig SND_X86
+	tristate "X86 sound devices"
+	---help---
+
+	  X86 sound devices that don't fall under SoC or PCI categories
+
+if SND_X86
+
+config HDMI_LPE_AUDIO
+	tristate "HDMI audio without HDaudio on Intel Atom platforms"
+	depends on DRM_I915
+	default n
+	help
+	 Choose this option to support HDMI LPE Audio mode
+
+endif	# SND_X86
diff -Naurp -x debian.hwe linux-4.10.x.ori/sound/x86/Makefile linux-4.10.x/sound/x86/Makefile
--- linux-4.10.x.ori/sound/x86/Makefile	1970-01-01 01:00:00.000000000 +0100
+++ linux-4.10.x/sound/x86/Makefile	2017-04-21 17:01:32.706015000 +0200
@@ -0,0 +1,8 @@
+ccflags-y += -Iinclude/drm
+
+snd-hdmi-lpe-audio-objs += \
+	intel_hdmi_audio.o \
+	intel_hdmi_audio_if.o \
+	intel_hdmi_lpe_audio.o
+
+obj-$(CONFIG_HDMI_LPE_AUDIO) += snd-hdmi-lpe-audio.o
diff -Naurp -x debian.hwe linux-4.10.x.ori/ubuntu/Makefile linux-4.10.x/ubuntu/Makefile
--- linux-4.10.x.ori/ubuntu/Makefile	2017-04-10 11:27:25.836919000 +0200
+++ linux-4.10.x/ubuntu/Makefile	2017-04-21 12:54:13.566623000 +0200
@@ -15,9 +15,12 @@
 ##
 ##
 ##
-ifeq ($(ARCH),x86)
-obj-y                         += vbox/
-endif
+# gottwald@igel.com we use virtualbox from thirdparty modules due to
+# the fact they are easier to keep up to date, so do not build it here
+# for nothing.
+#ifeq ($(ARCH),x86)
+#obj-y                         += vbox/
+#endif
 ##
 ##
 ##
